{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0c8ff7",
   "metadata": {},
   "source": [
    "|평가문항|상세기준|\n",
    "|:--|:--|\n",
    "|1. tfrecord를 활용한 데이터셋 구성과 전처리를 통해 프로젝트 베이스라인 구성을 확인하였다.|MPII 데이터셋을 기반으로 1epoch에 30분 이내에 학습가능한 베이스라인을 구축하였다.|\n",
    "|2. simplebaseline 모델을 정상적으로 구현하였다.|simplebaseline 모델을 구현하여 실습코드의 모델을 대체하여 정상적으로 학습이 진행되었다.|\n",
    "|3. Hourglass 모델과 simplebaseline 모델을 비교분석한 결과를 체계적으로 정리하였다.|두 모델의 pose estimation 테스트결과 이미지 및 학습진행상황 등을 체계적으로 비교분석하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6248c6",
   "metadata": {},
   "source": [
    "## Simple baseline\n",
    "![](https://velog.velcdn.com/images/xpelqpdj0422/post/7989c3b8-0f98-41e1-866c-5aa263eef7ca/image.png)\n",
    "\n",
    "\n",
    "### Resnet-50\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9LqUp7XyEx1QNc6A.png)\n",
    "\n",
    "``ResNet(C5)``에 ``deconvolutional layer``가 더해졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e515ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694a0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주의! ray를 tensorflow보다 먼저 import하면 오류가 발생할 수 있습니다\n",
    "import io, json, os, math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import ray\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "IMAGE_PATH = os.path.join(PROJECT_PATH, 'images')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')\n",
    "TFRECORD_PATH = os.path.join(PROJECT_PATH, 'tfrecords_mpii')\n",
    "TRAIN_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'train.json')\n",
    "VALID_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'validation.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2cf24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json 파일로부터 필요한 정보를 파싱하는 함수\n",
    "def parse_one_annotation(anno, image_dir):\n",
    "    filename = anno['image']\n",
    "    joints = anno['joints']\n",
    "    joints_visibility = anno['joints_vis']\n",
    "    annotation = {\n",
    "        'filename': filename,\n",
    "        'filepath': os.path.join(image_dir, filename),\n",
    "        'joints_visibility': joints_visibility,\n",
    "        'joints': joints,\n",
    "        'center': anno['center'],\n",
    "        'scale' : anno['scale']\n",
    "    }\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1daa63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tfexample(anno):\n",
    "\n",
    "    # byte 인코딩을 위한 함수\n",
    "    def _bytes_feature(value):\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    filename = anno['filename']\n",
    "    filepath = anno['filepath']\n",
    "    with open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image.open(filepath)\n",
    "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "        image_rgb = image.convert('RGB')\n",
    "        with io.BytesIO() as output:\n",
    "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "            content = output.getvalue()\n",
    "\n",
    "    width, height = image.size\n",
    "    depth = 3\n",
    "\n",
    "    c_x = int(anno['center'][0])\n",
    "    c_y = int(anno['center'][1])\n",
    "    scale = anno['scale']\n",
    "\n",
    "    x = [\n",
    "        int(joint[0]) if joint[0] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    y = [\n",
    "        int(joint[1]) if joint[1] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "\n",
    "    v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "    feature = {\n",
    "        'image/height':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/depth':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "        'image/object/parts/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "        'image/object/parts/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "        'image/object/center/x': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_x])),\n",
    "        'image/object/center/y': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_y])),\n",
    "        'image/object/scale':\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(value=[scale])),\n",
    "        'image/object/parts/v':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=v)),\n",
    "        'image/encoded':\n",
    "        _bytes_feature(content),\n",
    "        'image/filename':\n",
    "        _bytes_feature(filename.encode())\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a43402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(l, n):\n",
    "    size = len(l) // n\n",
    "    start = 0\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        results.append(l[start:start + size])\n",
    "        start += size\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbe67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def build_single_tfrecord(chunk, path):\n",
    "    print('start to build tf records for ' + path)\n",
    "\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for anno in chunk:\n",
    "            tf_example = generate_tfexample(anno)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    print('finished building tf records for ' + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd138c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_records(annotations, total_shards, split):\n",
    "    chunks = chunkify(annotations, total_shards)\n",
    "    futures = [\n",
    "        build_single_tfrecord.remote(\n",
    "            chunk, '{}/{}_{}_of_{}.tfrecords'.format(\n",
    "                TFRECORD_PATH,\n",
    "                split,\n",
    "                str(i + 1).zfill(4),\n",
    "                str(total_shards).zfill(4),\n",
    "            )) for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "    ray.get(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f19125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nray.init()\\n\\nprint('Start to parse annotations.')\\nif not os.path.exists(TFRECORD_PATH):\\n    os.makedirs(TFRECORD_PATH)\\n\\nwith open(TRAIN_JSON) as train_json:\\n    train_annos = json.load(train_json)\\n    train_annotations = [\\n        parse_one_annotation(anno, IMAGE_PATH)\\n        for anno in train_annos\\n    ]\\n    print('First train annotation: ', train_annotations[0])\\n\\nwith open(VALID_JSON) as val_json:\\n    val_annos = json.load(val_json)\\n    val_annotations = [\\n        parse_one_annotation(anno, IMAGE_PATH) \\n        for anno in val_annos\\n    ]\\n    print('First val annotation: ', val_annotations[0])\\n    \\nprint('Start to build TF Records.')\\nbuild_tf_records(train_annotations, num_train_shards, 'train')\\nbuild_tf_records(val_annotations, num_val_shards, 'val')\\n\\nprint('Successfully wrote {} annotations to TF Records.'.format(\\n    len(train_annotations) + len(val_annotations)))\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_shards = 64\n",
    "num_val_shards = 8\n",
    "\n",
    "'''\n",
    "ray.init()\n",
    "\n",
    "print('Start to parse annotations.')\n",
    "if not os.path.exists(TFRECORD_PATH):\n",
    "    os.makedirs(TFRECORD_PATH)\n",
    "\n",
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    train_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH)\n",
    "        for anno in train_annos\n",
    "    ]\n",
    "    print('First train annotation: ', train_annotations[0])\n",
    "\n",
    "with open(VALID_JSON) as val_json:\n",
    "    val_annos = json.load(val_json)\n",
    "    val_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH) \n",
    "        for anno in val_annos\n",
    "    ]\n",
    "    print('First val annotation: ', val_annotations[0])\n",
    "    \n",
    "print('Start to build TF Records.')\n",
    "build_tf_records(train_annotations, num_train_shards, 'train')\n",
    "build_tf_records(val_annotations, num_val_shards, 'val')\n",
    "\n",
    "print('Successfully wrote {} annotations to TF Records.'.format(\n",
    "    len(train_annotations) + len(val_annotations)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c08048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self,\n",
    "                 image_shape=(256, 256, 3),\n",
    "                 heatmap_shape=(64, 64, 16),\n",
    "                 is_train=False):\n",
    "        self.is_train = is_train\n",
    "        self.image_shape = image_shape\n",
    "        self.heatmap_shape = heatmap_shape\n",
    "\n",
    "    def __call__(self, example):\n",
    "        features = self.parse_tfexample(example)\n",
    "        image = tf.io.decode_jpeg(features['image/encoded'])\n",
    "\n",
    "        if self.is_train:\n",
    "            random_margin = tf.random.uniform([1], 0.1, 0.3)[0]\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features, margin=random_margin)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "        else:\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "\n",
    "        image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "        heatmaps = self.make_heatmaps(features, keypoint_x, keypoint_y, self.heatmap_shape)\n",
    "\n",
    "        return image, heatmaps\n",
    "\n",
    "        \n",
    "    def crop_roi(self, image, features, margin=0.2):\n",
    "        img_shape = tf.shape(image)\n",
    "        img_height = img_shape[0]\n",
    "        img_width = img_shape[1]\n",
    "        img_depth = img_shape[2]\n",
    "\n",
    "        keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "        keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "        center_x = features['image/object/center/x']\n",
    "        center_y = features['image/object/center/y']\n",
    "        body_height = features['image/object/scale'] * 200.0\n",
    "        \n",
    "        masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "        masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "        \n",
    "        keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "        keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "        keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "        keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "        \n",
    "        xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        \n",
    "        effective_xmin = xmin if xmin > 0 else 0\n",
    "        effective_ymin = ymin if ymin > 0 else 0\n",
    "        effective_xmax = xmax if xmax < img_width else img_width\n",
    "        effective_ymax = ymax if ymax < img_height else img_height\n",
    "        effective_height = effective_ymax - effective_ymin\n",
    "        effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "        image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "        new_shape = tf.shape(image)\n",
    "        new_height = new_shape[0]\n",
    "        new_width = new_shape[1]\n",
    "        \n",
    "        effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "        effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "        \n",
    "        return image, effective_keypoint_x, effective_keypoint_y\n",
    "        \n",
    "    \n",
    "    def generate_2d_guassian(self, height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "        \n",
    "        heatmap = tf.zeros((height, width))\n",
    "\n",
    "        xmin = x0 - 3 * sigma\n",
    "        ymin = y0 - 3 * sigma\n",
    "        xmax = x0 + 3 * sigma\n",
    "        ymax = y0 + 3 * sigma\n",
    "\n",
    "        if xmin >= width or ymin >= height or xmax < 0 or ymax <0 or visibility == 0:\n",
    "            return heatmap\n",
    "\n",
    "        size = 6 * sigma + 1\n",
    "        x, y = tf.meshgrid(tf.range(0, 6*sigma+1, 1), tf.range(0, 6*sigma+1, 1), indexing='xy')\n",
    "\n",
    "        center_x = size // 2\n",
    "        center_y = size // 2\n",
    "\n",
    "        gaussian_patch = tf.cast(tf.math.exp(-(tf.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale, dtype=tf.float32)\n",
    "\n",
    "        patch_xmin = tf.math.maximum(0, -xmin)\n",
    "        patch_ymin = tf.math.maximum(0, -ymin)\n",
    "        patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "        patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "        heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "        heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "        heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "        heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "        indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in tf.range(patch_ymin, patch_ymax):\n",
    "            for i in tf.range(patch_xmin, patch_xmax):\n",
    "                indices = indices.write(count, [heatmap_ymin+j, heatmap_xmin+i])\n",
    "                updates = updates.write(count, gaussian_patch[j][i])\n",
    "                count += 1\n",
    "                \n",
    "        heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "        return heatmap\n",
    "\n",
    "\n",
    "    def make_heatmaps(self, features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "        v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "        x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "        y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "        \n",
    "        num_heatmap = heatmap_shape[2]\n",
    "        heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "        for i in range(num_heatmap):\n",
    "            gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "            heatmap_array = heatmap_array.write(i, gaussian)\n",
    "        \n",
    "        heatmaps = heatmap_array.stack()\n",
    "        heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0]) # change to (64, 64, 16)\n",
    "        \n",
    "        return heatmaps\n",
    "\n",
    "    def parse_tfexample(self, example):\n",
    "        image_feature_description = {\n",
    "            'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        return tf.io.parse_single_example(example,\n",
    "                                          image_feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d2d65",
   "metadata": {},
   "source": [
    "### Hourglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4586fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleneckBlock(inputs, filters, strides=1, downsample=False, name=None):\n",
    "    identity = inputs\n",
    "    if downsample:\n",
    "        identity = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = Add()([identity, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff1b07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassModule(inputs, order, filters, num_residual):\n",
    "    \n",
    "    up1 = BottleneckBlock(inputs, filters, downsample=False)\n",
    "    for i in range(num_residual):\n",
    "        up1 = BottleneckBlock(up1, filters, downsample=False)\n",
    "\n",
    "    low1 = MaxPool2D(pool_size=2, strides=2)(inputs)\n",
    "    for i in range(num_residual):\n",
    "        low1 = BottleneckBlock(low1, filters, downsample=False)\n",
    "\n",
    "    low2 = low1\n",
    "    if order > 1:\n",
    "        low2 = HourglassModule(low1, order - 1, filters, num_residual)\n",
    "    else:\n",
    "        for i in range(num_residual):\n",
    "            low2 = BottleneckBlock(low2, filters, downsample=False)\n",
    "\n",
    "    low3 = low2\n",
    "    for i in range(num_residual):\n",
    "        low3 = BottleneckBlock(low3, filters, downsample=False)\n",
    "\n",
    "    up2 = UpSampling2D(size=2)(low3)\n",
    "\n",
    "    return up2 + up1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a8bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearLayer(inputs, filters):\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9b492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), \n",
    "        num_stack=4, \n",
    "        num_residual=1,\n",
    "        num_heatmap=16):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=True)\n",
    "    x = MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=False)\n",
    "    x = BottleneckBlock(x, 256, downsample=True)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(num_stack):\n",
    "        x = HourglassModule(x, order=4, filters=256, num_residual=num_residual)\n",
    "        for i in range(num_residual):\n",
    "            x = BottleneckBlock(x, 256, downsample=False)\n",
    "\n",
    "        x = LinearLayer(x, 256)\n",
    "\n",
    "        y = Conv2D(\n",
    "            filters=num_heatmap,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if i < num_stack - 1:\n",
    "            y_intermediate_1 = Conv2D(filters=256, kernel_size=1, strides=1)(x)\n",
    "            y_intermediate_2 = Conv2D(filters=256, kernel_size=1, strides=1)(y)\n",
    "            x = Add()([y_intermediate_1, y_intermediate_2])\n",
    "\n",
    "    return tf.keras.Model(inputs, ys, name='stacked_hourglass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736c366",
   "metadata": {},
   "source": [
    "### Simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e476ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_deconv_layer(num_deconv_layers):\n",
    "    seq_model = tf.keras.models.Sequential()\n",
    "    for i in range(num_deconv_layers):\n",
    "        seq_model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same'))\n",
    "        seq_model.add(tf.keras.layers.BatchNormalization())\n",
    "        seq_model.add(tf.keras.layers.ReLU())\n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca2b2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simplebaseline(input_shape=(256, 256, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet')(inputs)\n",
    "    x = _make_deconv_layer(3)(x)\n",
    "    out = tf.keras.layers.Conv2D(16, kernel_size=(1,1), padding='same')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, out, name='simple_baseline')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd49c26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresnet = tf.keras.applications.resnet.ResNet50(include_top=False, weights=\\'imagenet\\')\\n\\ndef _make_deconv_layer(num_deconv_layers):\\n    seq_model = tf.keras.models.Sequential()\\n    for i in range(num_deconv_layers):\\n        # upsampling을 위해 \"Conv2DTranspose\"를 수행합니다. Standard Conv2D는 \"Downsampling\" 수행\\n        seq_model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding=\\'same\\'))\\n        seq_model.add(tf.keras.layers.BatchNormalization())\\n        seq_model.add(tf.keras.layers.ReLU())\\n    return seq_model\\n\\nupconv = _make_deconv_layer(3)\\n\\nfinal_layer = tf.keras.layers.Conv2D(16, kernel_size=(1,1), padding=\\'same\\')\\n\\n\\ndef Simplebaseline(input_shape=(256, 256, 3)):\\n    inputs = tf.keras.Input(shape=input_shape)\\n    x = resnet(inputs)\\n    x = upconv(x)\\n    out = final_layer(x)\\n    model = tf.keras.Model(inputs, out, name=\\'simple_baseline\\')\\n    return model\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "resnet = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet')\n",
    "\n",
    "def _make_deconv_layer(num_deconv_layers):\n",
    "    seq_model = tf.keras.models.Sequential()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\n",
    "    for i in range(num_deconv_layers):\n",
    "        # upsampling을 위해 \"Conv2DTranspose\"를 수행합니다. Standard Conv2D는 \"Downsampling\" 수행\n",
    "        seq_model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same'))\n",
    "        seq_model.add(tf.keras.layers.BatchNormalization())\n",
    "        seq_model.add(tf.keras.layers.ReLU())\n",
    "    return seq_model\n",
    "\n",
    "upconv = _make_deconv_layer(3)\n",
    "\n",
    "final_layer = tf.keras.layers.Conv2D(16, kernel_size=(1,1), padding='same')\n",
    "\n",
    "\n",
    "def Simplebaseline(input_shape=(256, 256, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = resnet(inputs)\n",
    "    x = upconv(x)\n",
    "    out = final_layer(x)\n",
    "    model = tf.keras.Model(inputs, out, name='simple_baseline')\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57d9db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_baseline\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, None, None, 2048)  23587712  \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 64, 64, 256)       10489600  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 16)        4112      \n",
      "=================================================================\n",
      "Total params: 34,081,424\n",
      "Trainable params: 34,026,768\n",
      "Non-trainable params: 54,656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model = Simplebaseline(input_shape=(256, 256, 3))\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49050890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 epochs,\n",
    "                 global_batch_size,\n",
    "                 strategy,\n",
    "                 initial_learning_rate):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.strategy = strategy\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.loss_object = tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=initial_learning_rate)\n",
    "        self.model = model\n",
    "\n",
    "        self.current_learning_rate = initial_learning_rate\n",
    "        self.last_val_loss = math.inf\n",
    "        self.lowest_val_loss = math.inf\n",
    "        self.patience_count = 0\n",
    "        self.max_patience = 10\n",
    "        self.best_model = None\n",
    "\n",
    "    def lr_decay(self):\n",
    "        if self.patience_count >= self.max_patience:\n",
    "            self.current_learning_rate /= 10.0\n",
    "            self.patience_count = 0\n",
    "        elif self.last_val_loss == self.lowest_val_loss:\n",
    "            self.patience_count = 0\n",
    "        self.patience_count += 1\n",
    "\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def lr_decay_step(self, epoch):\n",
    "        if epoch == 25 or epoch == 50 or epoch == 75:\n",
    "            self.current_learning_rate /= 10.0\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def compute_loss(self, labels, output):\n",
    "        weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "        loss = tf.math.reduce_mean(\n",
    "            tf.math.square(labels - output) * weights) * (\n",
    "                1. / self.global_batch_size)\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.model(images, training=True)\n",
    "            loss = self.compute_loss(labels, outputs)\n",
    "\n",
    "        grads = tape.gradient(\n",
    "            target=loss, sources=self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        outputs = self.model(images, training=False)\n",
    "        loss = self.compute_loss(labels, outputs)\n",
    "        return loss\n",
    "\n",
    "    def run(self, train_dist_dataset, val_dist_dataset):\n",
    "        @tf.function\n",
    "        def distributed_train_epoch(dataset):\n",
    "            tf.print('Start distributed traininng...')\n",
    "            total_loss = 0.0\n",
    "            num_train_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.train_step, args=(one_batch, ))\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                total_loss += batch_loss\n",
    "                num_train_batches += 1\n",
    "                tf.print('Trained batch', num_train_batches, 'batch loss',\n",
    "                         batch_loss, 'epoch total loss', total_loss / num_train_batches)\n",
    "            return total_loss, num_train_batches\n",
    "\n",
    "        @tf.function\n",
    "        def distributed_val_epoch(dataset):\n",
    "            total_loss = 0.0\n",
    "            num_val_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.val_step, args=(one_batch, ))\n",
    "                num_val_batches += 1\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                tf.print('Validated batch', num_val_batches, 'batch loss',\n",
    "                         batch_loss)\n",
    "                if not tf.math.is_nan(batch_loss):\n",
    "                    # TODO: Find out why the last validation batch loss become NaN\n",
    "                    total_loss += batch_loss\n",
    "                else:\n",
    "                    num_val_batches -= 1\n",
    "\n",
    "            return total_loss, num_val_batches\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.lr_decay()\n",
    "            print('Start epoch {} with learning rate {}'.format(\n",
    "                epoch, self.current_learning_rate))\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            train_total_loss, num_train_batches = distributed_train_epoch(\n",
    "                train_dist_dataset)\n",
    "            train_loss = train_total_loss / num_train_batches\n",
    "            print('Epoch {} train loss {} and time {}'.format(epoch, train_loss, (time.time()-start_time)))\n",
    "\n",
    "            val_total_loss, num_val_batches = distributed_val_epoch(\n",
    "                val_dist_dataset)\n",
    "            val_loss = val_total_loss / num_val_batches\n",
    "            print('Epoch {} val loss {}'.format(epoch, val_loss))\n",
    "\n",
    "            # save model when reach a new lowest validation loss\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.save_model(epoch, val_loss)\n",
    "                self.lowest_val_loss = val_loss\n",
    "            self.last_val_loss = val_loss\n",
    "\n",
    "        return self.best_model\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        model_name = MODEL_PATH + '/model-epoch-{}-loss-{:.4f}.h5'.format(epoch, loss)\n",
    "        self.model.save_weights(model_name)\n",
    "        self.best_model = model_name\n",
    "        print(\"Model {} saved.\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af58abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "HEATMAP_SIZE = (64, 64)\n",
    "\n",
    "def create_dataset(tfrecords, batch_size, num_heatmap, is_train):\n",
    "    preprocess = Preprocessor(\n",
    "        IMAGE_SHAPE, (HEATMAP_SIZE[0], HEATMAP_SIZE[1], num_heatmap), is_train)\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(tfrecords)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5438025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    global_batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "    train_dataset = create_dataset(\n",
    "        train_tfrecords, global_batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(\n",
    "        val_tfrecords, global_batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        val_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            val_dataset)\n",
    "\n",
    "        model = Simplebaseline(IMAGE_SHAPE)\n",
    "        # model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            epochs,\n",
    "            global_batch_size,\n",
    "            strategy,\n",
    "            initial_learning_rate=learning_rate)\n",
    "\n",
    "        print('Start training...')\n",
    "        return trainer.run(train_dist_dataset, val_dist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e556542",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Start training...\n",
      "Start epoch 1 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.629685521 epoch total loss 0.629685521\n",
      "Trained batch 2 batch loss 0.640620232 epoch total loss 0.635152876\n",
      "Trained batch 3 batch loss 0.52874887 epoch total loss 0.599684894\n",
      "Trained batch 4 batch loss 0.499085754 epoch total loss 0.574535072\n",
      "Trained batch 5 batch loss 0.494509071 epoch total loss 0.558529854\n",
      "Trained batch 6 batch loss 0.449686348 epoch total loss 0.54038924\n",
      "Trained batch 7 batch loss 0.436467707 epoch total loss 0.525543332\n",
      "Trained batch 8 batch loss 0.393799156 epoch total loss 0.509075284\n",
      "Trained batch 9 batch loss 0.380280733 epoch total loss 0.494764745\n",
      "Trained batch 10 batch loss 0.405600041 epoch total loss 0.485848278\n",
      "Trained batch 11 batch loss 0.410963953 epoch total loss 0.479040623\n",
      "Trained batch 12 batch loss 0.419109672 epoch total loss 0.474046379\n",
      "Trained batch 13 batch loss 0.433602452 epoch total loss 0.470935315\n",
      "Trained batch 14 batch loss 0.432613611 epoch total loss 0.468198031\n",
      "Trained batch 15 batch loss 0.406241596 epoch total loss 0.464067578\n",
      "Trained batch 16 batch loss 0.404831827 epoch total loss 0.460365355\n",
      "Trained batch 17 batch loss 0.415050179 epoch total loss 0.457699746\n",
      "Trained batch 18 batch loss 0.404867381 epoch total loss 0.454764634\n",
      "Trained batch 19 batch loss 0.394933045 epoch total loss 0.451615572\n",
      "Trained batch 20 batch loss 0.404047489 epoch total loss 0.449237168\n",
      "Trained batch 21 batch loss 0.422466069 epoch total loss 0.447962344\n",
      "Trained batch 22 batch loss 0.412332267 epoch total loss 0.446342826\n",
      "Trained batch 23 batch loss 0.427769423 epoch total loss 0.445535272\n",
      "Trained batch 24 batch loss 0.42577973 epoch total loss 0.444712132\n",
      "Trained batch 25 batch loss 0.411412925 epoch total loss 0.443380177\n",
      "Trained batch 26 batch loss 0.404534787 epoch total loss 0.441886097\n",
      "Trained batch 27 batch loss 0.402693808 epoch total loss 0.440434515\n",
      "Trained batch 28 batch loss 0.395478696 epoch total loss 0.438828945\n",
      "Trained batch 29 batch loss 0.402488053 epoch total loss 0.437575787\n",
      "Trained batch 30 batch loss 0.421582401 epoch total loss 0.437042683\n",
      "Trained batch 31 batch loss 0.432203621 epoch total loss 0.436886579\n",
      "Trained batch 32 batch loss 0.432401359 epoch total loss 0.436746418\n",
      "Trained batch 33 batch loss 0.400639176 epoch total loss 0.435652256\n",
      "Trained batch 34 batch loss 0.409131855 epoch total loss 0.43487227\n",
      "Trained batch 35 batch loss 0.39905563 epoch total loss 0.433848917\n",
      "Trained batch 36 batch loss 0.399210304 epoch total loss 0.43288672\n",
      "Trained batch 37 batch loss 0.377238452 epoch total loss 0.431382716\n",
      "Trained batch 38 batch loss 0.416436791 epoch total loss 0.430989414\n",
      "Trained batch 39 batch loss 0.408420116 epoch total loss 0.430410713\n",
      "Trained batch 40 batch loss 0.40325141 epoch total loss 0.429731756\n",
      "Trained batch 41 batch loss 0.387599975 epoch total loss 0.428704143\n",
      "Trained batch 42 batch loss 0.390368611 epoch total loss 0.427791417\n",
      "Trained batch 43 batch loss 0.38416329 epoch total loss 0.426776797\n",
      "Trained batch 44 batch loss 0.409600377 epoch total loss 0.426386446\n",
      "Trained batch 45 batch loss 0.40625602 epoch total loss 0.425939083\n",
      "Trained batch 46 batch loss 0.403518826 epoch total loss 0.425451696\n",
      "Trained batch 47 batch loss 0.41252926 epoch total loss 0.42517674\n",
      "Trained batch 48 batch loss 0.398274511 epoch total loss 0.424616307\n",
      "Trained batch 49 batch loss 0.376743257 epoch total loss 0.423639297\n",
      "Trained batch 50 batch loss 0.391192347 epoch total loss 0.422990352\n",
      "Trained batch 51 batch loss 0.388925463 epoch total loss 0.422322392\n",
      "Trained batch 52 batch loss 0.387865365 epoch total loss 0.421659768\n",
      "Trained batch 53 batch loss 0.408179551 epoch total loss 0.421405435\n",
      "Trained batch 54 batch loss 0.401325256 epoch total loss 0.421033591\n",
      "Trained batch 55 batch loss 0.382027864 epoch total loss 0.420324385\n",
      "Trained batch 56 batch loss 0.387878925 epoch total loss 0.419745\n",
      "Trained batch 57 batch loss 0.403261 epoch total loss 0.419455826\n",
      "Trained batch 58 batch loss 0.399442941 epoch total loss 0.419110745\n",
      "Trained batch 59 batch loss 0.39260295 epoch total loss 0.418661475\n",
      "Trained batch 60 batch loss 0.406947792 epoch total loss 0.41846624\n",
      "Trained batch 61 batch loss 0.375529319 epoch total loss 0.417762369\n",
      "Trained batch 62 batch loss 0.360159546 epoch total loss 0.416833282\n",
      "Trained batch 63 batch loss 0.369536877 epoch total loss 0.416082561\n",
      "Trained batch 64 batch loss 0.361906171 epoch total loss 0.415236056\n",
      "Trained batch 65 batch loss 0.379248649 epoch total loss 0.414682418\n",
      "Trained batch 66 batch loss 0.405855715 epoch total loss 0.414548665\n",
      "Trained batch 67 batch loss 0.438520432 epoch total loss 0.414906472\n",
      "Trained batch 68 batch loss 0.378993273 epoch total loss 0.414378345\n",
      "Trained batch 69 batch loss 0.379510731 epoch total loss 0.413873017\n",
      "Trained batch 70 batch loss 0.37831223 epoch total loss 0.413365\n",
      "Trained batch 71 batch loss 0.369156033 epoch total loss 0.412742347\n",
      "Trained batch 72 batch loss 0.388605207 epoch total loss 0.4124071\n",
      "Trained batch 73 batch loss 0.370043129 epoch total loss 0.41182676\n",
      "Trained batch 74 batch loss 0.370653778 epoch total loss 0.41127038\n",
      "Trained batch 75 batch loss 0.398119032 epoch total loss 0.411095023\n",
      "Trained batch 76 batch loss 0.411975712 epoch total loss 0.411106616\n",
      "Trained batch 77 batch loss 0.411946505 epoch total loss 0.411117524\n",
      "Trained batch 78 batch loss 0.396775305 epoch total loss 0.410933673\n",
      "Trained batch 79 batch loss 0.376303732 epoch total loss 0.410495311\n",
      "Trained batch 80 batch loss 0.379825801 epoch total loss 0.410111964\n",
      "Trained batch 81 batch loss 0.383735895 epoch total loss 0.409786314\n",
      "Trained batch 82 batch loss 0.380388498 epoch total loss 0.409427822\n",
      "Trained batch 83 batch loss 0.373359084 epoch total loss 0.408993274\n",
      "Trained batch 84 batch loss 0.362004131 epoch total loss 0.408433855\n",
      "Trained batch 85 batch loss 0.369597286 epoch total loss 0.407976985\n",
      "Trained batch 86 batch loss 0.363518476 epoch total loss 0.40746\n",
      "Trained batch 87 batch loss 0.361461639 epoch total loss 0.406931311\n",
      "Trained batch 88 batch loss 0.360427499 epoch total loss 0.406402856\n",
      "Trained batch 89 batch loss 0.378988534 epoch total loss 0.406094849\n",
      "Trained batch 90 batch loss 0.373251289 epoch total loss 0.40572992\n",
      "Trained batch 91 batch loss 0.374511212 epoch total loss 0.405386865\n",
      "Trained batch 92 batch loss 0.380818039 epoch total loss 0.405119807\n",
      "Trained batch 93 batch loss 0.379145324 epoch total loss 0.404840529\n",
      "Trained batch 94 batch loss 0.373628795 epoch total loss 0.404508501\n",
      "Trained batch 95 batch loss 0.379273385 epoch total loss 0.404242873\n",
      "Trained batch 96 batch loss 0.37462467 epoch total loss 0.40393436\n",
      "Trained batch 97 batch loss 0.370466173 epoch total loss 0.403589308\n",
      "Trained batch 98 batch loss 0.376722604 epoch total loss 0.403315187\n",
      "Trained batch 99 batch loss 0.370738387 epoch total loss 0.402986109\n",
      "Trained batch 100 batch loss 0.387307107 epoch total loss 0.402829319\n",
      "Trained batch 101 batch loss 0.397022873 epoch total loss 0.402771831\n",
      "Trained batch 102 batch loss 0.396812499 epoch total loss 0.402713388\n",
      "Trained batch 103 batch loss 0.407020688 epoch total loss 0.402755231\n",
      "Trained batch 104 batch loss 0.426892191 epoch total loss 0.402987301\n",
      "Trained batch 105 batch loss 0.428510964 epoch total loss 0.403230399\n",
      "Trained batch 106 batch loss 0.404097885 epoch total loss 0.403238595\n",
      "Trained batch 107 batch loss 0.384632289 epoch total loss 0.403064698\n",
      "Trained batch 108 batch loss 0.386833489 epoch total loss 0.402914405\n",
      "Trained batch 109 batch loss 0.387784302 epoch total loss 0.402775586\n",
      "Trained batch 110 batch loss 0.386986852 epoch total loss 0.402632028\n",
      "Trained batch 111 batch loss 0.394860953 epoch total loss 0.402562022\n",
      "Trained batch 112 batch loss 0.401477158 epoch total loss 0.402552336\n",
      "Trained batch 113 batch loss 0.397617608 epoch total loss 0.402508646\n",
      "Trained batch 114 batch loss 0.382621288 epoch total loss 0.402334213\n",
      "Trained batch 115 batch loss 0.392444611 epoch total loss 0.402248204\n",
      "Trained batch 116 batch loss 0.392835736 epoch total loss 0.402167082\n",
      "Trained batch 117 batch loss 0.400167853 epoch total loss 0.40215\n",
      "Trained batch 118 batch loss 0.390850395 epoch total loss 0.40205425\n",
      "Trained batch 119 batch loss 0.372402608 epoch total loss 0.401805073\n",
      "Trained batch 120 batch loss 0.3727189 epoch total loss 0.401562691\n",
      "Trained batch 121 batch loss 0.376875699 epoch total loss 0.401358664\n",
      "Trained batch 122 batch loss 0.361535519 epoch total loss 0.401032239\n",
      "Trained batch 123 batch loss 0.374590039 epoch total loss 0.400817275\n",
      "Trained batch 124 batch loss 0.361851245 epoch total loss 0.400503039\n",
      "Trained batch 125 batch loss 0.352733105 epoch total loss 0.400120884\n",
      "Trained batch 126 batch loss 0.385544866 epoch total loss 0.400005192\n",
      "Trained batch 127 batch loss 0.376880139 epoch total loss 0.399823099\n",
      "Trained batch 128 batch loss 0.373428613 epoch total loss 0.399616897\n",
      "Trained batch 129 batch loss 0.357221097 epoch total loss 0.399288237\n",
      "Trained batch 130 batch loss 0.360160887 epoch total loss 0.398987263\n",
      "Trained batch 131 batch loss 0.363789797 epoch total loss 0.398718566\n",
      "Trained batch 132 batch loss 0.387996078 epoch total loss 0.398637325\n",
      "Trained batch 133 batch loss 0.388353169 epoch total loss 0.39856\n",
      "Trained batch 134 batch loss 0.367307603 epoch total loss 0.398326755\n",
      "Trained batch 135 batch loss 0.357015103 epoch total loss 0.398020744\n",
      "Trained batch 136 batch loss 0.352738738 epoch total loss 0.397687763\n",
      "Trained batch 137 batch loss 0.383952409 epoch total loss 0.397587508\n",
      "Trained batch 138 batch loss 0.350156933 epoch total loss 0.397243828\n",
      "Trained batch 139 batch loss 0.339481503 epoch total loss 0.396828264\n",
      "Trained batch 140 batch loss 0.373427033 epoch total loss 0.396661133\n",
      "Trained batch 141 batch loss 0.351020187 epoch total loss 0.39633745\n",
      "Trained batch 142 batch loss 0.391800642 epoch total loss 0.396305501\n",
      "Trained batch 143 batch loss 0.377960593 epoch total loss 0.396177202\n",
      "Trained batch 144 batch loss 0.356283426 epoch total loss 0.39590016\n",
      "Trained batch 145 batch loss 0.358560711 epoch total loss 0.395642668\n",
      "Trained batch 146 batch loss 0.348636508 epoch total loss 0.395320714\n",
      "Trained batch 147 batch loss 0.367380977 epoch total loss 0.395130664\n",
      "Trained batch 148 batch loss 0.353629142 epoch total loss 0.394850254\n",
      "Trained batch 149 batch loss 0.364110947 epoch total loss 0.394643962\n",
      "Trained batch 150 batch loss 0.374277502 epoch total loss 0.394508183\n",
      "Trained batch 151 batch loss 0.372183472 epoch total loss 0.394360334\n",
      "Trained batch 152 batch loss 0.365484267 epoch total loss 0.394170374\n",
      "Trained batch 153 batch loss 0.368058324 epoch total loss 0.393999696\n",
      "Trained batch 154 batch loss 0.383393228 epoch total loss 0.393930823\n",
      "Trained batch 155 batch loss 0.394729733 epoch total loss 0.393935978\n",
      "Trained batch 156 batch loss 0.378216028 epoch total loss 0.393835217\n",
      "Trained batch 157 batch loss 0.390563488 epoch total loss 0.393814385\n",
      "Trained batch 158 batch loss 0.391103357 epoch total loss 0.393797219\n",
      "Trained batch 159 batch loss 0.364317 epoch total loss 0.393611819\n",
      "Trained batch 160 batch loss 0.375574 epoch total loss 0.393499076\n",
      "Trained batch 161 batch loss 0.379265904 epoch total loss 0.393410653\n",
      "Trained batch 162 batch loss 0.39574641 epoch total loss 0.393425077\n",
      "Trained batch 163 batch loss 0.39102605 epoch total loss 0.393410385\n",
      "Trained batch 164 batch loss 0.371389747 epoch total loss 0.393276125\n",
      "Trained batch 165 batch loss 0.372029096 epoch total loss 0.393147379\n",
      "Trained batch 166 batch loss 0.378442645 epoch total loss 0.393058777\n",
      "Trained batch 167 batch loss 0.379730254 epoch total loss 0.392978966\n",
      "Trained batch 168 batch loss 0.360788 epoch total loss 0.392787337\n",
      "Trained batch 169 batch loss 0.376532912 epoch total loss 0.392691165\n",
      "Trained batch 170 batch loss 0.386229426 epoch total loss 0.392653167\n",
      "Trained batch 171 batch loss 0.376773894 epoch total loss 0.392560333\n",
      "Trained batch 172 batch loss 0.343295664 epoch total loss 0.392273873\n",
      "Trained batch 173 batch loss 0.324849665 epoch total loss 0.391884148\n",
      "Trained batch 174 batch loss 0.319500625 epoch total loss 0.391468167\n",
      "Trained batch 175 batch loss 0.355655879 epoch total loss 0.391263545\n",
      "Trained batch 176 batch loss 0.391100526 epoch total loss 0.391262621\n",
      "Trained batch 177 batch loss 0.406351864 epoch total loss 0.391347855\n",
      "Trained batch 178 batch loss 0.385296434 epoch total loss 0.391313881\n",
      "Trained batch 179 batch loss 0.3998169 epoch total loss 0.391361386\n",
      "Trained batch 180 batch loss 0.383573383 epoch total loss 0.391318142\n",
      "Trained batch 181 batch loss 0.363225222 epoch total loss 0.391162932\n",
      "Trained batch 182 batch loss 0.345971465 epoch total loss 0.390914619\n",
      "Trained batch 183 batch loss 0.372260332 epoch total loss 0.390812695\n",
      "Trained batch 184 batch loss 0.363657445 epoch total loss 0.390665084\n",
      "Trained batch 185 batch loss 0.375053227 epoch total loss 0.390580714\n",
      "Trained batch 186 batch loss 0.36671567 epoch total loss 0.390452385\n",
      "Trained batch 187 batch loss 0.389860064 epoch total loss 0.390449226\n",
      "Trained batch 188 batch loss 0.352220178 epoch total loss 0.390245885\n",
      "Trained batch 189 batch loss 0.34962678 epoch total loss 0.39003095\n",
      "Trained batch 190 batch loss 0.373140037 epoch total loss 0.38994205\n",
      "Trained batch 191 batch loss 0.393738151 epoch total loss 0.389961928\n",
      "Trained batch 192 batch loss 0.369324327 epoch total loss 0.389854431\n",
      "Trained batch 193 batch loss 0.388171196 epoch total loss 0.389845699\n",
      "Trained batch 194 batch loss 0.386283159 epoch total loss 0.389827341\n",
      "Trained batch 195 batch loss 0.396324128 epoch total loss 0.38986066\n",
      "Trained batch 196 batch loss 0.383599371 epoch total loss 0.389828712\n",
      "Trained batch 197 batch loss 0.37316525 epoch total loss 0.389744133\n",
      "Trained batch 198 batch loss 0.369169444 epoch total loss 0.389640242\n",
      "Trained batch 199 batch loss 0.396697283 epoch total loss 0.389675707\n",
      "Trained batch 200 batch loss 0.362175405 epoch total loss 0.389538199\n",
      "Trained batch 201 batch loss 0.38700825 epoch total loss 0.389525622\n",
      "Trained batch 202 batch loss 0.342143327 epoch total loss 0.389291018\n",
      "Trained batch 203 batch loss 0.369145185 epoch total loss 0.389191806\n",
      "Trained batch 204 batch loss 0.360144913 epoch total loss 0.389049411\n",
      "Trained batch 205 batch loss 0.346182466 epoch total loss 0.388840318\n",
      "Trained batch 206 batch loss 0.362481296 epoch total loss 0.388712347\n",
      "Trained batch 207 batch loss 0.368240058 epoch total loss 0.388613462\n",
      "Trained batch 208 batch loss 0.369808793 epoch total loss 0.388523072\n",
      "Trained batch 209 batch loss 0.335528493 epoch total loss 0.388269484\n",
      "Trained batch 210 batch loss 0.341654956 epoch total loss 0.388047487\n",
      "Trained batch 211 batch loss 0.336292088 epoch total loss 0.387802184\n",
      "Trained batch 212 batch loss 0.352402538 epoch total loss 0.387635201\n",
      "Trained batch 213 batch loss 0.331585407 epoch total loss 0.387372077\n",
      "Trained batch 214 batch loss 0.345872194 epoch total loss 0.387178153\n",
      "Trained batch 215 batch loss 0.335197479 epoch total loss 0.386936396\n",
      "Trained batch 216 batch loss 0.321524709 epoch total loss 0.386633545\n",
      "Trained batch 217 batch loss 0.337229401 epoch total loss 0.386405885\n",
      "Trained batch 218 batch loss 0.349836737 epoch total loss 0.386238128\n",
      "Trained batch 219 batch loss 0.323085666 epoch total loss 0.385949761\n",
      "Trained batch 220 batch loss 0.334613025 epoch total loss 0.385716379\n",
      "Trained batch 221 batch loss 0.333234429 epoch total loss 0.385478914\n",
      "Trained batch 222 batch loss 0.380066305 epoch total loss 0.385454535\n",
      "Trained batch 223 batch loss 0.395236641 epoch total loss 0.385498375\n",
      "Trained batch 224 batch loss 0.406668216 epoch total loss 0.385592908\n",
      "Trained batch 225 batch loss 0.392241538 epoch total loss 0.385622472\n",
      "Trained batch 226 batch loss 0.377068907 epoch total loss 0.385584593\n",
      "Trained batch 227 batch loss 0.361920416 epoch total loss 0.385480374\n",
      "Trained batch 228 batch loss 0.358651102 epoch total loss 0.385362685\n",
      "Trained batch 229 batch loss 0.376341045 epoch total loss 0.385323316\n",
      "Trained batch 230 batch loss 0.358497649 epoch total loss 0.38520667\n",
      "Trained batch 231 batch loss 0.349721491 epoch total loss 0.385053068\n",
      "Trained batch 232 batch loss 0.360424161 epoch total loss 0.384946913\n",
      "Trained batch 233 batch loss 0.373978496 epoch total loss 0.384899855\n",
      "Trained batch 234 batch loss 0.3857494 epoch total loss 0.384903491\n",
      "Trained batch 235 batch loss 0.37449941 epoch total loss 0.384859204\n",
      "Trained batch 236 batch loss 0.342357874 epoch total loss 0.384679109\n",
      "Trained batch 237 batch loss 0.364949286 epoch total loss 0.384595871\n",
      "Trained batch 238 batch loss 0.34339118 epoch total loss 0.384422749\n",
      "Trained batch 239 batch loss 0.289786816 epoch total loss 0.384026796\n",
      "Trained batch 240 batch loss 0.275630146 epoch total loss 0.383575112\n",
      "Trained batch 241 batch loss 0.352631688 epoch total loss 0.383446723\n",
      "Trained batch 242 batch loss 0.323633045 epoch total loss 0.383199543\n",
      "Trained batch 243 batch loss 0.365192503 epoch total loss 0.383125454\n",
      "Trained batch 244 batch loss 0.333644 epoch total loss 0.382922649\n",
      "Trained batch 245 batch loss 0.357776284 epoch total loss 0.38282\n",
      "Trained batch 246 batch loss 0.357629359 epoch total loss 0.382717609\n",
      "Trained batch 247 batch loss 0.366523087 epoch total loss 0.382652044\n",
      "Trained batch 248 batch loss 0.347091645 epoch total loss 0.382508636\n",
      "Trained batch 249 batch loss 0.392555118 epoch total loss 0.382549\n",
      "Trained batch 250 batch loss 0.339297235 epoch total loss 0.382376\n",
      "Trained batch 251 batch loss 0.315223157 epoch total loss 0.38210845\n",
      "Trained batch 252 batch loss 0.341085285 epoch total loss 0.38194567\n",
      "Trained batch 253 batch loss 0.353929579 epoch total loss 0.381834924\n",
      "Trained batch 254 batch loss 0.338130027 epoch total loss 0.381662846\n",
      "Trained batch 255 batch loss 0.397606194 epoch total loss 0.381725371\n",
      "Trained batch 256 batch loss 0.401866794 epoch total loss 0.381804019\n",
      "Trained batch 257 batch loss 0.355152279 epoch total loss 0.381700337\n",
      "Trained batch 258 batch loss 0.328498691 epoch total loss 0.381494135\n",
      "Trained batch 259 batch loss 0.31679666 epoch total loss 0.381244332\n",
      "Trained batch 260 batch loss 0.361173868 epoch total loss 0.381167144\n",
      "Trained batch 261 batch loss 0.358830363 epoch total loss 0.381081551\n",
      "Trained batch 262 batch loss 0.33681792 epoch total loss 0.380912602\n",
      "Trained batch 263 batch loss 0.346834719 epoch total loss 0.380783021\n",
      "Trained batch 264 batch loss 0.3565346 epoch total loss 0.380691171\n",
      "Trained batch 265 batch loss 0.34762454 epoch total loss 0.380566418\n",
      "Trained batch 266 batch loss 0.370077908 epoch total loss 0.380527\n",
      "Trained batch 267 batch loss 0.336361349 epoch total loss 0.380361587\n",
      "Trained batch 268 batch loss 0.360741496 epoch total loss 0.380288363\n",
      "Trained batch 269 batch loss 0.367853314 epoch total loss 0.380242139\n",
      "Trained batch 270 batch loss 0.306350619 epoch total loss 0.379968464\n",
      "Trained batch 271 batch loss 0.288466215 epoch total loss 0.379630804\n",
      "Trained batch 272 batch loss 0.33200863 epoch total loss 0.379455745\n",
      "Trained batch 273 batch loss 0.32499072 epoch total loss 0.379256219\n",
      "Trained batch 274 batch loss 0.329097331 epoch total loss 0.379073143\n",
      "Trained batch 275 batch loss 0.342613339 epoch total loss 0.378940582\n",
      "Trained batch 276 batch loss 0.367464155 epoch total loss 0.378898978\n",
      "Trained batch 277 batch loss 0.360017776 epoch total loss 0.37883082\n",
      "Trained batch 278 batch loss 0.367535532 epoch total loss 0.3787902\n",
      "Trained batch 279 batch loss 0.354333878 epoch total loss 0.378702521\n",
      "Trained batch 280 batch loss 0.363706857 epoch total loss 0.378648967\n",
      "Trained batch 281 batch loss 0.398881227 epoch total loss 0.378720969\n",
      "Trained batch 282 batch loss 0.413075805 epoch total loss 0.378842801\n",
      "Trained batch 283 batch loss 0.359985352 epoch total loss 0.378776163\n",
      "Trained batch 284 batch loss 0.36309424 epoch total loss 0.378720939\n",
      "Trained batch 285 batch loss 0.361450136 epoch total loss 0.378660351\n",
      "Trained batch 286 batch loss 0.359957874 epoch total loss 0.378594935\n",
      "Trained batch 287 batch loss 0.399724066 epoch total loss 0.378668576\n",
      "Trained batch 288 batch loss 0.348949641 epoch total loss 0.378565401\n",
      "Trained batch 289 batch loss 0.344993144 epoch total loss 0.378449231\n",
      "Trained batch 290 batch loss 0.353775948 epoch total loss 0.378364146\n",
      "Trained batch 291 batch loss 0.383174837 epoch total loss 0.378380656\n",
      "Trained batch 292 batch loss 0.373238117 epoch total loss 0.378363043\n",
      "Trained batch 293 batch loss 0.337828279 epoch total loss 0.378224701\n",
      "Trained batch 294 batch loss 0.345126808 epoch total loss 0.378112108\n",
      "Trained batch 295 batch loss 0.322051108 epoch total loss 0.377922088\n",
      "Trained batch 296 batch loss 0.352078825 epoch total loss 0.377834797\n",
      "Trained batch 297 batch loss 0.354298115 epoch total loss 0.377755553\n",
      "Trained batch 298 batch loss 0.347873867 epoch total loss 0.377655298\n",
      "Trained batch 299 batch loss 0.347571075 epoch total loss 0.377554685\n",
      "Trained batch 300 batch loss 0.317386985 epoch total loss 0.377354115\n",
      "Trained batch 301 batch loss 0.350799471 epoch total loss 0.3772659\n",
      "Trained batch 302 batch loss 0.336270213 epoch total loss 0.377130181\n",
      "Trained batch 303 batch loss 0.343251884 epoch total loss 0.377018362\n",
      "Trained batch 304 batch loss 0.347440422 epoch total loss 0.376921088\n",
      "Trained batch 305 batch loss 0.328342974 epoch total loss 0.376761824\n",
      "Trained batch 306 batch loss 0.340625 epoch total loss 0.376643717\n",
      "Trained batch 307 batch loss 0.322608232 epoch total loss 0.376467705\n",
      "Trained batch 308 batch loss 0.300555468 epoch total loss 0.37622121\n",
      "Trained batch 309 batch loss 0.354025 epoch total loss 0.376149386\n",
      "Trained batch 310 batch loss 0.400070161 epoch total loss 0.376226574\n",
      "Trained batch 311 batch loss 0.35901469 epoch total loss 0.376171231\n",
      "Trained batch 312 batch loss 0.35295555 epoch total loss 0.376096815\n",
      "Trained batch 313 batch loss 0.35137713 epoch total loss 0.376017869\n",
      "Trained batch 314 batch loss 0.364942193 epoch total loss 0.375982583\n",
      "Trained batch 315 batch loss 0.359392554 epoch total loss 0.375929922\n",
      "Trained batch 316 batch loss 0.336130828 epoch total loss 0.375803947\n",
      "Trained batch 317 batch loss 0.352394432 epoch total loss 0.375730097\n",
      "Trained batch 318 batch loss 0.347717851 epoch total loss 0.375642031\n",
      "Trained batch 319 batch loss 0.346929967 epoch total loss 0.375552028\n",
      "Trained batch 320 batch loss 0.338708133 epoch total loss 0.375436872\n",
      "Trained batch 321 batch loss 0.3580302 epoch total loss 0.375382662\n",
      "Trained batch 322 batch loss 0.336008936 epoch total loss 0.375260383\n",
      "Trained batch 323 batch loss 0.33919093 epoch total loss 0.375148684\n",
      "Trained batch 324 batch loss 0.328924 epoch total loss 0.37500602\n",
      "Trained batch 325 batch loss 0.347419679 epoch total loss 0.374921143\n",
      "Trained batch 326 batch loss 0.350224912 epoch total loss 0.374845386\n",
      "Trained batch 327 batch loss 0.352243 epoch total loss 0.374776274\n",
      "Trained batch 328 batch loss 0.369386315 epoch total loss 0.374759823\n",
      "Trained batch 329 batch loss 0.359198749 epoch total loss 0.374712527\n",
      "Trained batch 330 batch loss 0.405354977 epoch total loss 0.374805391\n",
      "Trained batch 331 batch loss 0.406912744 epoch total loss 0.374902397\n",
      "Trained batch 332 batch loss 0.361035347 epoch total loss 0.374860644\n",
      "Trained batch 333 batch loss 0.345037311 epoch total loss 0.374771088\n",
      "Trained batch 334 batch loss 0.3288697 epoch total loss 0.37463367\n",
      "Trained batch 335 batch loss 0.289851636 epoch total loss 0.374380589\n",
      "Trained batch 336 batch loss 0.313587338 epoch total loss 0.374199659\n",
      "Trained batch 337 batch loss 0.331702501 epoch total loss 0.374073565\n",
      "Trained batch 338 batch loss 0.281116962 epoch total loss 0.373798549\n",
      "Trained batch 339 batch loss 0.298771054 epoch total loss 0.373577237\n",
      "Trained batch 340 batch loss 0.273642123 epoch total loss 0.373283327\n",
      "Trained batch 341 batch loss 0.310266107 epoch total loss 0.373098522\n",
      "Trained batch 342 batch loss 0.326458901 epoch total loss 0.372962147\n",
      "Trained batch 343 batch loss 0.361682475 epoch total loss 0.372929245\n",
      "Trained batch 344 batch loss 0.367657661 epoch total loss 0.372913927\n",
      "Trained batch 345 batch loss 0.371127695 epoch total loss 0.372908741\n",
      "Trained batch 346 batch loss 0.393407643 epoch total loss 0.372968\n",
      "Trained batch 347 batch loss 0.369470656 epoch total loss 0.372957915\n",
      "Trained batch 348 batch loss 0.341996193 epoch total loss 0.372868955\n",
      "Trained batch 349 batch loss 0.345436275 epoch total loss 0.372790366\n",
      "Trained batch 350 batch loss 0.355709612 epoch total loss 0.37274158\n",
      "Trained batch 351 batch loss 0.347336203 epoch total loss 0.37266919\n",
      "Trained batch 352 batch loss 0.333795726 epoch total loss 0.372558773\n",
      "Trained batch 353 batch loss 0.34057349 epoch total loss 0.372468174\n",
      "Trained batch 354 batch loss 0.347133696 epoch total loss 0.372396618\n",
      "Trained batch 355 batch loss 0.326928437 epoch total loss 0.372268558\n",
      "Trained batch 356 batch loss 0.305698395 epoch total loss 0.372081548\n",
      "Trained batch 357 batch loss 0.269642 epoch total loss 0.371794581\n",
      "Trained batch 358 batch loss 0.325374901 epoch total loss 0.371664941\n",
      "Trained batch 359 batch loss 0.350024045 epoch total loss 0.371604651\n",
      "Trained batch 360 batch loss 0.356474161 epoch total loss 0.37156263\n",
      "Trained batch 361 batch loss 0.351881623 epoch total loss 0.371508092\n",
      "Trained batch 362 batch loss 0.359094054 epoch total loss 0.371473819\n",
      "Trained batch 363 batch loss 0.332975119 epoch total loss 0.371367782\n",
      "Trained batch 364 batch loss 0.319126308 epoch total loss 0.371224254\n",
      "Trained batch 365 batch loss 0.313725173 epoch total loss 0.371066689\n",
      "Trained batch 366 batch loss 0.340480506 epoch total loss 0.370983154\n",
      "Trained batch 367 batch loss 0.318524957 epoch total loss 0.370840222\n",
      "Trained batch 368 batch loss 0.352380216 epoch total loss 0.370790064\n",
      "Trained batch 369 batch loss 0.331534535 epoch total loss 0.37068367\n",
      "Trained batch 370 batch loss 0.362048149 epoch total loss 0.370660305\n",
      "Trained batch 371 batch loss 0.338571429 epoch total loss 0.370573848\n",
      "Trained batch 372 batch loss 0.355425537 epoch total loss 0.370533109\n",
      "Trained batch 373 batch loss 0.333877206 epoch total loss 0.37043485\n",
      "Trained batch 374 batch loss 0.331742823 epoch total loss 0.370331377\n",
      "Trained batch 375 batch loss 0.354163826 epoch total loss 0.370288253\n",
      "Trained batch 376 batch loss 0.375476867 epoch total loss 0.370302051\n",
      "Trained batch 377 batch loss 0.345571458 epoch total loss 0.370236427\n",
      "Trained batch 378 batch loss 0.374122798 epoch total loss 0.370246738\n",
      "Trained batch 379 batch loss 0.36183551 epoch total loss 0.370224535\n",
      "Trained batch 380 batch loss 0.358772725 epoch total loss 0.370194405\n",
      "Trained batch 381 batch loss 0.341451168 epoch total loss 0.370118946\n",
      "Trained batch 382 batch loss 0.344329178 epoch total loss 0.370051444\n",
      "Trained batch 383 batch loss 0.341121703 epoch total loss 0.369975924\n",
      "Trained batch 384 batch loss 0.356714368 epoch total loss 0.369941384\n",
      "Trained batch 385 batch loss 0.360629827 epoch total loss 0.369917184\n",
      "Trained batch 386 batch loss 0.358131289 epoch total loss 0.369886637\n",
      "Trained batch 387 batch loss 0.361719519 epoch total loss 0.369865566\n",
      "Trained batch 388 batch loss 0.347979277 epoch total loss 0.369809151\n",
      "Trained batch 389 batch loss 0.3351928 epoch total loss 0.369720131\n",
      "Trained batch 390 batch loss 0.351195 epoch total loss 0.369672656\n",
      "Trained batch 391 batch loss 0.370161057 epoch total loss 0.369673908\n",
      "Trained batch 392 batch loss 0.384264767 epoch total loss 0.369711131\n",
      "Trained batch 393 batch loss 0.369387239 epoch total loss 0.369710296\n",
      "Trained batch 394 batch loss 0.339673221 epoch total loss 0.369634062\n",
      "Trained batch 395 batch loss 0.342850596 epoch total loss 0.369566262\n",
      "Trained batch 396 batch loss 0.341791451 epoch total loss 0.369496137\n",
      "Trained batch 397 batch loss 0.347665131 epoch total loss 0.369441152\n",
      "Trained batch 398 batch loss 0.34808147 epoch total loss 0.369387478\n",
      "Trained batch 399 batch loss 0.326555 epoch total loss 0.36928013\n",
      "Trained batch 400 batch loss 0.37069875 epoch total loss 0.369283676\n",
      "Trained batch 401 batch loss 0.355564952 epoch total loss 0.369249463\n",
      "Trained batch 402 batch loss 0.331690073 epoch total loss 0.369156033\n",
      "Trained batch 403 batch loss 0.352521926 epoch total loss 0.369114757\n",
      "Trained batch 404 batch loss 0.344135 epoch total loss 0.369052917\n",
      "Trained batch 405 batch loss 0.33417052 epoch total loss 0.368966788\n",
      "Trained batch 406 batch loss 0.347933352 epoch total loss 0.368914962\n",
      "Trained batch 407 batch loss 0.334186614 epoch total loss 0.368829638\n",
      "Trained batch 408 batch loss 0.334992558 epoch total loss 0.368746698\n",
      "Trained batch 409 batch loss 0.321582019 epoch total loss 0.368631363\n",
      "Trained batch 410 batch loss 0.327386558 epoch total loss 0.36853078\n",
      "Trained batch 411 batch loss 0.345635504 epoch total loss 0.368475109\n",
      "Trained batch 412 batch loss 0.361290842 epoch total loss 0.368457675\n",
      "Trained batch 413 batch loss 0.375055701 epoch total loss 0.368473679\n",
      "Trained batch 414 batch loss 0.35565275 epoch total loss 0.368442714\n",
      "Trained batch 415 batch loss 0.305483639 epoch total loss 0.368291\n",
      "Trained batch 416 batch loss 0.309794605 epoch total loss 0.368150383\n",
      "Trained batch 417 batch loss 0.324676722 epoch total loss 0.368046135\n",
      "Trained batch 418 batch loss 0.356207579 epoch total loss 0.368017793\n",
      "Trained batch 419 batch loss 0.345517397 epoch total loss 0.367964089\n",
      "Trained batch 420 batch loss 0.365817487 epoch total loss 0.367958963\n",
      "Trained batch 421 batch loss 0.344362706 epoch total loss 0.367902935\n",
      "Trained batch 422 batch loss 0.342690885 epoch total loss 0.367843181\n",
      "Trained batch 423 batch loss 0.34148705 epoch total loss 0.367780894\n",
      "Trained batch 424 batch loss 0.338444084 epoch total loss 0.367711693\n",
      "Trained batch 425 batch loss 0.330617219 epoch total loss 0.367624402\n",
      "Trained batch 426 batch loss 0.342573822 epoch total loss 0.367565602\n",
      "Trained batch 427 batch loss 0.339786172 epoch total loss 0.367500544\n",
      "Trained batch 428 batch loss 0.34709847 epoch total loss 0.36745286\n",
      "Trained batch 429 batch loss 0.343093216 epoch total loss 0.367396086\n",
      "Trained batch 430 batch loss 0.354371697 epoch total loss 0.367365777\n",
      "Trained batch 431 batch loss 0.335100442 epoch total loss 0.367290914\n",
      "Trained batch 432 batch loss 0.357679725 epoch total loss 0.367268682\n",
      "Trained batch 433 batch loss 0.351703227 epoch total loss 0.36723271\n",
      "Trained batch 434 batch loss 0.342200518 epoch total loss 0.367175\n",
      "Trained batch 435 batch loss 0.340533495 epoch total loss 0.367113769\n",
      "Trained batch 436 batch loss 0.351135612 epoch total loss 0.367077112\n",
      "Trained batch 437 batch loss 0.334223479 epoch total loss 0.367001951\n",
      "Trained batch 438 batch loss 0.357178241 epoch total loss 0.36697951\n",
      "Trained batch 439 batch loss 0.392540157 epoch total loss 0.367037773\n",
      "Trained batch 440 batch loss 0.391290486 epoch total loss 0.367092907\n",
      "Trained batch 441 batch loss 0.366907418 epoch total loss 0.36709249\n",
      "Trained batch 442 batch loss 0.321444869 epoch total loss 0.366989195\n",
      "Trained batch 443 batch loss 0.311769307 epoch total loss 0.366864562\n",
      "Trained batch 444 batch loss 0.326436132 epoch total loss 0.366773486\n",
      "Trained batch 445 batch loss 0.346864 epoch total loss 0.366728753\n",
      "Trained batch 446 batch loss 0.328551739 epoch total loss 0.366643131\n",
      "Trained batch 447 batch loss 0.329983652 epoch total loss 0.366561145\n",
      "Trained batch 448 batch loss 0.336417556 epoch total loss 0.366493851\n",
      "Trained batch 449 batch loss 0.327012628 epoch total loss 0.366405904\n",
      "Trained batch 450 batch loss 0.320579231 epoch total loss 0.36630404\n",
      "Trained batch 451 batch loss 0.320900261 epoch total loss 0.366203398\n",
      "Trained batch 452 batch loss 0.341822386 epoch total loss 0.366149455\n",
      "Trained batch 453 batch loss 0.326188385 epoch total loss 0.36606124\n",
      "Trained batch 454 batch loss 0.317560703 epoch total loss 0.365954429\n",
      "Trained batch 455 batch loss 0.309319615 epoch total loss 0.365829974\n",
      "Trained batch 456 batch loss 0.320515573 epoch total loss 0.365730584\n",
      "Trained batch 457 batch loss 0.283202112 epoch total loss 0.36555\n",
      "Trained batch 458 batch loss 0.344906926 epoch total loss 0.36550492\n",
      "Trained batch 459 batch loss 0.363472819 epoch total loss 0.36550051\n",
      "Trained batch 460 batch loss 0.354810834 epoch total loss 0.365477294\n",
      "Trained batch 461 batch loss 0.364326268 epoch total loss 0.365474761\n",
      "Trained batch 462 batch loss 0.386983782 epoch total loss 0.365521312\n",
      "Trained batch 463 batch loss 0.367590666 epoch total loss 0.365525782\n",
      "Trained batch 464 batch loss 0.359085679 epoch total loss 0.365511894\n",
      "Trained batch 465 batch loss 0.379972041 epoch total loss 0.365543\n",
      "Trained batch 466 batch loss 0.373829752 epoch total loss 0.36556077\n",
      "Trained batch 467 batch loss 0.354212105 epoch total loss 0.365536481\n",
      "Trained batch 468 batch loss 0.343016475 epoch total loss 0.36548835\n",
      "Trained batch 469 batch loss 0.342724711 epoch total loss 0.365439832\n",
      "Trained batch 470 batch loss 0.300065696 epoch total loss 0.365300745\n",
      "Trained batch 471 batch loss 0.311273456 epoch total loss 0.365186036\n",
      "Trained batch 472 batch loss 0.340048462 epoch total loss 0.365132779\n",
      "Trained batch 473 batch loss 0.352085203 epoch total loss 0.365105182\n",
      "Trained batch 474 batch loss 0.341683835 epoch total loss 0.36505577\n",
      "Trained batch 475 batch loss 0.348901778 epoch total loss 0.365021765\n",
      "Trained batch 476 batch loss 0.356418312 epoch total loss 0.365003705\n",
      "Trained batch 477 batch loss 0.35725683 epoch total loss 0.364987463\n",
      "Trained batch 478 batch loss 0.364853263 epoch total loss 0.364987165\n",
      "Trained batch 479 batch loss 0.344499946 epoch total loss 0.364944398\n",
      "Trained batch 480 batch loss 0.349834859 epoch total loss 0.364912927\n",
      "Trained batch 481 batch loss 0.356200099 epoch total loss 0.364894807\n",
      "Trained batch 482 batch loss 0.359773427 epoch total loss 0.364884168\n",
      "Trained batch 483 batch loss 0.362383902 epoch total loss 0.364879\n",
      "Trained batch 484 batch loss 0.344102621 epoch total loss 0.364836067\n",
      "Trained batch 485 batch loss 0.323200524 epoch total loss 0.364750206\n",
      "Trained batch 486 batch loss 0.313325524 epoch total loss 0.364644408\n",
      "Trained batch 487 batch loss 0.302256644 epoch total loss 0.364516318\n",
      "Trained batch 488 batch loss 0.301006496 epoch total loss 0.364386171\n",
      "Trained batch 489 batch loss 0.311461091 epoch total loss 0.364277929\n",
      "Trained batch 490 batch loss 0.29301849 epoch total loss 0.364132494\n",
      "Trained batch 491 batch loss 0.26917392 epoch total loss 0.363939106\n",
      "Trained batch 492 batch loss 0.280473679 epoch total loss 0.363769472\n",
      "Trained batch 493 batch loss 0.258906811 epoch total loss 0.363556772\n",
      "Trained batch 494 batch loss 0.309516072 epoch total loss 0.363447368\n",
      "Trained batch 495 batch loss 0.347031 epoch total loss 0.363414198\n",
      "Trained batch 496 batch loss 0.338054 epoch total loss 0.363363087\n",
      "Trained batch 497 batch loss 0.329971224 epoch total loss 0.363295883\n",
      "Trained batch 498 batch loss 0.309500784 epoch total loss 0.36318785\n",
      "Trained batch 499 batch loss 0.336206734 epoch total loss 0.363133788\n",
      "Trained batch 500 batch loss 0.368264019 epoch total loss 0.36314407\n",
      "Trained batch 501 batch loss 0.345315635 epoch total loss 0.363108486\n",
      "Trained batch 502 batch loss 0.351496965 epoch total loss 0.363085389\n",
      "Trained batch 503 batch loss 0.323421508 epoch total loss 0.363006532\n",
      "Trained batch 504 batch loss 0.310608834 epoch total loss 0.362902552\n",
      "Trained batch 505 batch loss 0.318326384 epoch total loss 0.362814307\n",
      "Trained batch 506 batch loss 0.337330848 epoch total loss 0.362763941\n",
      "Trained batch 507 batch loss 0.315033585 epoch total loss 0.362669796\n",
      "Trained batch 508 batch loss 0.31680423 epoch total loss 0.362579495\n",
      "Trained batch 509 batch loss 0.296356708 epoch total loss 0.362449378\n",
      "Trained batch 510 batch loss 0.312463224 epoch total loss 0.362351388\n",
      "Trained batch 511 batch loss 0.336294234 epoch total loss 0.362300396\n",
      "Trained batch 512 batch loss 0.322899967 epoch total loss 0.362223446\n",
      "Trained batch 513 batch loss 0.30970633 epoch total loss 0.362121075\n",
      "Trained batch 514 batch loss 0.320306391 epoch total loss 0.362039745\n",
      "Trained batch 515 batch loss 0.327935517 epoch total loss 0.361973524\n",
      "Trained batch 516 batch loss 0.379662424 epoch total loss 0.362007827\n",
      "Trained batch 517 batch loss 0.366038829 epoch total loss 0.362015635\n",
      "Trained batch 518 batch loss 0.331503272 epoch total loss 0.361956716\n",
      "Trained batch 519 batch loss 0.353937835 epoch total loss 0.361941278\n",
      "Trained batch 520 batch loss 0.334824204 epoch total loss 0.361889124\n",
      "Trained batch 521 batch loss 0.306869 epoch total loss 0.361783504\n",
      "Trained batch 522 batch loss 0.338956684 epoch total loss 0.361739784\n",
      "Trained batch 523 batch loss 0.344058573 epoch total loss 0.361706\n",
      "Trained batch 524 batch loss 0.324645877 epoch total loss 0.361635238\n",
      "Trained batch 525 batch loss 0.34691751 epoch total loss 0.361607224\n",
      "Trained batch 526 batch loss 0.326398402 epoch total loss 0.361540288\n",
      "Trained batch 527 batch loss 0.3108235 epoch total loss 0.361444056\n",
      "Trained batch 528 batch loss 0.333464891 epoch total loss 0.361391068\n",
      "Trained batch 529 batch loss 0.34745273 epoch total loss 0.361364722\n",
      "Trained batch 530 batch loss 0.355398446 epoch total loss 0.361353457\n",
      "Trained batch 531 batch loss 0.350103527 epoch total loss 0.361332268\n",
      "Trained batch 532 batch loss 0.332638323 epoch total loss 0.361278325\n",
      "Trained batch 533 batch loss 0.303628385 epoch total loss 0.361170173\n",
      "Trained batch 534 batch loss 0.326888472 epoch total loss 0.361105978\n",
      "Trained batch 535 batch loss 0.353357196 epoch total loss 0.361091524\n",
      "Trained batch 536 batch loss 0.348188877 epoch total loss 0.361067444\n",
      "Trained batch 537 batch loss 0.337587744 epoch total loss 0.361023724\n",
      "Trained batch 538 batch loss 0.36882627 epoch total loss 0.361038208\n",
      "Trained batch 539 batch loss 0.357776225 epoch total loss 0.361032158\n",
      "Trained batch 540 batch loss 0.35193485 epoch total loss 0.36101529\n",
      "Trained batch 541 batch loss 0.33892563 epoch total loss 0.360974461\n",
      "Trained batch 542 batch loss 0.322818041 epoch total loss 0.360904068\n",
      "Trained batch 543 batch loss 0.324250579 epoch total loss 0.360836565\n",
      "Trained batch 544 batch loss 0.3493945 epoch total loss 0.360815525\n",
      "Trained batch 545 batch loss 0.348512083 epoch total loss 0.360792935\n",
      "Trained batch 546 batch loss 0.399448752 epoch total loss 0.360863745\n",
      "Trained batch 547 batch loss 0.393504292 epoch total loss 0.360923409\n",
      "Trained batch 548 batch loss 0.363195598 epoch total loss 0.360927552\n",
      "Trained batch 549 batch loss 0.356362581 epoch total loss 0.360919237\n",
      "Trained batch 550 batch loss 0.353083462 epoch total loss 0.360905021\n",
      "Trained batch 551 batch loss 0.323062241 epoch total loss 0.360836327\n",
      "Trained batch 552 batch loss 0.301986635 epoch total loss 0.360729724\n",
      "Trained batch 553 batch loss 0.341794759 epoch total loss 0.360695481\n",
      "Trained batch 554 batch loss 0.373589337 epoch total loss 0.360718757\n",
      "Trained batch 555 batch loss 0.33508724 epoch total loss 0.360672563\n",
      "Trained batch 556 batch loss 0.342279881 epoch total loss 0.360639513\n",
      "Trained batch 557 batch loss 0.335229665 epoch total loss 0.360593885\n",
      "Trained batch 558 batch loss 0.312145561 epoch total loss 0.360507071\n",
      "Trained batch 559 batch loss 0.316611171 epoch total loss 0.360428542\n",
      "Trained batch 560 batch loss 0.304196626 epoch total loss 0.360328138\n",
      "Trained batch 561 batch loss 0.321600437 epoch total loss 0.360259086\n",
      "Trained batch 562 batch loss 0.311177582 epoch total loss 0.360171735\n",
      "Trained batch 563 batch loss 0.312098086 epoch total loss 0.360086352\n",
      "Trained batch 564 batch loss 0.305493355 epoch total loss 0.359989583\n",
      "Trained batch 565 batch loss 0.327287734 epoch total loss 0.359931678\n",
      "Trained batch 566 batch loss 0.365615249 epoch total loss 0.359941721\n",
      "Trained batch 567 batch loss 0.381735891 epoch total loss 0.359980166\n",
      "Trained batch 568 batch loss 0.310090333 epoch total loss 0.359892309\n",
      "Trained batch 569 batch loss 0.333382875 epoch total loss 0.359845757\n",
      "Trained batch 570 batch loss 0.321513236 epoch total loss 0.359778494\n",
      "Trained batch 571 batch loss 0.33331424 epoch total loss 0.359732151\n",
      "Trained batch 572 batch loss 0.35296753 epoch total loss 0.35972032\n",
      "Trained batch 573 batch loss 0.367967963 epoch total loss 0.359734714\n",
      "Trained batch 574 batch loss 0.350047171 epoch total loss 0.359717846\n",
      "Trained batch 575 batch loss 0.336531043 epoch total loss 0.359677523\n",
      "Trained batch 576 batch loss 0.337773561 epoch total loss 0.359639496\n",
      "Trained batch 577 batch loss 0.313640863 epoch total loss 0.359559774\n",
      "Trained batch 578 batch loss 0.343405873 epoch total loss 0.35953182\n",
      "Trained batch 579 batch loss 0.337341487 epoch total loss 0.359493494\n",
      "Trained batch 580 batch loss 0.389402777 epoch total loss 0.359545052\n",
      "Trained batch 581 batch loss 0.35759452 epoch total loss 0.359541684\n",
      "Trained batch 582 batch loss 0.327821374 epoch total loss 0.359487176\n",
      "Trained batch 583 batch loss 0.321370214 epoch total loss 0.35942179\n",
      "Trained batch 584 batch loss 0.321733654 epoch total loss 0.359357268\n",
      "Trained batch 585 batch loss 0.33704704 epoch total loss 0.359319121\n",
      "Trained batch 586 batch loss 0.341179907 epoch total loss 0.359288186\n",
      "Trained batch 587 batch loss 0.342066288 epoch total loss 0.35925886\n",
      "Trained batch 588 batch loss 0.356006384 epoch total loss 0.359253317\n",
      "Trained batch 589 batch loss 0.341360599 epoch total loss 0.359222919\n",
      "Trained batch 590 batch loss 0.320774525 epoch total loss 0.359157771\n",
      "Trained batch 591 batch loss 0.324968 epoch total loss 0.359099895\n",
      "Trained batch 592 batch loss 0.314688742 epoch total loss 0.359024882\n",
      "Trained batch 593 batch loss 0.323155195 epoch total loss 0.358964384\n",
      "Trained batch 594 batch loss 0.340808779 epoch total loss 0.358933806\n",
      "Trained batch 595 batch loss 0.343426466 epoch total loss 0.358907759\n",
      "Trained batch 596 batch loss 0.343064129 epoch total loss 0.358881176\n",
      "Trained batch 597 batch loss 0.334111542 epoch total loss 0.358839661\n",
      "Trained batch 598 batch loss 0.359960765 epoch total loss 0.358841538\n",
      "Trained batch 599 batch loss 0.3597911 epoch total loss 0.358843118\n",
      "Trained batch 600 batch loss 0.341867119 epoch total loss 0.358814836\n",
      "Trained batch 601 batch loss 0.34163776 epoch total loss 0.358786255\n",
      "Trained batch 602 batch loss 0.36106205 epoch total loss 0.35879004\n",
      "Trained batch 603 batch loss 0.326742232 epoch total loss 0.358736902\n",
      "Trained batch 604 batch loss 0.341871023 epoch total loss 0.358708978\n",
      "Trained batch 605 batch loss 0.316577494 epoch total loss 0.35863933\n",
      "Trained batch 606 batch loss 0.300646842 epoch total loss 0.358543634\n",
      "Trained batch 607 batch loss 0.298228562 epoch total loss 0.358444273\n",
      "Trained batch 608 batch loss 0.329048932 epoch total loss 0.358395934\n",
      "Trained batch 609 batch loss 0.314763427 epoch total loss 0.35832426\n",
      "Trained batch 610 batch loss 0.285190493 epoch total loss 0.358204365\n",
      "Trained batch 611 batch loss 0.281160444 epoch total loss 0.358078271\n",
      "Trained batch 612 batch loss 0.311892718 epoch total loss 0.358002812\n",
      "Trained batch 613 batch loss 0.329570889 epoch total loss 0.357956439\n",
      "Trained batch 614 batch loss 0.317703366 epoch total loss 0.357890874\n",
      "Trained batch 615 batch loss 0.329840213 epoch total loss 0.357845247\n",
      "Trained batch 616 batch loss 0.376749337 epoch total loss 0.357875943\n",
      "Trained batch 617 batch loss 0.31207487 epoch total loss 0.357801706\n",
      "Trained batch 618 batch loss 0.334672034 epoch total loss 0.357764274\n",
      "Trained batch 619 batch loss 0.31330961 epoch total loss 0.35769248\n",
      "Trained batch 620 batch loss 0.335613459 epoch total loss 0.357656866\n",
      "Trained batch 621 batch loss 0.338235795 epoch total loss 0.357625604\n",
      "Trained batch 622 batch loss 0.303067178 epoch total loss 0.357537895\n",
      "Trained batch 623 batch loss 0.258665264 epoch total loss 0.357379198\n",
      "Trained batch 624 batch loss 0.256313741 epoch total loss 0.357217222\n",
      "Trained batch 625 batch loss 0.315042853 epoch total loss 0.35714975\n",
      "Trained batch 626 batch loss 0.36930263 epoch total loss 0.357169181\n",
      "Trained batch 627 batch loss 0.389351189 epoch total loss 0.357220531\n",
      "Trained batch 628 batch loss 0.366500735 epoch total loss 0.357235283\n",
      "Trained batch 629 batch loss 0.362154305 epoch total loss 0.357243121\n",
      "Trained batch 630 batch loss 0.347136885 epoch total loss 0.357227057\n",
      "Trained batch 631 batch loss 0.341270715 epoch total loss 0.357201785\n",
      "Trained batch 632 batch loss 0.319093347 epoch total loss 0.357141495\n",
      "Trained batch 633 batch loss 0.32626316 epoch total loss 0.357092708\n",
      "Trained batch 634 batch loss 0.324222803 epoch total loss 0.357040852\n",
      "Trained batch 635 batch loss 0.302812159 epoch total loss 0.356955469\n",
      "Trained batch 636 batch loss 0.323312044 epoch total loss 0.35690257\n",
      "Trained batch 637 batch loss 0.316909045 epoch total loss 0.356839776\n",
      "Trained batch 638 batch loss 0.331796646 epoch total loss 0.356800556\n",
      "Trained batch 639 batch loss 0.320002735 epoch total loss 0.356742978\n",
      "Trained batch 640 batch loss 0.319202691 epoch total loss 0.356684297\n",
      "Trained batch 641 batch loss 0.316920161 epoch total loss 0.356622279\n",
      "Trained batch 642 batch loss 0.337664336 epoch total loss 0.356592745\n",
      "Trained batch 643 batch loss 0.344960243 epoch total loss 0.356574655\n",
      "Trained batch 644 batch loss 0.337125868 epoch total loss 0.356544435\n",
      "Trained batch 645 batch loss 0.366532207 epoch total loss 0.356559932\n",
      "Trained batch 646 batch loss 0.357161403 epoch total loss 0.356560856\n",
      "Trained batch 647 batch loss 0.331765234 epoch total loss 0.35652256\n",
      "Trained batch 648 batch loss 0.330146372 epoch total loss 0.35648182\n",
      "Trained batch 649 batch loss 0.33872354 epoch total loss 0.356454492\n",
      "Trained batch 650 batch loss 0.325543582 epoch total loss 0.356406927\n",
      "Trained batch 651 batch loss 0.317612857 epoch total loss 0.356347352\n",
      "Trained batch 652 batch loss 0.346521109 epoch total loss 0.356332272\n",
      "Trained batch 653 batch loss 0.356828809 epoch total loss 0.356333047\n",
      "Trained batch 654 batch loss 0.322139651 epoch total loss 0.356280744\n",
      "Trained batch 655 batch loss 0.331139058 epoch total loss 0.356242388\n",
      "Trained batch 656 batch loss 0.326458812 epoch total loss 0.356197\n",
      "Trained batch 657 batch loss 0.328102142 epoch total loss 0.356154233\n",
      "Trained batch 658 batch loss 0.360221088 epoch total loss 0.356160402\n",
      "Trained batch 659 batch loss 0.362504125 epoch total loss 0.356170028\n",
      "Trained batch 660 batch loss 0.370421231 epoch total loss 0.356191635\n",
      "Trained batch 661 batch loss 0.324841142 epoch total loss 0.35614419\n",
      "Trained batch 662 batch loss 0.295320868 epoch total loss 0.356052309\n",
      "Trained batch 663 batch loss 0.359788775 epoch total loss 0.356057942\n",
      "Trained batch 664 batch loss 0.337279409 epoch total loss 0.35602966\n",
      "Trained batch 665 batch loss 0.326506913 epoch total loss 0.355985284\n",
      "Trained batch 666 batch loss 0.344533354 epoch total loss 0.355968088\n",
      "Trained batch 667 batch loss 0.333603412 epoch total loss 0.35593453\n",
      "Trained batch 668 batch loss 0.351121962 epoch total loss 0.355927348\n",
      "Trained batch 669 batch loss 0.315469086 epoch total loss 0.355866879\n",
      "Trained batch 670 batch loss 0.342222571 epoch total loss 0.355846494\n",
      "Trained batch 671 batch loss 0.338876307 epoch total loss 0.355821222\n",
      "Trained batch 672 batch loss 0.335823834 epoch total loss 0.355791479\n",
      "Trained batch 673 batch loss 0.325552016 epoch total loss 0.355746537\n",
      "Trained batch 674 batch loss 0.324297369 epoch total loss 0.355699867\n",
      "Trained batch 675 batch loss 0.343227535 epoch total loss 0.35568139\n",
      "Trained batch 676 batch loss 0.338478297 epoch total loss 0.355655968\n",
      "Trained batch 677 batch loss 0.35846442 epoch total loss 0.355660111\n",
      "Trained batch 678 batch loss 0.368189454 epoch total loss 0.355678588\n",
      "Trained batch 679 batch loss 0.342611849 epoch total loss 0.355659336\n",
      "Trained batch 680 batch loss 0.337666 epoch total loss 0.355632871\n",
      "Trained batch 681 batch loss 0.343418568 epoch total loss 0.35561493\n",
      "Trained batch 682 batch loss 0.330420673 epoch total loss 0.355577976\n",
      "Trained batch 683 batch loss 0.335198313 epoch total loss 0.355548143\n",
      "Trained batch 684 batch loss 0.332077205 epoch total loss 0.355513841\n",
      "Trained batch 685 batch loss 0.357794255 epoch total loss 0.355517149\n",
      "Trained batch 686 batch loss 0.361867636 epoch total loss 0.355526417\n",
      "Trained batch 687 batch loss 0.368059486 epoch total loss 0.355544657\n",
      "Trained batch 688 batch loss 0.376497746 epoch total loss 0.355575085\n",
      "Trained batch 689 batch loss 0.391704768 epoch total loss 0.355627537\n",
      "Trained batch 690 batch loss 0.367301106 epoch total loss 0.355644435\n",
      "Trained batch 691 batch loss 0.361112297 epoch total loss 0.355652362\n",
      "Trained batch 692 batch loss 0.352323771 epoch total loss 0.355647564\n",
      "Trained batch 693 batch loss 0.370410562 epoch total loss 0.355668843\n",
      "Trained batch 694 batch loss 0.356956869 epoch total loss 0.35567072\n",
      "Trained batch 695 batch loss 0.360118449 epoch total loss 0.355677128\n",
      "Trained batch 696 batch loss 0.322249949 epoch total loss 0.355629086\n",
      "Trained batch 697 batch loss 0.330108821 epoch total loss 0.355592489\n",
      "Trained batch 698 batch loss 0.335869551 epoch total loss 0.355564237\n",
      "Trained batch 699 batch loss 0.326651752 epoch total loss 0.355522871\n",
      "Trained batch 700 batch loss 0.337944567 epoch total loss 0.355497777\n",
      "Trained batch 701 batch loss 0.345327228 epoch total loss 0.355483234\n",
      "Trained batch 702 batch loss 0.338183224 epoch total loss 0.355458587\n",
      "Trained batch 703 batch loss 0.347704172 epoch total loss 0.355447561\n",
      "Trained batch 704 batch loss 0.352746814 epoch total loss 0.355443746\n",
      "Trained batch 705 batch loss 0.350400567 epoch total loss 0.355436593\n",
      "Trained batch 706 batch loss 0.339616835 epoch total loss 0.355414182\n",
      "Trained batch 707 batch loss 0.33194 epoch total loss 0.355380982\n",
      "Trained batch 708 batch loss 0.326387554 epoch total loss 0.355340034\n",
      "Trained batch 709 batch loss 0.316829979 epoch total loss 0.355285704\n",
      "Trained batch 710 batch loss 0.341374904 epoch total loss 0.355266094\n",
      "Trained batch 711 batch loss 0.316575527 epoch total loss 0.355211675\n",
      "Trained batch 712 batch loss 0.316663 epoch total loss 0.355157554\n",
      "Trained batch 713 batch loss 0.323147923 epoch total loss 0.355112672\n",
      "Trained batch 714 batch loss 0.356534898 epoch total loss 0.355114669\n",
      "Trained batch 715 batch loss 0.336480886 epoch total loss 0.355088592\n",
      "Trained batch 716 batch loss 0.346823812 epoch total loss 0.355077058\n",
      "Trained batch 717 batch loss 0.33425647 epoch total loss 0.355048031\n",
      "Trained batch 718 batch loss 0.329793125 epoch total loss 0.355012834\n",
      "Trained batch 719 batch loss 0.315154225 epoch total loss 0.354957402\n",
      "Trained batch 720 batch loss 0.296922088 epoch total loss 0.354876786\n",
      "Trained batch 721 batch loss 0.320671618 epoch total loss 0.354829371\n",
      "Trained batch 722 batch loss 0.315971702 epoch total loss 0.354775548\n",
      "Trained batch 723 batch loss 0.30601576 epoch total loss 0.354708135\n",
      "Trained batch 724 batch loss 0.293803066 epoch total loss 0.354624\n",
      "Trained batch 725 batch loss 0.332963556 epoch total loss 0.354594141\n",
      "Trained batch 726 batch loss 0.33733952 epoch total loss 0.354570359\n",
      "Trained batch 727 batch loss 0.336649299 epoch total loss 0.354545712\n",
      "Trained batch 728 batch loss 0.354267389 epoch total loss 0.354545355\n",
      "Trained batch 729 batch loss 0.314213037 epoch total loss 0.35449\n",
      "Trained batch 730 batch loss 0.297371238 epoch total loss 0.354411751\n",
      "Trained batch 731 batch loss 0.298375845 epoch total loss 0.354335099\n",
      "Trained batch 732 batch loss 0.327936411 epoch total loss 0.354299039\n",
      "Trained batch 733 batch loss 0.358023703 epoch total loss 0.354304135\n",
      "Trained batch 734 batch loss 0.364508629 epoch total loss 0.354318023\n",
      "Trained batch 735 batch loss 0.343422979 epoch total loss 0.354303181\n",
      "Trained batch 736 batch loss 0.317766309 epoch total loss 0.35425356\n",
      "Trained batch 737 batch loss 0.302711248 epoch total loss 0.354183614\n",
      "Trained batch 738 batch loss 0.310168684 epoch total loss 0.35412398\n",
      "Trained batch 739 batch loss 0.307497233 epoch total loss 0.354060888\n",
      "Trained batch 740 batch loss 0.312266469 epoch total loss 0.354004413\n",
      "Trained batch 741 batch loss 0.319345593 epoch total loss 0.353957623\n",
      "Trained batch 742 batch loss 0.3375265 epoch total loss 0.35393548\n",
      "Trained batch 743 batch loss 0.339495778 epoch total loss 0.353916049\n",
      "Trained batch 744 batch loss 0.344475478 epoch total loss 0.353903383\n",
      "Trained batch 745 batch loss 0.320160061 epoch total loss 0.353858083\n",
      "Trained batch 746 batch loss 0.339933634 epoch total loss 0.353839427\n",
      "Trained batch 747 batch loss 0.367237151 epoch total loss 0.353857368\n",
      "Trained batch 748 batch loss 0.345024467 epoch total loss 0.353845567\n",
      "Trained batch 749 batch loss 0.335438192 epoch total loss 0.353821\n",
      "Trained batch 750 batch loss 0.322475851 epoch total loss 0.353779227\n",
      "Trained batch 751 batch loss 0.302117437 epoch total loss 0.353710443\n",
      "Trained batch 752 batch loss 0.318427891 epoch total loss 0.353663504\n",
      "Trained batch 753 batch loss 0.333075404 epoch total loss 0.353636146\n",
      "Trained batch 754 batch loss 0.359428227 epoch total loss 0.353643835\n",
      "Trained batch 755 batch loss 0.360371411 epoch total loss 0.353652775\n",
      "Trained batch 756 batch loss 0.349204689 epoch total loss 0.353646904\n",
      "Trained batch 757 batch loss 0.293030024 epoch total loss 0.353566825\n",
      "Trained batch 758 batch loss 0.319734037 epoch total loss 0.353522182\n",
      "Trained batch 759 batch loss 0.344426602 epoch total loss 0.353510201\n",
      "Trained batch 760 batch loss 0.353011429 epoch total loss 0.353509516\n",
      "Trained batch 761 batch loss 0.316739678 epoch total loss 0.353461206\n",
      "Trained batch 762 batch loss 0.340048045 epoch total loss 0.353443623\n",
      "Trained batch 763 batch loss 0.337503761 epoch total loss 0.353422701\n",
      "Trained batch 764 batch loss 0.30380547 epoch total loss 0.353357762\n",
      "Trained batch 765 batch loss 0.334876627 epoch total loss 0.353333592\n",
      "Trained batch 766 batch loss 0.329218686 epoch total loss 0.353302121\n",
      "Trained batch 767 batch loss 0.327898711 epoch total loss 0.353269\n",
      "Trained batch 768 batch loss 0.346350253 epoch total loss 0.35326\n",
      "Trained batch 769 batch loss 0.342029124 epoch total loss 0.353245407\n",
      "Trained batch 770 batch loss 0.336833775 epoch total loss 0.353224069\n",
      "Trained batch 771 batch loss 0.359905094 epoch total loss 0.353232741\n",
      "Trained batch 772 batch loss 0.351558715 epoch total loss 0.353230566\n",
      "Trained batch 773 batch loss 0.358899534 epoch total loss 0.353237897\n",
      "Trained batch 774 batch loss 0.316763133 epoch total loss 0.35319078\n",
      "Trained batch 775 batch loss 0.335469931 epoch total loss 0.353167921\n",
      "Trained batch 776 batch loss 0.322906047 epoch total loss 0.35312891\n",
      "Trained batch 777 batch loss 0.31601578 epoch total loss 0.353081167\n",
      "Trained batch 778 batch loss 0.309490889 epoch total loss 0.353025109\n",
      "Trained batch 779 batch loss 0.299788952 epoch total loss 0.352956742\n",
      "Trained batch 780 batch loss 0.332548797 epoch total loss 0.352930576\n",
      "Trained batch 781 batch loss 0.310856521 epoch total loss 0.352876723\n",
      "Trained batch 782 batch loss 0.331161052 epoch total loss 0.352848917\n",
      "Trained batch 783 batch loss 0.347574234 epoch total loss 0.352842182\n",
      "Trained batch 784 batch loss 0.324116558 epoch total loss 0.352805555\n",
      "Trained batch 785 batch loss 0.318977654 epoch total loss 0.352762431\n",
      "Trained batch 786 batch loss 0.333089679 epoch total loss 0.352737427\n",
      "Trained batch 787 batch loss 0.315850973 epoch total loss 0.352690578\n",
      "Trained batch 788 batch loss 0.289392591 epoch total loss 0.35261023\n",
      "Trained batch 789 batch loss 0.317742616 epoch total loss 0.352566063\n",
      "Trained batch 790 batch loss 0.329371333 epoch total loss 0.352536708\n",
      "Trained batch 791 batch loss 0.310471803 epoch total loss 0.352483541\n",
      "Trained batch 792 batch loss 0.318778813 epoch total loss 0.352440983\n",
      "Trained batch 793 batch loss 0.337077886 epoch total loss 0.352421612\n",
      "Trained batch 794 batch loss 0.301011384 epoch total loss 0.352356881\n",
      "Trained batch 795 batch loss 0.324796379 epoch total loss 0.352322221\n",
      "Trained batch 796 batch loss 0.320656061 epoch total loss 0.352282435\n",
      "Trained batch 797 batch loss 0.301965982 epoch total loss 0.352219284\n",
      "Trained batch 798 batch loss 0.320186377 epoch total loss 0.35217917\n",
      "Trained batch 799 batch loss 0.308166385 epoch total loss 0.352124065\n",
      "Trained batch 800 batch loss 0.312720746 epoch total loss 0.352074802\n",
      "Trained batch 801 batch loss 0.3162857 epoch total loss 0.352030128\n",
      "Trained batch 802 batch loss 0.352915347 epoch total loss 0.352031231\n",
      "Trained batch 803 batch loss 0.353906333 epoch total loss 0.352033556\n",
      "Trained batch 804 batch loss 0.320838273 epoch total loss 0.351994753\n",
      "Trained batch 805 batch loss 0.320893228 epoch total loss 0.351956129\n",
      "Trained batch 806 batch loss 0.323090523 epoch total loss 0.351920307\n",
      "Trained batch 807 batch loss 0.303505063 epoch total loss 0.351860315\n",
      "Trained batch 808 batch loss 0.298730224 epoch total loss 0.351794541\n",
      "Trained batch 809 batch loss 0.299390703 epoch total loss 0.351729751\n",
      "Trained batch 810 batch loss 0.307289302 epoch total loss 0.351674885\n",
      "Trained batch 811 batch loss 0.289832 epoch total loss 0.35159862\n",
      "Trained batch 812 batch loss 0.31013608 epoch total loss 0.351547569\n",
      "Trained batch 813 batch loss 0.322801143 epoch total loss 0.351512223\n",
      "Trained batch 814 batch loss 0.282560408 epoch total loss 0.351427525\n",
      "Trained batch 815 batch loss 0.323113471 epoch total loss 0.351392806\n",
      "Trained batch 816 batch loss 0.325068265 epoch total loss 0.351360559\n",
      "Trained batch 817 batch loss 0.345272154 epoch total loss 0.351353109\n",
      "Trained batch 818 batch loss 0.316465139 epoch total loss 0.351310462\n",
      "Trained batch 819 batch loss 0.334501147 epoch total loss 0.351289928\n",
      "Trained batch 820 batch loss 0.316588461 epoch total loss 0.351247609\n",
      "Trained batch 821 batch loss 0.327172607 epoch total loss 0.351218283\n",
      "Trained batch 822 batch loss 0.314372271 epoch total loss 0.35117346\n",
      "Trained batch 823 batch loss 0.333081 epoch total loss 0.351151466\n",
      "Trained batch 824 batch loss 0.386874259 epoch total loss 0.351194799\n",
      "Trained batch 825 batch loss 0.348486394 epoch total loss 0.351191521\n",
      "Trained batch 826 batch loss 0.35153234 epoch total loss 0.351191938\n",
      "Trained batch 827 batch loss 0.320352793 epoch total loss 0.351154625\n",
      "Trained batch 828 batch loss 0.343180209 epoch total loss 0.351144969\n",
      "Trained batch 829 batch loss 0.31467095 epoch total loss 0.351100981\n",
      "Trained batch 830 batch loss 0.306624353 epoch total loss 0.351047367\n",
      "Trained batch 831 batch loss 0.316425562 epoch total loss 0.351005733\n",
      "Trained batch 832 batch loss 0.326503783 epoch total loss 0.350976288\n",
      "Trained batch 833 batch loss 0.329826117 epoch total loss 0.350950897\n",
      "Trained batch 834 batch loss 0.313810349 epoch total loss 0.350906372\n",
      "Trained batch 835 batch loss 0.326461703 epoch total loss 0.350877076\n",
      "Trained batch 836 batch loss 0.327292413 epoch total loss 0.350848883\n",
      "Trained batch 837 batch loss 0.302724 epoch total loss 0.350791395\n",
      "Trained batch 838 batch loss 0.316278815 epoch total loss 0.350750208\n",
      "Trained batch 839 batch loss 0.338034183 epoch total loss 0.350735068\n",
      "Trained batch 840 batch loss 0.336760759 epoch total loss 0.350718439\n",
      "Trained batch 841 batch loss 0.33728683 epoch total loss 0.350702465\n",
      "Trained batch 842 batch loss 0.325669497 epoch total loss 0.350672752\n",
      "Trained batch 843 batch loss 0.307770729 epoch total loss 0.350621849\n",
      "Trained batch 844 batch loss 0.320533335 epoch total loss 0.350586176\n",
      "Trained batch 845 batch loss 0.312195539 epoch total loss 0.350540757\n",
      "Trained batch 846 batch loss 0.307370186 epoch total loss 0.350489736\n",
      "Trained batch 847 batch loss 0.273184597 epoch total loss 0.350398481\n",
      "Trained batch 848 batch loss 0.272257686 epoch total loss 0.350306302\n",
      "Trained batch 849 batch loss 0.321178943 epoch total loss 0.350272\n",
      "Trained batch 850 batch loss 0.350518048 epoch total loss 0.350272298\n",
      "Trained batch 851 batch loss 0.383497 epoch total loss 0.350311309\n",
      "Trained batch 852 batch loss 0.362332642 epoch total loss 0.350325435\n",
      "Trained batch 853 batch loss 0.326173097 epoch total loss 0.350297123\n",
      "Trained batch 854 batch loss 0.31368193 epoch total loss 0.350254238\n",
      "Trained batch 855 batch loss 0.328229934 epoch total loss 0.350228459\n",
      "Trained batch 856 batch loss 0.331974477 epoch total loss 0.35020715\n",
      "Trained batch 857 batch loss 0.345301718 epoch total loss 0.350201428\n",
      "Trained batch 858 batch loss 0.329237878 epoch total loss 0.35017696\n",
      "Trained batch 859 batch loss 0.342634052 epoch total loss 0.350168169\n",
      "Trained batch 860 batch loss 0.325947881 epoch total loss 0.350140035\n",
      "Trained batch 861 batch loss 0.335867614 epoch total loss 0.350123465\n",
      "Trained batch 862 batch loss 0.31960988 epoch total loss 0.35008806\n",
      "Trained batch 863 batch loss 0.323191106 epoch total loss 0.350056887\n",
      "Trained batch 864 batch loss 0.307044655 epoch total loss 0.350007087\n",
      "Trained batch 865 batch loss 0.329669625 epoch total loss 0.349983603\n",
      "Trained batch 866 batch loss 0.334669679 epoch total loss 0.3499659\n",
      "Trained batch 867 batch loss 0.275490433 epoch total loss 0.34987998\n",
      "Trained batch 868 batch loss 0.289895058 epoch total loss 0.349810869\n",
      "Trained batch 869 batch loss 0.291986465 epoch total loss 0.34974432\n",
      "Trained batch 870 batch loss 0.306383163 epoch total loss 0.34969452\n",
      "Trained batch 871 batch loss 0.313253284 epoch total loss 0.349652678\n",
      "Trained batch 872 batch loss 0.316704631 epoch total loss 0.349614918\n",
      "Trained batch 873 batch loss 0.317096978 epoch total loss 0.349577665\n",
      "Trained batch 874 batch loss 0.330181956 epoch total loss 0.349555463\n",
      "Trained batch 875 batch loss 0.344508857 epoch total loss 0.349549711\n",
      "Trained batch 876 batch loss 0.361715436 epoch total loss 0.349563599\n",
      "Trained batch 877 batch loss 0.325098425 epoch total loss 0.349535704\n",
      "Trained batch 878 batch loss 0.318976343 epoch total loss 0.349500895\n",
      "Trained batch 879 batch loss 0.332514852 epoch total loss 0.349481583\n",
      "Trained batch 880 batch loss 0.288731515 epoch total loss 0.349412531\n",
      "Trained batch 881 batch loss 0.287526906 epoch total loss 0.349342316\n",
      "Trained batch 882 batch loss 0.338943332 epoch total loss 0.349330485\n",
      "Trained batch 883 batch loss 0.328156233 epoch total loss 0.349306524\n",
      "Trained batch 884 batch loss 0.339199573 epoch total loss 0.34929508\n",
      "Trained batch 885 batch loss 0.305562824 epoch total loss 0.349245667\n",
      "Trained batch 886 batch loss 0.325371087 epoch total loss 0.349218756\n",
      "Trained batch 887 batch loss 0.315191388 epoch total loss 0.349180371\n",
      "Trained batch 888 batch loss 0.322330475 epoch total loss 0.349150121\n",
      "Trained batch 889 batch loss 0.295021147 epoch total loss 0.349089235\n",
      "Trained batch 890 batch loss 0.322583169 epoch total loss 0.349059433\n",
      "Trained batch 891 batch loss 0.338886291 epoch total loss 0.349048048\n",
      "Trained batch 892 batch loss 0.311887085 epoch total loss 0.349006385\n",
      "Trained batch 893 batch loss 0.34017244 epoch total loss 0.34899649\n",
      "Trained batch 894 batch loss 0.340711027 epoch total loss 0.348987222\n",
      "Trained batch 895 batch loss 0.343441814 epoch total loss 0.348981023\n",
      "Trained batch 896 batch loss 0.343998551 epoch total loss 0.34897545\n",
      "Trained batch 897 batch loss 0.319121122 epoch total loss 0.348942161\n",
      "Trained batch 898 batch loss 0.312405467 epoch total loss 0.34890148\n",
      "Trained batch 899 batch loss 0.313240588 epoch total loss 0.348861814\n",
      "Trained batch 900 batch loss 0.332730979 epoch total loss 0.348843902\n",
      "Trained batch 901 batch loss 0.35254854 epoch total loss 0.348848\n",
      "Trained batch 902 batch loss 0.31758523 epoch total loss 0.348813355\n",
      "Trained batch 903 batch loss 0.325008512 epoch total loss 0.34878698\n",
      "Trained batch 904 batch loss 0.340065598 epoch total loss 0.348777324\n",
      "Trained batch 905 batch loss 0.350882441 epoch total loss 0.348779678\n",
      "Trained batch 906 batch loss 0.305214942 epoch total loss 0.348731577\n",
      "Trained batch 907 batch loss 0.303113371 epoch total loss 0.348681271\n",
      "Trained batch 908 batch loss 0.32289207 epoch total loss 0.348652869\n",
      "Trained batch 909 batch loss 0.348976851 epoch total loss 0.348653227\n",
      "Trained batch 910 batch loss 0.344895273 epoch total loss 0.348649114\n",
      "Trained batch 911 batch loss 0.319986135 epoch total loss 0.348617643\n",
      "Trained batch 912 batch loss 0.30330497 epoch total loss 0.348567963\n",
      "Trained batch 913 batch loss 0.304401338 epoch total loss 0.348519593\n",
      "Trained batch 914 batch loss 0.302621841 epoch total loss 0.348469377\n",
      "Trained batch 915 batch loss 0.330676734 epoch total loss 0.348449945\n",
      "Trained batch 916 batch loss 0.302682936 epoch total loss 0.348399967\n",
      "Trained batch 917 batch loss 0.325023443 epoch total loss 0.348374456\n",
      "Trained batch 918 batch loss 0.352529317 epoch total loss 0.348379\n",
      "Trained batch 919 batch loss 0.342335373 epoch total loss 0.34837243\n",
      "Trained batch 920 batch loss 0.335460722 epoch total loss 0.348358393\n",
      "Trained batch 921 batch loss 0.339262187 epoch total loss 0.348348498\n",
      "Trained batch 922 batch loss 0.333515763 epoch total loss 0.348332435\n",
      "Trained batch 923 batch loss 0.329637766 epoch total loss 0.348312199\n",
      "Trained batch 924 batch loss 0.335974365 epoch total loss 0.348298848\n",
      "Trained batch 925 batch loss 0.351322591 epoch total loss 0.348302096\n",
      "Trained batch 926 batch loss 0.339884877 epoch total loss 0.348293\n",
      "Trained batch 927 batch loss 0.325366825 epoch total loss 0.34826827\n",
      "Trained batch 928 batch loss 0.354928 epoch total loss 0.348275453\n",
      "Trained batch 929 batch loss 0.359891 epoch total loss 0.34828794\n",
      "Trained batch 930 batch loss 0.379622757 epoch total loss 0.348321646\n",
      "Trained batch 931 batch loss 0.329187721 epoch total loss 0.348301083\n",
      "Trained batch 932 batch loss 0.311071187 epoch total loss 0.348261148\n",
      "Trained batch 933 batch loss 0.324899435 epoch total loss 0.348236084\n",
      "Trained batch 934 batch loss 0.338237286 epoch total loss 0.348225355\n",
      "Trained batch 935 batch loss 0.325233102 epoch total loss 0.348200768\n",
      "Trained batch 936 batch loss 0.33063966 epoch total loss 0.348182\n",
      "Trained batch 937 batch loss 0.335981369 epoch total loss 0.348168969\n",
      "Trained batch 938 batch loss 0.339677572 epoch total loss 0.348159909\n",
      "Trained batch 939 batch loss 0.310908765 epoch total loss 0.348120242\n",
      "Trained batch 940 batch loss 0.300278753 epoch total loss 0.34806937\n",
      "Trained batch 941 batch loss 0.307249 epoch total loss 0.348026\n",
      "Trained batch 942 batch loss 0.318627149 epoch total loss 0.347994804\n",
      "Trained batch 943 batch loss 0.323478281 epoch total loss 0.347968817\n",
      "Trained batch 944 batch loss 0.345376 epoch total loss 0.347966045\n",
      "Trained batch 945 batch loss 0.354544371 epoch total loss 0.347973019\n",
      "Trained batch 946 batch loss 0.331662029 epoch total loss 0.347955793\n",
      "Trained batch 947 batch loss 0.335608065 epoch total loss 0.34794274\n",
      "Trained batch 948 batch loss 0.338591725 epoch total loss 0.347932875\n",
      "Trained batch 949 batch loss 0.333665 epoch total loss 0.347917855\n",
      "Trained batch 950 batch loss 0.319697887 epoch total loss 0.347888142\n",
      "Trained batch 951 batch loss 0.317106724 epoch total loss 0.347855777\n",
      "Trained batch 952 batch loss 0.318858683 epoch total loss 0.347825319\n",
      "Trained batch 953 batch loss 0.298918873 epoch total loss 0.347774\n",
      "Trained batch 954 batch loss 0.311900556 epoch total loss 0.347736388\n",
      "Trained batch 955 batch loss 0.324503839 epoch total loss 0.34771204\n",
      "Trained batch 956 batch loss 0.333793461 epoch total loss 0.347697496\n",
      "Trained batch 957 batch loss 0.35164547 epoch total loss 0.347701639\n",
      "Trained batch 958 batch loss 0.350617707 epoch total loss 0.347704679\n",
      "Trained batch 959 batch loss 0.350171745 epoch total loss 0.347707242\n",
      "Trained batch 960 batch loss 0.336806327 epoch total loss 0.347695857\n",
      "Trained batch 961 batch loss 0.328532338 epoch total loss 0.34767592\n",
      "Trained batch 962 batch loss 0.315752149 epoch total loss 0.34764275\n",
      "Trained batch 963 batch loss 0.334485352 epoch total loss 0.34762907\n",
      "Trained batch 964 batch loss 0.323862016 epoch total loss 0.347604394\n",
      "Trained batch 965 batch loss 0.331121713 epoch total loss 0.347587317\n",
      "Trained batch 966 batch loss 0.3267124 epoch total loss 0.347565711\n",
      "Trained batch 967 batch loss 0.333494395 epoch total loss 0.347551167\n",
      "Trained batch 968 batch loss 0.307135522 epoch total loss 0.347509414\n",
      "Trained batch 969 batch loss 0.292273045 epoch total loss 0.347452402\n",
      "Trained batch 970 batch loss 0.277890146 epoch total loss 0.347380668\n",
      "Trained batch 971 batch loss 0.273511529 epoch total loss 0.347304583\n",
      "Trained batch 972 batch loss 0.334490299 epoch total loss 0.34729141\n",
      "Trained batch 973 batch loss 0.340260863 epoch total loss 0.347284198\n",
      "Trained batch 974 batch loss 0.34913063 epoch total loss 0.347286105\n",
      "Trained batch 975 batch loss 0.366687238 epoch total loss 0.347306\n",
      "Trained batch 976 batch loss 0.33503896 epoch total loss 0.347293437\n",
      "Trained batch 977 batch loss 0.327819884 epoch total loss 0.347273529\n",
      "Trained batch 978 batch loss 0.354601532 epoch total loss 0.347281\n",
      "Trained batch 979 batch loss 0.366361022 epoch total loss 0.3473005\n",
      "Trained batch 980 batch loss 0.336259395 epoch total loss 0.347289264\n",
      "Trained batch 981 batch loss 0.363592893 epoch total loss 0.347305864\n",
      "Trained batch 982 batch loss 0.313980311 epoch total loss 0.347271949\n",
      "Trained batch 983 batch loss 0.342922598 epoch total loss 0.347267538\n",
      "Trained batch 984 batch loss 0.294048429 epoch total loss 0.347213447\n",
      "Trained batch 985 batch loss 0.341293126 epoch total loss 0.347207397\n",
      "Trained batch 986 batch loss 0.326113731 epoch total loss 0.347186\n",
      "Trained batch 987 batch loss 0.318142891 epoch total loss 0.347156584\n",
      "Trained batch 988 batch loss 0.289508939 epoch total loss 0.347098261\n",
      "Trained batch 989 batch loss 0.294133127 epoch total loss 0.347044706\n",
      "Trained batch 990 batch loss 0.292997152 epoch total loss 0.346990108\n",
      "Trained batch 991 batch loss 0.312966734 epoch total loss 0.346955776\n",
      "Trained batch 992 batch loss 0.352705181 epoch total loss 0.346961558\n",
      "Trained batch 993 batch loss 0.394123673 epoch total loss 0.347009063\n",
      "Trained batch 994 batch loss 0.381805897 epoch total loss 0.347044051\n",
      "Trained batch 995 batch loss 0.337304831 epoch total loss 0.347034276\n",
      "Trained batch 996 batch loss 0.366236657 epoch total loss 0.347053558\n",
      "Trained batch 997 batch loss 0.377132058 epoch total loss 0.347083718\n",
      "Trained batch 998 batch loss 0.32512182 epoch total loss 0.347061723\n",
      "Trained batch 999 batch loss 0.34360826 epoch total loss 0.347058266\n",
      "Trained batch 1000 batch loss 0.348541617 epoch total loss 0.347059757\n",
      "Trained batch 1001 batch loss 0.311136335 epoch total loss 0.347023845\n",
      "Trained batch 1002 batch loss 0.36230734 epoch total loss 0.347039104\n",
      "Trained batch 1003 batch loss 0.342466593 epoch total loss 0.347034544\n",
      "Trained batch 1004 batch loss 0.336733222 epoch total loss 0.347024292\n",
      "Trained batch 1005 batch loss 0.326992869 epoch total loss 0.347004354\n",
      "Trained batch 1006 batch loss 0.281296045 epoch total loss 0.346939057\n",
      "Trained batch 1007 batch loss 0.31869033 epoch total loss 0.346911\n",
      "Trained batch 1008 batch loss 0.316505432 epoch total loss 0.346880823\n",
      "Trained batch 1009 batch loss 0.312521636 epoch total loss 0.346846789\n",
      "Trained batch 1010 batch loss 0.319857031 epoch total loss 0.346820056\n",
      "Trained batch 1011 batch loss 0.3529194 epoch total loss 0.346826077\n",
      "Trained batch 1012 batch loss 0.37748757 epoch total loss 0.346856385\n",
      "Trained batch 1013 batch loss 0.363520622 epoch total loss 0.346872866\n",
      "Trained batch 1014 batch loss 0.356073737 epoch total loss 0.346881926\n",
      "Trained batch 1015 batch loss 0.328965753 epoch total loss 0.346864283\n",
      "Trained batch 1016 batch loss 0.283566475 epoch total loss 0.346802\n",
      "Trained batch 1017 batch loss 0.269472361 epoch total loss 0.346725971\n",
      "Trained batch 1018 batch loss 0.253393292 epoch total loss 0.346634269\n",
      "Trained batch 1019 batch loss 0.290821522 epoch total loss 0.346579522\n",
      "Trained batch 1020 batch loss 0.308591694 epoch total loss 0.346542269\n",
      "Trained batch 1021 batch loss 0.308974922 epoch total loss 0.346505463\n",
      "Trained batch 1022 batch loss 0.336541474 epoch total loss 0.346495718\n",
      "Trained batch 1023 batch loss 0.327218056 epoch total loss 0.346476853\n",
      "Trained batch 1024 batch loss 0.333677471 epoch total loss 0.346464366\n",
      "Trained batch 1025 batch loss 0.304002345 epoch total loss 0.34642294\n",
      "Trained batch 1026 batch loss 0.28436321 epoch total loss 0.346362472\n",
      "Trained batch 1027 batch loss 0.284582675 epoch total loss 0.346302301\n",
      "Trained batch 1028 batch loss 0.306810826 epoch total loss 0.346263885\n",
      "Trained batch 1029 batch loss 0.324860215 epoch total loss 0.346243113\n",
      "Trained batch 1030 batch loss 0.317303747 epoch total loss 0.34621498\n",
      "Trained batch 1031 batch loss 0.31220904 epoch total loss 0.346182\n",
      "Trained batch 1032 batch loss 0.299875647 epoch total loss 0.346137106\n",
      "Trained batch 1033 batch loss 0.329927504 epoch total loss 0.34612143\n",
      "Trained batch 1034 batch loss 0.306564152 epoch total loss 0.346083134\n",
      "Trained batch 1035 batch loss 0.344101667 epoch total loss 0.346081257\n",
      "Trained batch 1036 batch loss 0.32127285 epoch total loss 0.346057296\n",
      "Trained batch 1037 batch loss 0.321147949 epoch total loss 0.346033245\n",
      "Trained batch 1038 batch loss 0.285014927 epoch total loss 0.345974475\n",
      "Trained batch 1039 batch loss 0.263364375 epoch total loss 0.345894963\n",
      "Trained batch 1040 batch loss 0.271358907 epoch total loss 0.345823288\n",
      "Trained batch 1041 batch loss 0.282378525 epoch total loss 0.345762342\n",
      "Trained batch 1042 batch loss 0.33365944 epoch total loss 0.345750719\n",
      "Trained batch 1043 batch loss 0.34534052 epoch total loss 0.345750332\n",
      "Trained batch 1044 batch loss 0.323583364 epoch total loss 0.345729083\n",
      "Trained batch 1045 batch loss 0.314688683 epoch total loss 0.3456994\n",
      "Trained batch 1046 batch loss 0.321069449 epoch total loss 0.345675856\n",
      "Trained batch 1047 batch loss 0.286857367 epoch total loss 0.345619678\n",
      "Trained batch 1048 batch loss 0.303905308 epoch total loss 0.345579863\n",
      "Trained batch 1049 batch loss 0.34844175 epoch total loss 0.345582604\n",
      "Trained batch 1050 batch loss 0.340890348 epoch total loss 0.345578134\n",
      "Trained batch 1051 batch loss 0.349801 epoch total loss 0.345582128\n",
      "Trained batch 1052 batch loss 0.353572398 epoch total loss 0.345589727\n",
      "Trained batch 1053 batch loss 0.33618176 epoch total loss 0.345580786\n",
      "Trained batch 1054 batch loss 0.343632877 epoch total loss 0.345578939\n",
      "Trained batch 1055 batch loss 0.352176934 epoch total loss 0.345585197\n",
      "Trained batch 1056 batch loss 0.321369946 epoch total loss 0.345562279\n",
      "Trained batch 1057 batch loss 0.343213528 epoch total loss 0.345560044\n",
      "Trained batch 1058 batch loss 0.333082825 epoch total loss 0.345548242\n",
      "Trained batch 1059 batch loss 0.369968712 epoch total loss 0.34557128\n",
      "Trained batch 1060 batch loss 0.33441332 epoch total loss 0.345560759\n",
      "Trained batch 1061 batch loss 0.332654625 epoch total loss 0.34554857\n",
      "Trained batch 1062 batch loss 0.327598125 epoch total loss 0.345531672\n",
      "Trained batch 1063 batch loss 0.305831552 epoch total loss 0.34549433\n",
      "Trained batch 1064 batch loss 0.294104755 epoch total loss 0.34544602\n",
      "Trained batch 1065 batch loss 0.340489328 epoch total loss 0.345441371\n",
      "Trained batch 1066 batch loss 0.331648499 epoch total loss 0.345428407\n",
      "Trained batch 1067 batch loss 0.309702456 epoch total loss 0.345394909\n",
      "Trained batch 1068 batch loss 0.341563642 epoch total loss 0.345391333\n",
      "Trained batch 1069 batch loss 0.312227786 epoch total loss 0.345360309\n",
      "Trained batch 1070 batch loss 0.32260108 epoch total loss 0.34533903\n",
      "Trained batch 1071 batch loss 0.301217318 epoch total loss 0.345297813\n",
      "Trained batch 1072 batch loss 0.326917887 epoch total loss 0.345280647\n",
      "Trained batch 1073 batch loss 0.329816341 epoch total loss 0.345266223\n",
      "Trained batch 1074 batch loss 0.309802592 epoch total loss 0.345233232\n",
      "Trained batch 1075 batch loss 0.299822032 epoch total loss 0.345191\n",
      "Trained batch 1076 batch loss 0.327080071 epoch total loss 0.345174164\n",
      "Trained batch 1077 batch loss 0.323054075 epoch total loss 0.34515363\n",
      "Trained batch 1078 batch loss 0.340144664 epoch total loss 0.345149\n",
      "Trained batch 1079 batch loss 0.33386746 epoch total loss 0.34513855\n",
      "Trained batch 1080 batch loss 0.292075306 epoch total loss 0.345089406\n",
      "Trained batch 1081 batch loss 0.304547966 epoch total loss 0.345051885\n",
      "Trained batch 1082 batch loss 0.262287587 epoch total loss 0.344975412\n",
      "Trained batch 1083 batch loss 0.281782478 epoch total loss 0.344917059\n",
      "Trained batch 1084 batch loss 0.282693 epoch total loss 0.34485963\n",
      "Trained batch 1085 batch loss 0.31846422 epoch total loss 0.344835311\n",
      "Trained batch 1086 batch loss 0.304641753 epoch total loss 0.344798297\n",
      "Trained batch 1087 batch loss 0.303042859 epoch total loss 0.344759881\n",
      "Trained batch 1088 batch loss 0.27177918 epoch total loss 0.344692826\n",
      "Trained batch 1089 batch loss 0.262340605 epoch total loss 0.344617188\n",
      "Trained batch 1090 batch loss 0.313752592 epoch total loss 0.344588876\n",
      "Trained batch 1091 batch loss 0.330866963 epoch total loss 0.344576299\n",
      "Trained batch 1092 batch loss 0.346845359 epoch total loss 0.344578356\n",
      "Trained batch 1093 batch loss 0.339800179 epoch total loss 0.344574\n",
      "Trained batch 1094 batch loss 0.317422 epoch total loss 0.344549179\n",
      "Trained batch 1095 batch loss 0.301015377 epoch total loss 0.344509423\n",
      "Trained batch 1096 batch loss 0.323053062 epoch total loss 0.344489843\n",
      "Trained batch 1097 batch loss 0.315885663 epoch total loss 0.344463795\n",
      "Trained batch 1098 batch loss 0.348516852 epoch total loss 0.344467461\n",
      "Trained batch 1099 batch loss 0.324072033 epoch total loss 0.344448894\n",
      "Trained batch 1100 batch loss 0.339792788 epoch total loss 0.344444662\n",
      "Trained batch 1101 batch loss 0.351346135 epoch total loss 0.344450921\n",
      "Trained batch 1102 batch loss 0.336089194 epoch total loss 0.344443351\n",
      "Trained batch 1103 batch loss 0.337143302 epoch total loss 0.344436735\n",
      "Trained batch 1104 batch loss 0.321506619 epoch total loss 0.344415963\n",
      "Trained batch 1105 batch loss 0.286966681 epoch total loss 0.344363958\n",
      "Trained batch 1106 batch loss 0.31696856 epoch total loss 0.344339192\n",
      "Trained batch 1107 batch loss 0.2928873 epoch total loss 0.3442927\n",
      "Trained batch 1108 batch loss 0.306139469 epoch total loss 0.344258279\n",
      "Trained batch 1109 batch loss 0.325840592 epoch total loss 0.344241679\n",
      "Trained batch 1110 batch loss 0.300241709 epoch total loss 0.344202\n",
      "Trained batch 1111 batch loss 0.29018569 epoch total loss 0.344153404\n",
      "Trained batch 1112 batch loss 0.316779763 epoch total loss 0.344128788\n",
      "Trained batch 1113 batch loss 0.288733333 epoch total loss 0.344079018\n",
      "Trained batch 1114 batch loss 0.295226783 epoch total loss 0.344035149\n",
      "Trained batch 1115 batch loss 0.315947354 epoch total loss 0.344009966\n",
      "Trained batch 1116 batch loss 0.279069483 epoch total loss 0.343951792\n",
      "Trained batch 1117 batch loss 0.283764124 epoch total loss 0.343897879\n",
      "Trained batch 1118 batch loss 0.30447042 epoch total loss 0.343862623\n",
      "Trained batch 1119 batch loss 0.290279984 epoch total loss 0.343814731\n",
      "Trained batch 1120 batch loss 0.303981751 epoch total loss 0.343779176\n",
      "Trained batch 1121 batch loss 0.323428452 epoch total loss 0.343761027\n",
      "Trained batch 1122 batch loss 0.308451772 epoch total loss 0.343729556\n",
      "Trained batch 1123 batch loss 0.327307582 epoch total loss 0.343714923\n",
      "Trained batch 1124 batch loss 0.337280244 epoch total loss 0.343709201\n",
      "Trained batch 1125 batch loss 0.33582449 epoch total loss 0.343702167\n",
      "Trained batch 1126 batch loss 0.355010629 epoch total loss 0.343712211\n",
      "Trained batch 1127 batch loss 0.32076633 epoch total loss 0.343691856\n",
      "Trained batch 1128 batch loss 0.320189565 epoch total loss 0.343671024\n",
      "Trained batch 1129 batch loss 0.320477605 epoch total loss 0.34365046\n",
      "Trained batch 1130 batch loss 0.288214892 epoch total loss 0.343601406\n",
      "Trained batch 1131 batch loss 0.306210399 epoch total loss 0.343568355\n",
      "Trained batch 1132 batch loss 0.33377856 epoch total loss 0.343559682\n",
      "Trained batch 1133 batch loss 0.324355543 epoch total loss 0.343542725\n",
      "Trained batch 1134 batch loss 0.290156275 epoch total loss 0.343495667\n",
      "Trained batch 1135 batch loss 0.298926175 epoch total loss 0.343456388\n",
      "Trained batch 1136 batch loss 0.304976076 epoch total loss 0.343422502\n",
      "Trained batch 1137 batch loss 0.32043618 epoch total loss 0.343402296\n",
      "Trained batch 1138 batch loss 0.351362288 epoch total loss 0.34340927\n",
      "Trained batch 1139 batch loss 0.331602693 epoch total loss 0.343398899\n",
      "Trained batch 1140 batch loss 0.297442198 epoch total loss 0.343358606\n",
      "Trained batch 1141 batch loss 0.31105274 epoch total loss 0.343330294\n",
      "Trained batch 1142 batch loss 0.320177168 epoch total loss 0.343310028\n",
      "Trained batch 1143 batch loss 0.329808652 epoch total loss 0.343298227\n",
      "Trained batch 1144 batch loss 0.329145581 epoch total loss 0.343285829\n",
      "Trained batch 1145 batch loss 0.311008126 epoch total loss 0.343257636\n",
      "Trained batch 1146 batch loss 0.307293266 epoch total loss 0.343226254\n",
      "Trained batch 1147 batch loss 0.305345 epoch total loss 0.343193233\n",
      "Trained batch 1148 batch loss 0.313031107 epoch total loss 0.343166947\n",
      "Trained batch 1149 batch loss 0.301475883 epoch total loss 0.343130678\n",
      "Trained batch 1150 batch loss 0.326864153 epoch total loss 0.343116522\n",
      "Trained batch 1151 batch loss 0.314130068 epoch total loss 0.343091339\n",
      "Trained batch 1152 batch loss 0.363344878 epoch total loss 0.343108922\n",
      "Trained batch 1153 batch loss 0.295437723 epoch total loss 0.343067586\n",
      "Trained batch 1154 batch loss 0.301977873 epoch total loss 0.343031973\n",
      "Trained batch 1155 batch loss 0.306512833 epoch total loss 0.343000352\n",
      "Trained batch 1156 batch loss 0.296443552 epoch total loss 0.342960089\n",
      "Trained batch 1157 batch loss 0.322714865 epoch total loss 0.342942595\n",
      "Trained batch 1158 batch loss 0.318278223 epoch total loss 0.342921287\n",
      "Trained batch 1159 batch loss 0.318276614 epoch total loss 0.3429\n",
      "Trained batch 1160 batch loss 0.33152315 epoch total loss 0.342890203\n",
      "Trained batch 1161 batch loss 0.319359124 epoch total loss 0.342869937\n",
      "Trained batch 1162 batch loss 0.301929384 epoch total loss 0.342834711\n",
      "Trained batch 1163 batch loss 0.321907103 epoch total loss 0.34281671\n",
      "Trained batch 1164 batch loss 0.290802121 epoch total loss 0.342772\n",
      "Trained batch 1165 batch loss 0.305526078 epoch total loss 0.342740029\n",
      "Trained batch 1166 batch loss 0.314632028 epoch total loss 0.342715949\n",
      "Trained batch 1167 batch loss 0.306903839 epoch total loss 0.342685252\n",
      "Trained batch 1168 batch loss 0.319553703 epoch total loss 0.342665464\n",
      "Trained batch 1169 batch loss 0.315006167 epoch total loss 0.342641801\n",
      "Trained batch 1170 batch loss 0.296462 epoch total loss 0.342602313\n",
      "Trained batch 1171 batch loss 0.303700179 epoch total loss 0.342569083\n",
      "Trained batch 1172 batch loss 0.339268863 epoch total loss 0.342566282\n",
      "Trained batch 1173 batch loss 0.326432437 epoch total loss 0.342552543\n",
      "Trained batch 1174 batch loss 0.305029809 epoch total loss 0.342520565\n",
      "Trained batch 1175 batch loss 0.266984642 epoch total loss 0.342456281\n",
      "Trained batch 1176 batch loss 0.308995336 epoch total loss 0.34242782\n",
      "Trained batch 1177 batch loss 0.284926295 epoch total loss 0.342378974\n",
      "Trained batch 1178 batch loss 0.295573175 epoch total loss 0.342339218\n",
      "Trained batch 1179 batch loss 0.313884199 epoch total loss 0.342315078\n",
      "Trained batch 1180 batch loss 0.341747344 epoch total loss 0.342314601\n",
      "Trained batch 1181 batch loss 0.326959759 epoch total loss 0.342301577\n",
      "Trained batch 1182 batch loss 0.315309465 epoch total loss 0.342278749\n",
      "Trained batch 1183 batch loss 0.33940348 epoch total loss 0.342276335\n",
      "Trained batch 1184 batch loss 0.355553 epoch total loss 0.34228754\n",
      "Trained batch 1185 batch loss 0.383524746 epoch total loss 0.34232235\n",
      "Trained batch 1186 batch loss 0.380940408 epoch total loss 0.342354923\n",
      "Trained batch 1187 batch loss 0.361530483 epoch total loss 0.342371076\n",
      "Trained batch 1188 batch loss 0.302017868 epoch total loss 0.342337132\n",
      "Trained batch 1189 batch loss 0.290871948 epoch total loss 0.342293829\n",
      "Trained batch 1190 batch loss 0.348445833 epoch total loss 0.342299\n",
      "Trained batch 1191 batch loss 0.3654387 epoch total loss 0.342318445\n",
      "Trained batch 1192 batch loss 0.332312673 epoch total loss 0.342310041\n",
      "Trained batch 1193 batch loss 0.32882151 epoch total loss 0.342298746\n",
      "Trained batch 1194 batch loss 0.335695773 epoch total loss 0.342293203\n",
      "Trained batch 1195 batch loss 0.314784944 epoch total loss 0.342270195\n",
      "Trained batch 1196 batch loss 0.336355954 epoch total loss 0.342265248\n",
      "Trained batch 1197 batch loss 0.318686634 epoch total loss 0.342245549\n",
      "Trained batch 1198 batch loss 0.352064073 epoch total loss 0.342253745\n",
      "Trained batch 1199 batch loss 0.356713265 epoch total loss 0.342265815\n",
      "Trained batch 1200 batch loss 0.324118048 epoch total loss 0.342250705\n",
      "Trained batch 1201 batch loss 0.329815269 epoch total loss 0.342240334\n",
      "Trained batch 1202 batch loss 0.330919683 epoch total loss 0.342230916\n",
      "Trained batch 1203 batch loss 0.348162442 epoch total loss 0.342235863\n",
      "Trained batch 1204 batch loss 0.327814043 epoch total loss 0.342223883\n",
      "Trained batch 1205 batch loss 0.306882322 epoch total loss 0.342194557\n",
      "Trained batch 1206 batch loss 0.318856299 epoch total loss 0.342175215\n",
      "Trained batch 1207 batch loss 0.308137864 epoch total loss 0.342147\n",
      "Trained batch 1208 batch loss 0.294418484 epoch total loss 0.342107505\n",
      "Trained batch 1209 batch loss 0.315313309 epoch total loss 0.342085332\n",
      "Trained batch 1210 batch loss 0.316226542 epoch total loss 0.342063963\n",
      "Trained batch 1211 batch loss 0.316279113 epoch total loss 0.342042685\n",
      "Trained batch 1212 batch loss 0.30412516 epoch total loss 0.342011392\n",
      "Trained batch 1213 batch loss 0.304834068 epoch total loss 0.341980755\n",
      "Trained batch 1214 batch loss 0.300279289 epoch total loss 0.341946423\n",
      "Trained batch 1215 batch loss 0.315163821 epoch total loss 0.341924369\n",
      "Trained batch 1216 batch loss 0.303712815 epoch total loss 0.341892958\n",
      "Trained batch 1217 batch loss 0.299220622 epoch total loss 0.34185788\n",
      "Trained batch 1218 batch loss 0.30224517 epoch total loss 0.341825366\n",
      "Trained batch 1219 batch loss 0.341436714 epoch total loss 0.341825038\n",
      "Trained batch 1220 batch loss 0.319276363 epoch total loss 0.341806561\n",
      "Trained batch 1221 batch loss 0.328462303 epoch total loss 0.341795623\n",
      "Trained batch 1222 batch loss 0.3422665 epoch total loss 0.341796\n",
      "Trained batch 1223 batch loss 0.349048108 epoch total loss 0.341801941\n",
      "Trained batch 1224 batch loss 0.36734575 epoch total loss 0.341822803\n",
      "Trained batch 1225 batch loss 0.358299911 epoch total loss 0.341836274\n",
      "Trained batch 1226 batch loss 0.317050099 epoch total loss 0.341816038\n",
      "Trained batch 1227 batch loss 0.315717131 epoch total loss 0.341794759\n",
      "Trained batch 1228 batch loss 0.354779869 epoch total loss 0.341805339\n",
      "Trained batch 1229 batch loss 0.325502336 epoch total loss 0.341792047\n",
      "Trained batch 1230 batch loss 0.314624548 epoch total loss 0.34177\n",
      "Trained batch 1231 batch loss 0.315624863 epoch total loss 0.341748744\n",
      "Trained batch 1232 batch loss 0.305641 epoch total loss 0.341719419\n",
      "Trained batch 1233 batch loss 0.293346018 epoch total loss 0.341680169\n",
      "Trained batch 1234 batch loss 0.302470863 epoch total loss 0.3416484\n",
      "Trained batch 1235 batch loss 0.326215625 epoch total loss 0.341635883\n",
      "Trained batch 1236 batch loss 0.310939789 epoch total loss 0.341611058\n",
      "Trained batch 1237 batch loss 0.313607693 epoch total loss 0.341588408\n",
      "Trained batch 1238 batch loss 0.335103661 epoch total loss 0.341583192\n",
      "Trained batch 1239 batch loss 0.334166378 epoch total loss 0.341577202\n",
      "Trained batch 1240 batch loss 0.331833214 epoch total loss 0.341569334\n",
      "Trained batch 1241 batch loss 0.336404353 epoch total loss 0.341565192\n",
      "Trained batch 1242 batch loss 0.317152411 epoch total loss 0.341545522\n",
      "Trained batch 1243 batch loss 0.315278441 epoch total loss 0.341524363\n",
      "Trained batch 1244 batch loss 0.311451346 epoch total loss 0.341500223\n",
      "Trained batch 1245 batch loss 0.287029892 epoch total loss 0.341456443\n",
      "Trained batch 1246 batch loss 0.295825124 epoch total loss 0.341419846\n",
      "Trained batch 1247 batch loss 0.306058586 epoch total loss 0.341391474\n",
      "Trained batch 1248 batch loss 0.300108045 epoch total loss 0.341358393\n",
      "Trained batch 1249 batch loss 0.319831342 epoch total loss 0.341341168\n",
      "Trained batch 1250 batch loss 0.300736308 epoch total loss 0.341308683\n",
      "Trained batch 1251 batch loss 0.311848909 epoch total loss 0.341285139\n",
      "Trained batch 1252 batch loss 0.304205656 epoch total loss 0.341255516\n",
      "Trained batch 1253 batch loss 0.294408 epoch total loss 0.341218144\n",
      "Trained batch 1254 batch loss 0.33157593 epoch total loss 0.341210455\n",
      "Trained batch 1255 batch loss 0.33251822 epoch total loss 0.341203511\n",
      "Trained batch 1256 batch loss 0.324315965 epoch total loss 0.34119007\n",
      "Trained batch 1257 batch loss 0.324006885 epoch total loss 0.341176391\n",
      "Trained batch 1258 batch loss 0.319031924 epoch total loss 0.341158807\n",
      "Trained batch 1259 batch loss 0.330729127 epoch total loss 0.341150492\n",
      "Trained batch 1260 batch loss 0.30695951 epoch total loss 0.341123343\n",
      "Trained batch 1261 batch loss 0.311378896 epoch total loss 0.341099769\n",
      "Trained batch 1262 batch loss 0.36454156 epoch total loss 0.341118336\n",
      "Trained batch 1263 batch loss 0.34344852 epoch total loss 0.341120183\n",
      "Trained batch 1264 batch loss 0.353820533 epoch total loss 0.341130227\n",
      "Trained batch 1265 batch loss 0.3169837 epoch total loss 0.341111124\n",
      "Trained batch 1266 batch loss 0.32036081 epoch total loss 0.341094762\n",
      "Trained batch 1267 batch loss 0.311187238 epoch total loss 0.341071159\n",
      "Trained batch 1268 batch loss 0.323585927 epoch total loss 0.34105736\n",
      "Trained batch 1269 batch loss 0.347899616 epoch total loss 0.341062754\n",
      "Trained batch 1270 batch loss 0.337172866 epoch total loss 0.341059685\n",
      "Trained batch 1271 batch loss 0.389646 epoch total loss 0.341097891\n",
      "Trained batch 1272 batch loss 0.392051935 epoch total loss 0.341137975\n",
      "Trained batch 1273 batch loss 0.31626597 epoch total loss 0.341118425\n",
      "Trained batch 1274 batch loss 0.336555243 epoch total loss 0.341114819\n",
      "Trained batch 1275 batch loss 0.351664424 epoch total loss 0.341123104\n",
      "Trained batch 1276 batch loss 0.337767899 epoch total loss 0.341120452\n",
      "Trained batch 1277 batch loss 0.351454973 epoch total loss 0.341128558\n",
      "Trained batch 1278 batch loss 0.339348674 epoch total loss 0.341127157\n",
      "Trained batch 1279 batch loss 0.304993808 epoch total loss 0.341098905\n",
      "Trained batch 1280 batch loss 0.313304305 epoch total loss 0.341077179\n",
      "Trained batch 1281 batch loss 0.304033697 epoch total loss 0.34104827\n",
      "Trained batch 1282 batch loss 0.294614375 epoch total loss 0.341012061\n",
      "Trained batch 1283 batch loss 0.351405472 epoch total loss 0.341020167\n",
      "Trained batch 1284 batch loss 0.323707432 epoch total loss 0.341006666\n",
      "Trained batch 1285 batch loss 0.284997433 epoch total loss 0.340963095\n",
      "Trained batch 1286 batch loss 0.341910869 epoch total loss 0.34096384\n",
      "Trained batch 1287 batch loss 0.353071272 epoch total loss 0.340973228\n",
      "Trained batch 1288 batch loss 0.346669108 epoch total loss 0.340977669\n",
      "Trained batch 1289 batch loss 0.299394101 epoch total loss 0.340945423\n",
      "Trained batch 1290 batch loss 0.284406066 epoch total loss 0.340901583\n",
      "Trained batch 1291 batch loss 0.295640469 epoch total loss 0.340866536\n",
      "Trained batch 1292 batch loss 0.297241956 epoch total loss 0.34083277\n",
      "Trained batch 1293 batch loss 0.275953829 epoch total loss 0.340782583\n",
      "Trained batch 1294 batch loss 0.277768284 epoch total loss 0.340733886\n",
      "Trained batch 1295 batch loss 0.282875121 epoch total loss 0.340689182\n",
      "Trained batch 1296 batch loss 0.314824283 epoch total loss 0.340669245\n",
      "Trained batch 1297 batch loss 0.30242753 epoch total loss 0.34063974\n",
      "Trained batch 1298 batch loss 0.327915788 epoch total loss 0.340629935\n",
      "Trained batch 1299 batch loss 0.319010079 epoch total loss 0.340613306\n",
      "Trained batch 1300 batch loss 0.320830971 epoch total loss 0.340598077\n",
      "Trained batch 1301 batch loss 0.323355138 epoch total loss 0.340584815\n",
      "Trained batch 1302 batch loss 0.32355991 epoch total loss 0.340571731\n",
      "Trained batch 1303 batch loss 0.327465802 epoch total loss 0.340561688\n",
      "Trained batch 1304 batch loss 0.314431041 epoch total loss 0.340541631\n",
      "Trained batch 1305 batch loss 0.336962909 epoch total loss 0.340538889\n",
      "Trained batch 1306 batch loss 0.310348958 epoch total loss 0.340515792\n",
      "Trained batch 1307 batch loss 0.329885602 epoch total loss 0.340507656\n",
      "Trained batch 1308 batch loss 0.329189688 epoch total loss 0.340499\n",
      "Trained batch 1309 batch loss 0.342330337 epoch total loss 0.340500414\n",
      "Trained batch 1310 batch loss 0.316726834 epoch total loss 0.340482265\n",
      "Trained batch 1311 batch loss 0.314306974 epoch total loss 0.340462297\n",
      "Trained batch 1312 batch loss 0.329656 epoch total loss 0.340454042\n",
      "Trained batch 1313 batch loss 0.322146893 epoch total loss 0.340440124\n",
      "Trained batch 1314 batch loss 0.323215395 epoch total loss 0.340427\n",
      "Trained batch 1315 batch loss 0.305852115 epoch total loss 0.340400696\n",
      "Trained batch 1316 batch loss 0.314811051 epoch total loss 0.340381265\n",
      "Trained batch 1317 batch loss 0.322977364 epoch total loss 0.340368032\n",
      "Trained batch 1318 batch loss 0.352432072 epoch total loss 0.340377182\n",
      "Trained batch 1319 batch loss 0.335464239 epoch total loss 0.340373456\n",
      "Trained batch 1320 batch loss 0.339240134 epoch total loss 0.340372592\n",
      "Trained batch 1321 batch loss 0.315809518 epoch total loss 0.340353966\n",
      "Trained batch 1322 batch loss 0.344653726 epoch total loss 0.340357244\n",
      "Trained batch 1323 batch loss 0.332411289 epoch total loss 0.340351224\n",
      "Trained batch 1324 batch loss 0.353402376 epoch total loss 0.340361089\n",
      "Trained batch 1325 batch loss 0.353058606 epoch total loss 0.340370655\n",
      "Trained batch 1326 batch loss 0.317532748 epoch total loss 0.340353429\n",
      "Trained batch 1327 batch loss 0.336319894 epoch total loss 0.340350419\n",
      "Trained batch 1328 batch loss 0.377664536 epoch total loss 0.340378493\n",
      "Trained batch 1329 batch loss 0.342615783 epoch total loss 0.340380192\n",
      "Trained batch 1330 batch loss 0.326692015 epoch total loss 0.34036988\n",
      "Trained batch 1331 batch loss 0.30804798 epoch total loss 0.340345591\n",
      "Trained batch 1332 batch loss 0.331489116 epoch total loss 0.340338945\n",
      "Trained batch 1333 batch loss 0.306173116 epoch total loss 0.340313315\n",
      "Trained batch 1334 batch loss 0.325982243 epoch total loss 0.340302587\n",
      "Trained batch 1335 batch loss 0.342585981 epoch total loss 0.340304315\n",
      "Trained batch 1336 batch loss 0.352454871 epoch total loss 0.340313405\n",
      "Trained batch 1337 batch loss 0.309174329 epoch total loss 0.340290099\n",
      "Trained batch 1338 batch loss 0.332680255 epoch total loss 0.340284407\n",
      "Trained batch 1339 batch loss 0.313600242 epoch total loss 0.340264469\n",
      "Trained batch 1340 batch loss 0.302041322 epoch total loss 0.340235949\n",
      "Trained batch 1341 batch loss 0.302738935 epoch total loss 0.340208\n",
      "Trained batch 1342 batch loss 0.323266238 epoch total loss 0.340195358\n",
      "Trained batch 1343 batch loss 0.318007439 epoch total loss 0.340178818\n",
      "Trained batch 1344 batch loss 0.309115112 epoch total loss 0.340155721\n",
      "Trained batch 1345 batch loss 0.336889088 epoch total loss 0.340153277\n",
      "Trained batch 1346 batch loss 0.328929573 epoch total loss 0.340144932\n",
      "Trained batch 1347 batch loss 0.321530879 epoch total loss 0.340131104\n",
      "Trained batch 1348 batch loss 0.317493439 epoch total loss 0.340114325\n",
      "Trained batch 1349 batch loss 0.314129442 epoch total loss 0.340095073\n",
      "Trained batch 1350 batch loss 0.286886156 epoch total loss 0.340055645\n",
      "Trained batch 1351 batch loss 0.32493338 epoch total loss 0.340044439\n",
      "Trained batch 1352 batch loss 0.283636421 epoch total loss 0.340002716\n",
      "Trained batch 1353 batch loss 0.273413301 epoch total loss 0.339953512\n",
      "Trained batch 1354 batch loss 0.275156677 epoch total loss 0.339905649\n",
      "Trained batch 1355 batch loss 0.297175974 epoch total loss 0.339874119\n",
      "Trained batch 1356 batch loss 0.297090441 epoch total loss 0.339842558\n",
      "Trained batch 1357 batch loss 0.260424733 epoch total loss 0.339784056\n",
      "Trained batch 1358 batch loss 0.30127731 epoch total loss 0.339755684\n",
      "Trained batch 1359 batch loss 0.314811975 epoch total loss 0.339737326\n",
      "Trained batch 1360 batch loss 0.323894233 epoch total loss 0.339725673\n",
      "Trained batch 1361 batch loss 0.297963083 epoch total loss 0.339695\n",
      "Trained batch 1362 batch loss 0.295611113 epoch total loss 0.339662641\n",
      "Trained batch 1363 batch loss 0.308601558 epoch total loss 0.339639843\n",
      "Trained batch 1364 batch loss 0.343291909 epoch total loss 0.339642525\n",
      "Trained batch 1365 batch loss 0.328371912 epoch total loss 0.339634269\n",
      "Trained batch 1366 batch loss 0.329067111 epoch total loss 0.339626521\n",
      "Trained batch 1367 batch loss 0.323473483 epoch total loss 0.339614719\n",
      "Trained batch 1368 batch loss 0.307025343 epoch total loss 0.339590907\n",
      "Trained batch 1369 batch loss 0.323353499 epoch total loss 0.339579046\n",
      "Trained batch 1370 batch loss 0.293726772 epoch total loss 0.339545578\n",
      "Trained batch 1371 batch loss 0.273973525 epoch total loss 0.339497775\n",
      "Trained batch 1372 batch loss 0.316141188 epoch total loss 0.339480728\n",
      "Trained batch 1373 batch loss 0.314716429 epoch total loss 0.339462727\n",
      "Trained batch 1374 batch loss 0.329592556 epoch total loss 0.339455515\n",
      "Trained batch 1375 batch loss 0.311608791 epoch total loss 0.339435279\n",
      "Trained batch 1376 batch loss 0.313595653 epoch total loss 0.339416504\n",
      "Trained batch 1377 batch loss 0.306082398 epoch total loss 0.339392304\n",
      "Trained batch 1378 batch loss 0.327822059 epoch total loss 0.3393839\n",
      "Trained batch 1379 batch loss 0.335063845 epoch total loss 0.339380771\n",
      "Trained batch 1380 batch loss 0.323039412 epoch total loss 0.33936891\n",
      "Trained batch 1381 batch loss 0.304731488 epoch total loss 0.339343816\n",
      "Trained batch 1382 batch loss 0.318127036 epoch total loss 0.339328468\n",
      "Trained batch 1383 batch loss 0.301692963 epoch total loss 0.339301258\n",
      "Trained batch 1384 batch loss 0.286965102 epoch total loss 0.339263439\n",
      "Trained batch 1385 batch loss 0.288511932 epoch total loss 0.339226782\n",
      "Trained batch 1386 batch loss 0.336657196 epoch total loss 0.339224935\n",
      "Trained batch 1387 batch loss 0.302128762 epoch total loss 0.339198202\n",
      "Trained batch 1388 batch loss 0.303603858 epoch total loss 0.339172542\n",
      "Epoch 1 train loss 0.3391725420951843 and time 694.7776353359222\n",
      "Validated batch 1 batch loss 0.32799229\n",
      "Validated batch 2 batch loss 0.311282814\n",
      "Validated batch 3 batch loss 0.310868561\n",
      "Validated batch 4 batch loss 0.315044165\n",
      "Validated batch 5 batch loss 0.333941519\n",
      "Validated batch 6 batch loss 0.337161183\n",
      "Validated batch 7 batch loss 0.304001749\n",
      "Validated batch 8 batch loss 0.326591402\n",
      "Validated batch 9 batch loss 0.325087488\n",
      "Validated batch 10 batch loss 0.311942875\n",
      "Validated batch 11 batch loss 0.330709428\n",
      "Validated batch 12 batch loss 0.293616414\n",
      "Validated batch 13 batch loss 0.364886969\n",
      "Validated batch 14 batch loss 0.302696735\n",
      "Validated batch 15 batch loss 0.330512881\n",
      "Validated batch 16 batch loss 0.323256522\n",
      "Validated batch 17 batch loss 0.343849838\n",
      "Validated batch 18 batch loss 0.271717489\n",
      "Validated batch 19 batch loss 0.32742846\n",
      "Validated batch 20 batch loss 0.295593739\n",
      "Validated batch 21 batch loss 0.324666053\n",
      "Validated batch 22 batch loss 0.309076071\n",
      "Validated batch 23 batch loss 0.324432015\n",
      "Validated batch 24 batch loss 0.314932168\n",
      "Validated batch 25 batch loss 0.300020128\n",
      "Validated batch 26 batch loss 0.303290308\n",
      "Validated batch 27 batch loss 0.300666869\n",
      "Validated batch 28 batch loss 0.31993553\n",
      "Validated batch 29 batch loss 0.323595643\n",
      "Validated batch 30 batch loss 0.321943462\n",
      "Validated batch 31 batch loss 0.309729755\n",
      "Validated batch 32 batch loss 0.312622279\n",
      "Validated batch 33 batch loss 0.322276294\n",
      "Validated batch 34 batch loss 0.327797353\n",
      "Validated batch 35 batch loss 0.328512698\n",
      "Validated batch 36 batch loss 0.314810783\n",
      "Validated batch 37 batch loss 0.319209963\n",
      "Validated batch 38 batch loss 0.316399783\n",
      "Validated batch 39 batch loss 0.31212765\n",
      "Validated batch 40 batch loss 0.349285543\n",
      "Validated batch 41 batch loss 0.326604664\n",
      "Validated batch 42 batch loss 0.290382087\n",
      "Validated batch 43 batch loss 0.341927767\n",
      "Validated batch 44 batch loss 0.312720299\n",
      "Validated batch 45 batch loss 0.308378696\n",
      "Validated batch 46 batch loss 0.334961325\n",
      "Validated batch 47 batch loss 0.31388092\n",
      "Validated batch 48 batch loss 0.322850406\n",
      "Validated batch 49 batch loss 0.308102459\n",
      "Validated batch 50 batch loss 0.322744\n",
      "Validated batch 51 batch loss 0.320204079\n",
      "Validated batch 52 batch loss 0.324805737\n",
      "Validated batch 53 batch loss 0.337043226\n",
      "Validated batch 54 batch loss 0.328521043\n",
      "Validated batch 55 batch loss 0.325813234\n",
      "Validated batch 56 batch loss 0.319164962\n",
      "Validated batch 57 batch loss 0.344249427\n",
      "Validated batch 58 batch loss 0.332604408\n",
      "Validated batch 59 batch loss 0.310520828\n",
      "Validated batch 60 batch loss 0.346963465\n",
      "Validated batch 61 batch loss 0.330241\n",
      "Validated batch 62 batch loss 0.325204074\n",
      "Validated batch 63 batch loss 0.360157907\n",
      "Validated batch 64 batch loss 0.272666574\n",
      "Validated batch 65 batch loss 0.327632666\n",
      "Validated batch 66 batch loss 0.291246\n",
      "Validated batch 67 batch loss 0.308279097\n",
      "Validated batch 68 batch loss 0.351343\n",
      "Validated batch 69 batch loss 0.309347183\n",
      "Validated batch 70 batch loss 0.348095775\n",
      "Validated batch 71 batch loss 0.317911863\n",
      "Validated batch 72 batch loss 0.312828124\n",
      "Validated batch 73 batch loss 0.312284529\n",
      "Validated batch 74 batch loss 0.300479352\n",
      "Validated batch 75 batch loss 0.329545319\n",
      "Validated batch 76 batch loss 0.309073269\n",
      "Validated batch 77 batch loss 0.29707408\n",
      "Validated batch 78 batch loss 0.30342114\n",
      "Validated batch 79 batch loss 0.314379\n",
      "Validated batch 80 batch loss 0.328514725\n",
      "Validated batch 81 batch loss 0.322602123\n",
      "Validated batch 82 batch loss 0.313392699\n",
      "Validated batch 83 batch loss 0.293793142\n",
      "Validated batch 84 batch loss 0.309378862\n",
      "Validated batch 85 batch loss 0.318966627\n",
      "Validated batch 86 batch loss 0.324539274\n",
      "Validated batch 87 batch loss 0.331104964\n",
      "Validated batch 88 batch loss 0.339259326\n",
      "Validated batch 89 batch loss 0.390298367\n",
      "Validated batch 90 batch loss 0.347651\n",
      "Validated batch 91 batch loss 0.32301116\n",
      "Validated batch 92 batch loss 0.296526104\n",
      "Validated batch 93 batch loss 0.300544798\n",
      "Validated batch 94 batch loss 0.291480184\n",
      "Validated batch 95 batch loss 0.310435593\n",
      "Validated batch 96 batch loss 0.301678747\n",
      "Validated batch 97 batch loss 0.318674445\n",
      "Validated batch 98 batch loss 0.336423576\n",
      "Validated batch 99 batch loss 0.318914831\n",
      "Validated batch 100 batch loss 0.325886577\n",
      "Validated batch 101 batch loss 0.33627367\n",
      "Validated batch 102 batch loss 0.328716367\n",
      "Validated batch 103 batch loss 0.311179698\n",
      "Validated batch 104 batch loss 0.344935\n",
      "Validated batch 105 batch loss 0.321719885\n",
      "Validated batch 106 batch loss 0.336850196\n",
      "Validated batch 107 batch loss 0.335900664\n",
      "Validated batch 108 batch loss 0.352654397\n",
      "Validated batch 109 batch loss 0.337172985\n",
      "Validated batch 110 batch loss 0.292630017\n",
      "Validated batch 111 batch loss 0.313216299\n",
      "Validated batch 112 batch loss 0.327987075\n",
      "Validated batch 113 batch loss 0.326802522\n",
      "Validated batch 114 batch loss 0.314183891\n",
      "Validated batch 115 batch loss 0.309048951\n",
      "Validated batch 116 batch loss 0.334700227\n",
      "Validated batch 117 batch loss 0.349626958\n",
      "Validated batch 118 batch loss 0.315187901\n",
      "Validated batch 119 batch loss 0.304156303\n",
      "Validated batch 120 batch loss 0.3149876\n",
      "Validated batch 121 batch loss 0.31156221\n",
      "Validated batch 122 batch loss 0.316349596\n",
      "Validated batch 123 batch loss 0.30279687\n",
      "Validated batch 124 batch loss 0.297801018\n",
      "Validated batch 125 batch loss 0.337994307\n",
      "Validated batch 126 batch loss 0.302761227\n",
      "Validated batch 127 batch loss 0.294685125\n",
      "Validated batch 128 batch loss 0.301550955\n",
      "Validated batch 129 batch loss 0.348544657\n",
      "Validated batch 130 batch loss 0.334171712\n",
      "Validated batch 131 batch loss 0.346980393\n",
      "Validated batch 132 batch loss 0.312273294\n",
      "Validated batch 133 batch loss 0.347187549\n",
      "Validated batch 134 batch loss 0.31646508\n",
      "Validated batch 135 batch loss 0.342201412\n",
      "Validated batch 136 batch loss 0.340256274\n",
      "Validated batch 137 batch loss 0.262607694\n",
      "Validated batch 138 batch loss 0.319724083\n",
      "Validated batch 139 batch loss 0.317020833\n",
      "Validated batch 140 batch loss 0.317046\n",
      "Validated batch 141 batch loss 0.312268287\n",
      "Validated batch 142 batch loss 0.306048036\n",
      "Validated batch 143 batch loss 0.331324726\n",
      "Validated batch 144 batch loss 0.362241864\n",
      "Validated batch 145 batch loss 0.293557942\n",
      "Validated batch 146 batch loss 0.326594561\n",
      "Validated batch 147 batch loss 0.303926647\n",
      "Validated batch 148 batch loss 0.320804149\n",
      "Validated batch 149 batch loss 0.318053275\n",
      "Validated batch 150 batch loss 0.30846709\n",
      "Validated batch 151 batch loss 0.26316449\n",
      "Validated batch 152 batch loss 0.314297467\n",
      "Validated batch 153 batch loss 0.303119153\n",
      "Validated batch 154 batch loss 0.313884825\n",
      "Validated batch 155 batch loss 0.328035116\n",
      "Validated batch 156 batch loss 0.29895997\n",
      "Validated batch 157 batch loss 0.32001549\n",
      "Validated batch 158 batch loss 0.33786881\n",
      "Validated batch 159 batch loss 0.319824457\n",
      "Validated batch 160 batch loss 0.315407485\n",
      "Validated batch 161 batch loss 0.296267241\n",
      "Validated batch 162 batch loss 0.303943932\n",
      "Validated batch 163 batch loss 0.314144611\n",
      "Validated batch 164 batch loss 0.315370083\n",
      "Validated batch 165 batch loss 0.285381109\n",
      "Validated batch 166 batch loss 0.304068506\n",
      "Validated batch 167 batch loss 0.344942898\n",
      "Validated batch 168 batch loss 0.298577964\n",
      "Validated batch 169 batch loss 0.298314035\n",
      "Validated batch 170 batch loss 0.307530046\n",
      "Validated batch 171 batch loss 0.332288444\n",
      "Validated batch 172 batch loss 0.305532545\n",
      "Validated batch 173 batch loss 0.326972425\n",
      "Validated batch 174 batch loss 0.28632158\n",
      "Validated batch 175 batch loss 0.321720928\n",
      "Validated batch 176 batch loss 0.343852699\n",
      "Validated batch 177 batch loss 0.351699293\n",
      "Validated batch 178 batch loss 0.307437599\n",
      "Validated batch 179 batch loss 0.343796164\n",
      "Validated batch 180 batch loss 0.294170678\n",
      "Validated batch 181 batch loss 0.290862024\n",
      "Validated batch 182 batch loss 0.30687505\n",
      "Validated batch 183 batch loss 0.30695948\n",
      "Validated batch 184 batch loss 0.347211361\n",
      "Validated batch 185 batch loss 0.343375444\n",
      "Epoch 1 val loss 0.3191007077693939\n",
      "Model /aiffel/aiffel/CV-PoseEstimation/models/model-epoch-1-loss-0.3191.h5 saved.\n",
      "Start epoch 2 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.31842041 epoch total loss 0.31842041\n",
      "Trained batch 2 batch loss 0.324784577 epoch total loss 0.321602494\n",
      "Trained batch 3 batch loss 0.313644648 epoch total loss 0.318949878\n",
      "Trained batch 4 batch loss 0.324793875 epoch total loss 0.320410877\n",
      "Trained batch 5 batch loss 0.351709217 epoch total loss 0.326670557\n",
      "Trained batch 6 batch loss 0.306800604 epoch total loss 0.323358893\n",
      "Trained batch 7 batch loss 0.287158072 epoch total loss 0.318187326\n",
      "Trained batch 8 batch loss 0.296444297 epoch total loss 0.315469444\n",
      "Trained batch 9 batch loss 0.291451812 epoch total loss 0.312800825\n",
      "Trained batch 10 batch loss 0.315392733 epoch total loss 0.313060015\n",
      "Trained batch 11 batch loss 0.30341652 epoch total loss 0.31218335\n",
      "Trained batch 12 batch loss 0.350993037 epoch total loss 0.315417498\n",
      "Trained batch 13 batch loss 0.318664432 epoch total loss 0.315667272\n",
      "Trained batch 14 batch loss 0.329022884 epoch total loss 0.316621244\n",
      "Trained batch 15 batch loss 0.327555865 epoch total loss 0.317350209\n",
      "Trained batch 16 batch loss 0.320047796 epoch total loss 0.3175188\n",
      "Trained batch 17 batch loss 0.303023696 epoch total loss 0.316666156\n",
      "Trained batch 18 batch loss 0.319975287 epoch total loss 0.31685\n",
      "Trained batch 19 batch loss 0.300358653 epoch total loss 0.315982044\n",
      "Trained batch 20 batch loss 0.292827964 epoch total loss 0.314824343\n",
      "Trained batch 21 batch loss 0.283736318 epoch total loss 0.313343942\n",
      "Trained batch 22 batch loss 0.303415418 epoch total loss 0.312892646\n",
      "Trained batch 23 batch loss 0.315228105 epoch total loss 0.312994182\n",
      "Trained batch 24 batch loss 0.3306095 epoch total loss 0.313728154\n",
      "Trained batch 25 batch loss 0.365925223 epoch total loss 0.315816045\n",
      "Trained batch 26 batch loss 0.340083659 epoch total loss 0.316749424\n",
      "Trained batch 27 batch loss 0.317859709 epoch total loss 0.316790551\n",
      "Trained batch 28 batch loss 0.312427908 epoch total loss 0.316634715\n",
      "Trained batch 29 batch loss 0.326462537 epoch total loss 0.316973627\n",
      "Trained batch 30 batch loss 0.288150638 epoch total loss 0.316012859\n",
      "Trained batch 31 batch loss 0.317144275 epoch total loss 0.316049367\n",
      "Trained batch 32 batch loss 0.30472374 epoch total loss 0.315695435\n",
      "Trained batch 33 batch loss 0.306606174 epoch total loss 0.31542\n",
      "Trained batch 34 batch loss 0.279512793 epoch total loss 0.314363897\n",
      "Trained batch 35 batch loss 0.256068975 epoch total loss 0.312698334\n",
      "Trained batch 36 batch loss 0.273999572 epoch total loss 0.311623365\n",
      "Trained batch 37 batch loss 0.297233939 epoch total loss 0.311234444\n",
      "Trained batch 38 batch loss 0.366213 epoch total loss 0.312681258\n",
      "Trained batch 39 batch loss 0.369655401 epoch total loss 0.314142138\n",
      "Trained batch 40 batch loss 0.349069893 epoch total loss 0.315015316\n",
      "Trained batch 41 batch loss 0.345128655 epoch total loss 0.315749794\n",
      "Trained batch 42 batch loss 0.331997067 epoch total loss 0.316136628\n",
      "Trained batch 43 batch loss 0.344052732 epoch total loss 0.316785842\n",
      "Trained batch 44 batch loss 0.309674501 epoch total loss 0.316624194\n",
      "Trained batch 45 batch loss 0.268971443 epoch total loss 0.315565258\n",
      "Trained batch 46 batch loss 0.296071887 epoch total loss 0.315141499\n",
      "Trained batch 47 batch loss 0.319785625 epoch total loss 0.315240324\n",
      "Trained batch 48 batch loss 0.308774173 epoch total loss 0.315105587\n",
      "Trained batch 49 batch loss 0.323795855 epoch total loss 0.315282971\n",
      "Trained batch 50 batch loss 0.327501982 epoch total loss 0.31552735\n",
      "Trained batch 51 batch loss 0.339623809 epoch total loss 0.315999836\n",
      "Trained batch 52 batch loss 0.361025 epoch total loss 0.316865712\n",
      "Trained batch 53 batch loss 0.344953537 epoch total loss 0.317395657\n",
      "Trained batch 54 batch loss 0.331864834 epoch total loss 0.31766361\n",
      "Trained batch 55 batch loss 0.29783076 epoch total loss 0.317303\n",
      "Trained batch 56 batch loss 0.335759729 epoch total loss 0.317632616\n",
      "Trained batch 57 batch loss 0.349324316 epoch total loss 0.318188608\n",
      "Trained batch 58 batch loss 0.296171397 epoch total loss 0.317809016\n",
      "Trained batch 59 batch loss 0.29289788 epoch total loss 0.317386776\n",
      "Trained batch 60 batch loss 0.295676053 epoch total loss 0.317024916\n",
      "Trained batch 61 batch loss 0.29651159 epoch total loss 0.316688627\n",
      "Trained batch 62 batch loss 0.2955603 epoch total loss 0.316347867\n",
      "Trained batch 63 batch loss 0.281728327 epoch total loss 0.315798342\n",
      "Trained batch 64 batch loss 0.301748902 epoch total loss 0.315578818\n",
      "Trained batch 65 batch loss 0.313515037 epoch total loss 0.315547049\n",
      "Trained batch 66 batch loss 0.325242341 epoch total loss 0.315693974\n",
      "Trained batch 67 batch loss 0.317996353 epoch total loss 0.315728337\n",
      "Trained batch 68 batch loss 0.371628225 epoch total loss 0.316550404\n",
      "Trained batch 69 batch loss 0.329424083 epoch total loss 0.316736966\n",
      "Trained batch 70 batch loss 0.317318 epoch total loss 0.316745281\n",
      "Trained batch 71 batch loss 0.356307358 epoch total loss 0.317302495\n",
      "Trained batch 72 batch loss 0.325762868 epoch total loss 0.31742\n",
      "Trained batch 73 batch loss 0.317308903 epoch total loss 0.317418486\n",
      "Trained batch 74 batch loss 0.302250147 epoch total loss 0.317213506\n",
      "Trained batch 75 batch loss 0.353568256 epoch total loss 0.31769824\n",
      "Trained batch 76 batch loss 0.347860128 epoch total loss 0.318095118\n",
      "Trained batch 77 batch loss 0.326275229 epoch total loss 0.318201333\n",
      "Trained batch 78 batch loss 0.341889143 epoch total loss 0.318505019\n",
      "Trained batch 79 batch loss 0.331841201 epoch total loss 0.318673819\n",
      "Trained batch 80 batch loss 0.326767206 epoch total loss 0.318775\n",
      "Trained batch 81 batch loss 0.336783111 epoch total loss 0.318997294\n",
      "Trained batch 82 batch loss 0.344164342 epoch total loss 0.319304198\n",
      "Trained batch 83 batch loss 0.353785068 epoch total loss 0.319719642\n",
      "Trained batch 84 batch loss 0.342671752 epoch total loss 0.31999287\n",
      "Trained batch 85 batch loss 0.304207146 epoch total loss 0.319807172\n",
      "Trained batch 86 batch loss 0.291492283 epoch total loss 0.319477916\n",
      "Trained batch 87 batch loss 0.300690234 epoch total loss 0.319261968\n",
      "Trained batch 88 batch loss 0.305350929 epoch total loss 0.319103897\n",
      "Trained batch 89 batch loss 0.30511862 epoch total loss 0.318946749\n",
      "Trained batch 90 batch loss 0.303322315 epoch total loss 0.31877315\n",
      "Trained batch 91 batch loss 0.300592542 epoch total loss 0.318573356\n",
      "Trained batch 92 batch loss 0.332144111 epoch total loss 0.318720847\n",
      "Trained batch 93 batch loss 0.325000286 epoch total loss 0.318788379\n",
      "Trained batch 94 batch loss 0.338877469 epoch total loss 0.319002092\n",
      "Trained batch 95 batch loss 0.312350154 epoch total loss 0.318932056\n",
      "Trained batch 96 batch loss 0.306769788 epoch total loss 0.318805367\n",
      "Trained batch 97 batch loss 0.303403437 epoch total loss 0.31864661\n",
      "Trained batch 98 batch loss 0.310613632 epoch total loss 0.318564624\n",
      "Trained batch 99 batch loss 0.308833748 epoch total loss 0.318466336\n",
      "Trained batch 100 batch loss 0.309929818 epoch total loss 0.318380952\n",
      "Trained batch 101 batch loss 0.304197311 epoch total loss 0.318240553\n",
      "Trained batch 102 batch loss 0.329020232 epoch total loss 0.318346262\n",
      "Trained batch 103 batch loss 0.331778646 epoch total loss 0.318476677\n",
      "Trained batch 104 batch loss 0.340653449 epoch total loss 0.318689883\n",
      "Trained batch 105 batch loss 0.303150773 epoch total loss 0.318541884\n",
      "Trained batch 106 batch loss 0.341047674 epoch total loss 0.318754226\n",
      "Trained batch 107 batch loss 0.309866667 epoch total loss 0.318671197\n",
      "Trained batch 108 batch loss 0.289101183 epoch total loss 0.318397373\n",
      "Trained batch 109 batch loss 0.352519065 epoch total loss 0.318710446\n",
      "Trained batch 110 batch loss 0.319444954 epoch total loss 0.318717122\n",
      "Trained batch 111 batch loss 0.309423715 epoch total loss 0.318633407\n",
      "Trained batch 112 batch loss 0.322835714 epoch total loss 0.318670928\n",
      "Trained batch 113 batch loss 0.321556062 epoch total loss 0.318696439\n",
      "Trained batch 114 batch loss 0.305115581 epoch total loss 0.318577319\n",
      "Trained batch 115 batch loss 0.337323546 epoch total loss 0.318740308\n",
      "Trained batch 116 batch loss 0.315760523 epoch total loss 0.318714648\n",
      "Trained batch 117 batch loss 0.340746164 epoch total loss 0.31890294\n",
      "Trained batch 118 batch loss 0.324356884 epoch total loss 0.318949163\n",
      "Trained batch 119 batch loss 0.322130859 epoch total loss 0.318975925\n",
      "Trained batch 120 batch loss 0.332370341 epoch total loss 0.319087535\n",
      "Trained batch 121 batch loss 0.309974462 epoch total loss 0.319012225\n",
      "Trained batch 122 batch loss 0.31338945 epoch total loss 0.31896612\n",
      "Trained batch 123 batch loss 0.308937699 epoch total loss 0.318884581\n",
      "Trained batch 124 batch loss 0.306813806 epoch total loss 0.318787247\n",
      "Trained batch 125 batch loss 0.309692949 epoch total loss 0.31871447\n",
      "Trained batch 126 batch loss 0.30985257 epoch total loss 0.318644136\n",
      "Trained batch 127 batch loss 0.321208268 epoch total loss 0.318664342\n",
      "Trained batch 128 batch loss 0.304870725 epoch total loss 0.318556577\n",
      "Trained batch 129 batch loss 0.303280622 epoch total loss 0.318438143\n",
      "Trained batch 130 batch loss 0.308636725 epoch total loss 0.318362743\n",
      "Trained batch 131 batch loss 0.317329258 epoch total loss 0.318354875\n",
      "Trained batch 132 batch loss 0.31029433 epoch total loss 0.31829381\n",
      "Trained batch 133 batch loss 0.313926309 epoch total loss 0.318260968\n",
      "Trained batch 134 batch loss 0.333948553 epoch total loss 0.318378061\n",
      "Trained batch 135 batch loss 0.277367949 epoch total loss 0.318074256\n",
      "Trained batch 136 batch loss 0.294951171 epoch total loss 0.317904234\n",
      "Trained batch 137 batch loss 0.315227211 epoch total loss 0.317884713\n",
      "Trained batch 138 batch loss 0.289359063 epoch total loss 0.317678\n",
      "Trained batch 139 batch loss 0.288990915 epoch total loss 0.317471623\n",
      "Trained batch 140 batch loss 0.274124026 epoch total loss 0.317162\n",
      "Trained batch 141 batch loss 0.276779234 epoch total loss 0.316875607\n",
      "Trained batch 142 batch loss 0.303121507 epoch total loss 0.316778719\n",
      "Trained batch 143 batch loss 0.277640224 epoch total loss 0.316505045\n",
      "Trained batch 144 batch loss 0.290713459 epoch total loss 0.316325933\n",
      "Trained batch 145 batch loss 0.288853198 epoch total loss 0.31613645\n",
      "Trained batch 146 batch loss 0.286126763 epoch total loss 0.315930903\n",
      "Trained batch 147 batch loss 0.306497633 epoch total loss 0.315866739\n",
      "Trained batch 148 batch loss 0.350653112 epoch total loss 0.316101789\n",
      "Trained batch 149 batch loss 0.34371534 epoch total loss 0.31628713\n",
      "Trained batch 150 batch loss 0.312863708 epoch total loss 0.316264302\n",
      "Trained batch 151 batch loss 0.318951726 epoch total loss 0.316282094\n",
      "Trained batch 152 batch loss 0.320630044 epoch total loss 0.316310674\n",
      "Trained batch 153 batch loss 0.304615647 epoch total loss 0.316234231\n",
      "Trained batch 154 batch loss 0.295313567 epoch total loss 0.316098392\n",
      "Trained batch 155 batch loss 0.248104721 epoch total loss 0.315659732\n",
      "Trained batch 156 batch loss 0.25504756 epoch total loss 0.315271169\n",
      "Trained batch 157 batch loss 0.281373084 epoch total loss 0.315055251\n",
      "Trained batch 158 batch loss 0.319938 epoch total loss 0.315086186\n",
      "Trained batch 159 batch loss 0.322315574 epoch total loss 0.315131634\n",
      "Trained batch 160 batch loss 0.324925601 epoch total loss 0.315192848\n",
      "Trained batch 161 batch loss 0.31547305 epoch total loss 0.315194577\n",
      "Trained batch 162 batch loss 0.304289222 epoch total loss 0.315127254\n",
      "Trained batch 163 batch loss 0.277583212 epoch total loss 0.314896941\n",
      "Trained batch 164 batch loss 0.321705461 epoch total loss 0.314938456\n",
      "Trained batch 165 batch loss 0.315475941 epoch total loss 0.314941704\n",
      "Trained batch 166 batch loss 0.291817218 epoch total loss 0.314802408\n",
      "Trained batch 167 batch loss 0.319799602 epoch total loss 0.31483233\n",
      "Trained batch 168 batch loss 0.333350033 epoch total loss 0.314942569\n",
      "Trained batch 169 batch loss 0.347247064 epoch total loss 0.315133721\n",
      "Trained batch 170 batch loss 0.327494413 epoch total loss 0.315206438\n",
      "Trained batch 171 batch loss 0.313972861 epoch total loss 0.315199226\n",
      "Trained batch 172 batch loss 0.280992955 epoch total loss 0.315000355\n",
      "Trained batch 173 batch loss 0.288506627 epoch total loss 0.314847201\n",
      "Trained batch 174 batch loss 0.291446298 epoch total loss 0.314712733\n",
      "Trained batch 175 batch loss 0.274479836 epoch total loss 0.314482808\n",
      "Trained batch 176 batch loss 0.299448 epoch total loss 0.314397365\n",
      "Trained batch 177 batch loss 0.296689212 epoch total loss 0.314297318\n",
      "Trained batch 178 batch loss 0.292859823 epoch total loss 0.314176887\n",
      "Trained batch 179 batch loss 0.320078164 epoch total loss 0.314209849\n",
      "Trained batch 180 batch loss 0.285318136 epoch total loss 0.314049333\n",
      "Trained batch 181 batch loss 0.27141577 epoch total loss 0.313813806\n",
      "Trained batch 182 batch loss 0.288982421 epoch total loss 0.313677371\n",
      "Trained batch 183 batch loss 0.295420229 epoch total loss 0.313577592\n",
      "Trained batch 184 batch loss 0.278622448 epoch total loss 0.313387632\n",
      "Trained batch 185 batch loss 0.268608212 epoch total loss 0.313145578\n",
      "Trained batch 186 batch loss 0.283183634 epoch total loss 0.312984496\n",
      "Trained batch 187 batch loss 0.287501872 epoch total loss 0.31284821\n",
      "Trained batch 188 batch loss 0.306803435 epoch total loss 0.312816083\n",
      "Trained batch 189 batch loss 0.30401203 epoch total loss 0.312769502\n",
      "Trained batch 190 batch loss 0.299442381 epoch total loss 0.312699348\n",
      "Trained batch 191 batch loss 0.337064296 epoch total loss 0.312826902\n",
      "Trained batch 192 batch loss 0.320919156 epoch total loss 0.312869042\n",
      "Trained batch 193 batch loss 0.342120528 epoch total loss 0.313020617\n",
      "Trained batch 194 batch loss 0.310890228 epoch total loss 0.31300965\n",
      "Trained batch 195 batch loss 0.302088857 epoch total loss 0.312953621\n",
      "Trained batch 196 batch loss 0.305419326 epoch total loss 0.312915206\n",
      "Trained batch 197 batch loss 0.325662315 epoch total loss 0.312979907\n",
      "Trained batch 198 batch loss 0.323358536 epoch total loss 0.313032329\n",
      "Trained batch 199 batch loss 0.330699325 epoch total loss 0.31312111\n",
      "Trained batch 200 batch loss 0.377125084 epoch total loss 0.313441128\n",
      "Trained batch 201 batch loss 0.355842471 epoch total loss 0.313652068\n",
      "Trained batch 202 batch loss 0.310726 epoch total loss 0.313637584\n",
      "Trained batch 203 batch loss 0.30764851 epoch total loss 0.31360808\n",
      "Trained batch 204 batch loss 0.287505478 epoch total loss 0.313480139\n",
      "Trained batch 205 batch loss 0.263633251 epoch total loss 0.313236952\n",
      "Trained batch 206 batch loss 0.272102237 epoch total loss 0.313037276\n",
      "Trained batch 207 batch loss 0.301283777 epoch total loss 0.312980503\n",
      "Trained batch 208 batch loss 0.253054023 epoch total loss 0.312692374\n",
      "Trained batch 209 batch loss 0.255984485 epoch total loss 0.312421054\n",
      "Trained batch 210 batch loss 0.270778358 epoch total loss 0.312222719\n",
      "Trained batch 211 batch loss 0.284149975 epoch total loss 0.312089682\n",
      "Trained batch 212 batch loss 0.274982572 epoch total loss 0.311914653\n",
      "Trained batch 213 batch loss 0.312175661 epoch total loss 0.311915874\n",
      "Trained batch 214 batch loss 0.328754246 epoch total loss 0.311994523\n",
      "Trained batch 215 batch loss 0.339234948 epoch total loss 0.312121212\n",
      "Trained batch 216 batch loss 0.342679203 epoch total loss 0.312262714\n",
      "Trained batch 217 batch loss 0.338537931 epoch total loss 0.312383801\n",
      "Trained batch 218 batch loss 0.325104982 epoch total loss 0.312442154\n",
      "Trained batch 219 batch loss 0.320714116 epoch total loss 0.312479943\n",
      "Trained batch 220 batch loss 0.286447436 epoch total loss 0.312361598\n",
      "Trained batch 221 batch loss 0.297522873 epoch total loss 0.312294453\n",
      "Trained batch 222 batch loss 0.317720324 epoch total loss 0.312318891\n",
      "Trained batch 223 batch loss 0.290601134 epoch total loss 0.312221497\n",
      "Trained batch 224 batch loss 0.287882507 epoch total loss 0.312112838\n",
      "Trained batch 225 batch loss 0.309352368 epoch total loss 0.312100559\n",
      "Trained batch 226 batch loss 0.295205742 epoch total loss 0.312025785\n",
      "Trained batch 227 batch loss 0.308251411 epoch total loss 0.312009156\n",
      "Trained batch 228 batch loss 0.318144768 epoch total loss 0.312036067\n",
      "Trained batch 229 batch loss 0.333757281 epoch total loss 0.312130928\n",
      "Trained batch 230 batch loss 0.348487318 epoch total loss 0.312289\n",
      "Trained batch 231 batch loss 0.354989618 epoch total loss 0.312473834\n",
      "Trained batch 232 batch loss 0.393158227 epoch total loss 0.312821627\n",
      "Trained batch 233 batch loss 0.347811669 epoch total loss 0.312971771\n",
      "Trained batch 234 batch loss 0.288933784 epoch total loss 0.312869042\n",
      "Trained batch 235 batch loss 0.293771476 epoch total loss 0.312787771\n",
      "Trained batch 236 batch loss 0.363760442 epoch total loss 0.313003778\n",
      "Trained batch 237 batch loss 0.328199267 epoch total loss 0.313067883\n",
      "Trained batch 238 batch loss 0.331432879 epoch total loss 0.313145071\n",
      "Trained batch 239 batch loss 0.329239368 epoch total loss 0.313212395\n",
      "Trained batch 240 batch loss 0.339335203 epoch total loss 0.313321233\n",
      "Trained batch 241 batch loss 0.337701529 epoch total loss 0.313422412\n",
      "Trained batch 242 batch loss 0.305142492 epoch total loss 0.313388199\n",
      "Trained batch 243 batch loss 0.289726526 epoch total loss 0.313290834\n",
      "Trained batch 244 batch loss 0.277481 epoch total loss 0.313144058\n",
      "Trained batch 245 batch loss 0.316784739 epoch total loss 0.313158929\n",
      "Trained batch 246 batch loss 0.327744395 epoch total loss 0.313218206\n",
      "Trained batch 247 batch loss 0.335476488 epoch total loss 0.313308358\n",
      "Trained batch 248 batch loss 0.368588299 epoch total loss 0.31353125\n",
      "Trained batch 249 batch loss 0.340347767 epoch total loss 0.313638955\n",
      "Trained batch 250 batch loss 0.348135501 epoch total loss 0.31377694\n",
      "Trained batch 251 batch loss 0.345853418 epoch total loss 0.313904762\n",
      "Trained batch 252 batch loss 0.301194 epoch total loss 0.313854307\n",
      "Trained batch 253 batch loss 0.303291887 epoch total loss 0.313812554\n",
      "Trained batch 254 batch loss 0.295040429 epoch total loss 0.313738674\n",
      "Trained batch 255 batch loss 0.320248067 epoch total loss 0.313764215\n",
      "Trained batch 256 batch loss 0.317833424 epoch total loss 0.313780099\n",
      "Trained batch 257 batch loss 0.32685411 epoch total loss 0.313830972\n",
      "Trained batch 258 batch loss 0.314382702 epoch total loss 0.313833117\n",
      "Trained batch 259 batch loss 0.31230557 epoch total loss 0.313827217\n",
      "Trained batch 260 batch loss 0.320916891 epoch total loss 0.313854486\n",
      "Trained batch 261 batch loss 0.30927971 epoch total loss 0.313836962\n",
      "Trained batch 262 batch loss 0.326392204 epoch total loss 0.313884884\n",
      "Trained batch 263 batch loss 0.312391818 epoch total loss 0.313879222\n",
      "Trained batch 264 batch loss 0.256421447 epoch total loss 0.313661575\n",
      "Trained batch 265 batch loss 0.266307354 epoch total loss 0.313482881\n",
      "Trained batch 266 batch loss 0.31268692 epoch total loss 0.3134799\n",
      "Trained batch 267 batch loss 0.28460452 epoch total loss 0.313371748\n",
      "Trained batch 268 batch loss 0.292264253 epoch total loss 0.313293\n",
      "Trained batch 269 batch loss 0.314151764 epoch total loss 0.313296169\n",
      "Trained batch 270 batch loss 0.313363791 epoch total loss 0.313296437\n",
      "Trained batch 271 batch loss 0.305669755 epoch total loss 0.313268274\n",
      "Trained batch 272 batch loss 0.319282264 epoch total loss 0.313290387\n",
      "Trained batch 273 batch loss 0.328640223 epoch total loss 0.313346624\n",
      "Trained batch 274 batch loss 0.316178769 epoch total loss 0.313356966\n",
      "Trained batch 275 batch loss 0.317637712 epoch total loss 0.313372523\n",
      "Trained batch 276 batch loss 0.305221111 epoch total loss 0.313343\n",
      "Trained batch 277 batch loss 0.281912416 epoch total loss 0.313229531\n",
      "Trained batch 278 batch loss 0.291038632 epoch total loss 0.31314972\n",
      "Trained batch 279 batch loss 0.315857649 epoch total loss 0.313159406\n",
      "Trained batch 280 batch loss 0.307798594 epoch total loss 0.313140273\n",
      "Trained batch 281 batch loss 0.300742537 epoch total loss 0.313096166\n",
      "Trained batch 282 batch loss 0.301169276 epoch total loss 0.313053876\n",
      "Trained batch 283 batch loss 0.300359309 epoch total loss 0.313009024\n",
      "Trained batch 284 batch loss 0.309132487 epoch total loss 0.312995374\n",
      "Trained batch 285 batch loss 0.324990869 epoch total loss 0.313037455\n",
      "Trained batch 286 batch loss 0.332785249 epoch total loss 0.313106507\n",
      "Trained batch 287 batch loss 0.308380783 epoch total loss 0.313090056\n",
      "Trained batch 288 batch loss 0.293640584 epoch total loss 0.313022494\n",
      "Trained batch 289 batch loss 0.285473973 epoch total loss 0.312927186\n",
      "Trained batch 290 batch loss 0.269513756 epoch total loss 0.312777489\n",
      "Trained batch 291 batch loss 0.289697587 epoch total loss 0.312698185\n",
      "Trained batch 292 batch loss 0.317672 epoch total loss 0.312715203\n",
      "Trained batch 293 batch loss 0.309305966 epoch total loss 0.31270358\n",
      "Trained batch 294 batch loss 0.290186077 epoch total loss 0.312627\n",
      "Trained batch 295 batch loss 0.286074787 epoch total loss 0.312536955\n",
      "Trained batch 296 batch loss 0.296269536 epoch total loss 0.312482\n",
      "Trained batch 297 batch loss 0.314164221 epoch total loss 0.312487662\n",
      "Trained batch 298 batch loss 0.3345837 epoch total loss 0.31256184\n",
      "Trained batch 299 batch loss 0.313397169 epoch total loss 0.312564641\n",
      "Trained batch 300 batch loss 0.283592731 epoch total loss 0.312468052\n",
      "Trained batch 301 batch loss 0.256956279 epoch total loss 0.312283635\n",
      "Trained batch 302 batch loss 0.231342971 epoch total loss 0.312015623\n",
      "Trained batch 303 batch loss 0.272886038 epoch total loss 0.311886489\n",
      "Trained batch 304 batch loss 0.269953 epoch total loss 0.311748564\n",
      "Trained batch 305 batch loss 0.348879397 epoch total loss 0.311870277\n",
      "Trained batch 306 batch loss 0.310853183 epoch total loss 0.311866969\n",
      "Trained batch 307 batch loss 0.308637679 epoch total loss 0.311856449\n",
      "Trained batch 308 batch loss 0.284569502 epoch total loss 0.311767846\n",
      "Trained batch 309 batch loss 0.292940944 epoch total loss 0.311706901\n",
      "Trained batch 310 batch loss 0.289521068 epoch total loss 0.311635345\n",
      "Trained batch 311 batch loss 0.303282708 epoch total loss 0.311608493\n",
      "Trained batch 312 batch loss 0.314323127 epoch total loss 0.311617196\n",
      "Trained batch 313 batch loss 0.303333282 epoch total loss 0.311590701\n",
      "Trained batch 314 batch loss 0.322603256 epoch total loss 0.311625779\n",
      "Trained batch 315 batch loss 0.302636653 epoch total loss 0.311597228\n",
      "Trained batch 316 batch loss 0.293563247 epoch total loss 0.311540157\n",
      "Trained batch 317 batch loss 0.297168642 epoch total loss 0.311494827\n",
      "Trained batch 318 batch loss 0.307729185 epoch total loss 0.311483\n",
      "Trained batch 319 batch loss 0.285899043 epoch total loss 0.311402768\n",
      "Trained batch 320 batch loss 0.293762356 epoch total loss 0.311347663\n",
      "Trained batch 321 batch loss 0.300495893 epoch total loss 0.311313868\n",
      "Trained batch 322 batch loss 0.312392771 epoch total loss 0.311317205\n",
      "Trained batch 323 batch loss 0.283214509 epoch total loss 0.311230183\n",
      "Trained batch 324 batch loss 0.305176854 epoch total loss 0.311211497\n",
      "Trained batch 325 batch loss 0.28286472 epoch total loss 0.311124295\n",
      "Trained batch 326 batch loss 0.271713406 epoch total loss 0.311003387\n",
      "Trained batch 327 batch loss 0.306784928 epoch total loss 0.310990512\n",
      "Trained batch 328 batch loss 0.2954849 epoch total loss 0.310943246\n",
      "Trained batch 329 batch loss 0.286592305 epoch total loss 0.310869217\n",
      "Trained batch 330 batch loss 0.291172862 epoch total loss 0.310809523\n",
      "Trained batch 331 batch loss 0.271943 epoch total loss 0.310692102\n",
      "Trained batch 332 batch loss 0.28805235 epoch total loss 0.310623914\n",
      "Trained batch 333 batch loss 0.295485407 epoch total loss 0.310578465\n",
      "Trained batch 334 batch loss 0.298069924 epoch total loss 0.310541034\n",
      "Trained batch 335 batch loss 0.307243228 epoch total loss 0.310531169\n",
      "Trained batch 336 batch loss 0.289773405 epoch total loss 0.310469389\n",
      "Trained batch 337 batch loss 0.284899026 epoch total loss 0.310393512\n",
      "Trained batch 338 batch loss 0.275519878 epoch total loss 0.310290337\n",
      "Trained batch 339 batch loss 0.378899872 epoch total loss 0.310492724\n",
      "Trained batch 340 batch loss 0.374417067 epoch total loss 0.310680747\n",
      "Trained batch 341 batch loss 0.31640771 epoch total loss 0.310697526\n",
      "Trained batch 342 batch loss 0.328999341 epoch total loss 0.310751051\n",
      "Trained batch 343 batch loss 0.373344272 epoch total loss 0.31093356\n",
      "Trained batch 344 batch loss 0.333351374 epoch total loss 0.310998708\n",
      "Trained batch 345 batch loss 0.337969869 epoch total loss 0.31107688\n",
      "Trained batch 346 batch loss 0.285861045 epoch total loss 0.311004\n",
      "Trained batch 347 batch loss 0.330332786 epoch total loss 0.311059684\n",
      "Trained batch 348 batch loss 0.299436092 epoch total loss 0.311026305\n",
      "Trained batch 349 batch loss 0.323514849 epoch total loss 0.311062098\n",
      "Trained batch 350 batch loss 0.317129791 epoch total loss 0.311079443\n",
      "Trained batch 351 batch loss 0.332493871 epoch total loss 0.311140448\n",
      "Trained batch 352 batch loss 0.338279247 epoch total loss 0.311217546\n",
      "Trained batch 353 batch loss 0.319098443 epoch total loss 0.311239868\n",
      "Trained batch 354 batch loss 0.337930083 epoch total loss 0.311315268\n",
      "Trained batch 355 batch loss 0.346978247 epoch total loss 0.311415732\n",
      "Trained batch 356 batch loss 0.329539567 epoch total loss 0.311466634\n",
      "Trained batch 357 batch loss 0.324685335 epoch total loss 0.311503649\n",
      "Trained batch 358 batch loss 0.342004627 epoch total loss 0.311588854\n",
      "Trained batch 359 batch loss 0.326345712 epoch total loss 0.311629951\n",
      "Trained batch 360 batch loss 0.333432853 epoch total loss 0.311690509\n",
      "Trained batch 361 batch loss 0.348500788 epoch total loss 0.311792493\n",
      "Trained batch 362 batch loss 0.306549758 epoch total loss 0.311778\n",
      "Trained batch 363 batch loss 0.310327113 epoch total loss 0.311774015\n",
      "Trained batch 364 batch loss 0.313710511 epoch total loss 0.31177935\n",
      "Trained batch 365 batch loss 0.335855961 epoch total loss 0.311845303\n",
      "Trained batch 366 batch loss 0.348808616 epoch total loss 0.311946273\n",
      "Trained batch 367 batch loss 0.28546989 epoch total loss 0.311874151\n",
      "Trained batch 368 batch loss 0.284770608 epoch total loss 0.31180048\n",
      "Trained batch 369 batch loss 0.295162648 epoch total loss 0.311755389\n",
      "Trained batch 370 batch loss 0.292272806 epoch total loss 0.311702758\n",
      "Trained batch 371 batch loss 0.355379 epoch total loss 0.311820477\n",
      "Trained batch 372 batch loss 0.312634826 epoch total loss 0.311822653\n",
      "Trained batch 373 batch loss 0.318287015 epoch total loss 0.31184\n",
      "Trained batch 374 batch loss 0.279735565 epoch total loss 0.311754167\n",
      "Trained batch 375 batch loss 0.280068964 epoch total loss 0.311669648\n",
      "Trained batch 376 batch loss 0.299405068 epoch total loss 0.311637044\n",
      "Trained batch 377 batch loss 0.337929 epoch total loss 0.311706781\n",
      "Trained batch 378 batch loss 0.322980225 epoch total loss 0.311736614\n",
      "Trained batch 379 batch loss 0.301382095 epoch total loss 0.311709315\n",
      "Trained batch 380 batch loss 0.343227893 epoch total loss 0.311792254\n",
      "Trained batch 381 batch loss 0.323243082 epoch total loss 0.311822295\n",
      "Trained batch 382 batch loss 0.284072608 epoch total loss 0.311749667\n",
      "Trained batch 383 batch loss 0.309472144 epoch total loss 0.311743706\n",
      "Trained batch 384 batch loss 0.315099686 epoch total loss 0.311752468\n",
      "Trained batch 385 batch loss 0.354457736 epoch total loss 0.311863363\n",
      "Trained batch 386 batch loss 0.304747105 epoch total loss 0.311844945\n",
      "Trained batch 387 batch loss 0.295416087 epoch total loss 0.311802506\n",
      "Trained batch 388 batch loss 0.295822799 epoch total loss 0.31176132\n",
      "Trained batch 389 batch loss 0.283895046 epoch total loss 0.311689675\n",
      "Trained batch 390 batch loss 0.307390213 epoch total loss 0.311678648\n",
      "Trained batch 391 batch loss 0.326058716 epoch total loss 0.311715424\n",
      "Trained batch 392 batch loss 0.300824612 epoch total loss 0.311687648\n",
      "Trained batch 393 batch loss 0.317592829 epoch total loss 0.311702669\n",
      "Trained batch 394 batch loss 0.303347319 epoch total loss 0.311681479\n",
      "Trained batch 395 batch loss 0.34384644 epoch total loss 0.311762899\n",
      "Trained batch 396 batch loss 0.332986474 epoch total loss 0.311816484\n",
      "Trained batch 397 batch loss 0.323245674 epoch total loss 0.311845273\n",
      "Trained batch 398 batch loss 0.311940819 epoch total loss 0.311845511\n",
      "Trained batch 399 batch loss 0.310518086 epoch total loss 0.311842203\n",
      "Trained batch 400 batch loss 0.300824314 epoch total loss 0.311814666\n",
      "Trained batch 401 batch loss 0.295241624 epoch total loss 0.31177333\n",
      "Trained batch 402 batch loss 0.3468979 epoch total loss 0.31186071\n",
      "Trained batch 403 batch loss 0.340412676 epoch total loss 0.311931551\n",
      "Trained batch 404 batch loss 0.348260343 epoch total loss 0.312021494\n",
      "Trained batch 405 batch loss 0.349687099 epoch total loss 0.312114477\n",
      "Trained batch 406 batch loss 0.309172034 epoch total loss 0.312107235\n",
      "Trained batch 407 batch loss 0.324655116 epoch total loss 0.312138051\n",
      "Trained batch 408 batch loss 0.317876935 epoch total loss 0.312152147\n",
      "Trained batch 409 batch loss 0.361519605 epoch total loss 0.312272847\n",
      "Trained batch 410 batch loss 0.328294039 epoch total loss 0.312311918\n",
      "Trained batch 411 batch loss 0.296083152 epoch total loss 0.312272429\n",
      "Trained batch 412 batch loss 0.276441574 epoch total loss 0.312185466\n",
      "Trained batch 413 batch loss 0.2988787 epoch total loss 0.31215322\n",
      "Trained batch 414 batch loss 0.293541282 epoch total loss 0.312108278\n",
      "Trained batch 415 batch loss 0.276973039 epoch total loss 0.31202364\n",
      "Trained batch 416 batch loss 0.320714176 epoch total loss 0.312044501\n",
      "Trained batch 417 batch loss 0.320149839 epoch total loss 0.312063932\n",
      "Trained batch 418 batch loss 0.341612846 epoch total loss 0.312134624\n",
      "Trained batch 419 batch loss 0.309566617 epoch total loss 0.312128514\n",
      "Trained batch 420 batch loss 0.293976367 epoch total loss 0.312085301\n",
      "Trained batch 421 batch loss 0.285347581 epoch total loss 0.312021792\n",
      "Trained batch 422 batch loss 0.281517804 epoch total loss 0.311949521\n",
      "Trained batch 423 batch loss 0.304722905 epoch total loss 0.311932445\n",
      "Trained batch 424 batch loss 0.321075946 epoch total loss 0.311954\n",
      "Trained batch 425 batch loss 0.327807486 epoch total loss 0.311991304\n",
      "Trained batch 426 batch loss 0.343355 epoch total loss 0.312064916\n",
      "Trained batch 427 batch loss 0.316320449 epoch total loss 0.31207487\n",
      "Trained batch 428 batch loss 0.325506896 epoch total loss 0.312106222\n",
      "Trained batch 429 batch loss 0.300808609 epoch total loss 0.312079906\n",
      "Trained batch 430 batch loss 0.301198542 epoch total loss 0.312054574\n",
      "Trained batch 431 batch loss 0.31858319 epoch total loss 0.312069744\n",
      "Trained batch 432 batch loss 0.30632174 epoch total loss 0.312056422\n",
      "Trained batch 433 batch loss 0.338456959 epoch total loss 0.312117398\n",
      "Trained batch 434 batch loss 0.304533303 epoch total loss 0.312099934\n",
      "Trained batch 435 batch loss 0.324613094 epoch total loss 0.312128693\n",
      "Trained batch 436 batch loss 0.317578197 epoch total loss 0.31214121\n",
      "Trained batch 437 batch loss 0.314926684 epoch total loss 0.312147588\n",
      "Trained batch 438 batch loss 0.291557342 epoch total loss 0.312100589\n",
      "Trained batch 439 batch loss 0.307619572 epoch total loss 0.312090367\n",
      "Trained batch 440 batch loss 0.29316023 epoch total loss 0.312047362\n",
      "Trained batch 441 batch loss 0.292539299 epoch total loss 0.312003136\n",
      "Trained batch 442 batch loss 0.29599604 epoch total loss 0.311966896\n",
      "Trained batch 443 batch loss 0.310937524 epoch total loss 0.311964601\n",
      "Trained batch 444 batch loss 0.301531076 epoch total loss 0.311941087\n",
      "Trained batch 445 batch loss 0.28454271 epoch total loss 0.311879545\n",
      "Trained batch 446 batch loss 0.326790571 epoch total loss 0.311912984\n",
      "Trained batch 447 batch loss 0.284200251 epoch total loss 0.311850965\n",
      "Trained batch 448 batch loss 0.311465651 epoch total loss 0.311850101\n",
      "Trained batch 449 batch loss 0.288112879 epoch total loss 0.311797231\n",
      "Trained batch 450 batch loss 0.298998773 epoch total loss 0.3117688\n",
      "Trained batch 451 batch loss 0.28812322 epoch total loss 0.311716348\n",
      "Trained batch 452 batch loss 0.289469063 epoch total loss 0.311667144\n",
      "Trained batch 453 batch loss 0.301947176 epoch total loss 0.311645687\n",
      "Trained batch 454 batch loss 0.305173755 epoch total loss 0.311631411\n",
      "Trained batch 455 batch loss 0.340427488 epoch total loss 0.311694711\n",
      "Trained batch 456 batch loss 0.29906112 epoch total loss 0.311667\n",
      "Trained batch 457 batch loss 0.307549298 epoch total loss 0.311658\n",
      "Trained batch 458 batch loss 0.310079753 epoch total loss 0.311654538\n",
      "Trained batch 459 batch loss 0.28916958 epoch total loss 0.311605543\n",
      "Trained batch 460 batch loss 0.289376646 epoch total loss 0.311557233\n",
      "Trained batch 461 batch loss 0.283148468 epoch total loss 0.311495602\n",
      "Trained batch 462 batch loss 0.283799738 epoch total loss 0.31143564\n",
      "Trained batch 463 batch loss 0.269700646 epoch total loss 0.311345518\n",
      "Trained batch 464 batch loss 0.289390296 epoch total loss 0.311298162\n",
      "Trained batch 465 batch loss 0.322486848 epoch total loss 0.311322212\n",
      "Trained batch 466 batch loss 0.293179393 epoch total loss 0.31128329\n",
      "Trained batch 467 batch loss 0.283920437 epoch total loss 0.311224699\n",
      "Trained batch 468 batch loss 0.313594341 epoch total loss 0.311229765\n",
      "Trained batch 469 batch loss 0.309440404 epoch total loss 0.311225951\n",
      "Trained batch 470 batch loss 0.288796633 epoch total loss 0.311178237\n",
      "Trained batch 471 batch loss 0.322002172 epoch total loss 0.311201215\n",
      "Trained batch 472 batch loss 0.321833551 epoch total loss 0.311223745\n",
      "Trained batch 473 batch loss 0.31602335 epoch total loss 0.311233908\n",
      "Trained batch 474 batch loss 0.306773841 epoch total loss 0.31122452\n",
      "Trained batch 475 batch loss 0.321310937 epoch total loss 0.311245739\n",
      "Trained batch 476 batch loss 0.304158509 epoch total loss 0.311230838\n",
      "Trained batch 477 batch loss 0.289275795 epoch total loss 0.311184794\n",
      "Trained batch 478 batch loss 0.318717033 epoch total loss 0.311200559\n",
      "Trained batch 479 batch loss 0.323409289 epoch total loss 0.31122604\n",
      "Trained batch 480 batch loss 0.343970299 epoch total loss 0.311294228\n",
      "Trained batch 481 batch loss 0.336886644 epoch total loss 0.311347425\n",
      "Trained batch 482 batch loss 0.357549608 epoch total loss 0.311443269\n",
      "Trained batch 483 batch loss 0.340392977 epoch total loss 0.311503232\n",
      "Trained batch 484 batch loss 0.316809624 epoch total loss 0.311514169\n",
      "Trained batch 485 batch loss 0.320204496 epoch total loss 0.31153208\n",
      "Trained batch 486 batch loss 0.314569294 epoch total loss 0.311538339\n",
      "Trained batch 487 batch loss 0.334736884 epoch total loss 0.311585963\n",
      "Trained batch 488 batch loss 0.300963283 epoch total loss 0.311564207\n",
      "Trained batch 489 batch loss 0.308945775 epoch total loss 0.311558843\n",
      "Trained batch 490 batch loss 0.305878699 epoch total loss 0.31154725\n",
      "Trained batch 491 batch loss 0.301952451 epoch total loss 0.311527729\n",
      "Trained batch 492 batch loss 0.308424234 epoch total loss 0.311521411\n",
      "Trained batch 493 batch loss 0.250594497 epoch total loss 0.311397851\n",
      "Trained batch 494 batch loss 0.283072412 epoch total loss 0.311340481\n",
      "Trained batch 495 batch loss 0.28806445 epoch total loss 0.311293483\n",
      "Trained batch 496 batch loss 0.331900597 epoch total loss 0.311335\n",
      "Trained batch 497 batch loss 0.336397648 epoch total loss 0.311385423\n",
      "Trained batch 498 batch loss 0.349492401 epoch total loss 0.311461955\n",
      "Trained batch 499 batch loss 0.363472372 epoch total loss 0.311566174\n",
      "Trained batch 500 batch loss 0.346091509 epoch total loss 0.311635226\n",
      "Trained batch 501 batch loss 0.321634889 epoch total loss 0.311655194\n",
      "Trained batch 502 batch loss 0.331919968 epoch total loss 0.311695576\n",
      "Trained batch 503 batch loss 0.281607807 epoch total loss 0.311635733\n",
      "Trained batch 504 batch loss 0.306758195 epoch total loss 0.311626077\n",
      "Trained batch 505 batch loss 0.313586712 epoch total loss 0.311629951\n",
      "Trained batch 506 batch loss 0.277364343 epoch total loss 0.31156221\n",
      "Trained batch 507 batch loss 0.275139332 epoch total loss 0.311490387\n",
      "Trained batch 508 batch loss 0.268706203 epoch total loss 0.311406165\n",
      "Trained batch 509 batch loss 0.27304548 epoch total loss 0.311330795\n",
      "Trained batch 510 batch loss 0.286263615 epoch total loss 0.311281651\n",
      "Trained batch 511 batch loss 0.263706893 epoch total loss 0.311188549\n",
      "Trained batch 512 batch loss 0.281521797 epoch total loss 0.311130613\n",
      "Trained batch 513 batch loss 0.301518291 epoch total loss 0.311111867\n",
      "Trained batch 514 batch loss 0.311900437 epoch total loss 0.311113417\n",
      "Trained batch 515 batch loss 0.304148614 epoch total loss 0.311099887\n",
      "Trained batch 516 batch loss 0.286472023 epoch total loss 0.311052173\n",
      "Trained batch 517 batch loss 0.29874748 epoch total loss 0.311028361\n",
      "Trained batch 518 batch loss 0.318148881 epoch total loss 0.3110421\n",
      "Trained batch 519 batch loss 0.317104727 epoch total loss 0.311053783\n",
      "Trained batch 520 batch loss 0.319613278 epoch total loss 0.311070263\n",
      "Trained batch 521 batch loss 0.31243664 epoch total loss 0.311072886\n",
      "Trained batch 522 batch loss 0.330999851 epoch total loss 0.311111033\n",
      "Trained batch 523 batch loss 0.305458605 epoch total loss 0.311100245\n",
      "Trained batch 524 batch loss 0.294565707 epoch total loss 0.311068714\n",
      "Trained batch 525 batch loss 0.311109811 epoch total loss 0.311068773\n",
      "Trained batch 526 batch loss 0.274937689 epoch total loss 0.311000079\n",
      "Trained batch 527 batch loss 0.290226609 epoch total loss 0.31096065\n",
      "Trained batch 528 batch loss 0.288751066 epoch total loss 0.310918599\n",
      "Trained batch 529 batch loss 0.281954944 epoch total loss 0.310863853\n",
      "Trained batch 530 batch loss 0.281465948 epoch total loss 0.31080839\n",
      "Trained batch 531 batch loss 0.288217843 epoch total loss 0.310765833\n",
      "Trained batch 532 batch loss 0.281205326 epoch total loss 0.310710281\n",
      "Trained batch 533 batch loss 0.277510196 epoch total loss 0.310648\n",
      "Trained batch 534 batch loss 0.324611574 epoch total loss 0.310674161\n",
      "Trained batch 535 batch loss 0.329478681 epoch total loss 0.310709298\n",
      "Trained batch 536 batch loss 0.293376327 epoch total loss 0.310676962\n",
      "Trained batch 537 batch loss 0.324076772 epoch total loss 0.310701936\n",
      "Trained batch 538 batch loss 0.307849 epoch total loss 0.310696632\n",
      "Trained batch 539 batch loss 0.300889254 epoch total loss 0.310678422\n",
      "Trained batch 540 batch loss 0.317353398 epoch total loss 0.31069079\n",
      "Trained batch 541 batch loss 0.328677654 epoch total loss 0.31072402\n",
      "Trained batch 542 batch loss 0.299689204 epoch total loss 0.310703665\n",
      "Trained batch 543 batch loss 0.264180064 epoch total loss 0.310617983\n",
      "Trained batch 544 batch loss 0.317846447 epoch total loss 0.310631245\n",
      "Trained batch 545 batch loss 0.337558568 epoch total loss 0.310680658\n",
      "Trained batch 546 batch loss 0.323604524 epoch total loss 0.310704321\n",
      "Trained batch 547 batch loss 0.318523645 epoch total loss 0.310718626\n",
      "Trained batch 548 batch loss 0.322726488 epoch total loss 0.31074053\n",
      "Trained batch 549 batch loss 0.314062506 epoch total loss 0.31074658\n",
      "Trained batch 550 batch loss 0.300642073 epoch total loss 0.310728192\n",
      "Trained batch 551 batch loss 0.286829025 epoch total loss 0.31068483\n",
      "Trained batch 552 batch loss 0.305452406 epoch total loss 0.310675353\n",
      "Trained batch 553 batch loss 0.307317138 epoch total loss 0.310669273\n",
      "Trained batch 554 batch loss 0.307174176 epoch total loss 0.310662955\n",
      "Trained batch 555 batch loss 0.313122123 epoch total loss 0.310667396\n",
      "Trained batch 556 batch loss 0.35472694 epoch total loss 0.31074664\n",
      "Trained batch 557 batch loss 0.31244418 epoch total loss 0.31074968\n",
      "Trained batch 558 batch loss 0.323322117 epoch total loss 0.31077221\n",
      "Trained batch 559 batch loss 0.330820143 epoch total loss 0.310808063\n",
      "Trained batch 560 batch loss 0.359541178 epoch total loss 0.310895115\n",
      "Trained batch 561 batch loss 0.335307091 epoch total loss 0.310938627\n",
      "Trained batch 562 batch loss 0.362404108 epoch total loss 0.311030209\n",
      "Trained batch 563 batch loss 0.335982621 epoch total loss 0.311074525\n",
      "Trained batch 564 batch loss 0.296790361 epoch total loss 0.311049193\n",
      "Trained batch 565 batch loss 0.275983691 epoch total loss 0.310987145\n",
      "Trained batch 566 batch loss 0.283206314 epoch total loss 0.31093806\n",
      "Trained batch 567 batch loss 0.318076283 epoch total loss 0.310950637\n",
      "Trained batch 568 batch loss 0.305583686 epoch total loss 0.31094119\n",
      "Trained batch 569 batch loss 0.325963736 epoch total loss 0.310967565\n",
      "Trained batch 570 batch loss 0.309790671 epoch total loss 0.310965508\n",
      "Trained batch 571 batch loss 0.291867793 epoch total loss 0.31093207\n",
      "Trained batch 572 batch loss 0.308206081 epoch total loss 0.310927302\n",
      "Trained batch 573 batch loss 0.322070241 epoch total loss 0.310946733\n",
      "Trained batch 574 batch loss 0.292102396 epoch total loss 0.31091392\n",
      "Trained batch 575 batch loss 0.293628603 epoch total loss 0.31088385\n",
      "Trained batch 576 batch loss 0.26748246 epoch total loss 0.31080851\n",
      "Trained batch 577 batch loss 0.304585397 epoch total loss 0.310797691\n",
      "Trained batch 578 batch loss 0.322664171 epoch total loss 0.310818225\n",
      "Trained batch 579 batch loss 0.307184458 epoch total loss 0.310811967\n",
      "Trained batch 580 batch loss 0.299057186 epoch total loss 0.310791701\n",
      "Trained batch 581 batch loss 0.280393869 epoch total loss 0.310739368\n",
      "Trained batch 582 batch loss 0.274419099 epoch total loss 0.310676962\n",
      "Trained batch 583 batch loss 0.26335156 epoch total loss 0.310595781\n",
      "Trained batch 584 batch loss 0.272303343 epoch total loss 0.310530245\n",
      "Trained batch 585 batch loss 0.258270413 epoch total loss 0.310440898\n",
      "Trained batch 586 batch loss 0.272660017 epoch total loss 0.310376436\n",
      "Trained batch 587 batch loss 0.304923475 epoch total loss 0.310367137\n",
      "Trained batch 588 batch loss 0.274989963 epoch total loss 0.310306966\n",
      "Trained batch 589 batch loss 0.250034928 epoch total loss 0.310204625\n",
      "Trained batch 590 batch loss 0.273622215 epoch total loss 0.310142606\n",
      "Trained batch 591 batch loss 0.32134378 epoch total loss 0.310161591\n",
      "Trained batch 592 batch loss 0.312094241 epoch total loss 0.310164839\n",
      "Trained batch 593 batch loss 0.295580536 epoch total loss 0.310140252\n",
      "Trained batch 594 batch loss 0.340037167 epoch total loss 0.310190588\n",
      "Trained batch 595 batch loss 0.33977294 epoch total loss 0.310240299\n",
      "Trained batch 596 batch loss 0.282584488 epoch total loss 0.310193866\n",
      "Trained batch 597 batch loss 0.293139398 epoch total loss 0.310165316\n",
      "Trained batch 598 batch loss 0.29742378 epoch total loss 0.310144\n",
      "Trained batch 599 batch loss 0.316282332 epoch total loss 0.310154259\n",
      "Trained batch 600 batch loss 0.297621697 epoch total loss 0.310133368\n",
      "Trained batch 601 batch loss 0.246539503 epoch total loss 0.31002754\n",
      "Trained batch 602 batch loss 0.221385777 epoch total loss 0.309880316\n",
      "Trained batch 603 batch loss 0.283723235 epoch total loss 0.309836924\n",
      "Trained batch 604 batch loss 0.32260856 epoch total loss 0.309858054\n",
      "Trained batch 605 batch loss 0.360855281 epoch total loss 0.309942335\n",
      "Trained batch 606 batch loss 0.346477926 epoch total loss 0.310002655\n",
      "Trained batch 607 batch loss 0.323527366 epoch total loss 0.310024947\n",
      "Trained batch 608 batch loss 0.31876117 epoch total loss 0.310039282\n",
      "Trained batch 609 batch loss 0.303040326 epoch total loss 0.310027808\n",
      "Trained batch 610 batch loss 0.324932545 epoch total loss 0.310052246\n",
      "Trained batch 611 batch loss 0.319164753 epoch total loss 0.310067147\n",
      "Trained batch 612 batch loss 0.352620423 epoch total loss 0.310136676\n",
      "Trained batch 613 batch loss 0.346223086 epoch total loss 0.310195535\n",
      "Trained batch 614 batch loss 0.329677641 epoch total loss 0.310227275\n",
      "Trained batch 615 batch loss 0.327177107 epoch total loss 0.310254842\n",
      "Trained batch 616 batch loss 0.311783582 epoch total loss 0.310257316\n",
      "Trained batch 617 batch loss 0.312992394 epoch total loss 0.310261756\n",
      "Trained batch 618 batch loss 0.314565957 epoch total loss 0.3102687\n",
      "Trained batch 619 batch loss 0.306625664 epoch total loss 0.310262829\n",
      "Trained batch 620 batch loss 0.344682634 epoch total loss 0.310318351\n",
      "Trained batch 621 batch loss 0.336545557 epoch total loss 0.310360581\n",
      "Trained batch 622 batch loss 0.348800421 epoch total loss 0.310422391\n",
      "Trained batch 623 batch loss 0.352768123 epoch total loss 0.31049034\n",
      "Trained batch 624 batch loss 0.354551852 epoch total loss 0.310560971\n",
      "Trained batch 625 batch loss 0.356398553 epoch total loss 0.310634315\n",
      "Trained batch 626 batch loss 0.330370188 epoch total loss 0.310665816\n",
      "Trained batch 627 batch loss 0.334397465 epoch total loss 0.310703665\n",
      "Trained batch 628 batch loss 0.326966882 epoch total loss 0.310729563\n",
      "Trained batch 629 batch loss 0.340336382 epoch total loss 0.310776621\n",
      "Trained batch 630 batch loss 0.311275929 epoch total loss 0.310777426\n",
      "Trained batch 631 batch loss 0.318067849 epoch total loss 0.310789\n",
      "Trained batch 632 batch loss 0.311239719 epoch total loss 0.310789675\n",
      "Trained batch 633 batch loss 0.317257047 epoch total loss 0.310799897\n",
      "Trained batch 634 batch loss 0.332949609 epoch total loss 0.310834855\n",
      "Trained batch 635 batch loss 0.320878476 epoch total loss 0.31085065\n",
      "Trained batch 636 batch loss 0.284590751 epoch total loss 0.310809374\n",
      "Trained batch 637 batch loss 0.292435795 epoch total loss 0.310780525\n",
      "Trained batch 638 batch loss 0.276789337 epoch total loss 0.310727268\n",
      "Trained batch 639 batch loss 0.286267489 epoch total loss 0.310688972\n",
      "Trained batch 640 batch loss 0.29174608 epoch total loss 0.310659379\n",
      "Trained batch 641 batch loss 0.283145398 epoch total loss 0.310616463\n",
      "Trained batch 642 batch loss 0.300813317 epoch total loss 0.310601175\n",
      "Trained batch 643 batch loss 0.282343686 epoch total loss 0.310557246\n",
      "Trained batch 644 batch loss 0.29627642 epoch total loss 0.310535073\n",
      "Trained batch 645 batch loss 0.264380336 epoch total loss 0.310463518\n",
      "Trained batch 646 batch loss 0.295418948 epoch total loss 0.310440242\n",
      "Trained batch 647 batch loss 0.299228191 epoch total loss 0.310422897\n",
      "Trained batch 648 batch loss 0.316864192 epoch total loss 0.310432822\n",
      "Trained batch 649 batch loss 0.322140485 epoch total loss 0.310450882\n",
      "Trained batch 650 batch loss 0.286621481 epoch total loss 0.310414225\n",
      "Trained batch 651 batch loss 0.269296944 epoch total loss 0.310351074\n",
      "Trained batch 652 batch loss 0.253317654 epoch total loss 0.310263574\n",
      "Trained batch 653 batch loss 0.268608034 epoch total loss 0.310199767\n",
      "Trained batch 654 batch loss 0.278000832 epoch total loss 0.310150534\n",
      "Trained batch 655 batch loss 0.345952064 epoch total loss 0.310205191\n",
      "Trained batch 656 batch loss 0.388677597 epoch total loss 0.310324818\n",
      "Trained batch 657 batch loss 0.337090909 epoch total loss 0.310365558\n",
      "Trained batch 658 batch loss 0.305929124 epoch total loss 0.310358793\n",
      "Trained batch 659 batch loss 0.278241873 epoch total loss 0.310310066\n",
      "Trained batch 660 batch loss 0.298968017 epoch total loss 0.3102929\n",
      "Trained batch 661 batch loss 0.330377191 epoch total loss 0.310323268\n",
      "Trained batch 662 batch loss 0.308393598 epoch total loss 0.310320377\n",
      "Trained batch 663 batch loss 0.303623557 epoch total loss 0.310310274\n",
      "Trained batch 664 batch loss 0.32575 epoch total loss 0.31033349\n",
      "Trained batch 665 batch loss 0.314784586 epoch total loss 0.310340196\n",
      "Trained batch 666 batch loss 0.310019463 epoch total loss 0.310339719\n",
      "Trained batch 667 batch loss 0.281186074 epoch total loss 0.310296\n",
      "Trained batch 668 batch loss 0.317976773 epoch total loss 0.310307503\n",
      "Trained batch 669 batch loss 0.281446189 epoch total loss 0.310264379\n",
      "Trained batch 670 batch loss 0.305204332 epoch total loss 0.310256809\n",
      "Trained batch 671 batch loss 0.287635088 epoch total loss 0.310223103\n",
      "Trained batch 672 batch loss 0.292582065 epoch total loss 0.310196847\n",
      "Trained batch 673 batch loss 0.284297019 epoch total loss 0.310158372\n",
      "Trained batch 674 batch loss 0.28312692 epoch total loss 0.310118258\n",
      "Trained batch 675 batch loss 0.269929916 epoch total loss 0.310058743\n",
      "Trained batch 676 batch loss 0.288605 epoch total loss 0.310027\n",
      "Trained batch 677 batch loss 0.324399233 epoch total loss 0.310048223\n",
      "Trained batch 678 batch loss 0.325020611 epoch total loss 0.310070306\n",
      "Trained batch 679 batch loss 0.326238155 epoch total loss 0.310094118\n",
      "Trained batch 680 batch loss 0.304643333 epoch total loss 0.310086101\n",
      "Trained batch 681 batch loss 0.318505257 epoch total loss 0.310098469\n",
      "Trained batch 682 batch loss 0.326065183 epoch total loss 0.310121894\n",
      "Trained batch 683 batch loss 0.344231308 epoch total loss 0.310171843\n",
      "Trained batch 684 batch loss 0.298180819 epoch total loss 0.310154319\n",
      "Trained batch 685 batch loss 0.304110736 epoch total loss 0.310145497\n",
      "Trained batch 686 batch loss 0.300693631 epoch total loss 0.310131699\n",
      "Trained batch 687 batch loss 0.280018836 epoch total loss 0.31008786\n",
      "Trained batch 688 batch loss 0.275851935 epoch total loss 0.31003809\n",
      "Trained batch 689 batch loss 0.304763496 epoch total loss 0.31003046\n",
      "Trained batch 690 batch loss 0.2817536 epoch total loss 0.309989452\n",
      "Trained batch 691 batch loss 0.310809314 epoch total loss 0.309990644\n",
      "Trained batch 692 batch loss 0.280998707 epoch total loss 0.309948772\n",
      "Trained batch 693 batch loss 0.292330921 epoch total loss 0.309923321\n",
      "Trained batch 694 batch loss 0.297027409 epoch total loss 0.309904754\n",
      "Trained batch 695 batch loss 0.289394617 epoch total loss 0.30987525\n",
      "Trained batch 696 batch loss 0.286050409 epoch total loss 0.309841037\n",
      "Trained batch 697 batch loss 0.297728539 epoch total loss 0.309823662\n",
      "Trained batch 698 batch loss 0.317076921 epoch total loss 0.309834033\n",
      "Trained batch 699 batch loss 0.312660396 epoch total loss 0.309838086\n",
      "Trained batch 700 batch loss 0.305692047 epoch total loss 0.309832186\n",
      "Trained batch 701 batch loss 0.321897835 epoch total loss 0.309849381\n",
      "Trained batch 702 batch loss 0.319356471 epoch total loss 0.309862912\n",
      "Trained batch 703 batch loss 0.336247891 epoch total loss 0.309900463\n",
      "Trained batch 704 batch loss 0.308775 epoch total loss 0.309898853\n",
      "Trained batch 705 batch loss 0.345939577 epoch total loss 0.309949964\n",
      "Trained batch 706 batch loss 0.294521511 epoch total loss 0.309928119\n",
      "Trained batch 707 batch loss 0.284072757 epoch total loss 0.309891552\n",
      "Trained batch 708 batch loss 0.295229793 epoch total loss 0.309870839\n",
      "Trained batch 709 batch loss 0.294271141 epoch total loss 0.309848815\n",
      "Trained batch 710 batch loss 0.323417604 epoch total loss 0.309867918\n",
      "Trained batch 711 batch loss 0.345092416 epoch total loss 0.30991748\n",
      "Trained batch 712 batch loss 0.32862711 epoch total loss 0.309943736\n",
      "Trained batch 713 batch loss 0.324565411 epoch total loss 0.309964269\n",
      "Trained batch 714 batch loss 0.27977398 epoch total loss 0.30992198\n",
      "Trained batch 715 batch loss 0.318609715 epoch total loss 0.309934109\n",
      "Trained batch 716 batch loss 0.301903665 epoch total loss 0.309922904\n",
      "Trained batch 717 batch loss 0.339110196 epoch total loss 0.309963614\n",
      "Trained batch 718 batch loss 0.300841093 epoch total loss 0.309950918\n",
      "Trained batch 719 batch loss 0.297265977 epoch total loss 0.309933275\n",
      "Trained batch 720 batch loss 0.3222287 epoch total loss 0.309950352\n",
      "Trained batch 721 batch loss 0.265630513 epoch total loss 0.309888899\n",
      "Trained batch 722 batch loss 0.297972083 epoch total loss 0.309872389\n",
      "Trained batch 723 batch loss 0.33493492 epoch total loss 0.309907049\n",
      "Trained batch 724 batch loss 0.330714554 epoch total loss 0.309935778\n",
      "Trained batch 725 batch loss 0.293791503 epoch total loss 0.309913516\n",
      "Trained batch 726 batch loss 0.284375876 epoch total loss 0.309878349\n",
      "Trained batch 727 batch loss 0.260969609 epoch total loss 0.309811085\n",
      "Trained batch 728 batch loss 0.287720203 epoch total loss 0.309780717\n",
      "Trained batch 729 batch loss 0.272302032 epoch total loss 0.309729338\n",
      "Trained batch 730 batch loss 0.256664246 epoch total loss 0.30965665\n",
      "Trained batch 731 batch loss 0.271059513 epoch total loss 0.30960384\n",
      "Trained batch 732 batch loss 0.294126391 epoch total loss 0.30958268\n",
      "Trained batch 733 batch loss 0.287128657 epoch total loss 0.309552044\n",
      "Trained batch 734 batch loss 0.307714045 epoch total loss 0.30954954\n",
      "Trained batch 735 batch loss 0.312850058 epoch total loss 0.30955404\n",
      "Trained batch 736 batch loss 0.316970825 epoch total loss 0.309564114\n",
      "Trained batch 737 batch loss 0.292189747 epoch total loss 0.30954054\n",
      "Trained batch 738 batch loss 0.304542482 epoch total loss 0.309533745\n",
      "Trained batch 739 batch loss 0.285604507 epoch total loss 0.30950138\n",
      "Trained batch 740 batch loss 0.345366 epoch total loss 0.309549838\n",
      "Trained batch 741 batch loss 0.33245483 epoch total loss 0.309580743\n",
      "Trained batch 742 batch loss 0.311072 epoch total loss 0.30958274\n",
      "Trained batch 743 batch loss 0.304814607 epoch total loss 0.309576333\n",
      "Trained batch 744 batch loss 0.324183077 epoch total loss 0.309595972\n",
      "Trained batch 745 batch loss 0.314960569 epoch total loss 0.309603155\n",
      "Trained batch 746 batch loss 0.326956779 epoch total loss 0.30962643\n",
      "Trained batch 747 batch loss 0.319207698 epoch total loss 0.309639245\n",
      "Trained batch 748 batch loss 0.313743055 epoch total loss 0.309644729\n",
      "Trained batch 749 batch loss 0.333480924 epoch total loss 0.309676558\n",
      "Trained batch 750 batch loss 0.331223041 epoch total loss 0.309705287\n",
      "Trained batch 751 batch loss 0.329951 epoch total loss 0.309732258\n",
      "Trained batch 752 batch loss 0.299333751 epoch total loss 0.30971843\n",
      "Trained batch 753 batch loss 0.300801903 epoch total loss 0.309706569\n",
      "Trained batch 754 batch loss 0.267217666 epoch total loss 0.309650213\n",
      "Trained batch 755 batch loss 0.282652766 epoch total loss 0.30961445\n",
      "Trained batch 756 batch loss 0.269945145 epoch total loss 0.309561968\n",
      "Trained batch 757 batch loss 0.321804911 epoch total loss 0.309578151\n",
      "Trained batch 758 batch loss 0.328278154 epoch total loss 0.309602827\n",
      "Trained batch 759 batch loss 0.30842042 epoch total loss 0.309601277\n",
      "Trained batch 760 batch loss 0.260635287 epoch total loss 0.309536844\n",
      "Trained batch 761 batch loss 0.300604075 epoch total loss 0.309525102\n",
      "Trained batch 762 batch loss 0.335432649 epoch total loss 0.309559107\n",
      "Trained batch 763 batch loss 0.318615973 epoch total loss 0.309570968\n",
      "Trained batch 764 batch loss 0.324636519 epoch total loss 0.309590697\n",
      "Trained batch 765 batch loss 0.328112781 epoch total loss 0.309614897\n",
      "Trained batch 766 batch loss 0.365447521 epoch total loss 0.309687793\n",
      "Trained batch 767 batch loss 0.318442971 epoch total loss 0.309699178\n",
      "Trained batch 768 batch loss 0.325180978 epoch total loss 0.309719354\n",
      "Trained batch 769 batch loss 0.325786382 epoch total loss 0.309740245\n",
      "Trained batch 770 batch loss 0.348126143 epoch total loss 0.309790105\n",
      "Trained batch 771 batch loss 0.319928467 epoch total loss 0.309803247\n",
      "Trained batch 772 batch loss 0.297628134 epoch total loss 0.309787482\n",
      "Trained batch 773 batch loss 0.283740699 epoch total loss 0.309753776\n",
      "Trained batch 774 batch loss 0.267807961 epoch total loss 0.309699565\n",
      "Trained batch 775 batch loss 0.272608429 epoch total loss 0.309651732\n",
      "Trained batch 776 batch loss 0.316184402 epoch total loss 0.309660137\n",
      "Trained batch 777 batch loss 0.323166639 epoch total loss 0.309677511\n",
      "Trained batch 778 batch loss 0.312204808 epoch total loss 0.30968076\n",
      "Trained batch 779 batch loss 0.335396618 epoch total loss 0.309713781\n",
      "Trained batch 780 batch loss 0.306518465 epoch total loss 0.309709698\n",
      "Trained batch 781 batch loss 0.337647736 epoch total loss 0.309745461\n",
      "Trained batch 782 batch loss 0.311945 epoch total loss 0.309748292\n",
      "Trained batch 783 batch loss 0.31283167 epoch total loss 0.309752226\n",
      "Trained batch 784 batch loss 0.317200273 epoch total loss 0.309761733\n",
      "Trained batch 785 batch loss 0.313165575 epoch total loss 0.309766084\n",
      "Trained batch 786 batch loss 0.275373518 epoch total loss 0.309722304\n",
      "Trained batch 787 batch loss 0.296206295 epoch total loss 0.309705138\n",
      "Trained batch 788 batch loss 0.293984413 epoch total loss 0.3096852\n",
      "Trained batch 789 batch loss 0.303168923 epoch total loss 0.309676945\n",
      "Trained batch 790 batch loss 0.303134114 epoch total loss 0.30966863\n",
      "Trained batch 791 batch loss 0.326188922 epoch total loss 0.309689522\n",
      "Trained batch 792 batch loss 0.311594635 epoch total loss 0.309691936\n",
      "Trained batch 793 batch loss 0.308344871 epoch total loss 0.309690237\n",
      "Trained batch 794 batch loss 0.285691738 epoch total loss 0.309660017\n",
      "Trained batch 795 batch loss 0.299429715 epoch total loss 0.309647143\n",
      "Trained batch 796 batch loss 0.303744823 epoch total loss 0.309639722\n",
      "Trained batch 797 batch loss 0.278205693 epoch total loss 0.309600264\n",
      "Trained batch 798 batch loss 0.323671579 epoch total loss 0.309617907\n",
      "Trained batch 799 batch loss 0.30308941 epoch total loss 0.309609741\n",
      "Trained batch 800 batch loss 0.281245381 epoch total loss 0.309574276\n",
      "Trained batch 801 batch loss 0.275320202 epoch total loss 0.30953151\n",
      "Trained batch 802 batch loss 0.325609356 epoch total loss 0.309551567\n",
      "Trained batch 803 batch loss 0.385160416 epoch total loss 0.309645712\n",
      "Trained batch 804 batch loss 0.350873262 epoch total loss 0.309697\n",
      "Trained batch 805 batch loss 0.288330436 epoch total loss 0.309670448\n",
      "Trained batch 806 batch loss 0.338213563 epoch total loss 0.309705853\n",
      "Trained batch 807 batch loss 0.345927298 epoch total loss 0.309750766\n",
      "Trained batch 808 batch loss 0.334885687 epoch total loss 0.309781849\n",
      "Trained batch 809 batch loss 0.337047338 epoch total loss 0.309815556\n",
      "Trained batch 810 batch loss 0.288264394 epoch total loss 0.309788972\n",
      "Trained batch 811 batch loss 0.317266256 epoch total loss 0.309798181\n",
      "Trained batch 812 batch loss 0.2912696 epoch total loss 0.309775352\n",
      "Trained batch 813 batch loss 0.314988911 epoch total loss 0.30978179\n",
      "Trained batch 814 batch loss 0.326235741 epoch total loss 0.309802\n",
      "Trained batch 815 batch loss 0.334206969 epoch total loss 0.309831947\n",
      "Trained batch 816 batch loss 0.298986733 epoch total loss 0.309818655\n",
      "Trained batch 817 batch loss 0.337841213 epoch total loss 0.309852958\n",
      "Trained batch 818 batch loss 0.311259717 epoch total loss 0.309854656\n",
      "Trained batch 819 batch loss 0.285490513 epoch total loss 0.309824914\n",
      "Trained batch 820 batch loss 0.287393689 epoch total loss 0.309797585\n",
      "Trained batch 821 batch loss 0.289745867 epoch total loss 0.309773147\n",
      "Trained batch 822 batch loss 0.316042781 epoch total loss 0.309780777\n",
      "Trained batch 823 batch loss 0.301094204 epoch total loss 0.309770226\n",
      "Trained batch 824 batch loss 0.280653596 epoch total loss 0.309734911\n",
      "Trained batch 825 batch loss 0.288595051 epoch total loss 0.309709281\n",
      "Trained batch 826 batch loss 0.307982 epoch total loss 0.309707195\n",
      "Trained batch 827 batch loss 0.33667019 epoch total loss 0.309739798\n",
      "Trained batch 828 batch loss 0.36890009 epoch total loss 0.309811234\n",
      "Trained batch 829 batch loss 0.349591196 epoch total loss 0.309859216\n",
      "Trained batch 830 batch loss 0.343072593 epoch total loss 0.309899241\n",
      "Trained batch 831 batch loss 0.359613299 epoch total loss 0.309959084\n",
      "Trained batch 832 batch loss 0.309456497 epoch total loss 0.309958458\n",
      "Trained batch 833 batch loss 0.269778579 epoch total loss 0.309910208\n",
      "Trained batch 834 batch loss 0.285178035 epoch total loss 0.309880584\n",
      "Trained batch 835 batch loss 0.302748203 epoch total loss 0.309872\n",
      "Trained batch 836 batch loss 0.337547749 epoch total loss 0.309905142\n",
      "Trained batch 837 batch loss 0.31268996 epoch total loss 0.30990845\n",
      "Trained batch 838 batch loss 0.304347634 epoch total loss 0.309901804\n",
      "Trained batch 839 batch loss 0.291942686 epoch total loss 0.309880406\n",
      "Trained batch 840 batch loss 0.285524189 epoch total loss 0.309851408\n",
      "Trained batch 841 batch loss 0.27274251 epoch total loss 0.309807271\n",
      "Trained batch 842 batch loss 0.286732793 epoch total loss 0.309779882\n",
      "Trained batch 843 batch loss 0.283736 epoch total loss 0.309748977\n",
      "Trained batch 844 batch loss 0.277204067 epoch total loss 0.309710383\n",
      "Trained batch 845 batch loss 0.289899051 epoch total loss 0.309686929\n",
      "Trained batch 846 batch loss 0.300732821 epoch total loss 0.309676319\n",
      "Trained batch 847 batch loss 0.293304294 epoch total loss 0.309657\n",
      "Trained batch 848 batch loss 0.293192625 epoch total loss 0.309637576\n",
      "Trained batch 849 batch loss 0.296612561 epoch total loss 0.309622228\n",
      "Trained batch 850 batch loss 0.317059249 epoch total loss 0.30963096\n",
      "Trained batch 851 batch loss 0.298548162 epoch total loss 0.309617937\n",
      "Trained batch 852 batch loss 0.298119724 epoch total loss 0.309604436\n",
      "Trained batch 853 batch loss 0.273153186 epoch total loss 0.309561729\n",
      "Trained batch 854 batch loss 0.291482627 epoch total loss 0.30954054\n",
      "Trained batch 855 batch loss 0.302124619 epoch total loss 0.309531868\n",
      "Trained batch 856 batch loss 0.326009631 epoch total loss 0.30955112\n",
      "Trained batch 857 batch loss 0.304910362 epoch total loss 0.309545696\n",
      "Trained batch 858 batch loss 0.289303839 epoch total loss 0.309522122\n",
      "Trained batch 859 batch loss 0.303803027 epoch total loss 0.309515446\n",
      "Trained batch 860 batch loss 0.296826839 epoch total loss 0.309500694\n",
      "Trained batch 861 batch loss 0.290779144 epoch total loss 0.309478939\n",
      "Trained batch 862 batch loss 0.30916971 epoch total loss 0.309478581\n",
      "Trained batch 863 batch loss 0.318040371 epoch total loss 0.309488505\n",
      "Trained batch 864 batch loss 0.278185815 epoch total loss 0.309452295\n",
      "Trained batch 865 batch loss 0.275526017 epoch total loss 0.309413075\n",
      "Trained batch 866 batch loss 0.321123958 epoch total loss 0.309426606\n",
      "Trained batch 867 batch loss 0.254460663 epoch total loss 0.309363216\n",
      "Trained batch 868 batch loss 0.266148418 epoch total loss 0.309313416\n",
      "Trained batch 869 batch loss 0.23603332 epoch total loss 0.309229076\n",
      "Trained batch 870 batch loss 0.283886611 epoch total loss 0.309199929\n",
      "Trained batch 871 batch loss 0.280915201 epoch total loss 0.309167445\n",
      "Trained batch 872 batch loss 0.286730379 epoch total loss 0.309141725\n",
      "Trained batch 873 batch loss 0.291528285 epoch total loss 0.309121579\n",
      "Trained batch 874 batch loss 0.271074474 epoch total loss 0.309078038\n",
      "Trained batch 875 batch loss 0.274257302 epoch total loss 0.309038252\n",
      "Trained batch 876 batch loss 0.300529242 epoch total loss 0.309028566\n",
      "Trained batch 877 batch loss 0.297705233 epoch total loss 0.309015632\n",
      "Trained batch 878 batch loss 0.336870372 epoch total loss 0.309047371\n",
      "Trained batch 879 batch loss 0.267613918 epoch total loss 0.309000224\n",
      "Trained batch 880 batch loss 0.286325157 epoch total loss 0.308974445\n",
      "Trained batch 881 batch loss 0.274701864 epoch total loss 0.308935553\n",
      "Trained batch 882 batch loss 0.291104972 epoch total loss 0.308915317\n",
      "Trained batch 883 batch loss 0.314446956 epoch total loss 0.308921605\n",
      "Trained batch 884 batch loss 0.353912 epoch total loss 0.308972478\n",
      "Trained batch 885 batch loss 0.355070025 epoch total loss 0.309024572\n",
      "Trained batch 886 batch loss 0.336573541 epoch total loss 0.309055686\n",
      "Trained batch 887 batch loss 0.299766898 epoch total loss 0.309045225\n",
      "Trained batch 888 batch loss 0.278989792 epoch total loss 0.30901137\n",
      "Trained batch 889 batch loss 0.292218536 epoch total loss 0.308992475\n",
      "Trained batch 890 batch loss 0.328047335 epoch total loss 0.309013873\n",
      "Trained batch 891 batch loss 0.307459 epoch total loss 0.309012115\n",
      "Trained batch 892 batch loss 0.3102732 epoch total loss 0.309013546\n",
      "Trained batch 893 batch loss 0.312532902 epoch total loss 0.309017479\n",
      "Trained batch 894 batch loss 0.341942042 epoch total loss 0.309054315\n",
      "Trained batch 895 batch loss 0.305574983 epoch total loss 0.309050411\n",
      "Trained batch 896 batch loss 0.288425207 epoch total loss 0.309027404\n",
      "Trained batch 897 batch loss 0.303327411 epoch total loss 0.309021026\n",
      "Trained batch 898 batch loss 0.296891719 epoch total loss 0.309007525\n",
      "Trained batch 899 batch loss 0.303611577 epoch total loss 0.309001535\n",
      "Trained batch 900 batch loss 0.275604248 epoch total loss 0.308964431\n",
      "Trained batch 901 batch loss 0.295918 epoch total loss 0.308949977\n",
      "Trained batch 902 batch loss 0.32859832 epoch total loss 0.308971763\n",
      "Trained batch 903 batch loss 0.320964664 epoch total loss 0.308985025\n",
      "Trained batch 904 batch loss 0.345275551 epoch total loss 0.309025168\n",
      "Trained batch 905 batch loss 0.341632962 epoch total loss 0.309061229\n",
      "Trained batch 906 batch loss 0.319916338 epoch total loss 0.30907321\n",
      "Trained batch 907 batch loss 0.309709787 epoch total loss 0.309073925\n",
      "Trained batch 908 batch loss 0.256940514 epoch total loss 0.309016496\n",
      "Trained batch 909 batch loss 0.260703504 epoch total loss 0.308963358\n",
      "Trained batch 910 batch loss 0.244738266 epoch total loss 0.308892787\n",
      "Trained batch 911 batch loss 0.280050546 epoch total loss 0.308861136\n",
      "Trained batch 912 batch loss 0.296101451 epoch total loss 0.308847159\n",
      "Trained batch 913 batch loss 0.300501943 epoch total loss 0.308838\n",
      "Trained batch 914 batch loss 0.328640521 epoch total loss 0.308859706\n",
      "Trained batch 915 batch loss 0.310776204 epoch total loss 0.308861792\n",
      "Trained batch 916 batch loss 0.31285733 epoch total loss 0.308866173\n",
      "Trained batch 917 batch loss 0.248563439 epoch total loss 0.308800429\n",
      "Trained batch 918 batch loss 0.270542562 epoch total loss 0.308758736\n",
      "Trained batch 919 batch loss 0.334718913 epoch total loss 0.308787\n",
      "Trained batch 920 batch loss 0.320823491 epoch total loss 0.308800071\n",
      "Trained batch 921 batch loss 0.340896815 epoch total loss 0.30883494\n",
      "Trained batch 922 batch loss 0.337750673 epoch total loss 0.308866292\n",
      "Trained batch 923 batch loss 0.345737875 epoch total loss 0.308906227\n",
      "Trained batch 924 batch loss 0.319436073 epoch total loss 0.308917612\n",
      "Trained batch 925 batch loss 0.319266468 epoch total loss 0.308928818\n",
      "Trained batch 926 batch loss 0.313025236 epoch total loss 0.308933228\n",
      "Trained batch 927 batch loss 0.347760916 epoch total loss 0.308975101\n",
      "Trained batch 928 batch loss 0.308422655 epoch total loss 0.308974504\n",
      "Trained batch 929 batch loss 0.319140434 epoch total loss 0.308985442\n",
      "Trained batch 930 batch loss 0.335408568 epoch total loss 0.309013873\n",
      "Trained batch 931 batch loss 0.310514063 epoch total loss 0.309015483\n",
      "Trained batch 932 batch loss 0.328724027 epoch total loss 0.309036642\n",
      "Trained batch 933 batch loss 0.319515765 epoch total loss 0.309047878\n",
      "Trained batch 934 batch loss 0.35318768 epoch total loss 0.309095144\n",
      "Trained batch 935 batch loss 0.327914089 epoch total loss 0.309115261\n",
      "Trained batch 936 batch loss 0.311769068 epoch total loss 0.309118092\n",
      "Trained batch 937 batch loss 0.304542273 epoch total loss 0.309113204\n",
      "Trained batch 938 batch loss 0.315547347 epoch total loss 0.309120059\n",
      "Trained batch 939 batch loss 0.317113549 epoch total loss 0.309128582\n",
      "Trained batch 940 batch loss 0.289336771 epoch total loss 0.309107512\n",
      "Trained batch 941 batch loss 0.302098781 epoch total loss 0.309100062\n",
      "Trained batch 942 batch loss 0.319296688 epoch total loss 0.30911091\n",
      "Trained batch 943 batch loss 0.34024775 epoch total loss 0.309143901\n",
      "Trained batch 944 batch loss 0.297209084 epoch total loss 0.309131265\n",
      "Trained batch 945 batch loss 0.322249711 epoch total loss 0.309145123\n",
      "Trained batch 946 batch loss 0.301853836 epoch total loss 0.309137434\n",
      "Trained batch 947 batch loss 0.278751343 epoch total loss 0.309105337\n",
      "Trained batch 948 batch loss 0.304465353 epoch total loss 0.309100449\n",
      "Trained batch 949 batch loss 0.290210664 epoch total loss 0.309080541\n",
      "Trained batch 950 batch loss 0.289033532 epoch total loss 0.309059441\n",
      "Trained batch 951 batch loss 0.283233881 epoch total loss 0.309032291\n",
      "Trained batch 952 batch loss 0.268495291 epoch total loss 0.308989704\n",
      "Trained batch 953 batch loss 0.288685113 epoch total loss 0.308968425\n",
      "Trained batch 954 batch loss 0.31894803 epoch total loss 0.308978856\n",
      "Trained batch 955 batch loss 0.29457891 epoch total loss 0.308963805\n",
      "Trained batch 956 batch loss 0.27876398 epoch total loss 0.308932215\n",
      "Trained batch 957 batch loss 0.287170857 epoch total loss 0.308909476\n",
      "Trained batch 958 batch loss 0.277014 epoch total loss 0.308876187\n",
      "Trained batch 959 batch loss 0.294220895 epoch total loss 0.308860898\n",
      "Trained batch 960 batch loss 0.297023565 epoch total loss 0.30884856\n",
      "Trained batch 961 batch loss 0.327168435 epoch total loss 0.308867633\n",
      "Trained batch 962 batch loss 0.304442555 epoch total loss 0.308863044\n",
      "Trained batch 963 batch loss 0.322381824 epoch total loss 0.308877081\n",
      "Trained batch 964 batch loss 0.305971146 epoch total loss 0.308874071\n",
      "Trained batch 965 batch loss 0.300185889 epoch total loss 0.30886507\n",
      "Trained batch 966 batch loss 0.266382813 epoch total loss 0.308821082\n",
      "Trained batch 967 batch loss 0.253105372 epoch total loss 0.308763474\n",
      "Trained batch 968 batch loss 0.293233603 epoch total loss 0.308747441\n",
      "Trained batch 969 batch loss 0.318189025 epoch total loss 0.308757186\n",
      "Trained batch 970 batch loss 0.32541281 epoch total loss 0.308774352\n",
      "Trained batch 971 batch loss 0.327068418 epoch total loss 0.308793157\n",
      "Trained batch 972 batch loss 0.284292251 epoch total loss 0.308767974\n",
      "Trained batch 973 batch loss 0.306644291 epoch total loss 0.308765769\n",
      "Trained batch 974 batch loss 0.306153983 epoch total loss 0.308763087\n",
      "Trained batch 975 batch loss 0.2798706 epoch total loss 0.308733463\n",
      "Trained batch 976 batch loss 0.268713683 epoch total loss 0.308692455\n",
      "Trained batch 977 batch loss 0.324227095 epoch total loss 0.30870837\n",
      "Trained batch 978 batch loss 0.31328395 epoch total loss 0.308713049\n",
      "Trained batch 979 batch loss 0.316687286 epoch total loss 0.308721185\n",
      "Trained batch 980 batch loss 0.327832073 epoch total loss 0.308740675\n",
      "Trained batch 981 batch loss 0.365552217 epoch total loss 0.308798581\n",
      "Trained batch 982 batch loss 0.307276547 epoch total loss 0.308797032\n",
      "Trained batch 983 batch loss 0.314808846 epoch total loss 0.308803141\n",
      "Trained batch 984 batch loss 0.301127583 epoch total loss 0.308795333\n",
      "Trained batch 985 batch loss 0.361207098 epoch total loss 0.30884856\n",
      "Trained batch 986 batch loss 0.326676816 epoch total loss 0.30886665\n",
      "Trained batch 987 batch loss 0.320355922 epoch total loss 0.308878273\n",
      "Trained batch 988 batch loss 0.289019346 epoch total loss 0.308858186\n",
      "Trained batch 989 batch loss 0.265107423 epoch total loss 0.308813959\n",
      "Trained batch 990 batch loss 0.308243126 epoch total loss 0.308813393\n",
      "Trained batch 991 batch loss 0.31767866 epoch total loss 0.308822334\n",
      "Trained batch 992 batch loss 0.317514926 epoch total loss 0.308831096\n",
      "Trained batch 993 batch loss 0.307991773 epoch total loss 0.308830231\n",
      "Trained batch 994 batch loss 0.279200137 epoch total loss 0.308800429\n",
      "Trained batch 995 batch loss 0.32004261 epoch total loss 0.308811724\n",
      "Trained batch 996 batch loss 0.291776448 epoch total loss 0.308794618\n",
      "Trained batch 997 batch loss 0.272179484 epoch total loss 0.308757901\n",
      "Trained batch 998 batch loss 0.32413739 epoch total loss 0.308773309\n",
      "Trained batch 999 batch loss 0.309923738 epoch total loss 0.308774471\n",
      "Trained batch 1000 batch loss 0.310521275 epoch total loss 0.3087762\n",
      "Trained batch 1001 batch loss 0.315915525 epoch total loss 0.308783352\n",
      "Trained batch 1002 batch loss 0.30112204 epoch total loss 0.308775693\n",
      "Trained batch 1003 batch loss 0.31276989 epoch total loss 0.308779687\n",
      "Trained batch 1004 batch loss 0.29457593 epoch total loss 0.30876556\n",
      "Trained batch 1005 batch loss 0.305267543 epoch total loss 0.308762074\n",
      "Trained batch 1006 batch loss 0.33727774 epoch total loss 0.308790416\n",
      "Trained batch 1007 batch loss 0.289280087 epoch total loss 0.308771044\n",
      "Trained batch 1008 batch loss 0.257538319 epoch total loss 0.308720201\n",
      "Trained batch 1009 batch loss 0.271709681 epoch total loss 0.308683515\n",
      "Trained batch 1010 batch loss 0.29573077 epoch total loss 0.3086707\n",
      "Trained batch 1011 batch loss 0.28452161 epoch total loss 0.308646828\n",
      "Trained batch 1012 batch loss 0.28931427 epoch total loss 0.308627695\n",
      "Trained batch 1013 batch loss 0.295249373 epoch total loss 0.308614492\n",
      "Trained batch 1014 batch loss 0.312249601 epoch total loss 0.308618098\n",
      "Trained batch 1015 batch loss 0.321945757 epoch total loss 0.308631241\n",
      "Trained batch 1016 batch loss 0.315425694 epoch total loss 0.308637947\n",
      "Trained batch 1017 batch loss 0.313325018 epoch total loss 0.308642536\n",
      "Trained batch 1018 batch loss 0.363746136 epoch total loss 0.308696657\n",
      "Trained batch 1019 batch loss 0.38592276 epoch total loss 0.308772445\n",
      "Trained batch 1020 batch loss 0.37322402 epoch total loss 0.308835655\n",
      "Trained batch 1021 batch loss 0.365714371 epoch total loss 0.308891356\n",
      "Trained batch 1022 batch loss 0.324400067 epoch total loss 0.308906525\n",
      "Trained batch 1023 batch loss 0.299132437 epoch total loss 0.308897\n",
      "Trained batch 1024 batch loss 0.311090678 epoch total loss 0.308899134\n",
      "Trained batch 1025 batch loss 0.286471367 epoch total loss 0.308877259\n",
      "Trained batch 1026 batch loss 0.309179634 epoch total loss 0.308877528\n",
      "Trained batch 1027 batch loss 0.310114115 epoch total loss 0.30887875\n",
      "Trained batch 1028 batch loss 0.325647 epoch total loss 0.308895081\n",
      "Trained batch 1029 batch loss 0.340236187 epoch total loss 0.308925539\n",
      "Trained batch 1030 batch loss 0.356817871 epoch total loss 0.308972031\n",
      "Trained batch 1031 batch loss 0.356490672 epoch total loss 0.309018105\n",
      "Trained batch 1032 batch loss 0.326117337 epoch total loss 0.309034646\n",
      "Trained batch 1033 batch loss 0.30662027 epoch total loss 0.309032321\n",
      "Trained batch 1034 batch loss 0.300728083 epoch total loss 0.309024274\n",
      "Trained batch 1035 batch loss 0.309155583 epoch total loss 0.309024394\n",
      "Trained batch 1036 batch loss 0.320549965 epoch total loss 0.30903551\n",
      "Trained batch 1037 batch loss 0.299018413 epoch total loss 0.309025854\n",
      "Trained batch 1038 batch loss 0.294005096 epoch total loss 0.30901137\n",
      "Trained batch 1039 batch loss 0.307295233 epoch total loss 0.309009731\n",
      "Trained batch 1040 batch loss 0.266664356 epoch total loss 0.308969\n",
      "Trained batch 1041 batch loss 0.309356749 epoch total loss 0.308969378\n",
      "Trained batch 1042 batch loss 0.317247361 epoch total loss 0.308977336\n",
      "Trained batch 1043 batch loss 0.301833212 epoch total loss 0.308970451\n",
      "Trained batch 1044 batch loss 0.325942308 epoch total loss 0.308986694\n",
      "Trained batch 1045 batch loss 0.293043733 epoch total loss 0.308971435\n",
      "Trained batch 1046 batch loss 0.299855262 epoch total loss 0.308962733\n",
      "Trained batch 1047 batch loss 0.287102044 epoch total loss 0.308941871\n",
      "Trained batch 1048 batch loss 0.279034168 epoch total loss 0.30891332\n",
      "Trained batch 1049 batch loss 0.302497685 epoch total loss 0.308907181\n",
      "Trained batch 1050 batch loss 0.334720701 epoch total loss 0.308931768\n",
      "Trained batch 1051 batch loss 0.330413431 epoch total loss 0.308952212\n",
      "Trained batch 1052 batch loss 0.327012837 epoch total loss 0.308969378\n",
      "Trained batch 1053 batch loss 0.32252714 epoch total loss 0.308982283\n",
      "Trained batch 1054 batch loss 0.315750241 epoch total loss 0.30898872\n",
      "Trained batch 1055 batch loss 0.333561897 epoch total loss 0.309012\n",
      "Trained batch 1056 batch loss 0.318658262 epoch total loss 0.309021145\n",
      "Trained batch 1057 batch loss 0.321875572 epoch total loss 0.309033304\n",
      "Trained batch 1058 batch loss 0.293863088 epoch total loss 0.30901894\n",
      "Trained batch 1059 batch loss 0.307174951 epoch total loss 0.309017211\n",
      "Trained batch 1060 batch loss 0.278888732 epoch total loss 0.30898881\n",
      "Trained batch 1061 batch loss 0.2798599 epoch total loss 0.308961332\n",
      "Trained batch 1062 batch loss 0.307042837 epoch total loss 0.308959544\n",
      "Trained batch 1063 batch loss 0.304116368 epoch total loss 0.308954954\n",
      "Trained batch 1064 batch loss 0.284858704 epoch total loss 0.308932304\n",
      "Trained batch 1065 batch loss 0.280275613 epoch total loss 0.308905393\n",
      "Trained batch 1066 batch loss 0.309064776 epoch total loss 0.308905542\n",
      "Trained batch 1067 batch loss 0.313395202 epoch total loss 0.308909744\n",
      "Trained batch 1068 batch loss 0.328078508 epoch total loss 0.308927685\n",
      "Trained batch 1069 batch loss 0.315120548 epoch total loss 0.308933467\n",
      "Trained batch 1070 batch loss 0.300164402 epoch total loss 0.308925271\n",
      "Trained batch 1071 batch loss 0.287595928 epoch total loss 0.308905363\n",
      "Trained batch 1072 batch loss 0.268661469 epoch total loss 0.308867812\n",
      "Trained batch 1073 batch loss 0.284943759 epoch total loss 0.30884552\n",
      "Trained batch 1074 batch loss 0.328222305 epoch total loss 0.30886355\n",
      "Trained batch 1075 batch loss 0.318928033 epoch total loss 0.308872908\n",
      "Trained batch 1076 batch loss 0.329348803 epoch total loss 0.308891952\n",
      "Trained batch 1077 batch loss 0.295948982 epoch total loss 0.308879942\n",
      "Trained batch 1078 batch loss 0.308547139 epoch total loss 0.308879614\n",
      "Trained batch 1079 batch loss 0.325594366 epoch total loss 0.308895111\n",
      "Trained batch 1080 batch loss 0.256550789 epoch total loss 0.308846653\n",
      "Trained batch 1081 batch loss 0.270216107 epoch total loss 0.30881089\n",
      "Trained batch 1082 batch loss 0.323057622 epoch total loss 0.308824062\n",
      "Trained batch 1083 batch loss 0.330403864 epoch total loss 0.308844\n",
      "Trained batch 1084 batch loss 0.319795847 epoch total loss 0.308854103\n",
      "Trained batch 1085 batch loss 0.319162488 epoch total loss 0.30886361\n",
      "Trained batch 1086 batch loss 0.300690114 epoch total loss 0.30885607\n",
      "Trained batch 1087 batch loss 0.300332904 epoch total loss 0.308848232\n",
      "Trained batch 1088 batch loss 0.32908529 epoch total loss 0.308866799\n",
      "Trained batch 1089 batch loss 0.312597215 epoch total loss 0.308870226\n",
      "Trained batch 1090 batch loss 0.309919477 epoch total loss 0.30887118\n",
      "Trained batch 1091 batch loss 0.304252565 epoch total loss 0.308866948\n",
      "Trained batch 1092 batch loss 0.315748185 epoch total loss 0.308873236\n",
      "Trained batch 1093 batch loss 0.314905405 epoch total loss 0.308878779\n",
      "Trained batch 1094 batch loss 0.298532456 epoch total loss 0.308869302\n",
      "Trained batch 1095 batch loss 0.301770091 epoch total loss 0.308862805\n",
      "Trained batch 1096 batch loss 0.307688504 epoch total loss 0.308861732\n",
      "Trained batch 1097 batch loss 0.320821017 epoch total loss 0.30887264\n",
      "Trained batch 1098 batch loss 0.301013768 epoch total loss 0.308865488\n",
      "Trained batch 1099 batch loss 0.28706184 epoch total loss 0.308845639\n",
      "Trained batch 1100 batch loss 0.253431678 epoch total loss 0.308795244\n",
      "Trained batch 1101 batch loss 0.25992614 epoch total loss 0.308750868\n",
      "Trained batch 1102 batch loss 0.268459737 epoch total loss 0.3087143\n",
      "Trained batch 1103 batch loss 0.306269377 epoch total loss 0.308712095\n",
      "Trained batch 1104 batch loss 0.281637967 epoch total loss 0.308687568\n",
      "Trained batch 1105 batch loss 0.25679034 epoch total loss 0.308640629\n",
      "Trained batch 1106 batch loss 0.296696782 epoch total loss 0.308629811\n",
      "Trained batch 1107 batch loss 0.297315866 epoch total loss 0.308619589\n",
      "Trained batch 1108 batch loss 0.277385473 epoch total loss 0.308591396\n",
      "Trained batch 1109 batch loss 0.277233958 epoch total loss 0.308563083\n",
      "Trained batch 1110 batch loss 0.258159339 epoch total loss 0.308517665\n",
      "Trained batch 1111 batch loss 0.256608754 epoch total loss 0.308470964\n",
      "Trained batch 1112 batch loss 0.273918539 epoch total loss 0.30843991\n",
      "Trained batch 1113 batch loss 0.287550718 epoch total loss 0.308421105\n",
      "Trained batch 1114 batch loss 0.292237669 epoch total loss 0.308406591\n",
      "Trained batch 1115 batch loss 0.277194858 epoch total loss 0.308378607\n",
      "Trained batch 1116 batch loss 0.326280594 epoch total loss 0.308394641\n",
      "Trained batch 1117 batch loss 0.315402091 epoch total loss 0.308400929\n",
      "Trained batch 1118 batch loss 0.318320811 epoch total loss 0.30840981\n",
      "Trained batch 1119 batch loss 0.317304134 epoch total loss 0.308417737\n",
      "Trained batch 1120 batch loss 0.298361689 epoch total loss 0.308408767\n",
      "Trained batch 1121 batch loss 0.286936522 epoch total loss 0.308389604\n",
      "Trained batch 1122 batch loss 0.297269464 epoch total loss 0.30837968\n",
      "Trained batch 1123 batch loss 0.31488812 epoch total loss 0.308385491\n",
      "Trained batch 1124 batch loss 0.326438129 epoch total loss 0.308401555\n",
      "Trained batch 1125 batch loss 0.318679303 epoch total loss 0.308410674\n",
      "Trained batch 1126 batch loss 0.319078684 epoch total loss 0.308420151\n",
      "Trained batch 1127 batch loss 0.282510906 epoch total loss 0.308397174\n",
      "Trained batch 1128 batch loss 0.283388972 epoch total loss 0.308375\n",
      "Trained batch 1129 batch loss 0.307225287 epoch total loss 0.308373958\n",
      "Trained batch 1130 batch loss 0.262607276 epoch total loss 0.308333457\n",
      "Trained batch 1131 batch loss 0.29651776 epoch total loss 0.308323\n",
      "Trained batch 1132 batch loss 0.285783559 epoch total loss 0.308303118\n",
      "Trained batch 1133 batch loss 0.307073057 epoch total loss 0.308302015\n",
      "Trained batch 1134 batch loss 0.364231855 epoch total loss 0.308351338\n",
      "Trained batch 1135 batch loss 0.319065511 epoch total loss 0.308360755\n",
      "Trained batch 1136 batch loss 0.361732125 epoch total loss 0.308407754\n",
      "Trained batch 1137 batch loss 0.340695262 epoch total loss 0.308436155\n",
      "Trained batch 1138 batch loss 0.310047865 epoch total loss 0.308437556\n",
      "Trained batch 1139 batch loss 0.325081468 epoch total loss 0.308452189\n",
      "Trained batch 1140 batch loss 0.318169832 epoch total loss 0.308460712\n",
      "Trained batch 1141 batch loss 0.313168079 epoch total loss 0.308464825\n",
      "Trained batch 1142 batch loss 0.288374335 epoch total loss 0.308447242\n",
      "Trained batch 1143 batch loss 0.304790556 epoch total loss 0.308444023\n",
      "Trained batch 1144 batch loss 0.30107829 epoch total loss 0.308437586\n",
      "Trained batch 1145 batch loss 0.325049162 epoch total loss 0.3084521\n",
      "Trained batch 1146 batch loss 0.314917713 epoch total loss 0.308457732\n",
      "Trained batch 1147 batch loss 0.294046849 epoch total loss 0.308445156\n",
      "Trained batch 1148 batch loss 0.299394399 epoch total loss 0.308437288\n",
      "Trained batch 1149 batch loss 0.272834212 epoch total loss 0.308406293\n",
      "Trained batch 1150 batch loss 0.291681379 epoch total loss 0.30839175\n",
      "Trained batch 1151 batch loss 0.271235377 epoch total loss 0.308359474\n",
      "Trained batch 1152 batch loss 0.268918604 epoch total loss 0.308325231\n",
      "Trained batch 1153 batch loss 0.281031549 epoch total loss 0.308301568\n",
      "Trained batch 1154 batch loss 0.316188812 epoch total loss 0.308308423\n",
      "Trained batch 1155 batch loss 0.29149729 epoch total loss 0.308293849\n",
      "Trained batch 1156 batch loss 0.326019198 epoch total loss 0.308309197\n",
      "Trained batch 1157 batch loss 0.313992023 epoch total loss 0.308314115\n",
      "Trained batch 1158 batch loss 0.309791297 epoch total loss 0.308315367\n",
      "Trained batch 1159 batch loss 0.303943872 epoch total loss 0.308311611\n",
      "Trained batch 1160 batch loss 0.314424336 epoch total loss 0.308316886\n",
      "Trained batch 1161 batch loss 0.320532382 epoch total loss 0.308327407\n",
      "Trained batch 1162 batch loss 0.302184463 epoch total loss 0.308322102\n",
      "Trained batch 1163 batch loss 0.328481138 epoch total loss 0.308339447\n",
      "Trained batch 1164 batch loss 0.3295753 epoch total loss 0.308357716\n",
      "Trained batch 1165 batch loss 0.305254251 epoch total loss 0.308355063\n",
      "Trained batch 1166 batch loss 0.305618078 epoch total loss 0.308352709\n",
      "Trained batch 1167 batch loss 0.312808812 epoch total loss 0.308356524\n",
      "Trained batch 1168 batch loss 0.35814175 epoch total loss 0.308399141\n",
      "Trained batch 1169 batch loss 0.330624849 epoch total loss 0.308418155\n",
      "Trained batch 1170 batch loss 0.297345966 epoch total loss 0.308408678\n",
      "Trained batch 1171 batch loss 0.28946802 epoch total loss 0.308392495\n",
      "Trained batch 1172 batch loss 0.291296721 epoch total loss 0.308377922\n",
      "Trained batch 1173 batch loss 0.297148257 epoch total loss 0.308368355\n",
      "Trained batch 1174 batch loss 0.326647162 epoch total loss 0.308383912\n",
      "Trained batch 1175 batch loss 0.311569929 epoch total loss 0.308386654\n",
      "Trained batch 1176 batch loss 0.291292757 epoch total loss 0.30837211\n",
      "Trained batch 1177 batch loss 0.299765915 epoch total loss 0.308364809\n",
      "Trained batch 1178 batch loss 0.283610225 epoch total loss 0.308343768\n",
      "Trained batch 1179 batch loss 0.296177447 epoch total loss 0.308333457\n",
      "Trained batch 1180 batch loss 0.301859051 epoch total loss 0.308327973\n",
      "Trained batch 1181 batch loss 0.295446873 epoch total loss 0.308317065\n",
      "Trained batch 1182 batch loss 0.327935547 epoch total loss 0.308333665\n",
      "Trained batch 1183 batch loss 0.291671425 epoch total loss 0.308319569\n",
      "Trained batch 1184 batch loss 0.30427146 epoch total loss 0.308316141\n",
      "Trained batch 1185 batch loss 0.292974949 epoch total loss 0.308303177\n",
      "Trained batch 1186 batch loss 0.302699804 epoch total loss 0.308298469\n",
      "Trained batch 1187 batch loss 0.30507347 epoch total loss 0.308295757\n",
      "Trained batch 1188 batch loss 0.319888562 epoch total loss 0.308305502\n",
      "Trained batch 1189 batch loss 0.294707566 epoch total loss 0.308294058\n",
      "Trained batch 1190 batch loss 0.287683666 epoch total loss 0.308276743\n",
      "Trained batch 1191 batch loss 0.291145861 epoch total loss 0.308262348\n",
      "Trained batch 1192 batch loss 0.302257448 epoch total loss 0.308257312\n",
      "Trained batch 1193 batch loss 0.318246096 epoch total loss 0.308265686\n",
      "Trained batch 1194 batch loss 0.343594611 epoch total loss 0.30829528\n",
      "Trained batch 1195 batch loss 0.320410848 epoch total loss 0.308305413\n",
      "Trained batch 1196 batch loss 0.313228965 epoch total loss 0.308309525\n",
      "Trained batch 1197 batch loss 0.331546217 epoch total loss 0.308328927\n",
      "Trained batch 1198 batch loss 0.317217171 epoch total loss 0.308336377\n",
      "Trained batch 1199 batch loss 0.301645696 epoch total loss 0.308330774\n",
      "Trained batch 1200 batch loss 0.284322917 epoch total loss 0.308310777\n",
      "Trained batch 1201 batch loss 0.29104358 epoch total loss 0.308296412\n",
      "Trained batch 1202 batch loss 0.264550745 epoch total loss 0.308260024\n",
      "Trained batch 1203 batch loss 0.260138124 epoch total loss 0.30822\n",
      "Trained batch 1204 batch loss 0.269236743 epoch total loss 0.308187604\n",
      "Trained batch 1205 batch loss 0.279470354 epoch total loss 0.308163792\n",
      "Trained batch 1206 batch loss 0.246258304 epoch total loss 0.308112442\n",
      "Trained batch 1207 batch loss 0.226434857 epoch total loss 0.308044791\n",
      "Trained batch 1208 batch loss 0.227463245 epoch total loss 0.307978094\n",
      "Trained batch 1209 batch loss 0.235971868 epoch total loss 0.307918519\n",
      "Trained batch 1210 batch loss 0.291666776 epoch total loss 0.307905078\n",
      "Trained batch 1211 batch loss 0.292687714 epoch total loss 0.307892531\n",
      "Trained batch 1212 batch loss 0.289096922 epoch total loss 0.307877\n",
      "Trained batch 1213 batch loss 0.280693233 epoch total loss 0.307854623\n",
      "Trained batch 1214 batch loss 0.291809529 epoch total loss 0.30784139\n",
      "Trained batch 1215 batch loss 0.298381805 epoch total loss 0.307833612\n",
      "Trained batch 1216 batch loss 0.290562719 epoch total loss 0.307819396\n",
      "Trained batch 1217 batch loss 0.32137686 epoch total loss 0.307830542\n",
      "Trained batch 1218 batch loss 0.307870686 epoch total loss 0.307830572\n",
      "Trained batch 1219 batch loss 0.307806045 epoch total loss 0.307830542\n",
      "Trained batch 1220 batch loss 0.298965573 epoch total loss 0.307823271\n",
      "Trained batch 1221 batch loss 0.26880008 epoch total loss 0.307791322\n",
      "Trained batch 1222 batch loss 0.310603 epoch total loss 0.307793617\n",
      "Trained batch 1223 batch loss 0.309181035 epoch total loss 0.30779475\n",
      "Trained batch 1224 batch loss 0.323006302 epoch total loss 0.307807177\n",
      "Trained batch 1225 batch loss 0.331291586 epoch total loss 0.30782634\n",
      "Trained batch 1226 batch loss 0.2998586 epoch total loss 0.307819843\n",
      "Trained batch 1227 batch loss 0.27573514 epoch total loss 0.307793707\n",
      "Trained batch 1228 batch loss 0.301280499 epoch total loss 0.307788402\n",
      "Trained batch 1229 batch loss 0.320563287 epoch total loss 0.307798773\n",
      "Trained batch 1230 batch loss 0.309589237 epoch total loss 0.307800233\n",
      "Trained batch 1231 batch loss 0.319022924 epoch total loss 0.307809353\n",
      "Trained batch 1232 batch loss 0.35005331 epoch total loss 0.307843655\n",
      "Trained batch 1233 batch loss 0.3174344 epoch total loss 0.307851464\n",
      "Trained batch 1234 batch loss 0.329171509 epoch total loss 0.307868719\n",
      "Trained batch 1235 batch loss 0.299856514 epoch total loss 0.307862252\n",
      "Trained batch 1236 batch loss 0.30783549 epoch total loss 0.307862222\n",
      "Trained batch 1237 batch loss 0.305537194 epoch total loss 0.307860345\n",
      "Trained batch 1238 batch loss 0.306957513 epoch total loss 0.3078596\n",
      "Trained batch 1239 batch loss 0.311905533 epoch total loss 0.307862878\n",
      "Trained batch 1240 batch loss 0.28104502 epoch total loss 0.307841241\n",
      "Trained batch 1241 batch loss 0.284466147 epoch total loss 0.307822406\n",
      "Trained batch 1242 batch loss 0.295374572 epoch total loss 0.307812393\n",
      "Trained batch 1243 batch loss 0.296299785 epoch total loss 0.307803124\n",
      "Trained batch 1244 batch loss 0.316115797 epoch total loss 0.3078098\n",
      "Trained batch 1245 batch loss 0.313044965 epoch total loss 0.307814\n",
      "Trained batch 1246 batch loss 0.289480776 epoch total loss 0.30779928\n",
      "Trained batch 1247 batch loss 0.346897 epoch total loss 0.307830632\n",
      "Trained batch 1248 batch loss 0.322479546 epoch total loss 0.307842374\n",
      "Trained batch 1249 batch loss 0.327719867 epoch total loss 0.307858288\n",
      "Trained batch 1250 batch loss 0.336686701 epoch total loss 0.307881385\n",
      "Trained batch 1251 batch loss 0.313076735 epoch total loss 0.307885528\n",
      "Trained batch 1252 batch loss 0.297006607 epoch total loss 0.307876825\n",
      "Trained batch 1253 batch loss 0.308526278 epoch total loss 0.307877362\n",
      "Trained batch 1254 batch loss 0.282930821 epoch total loss 0.307857454\n",
      "Trained batch 1255 batch loss 0.292544127 epoch total loss 0.307845265\n",
      "Trained batch 1256 batch loss 0.264229447 epoch total loss 0.307810515\n",
      "Trained batch 1257 batch loss 0.302629769 epoch total loss 0.307806402\n",
      "Trained batch 1258 batch loss 0.31515798 epoch total loss 0.307812244\n",
      "Trained batch 1259 batch loss 0.299967825 epoch total loss 0.307806015\n",
      "Trained batch 1260 batch loss 0.301097929 epoch total loss 0.30780068\n",
      "Trained batch 1261 batch loss 0.270900697 epoch total loss 0.307771415\n",
      "Trained batch 1262 batch loss 0.264226913 epoch total loss 0.307736903\n",
      "Trained batch 1263 batch loss 0.272052944 epoch total loss 0.307708681\n",
      "Trained batch 1264 batch loss 0.35513854 epoch total loss 0.307746202\n",
      "Trained batch 1265 batch loss 0.329113752 epoch total loss 0.30776307\n",
      "Trained batch 1266 batch loss 0.29790917 epoch total loss 0.307755291\n",
      "Trained batch 1267 batch loss 0.290790141 epoch total loss 0.30774191\n",
      "Trained batch 1268 batch loss 0.310205191 epoch total loss 0.307743847\n",
      "Trained batch 1269 batch loss 0.295459628 epoch total loss 0.307734191\n",
      "Trained batch 1270 batch loss 0.287873447 epoch total loss 0.307718545\n",
      "Trained batch 1271 batch loss 0.295411378 epoch total loss 0.307708859\n",
      "Trained batch 1272 batch loss 0.318686932 epoch total loss 0.307717502\n",
      "Trained batch 1273 batch loss 0.292892694 epoch total loss 0.307705849\n",
      "Trained batch 1274 batch loss 0.298704624 epoch total loss 0.307698786\n",
      "Trained batch 1275 batch loss 0.30460003 epoch total loss 0.307696372\n",
      "Trained batch 1276 batch loss 0.305376232 epoch total loss 0.307694554\n",
      "Trained batch 1277 batch loss 0.28249076 epoch total loss 0.307674825\n",
      "Trained batch 1278 batch loss 0.283163875 epoch total loss 0.307655662\n",
      "Trained batch 1279 batch loss 0.277134717 epoch total loss 0.307631791\n",
      "Trained batch 1280 batch loss 0.307661414 epoch total loss 0.307631791\n",
      "Trained batch 1281 batch loss 0.320792079 epoch total loss 0.307642072\n",
      "Trained batch 1282 batch loss 0.349568546 epoch total loss 0.307674795\n",
      "Trained batch 1283 batch loss 0.310434252 epoch total loss 0.307676941\n",
      "Trained batch 1284 batch loss 0.316497684 epoch total loss 0.307683796\n",
      "Trained batch 1285 batch loss 0.301844269 epoch total loss 0.307679266\n",
      "Trained batch 1286 batch loss 0.291797221 epoch total loss 0.307666928\n",
      "Trained batch 1287 batch loss 0.304662973 epoch total loss 0.307664603\n",
      "Trained batch 1288 batch loss 0.327407479 epoch total loss 0.307679892\n",
      "Trained batch 1289 batch loss 0.336906731 epoch total loss 0.307702571\n",
      "Trained batch 1290 batch loss 0.305364221 epoch total loss 0.307700753\n",
      "Trained batch 1291 batch loss 0.300135732 epoch total loss 0.307694912\n",
      "Trained batch 1292 batch loss 0.328817397 epoch total loss 0.307711273\n",
      "Trained batch 1293 batch loss 0.299738 epoch total loss 0.307705104\n",
      "Trained batch 1294 batch loss 0.327302396 epoch total loss 0.307720244\n",
      "Trained batch 1295 batch loss 0.306299388 epoch total loss 0.307719171\n",
      "Trained batch 1296 batch loss 0.30373928 epoch total loss 0.307716101\n",
      "Trained batch 1297 batch loss 0.299695313 epoch total loss 0.307709903\n",
      "Trained batch 1298 batch loss 0.305478364 epoch total loss 0.307708174\n",
      "Trained batch 1299 batch loss 0.293310583 epoch total loss 0.307697088\n",
      "Trained batch 1300 batch loss 0.329736531 epoch total loss 0.307714045\n",
      "Trained batch 1301 batch loss 0.319057316 epoch total loss 0.307722777\n",
      "Trained batch 1302 batch loss 0.285207152 epoch total loss 0.307705492\n",
      "Trained batch 1303 batch loss 0.283853501 epoch total loss 0.307687163\n",
      "Trained batch 1304 batch loss 0.288751781 epoch total loss 0.30767265\n",
      "Trained batch 1305 batch loss 0.285708129 epoch total loss 0.307655811\n",
      "Trained batch 1306 batch loss 0.294282287 epoch total loss 0.307645589\n",
      "Trained batch 1307 batch loss 0.294213295 epoch total loss 0.307635307\n",
      "Trained batch 1308 batch loss 0.310586274 epoch total loss 0.307637542\n",
      "Trained batch 1309 batch loss 0.280529261 epoch total loss 0.30761683\n",
      "Trained batch 1310 batch loss 0.270934254 epoch total loss 0.307588845\n",
      "Trained batch 1311 batch loss 0.260285288 epoch total loss 0.307552755\n",
      "Trained batch 1312 batch loss 0.262153834 epoch total loss 0.307518154\n",
      "Trained batch 1313 batch loss 0.321760267 epoch total loss 0.307528973\n",
      "Trained batch 1314 batch loss 0.281843573 epoch total loss 0.307509422\n",
      "Trained batch 1315 batch loss 0.301187545 epoch total loss 0.307504594\n",
      "Trained batch 1316 batch loss 0.323685348 epoch total loss 0.307516903\n",
      "Trained batch 1317 batch loss 0.292160064 epoch total loss 0.30750528\n",
      "Trained batch 1318 batch loss 0.249818057 epoch total loss 0.3074615\n",
      "Trained batch 1319 batch loss 0.282608479 epoch total loss 0.307442665\n",
      "Trained batch 1320 batch loss 0.287342906 epoch total loss 0.307427436\n",
      "Trained batch 1321 batch loss 0.309087843 epoch total loss 0.307428688\n",
      "Trained batch 1322 batch loss 0.297577947 epoch total loss 0.307421237\n",
      "Trained batch 1323 batch loss 0.333134353 epoch total loss 0.307440668\n",
      "Trained batch 1324 batch loss 0.3392075 epoch total loss 0.307464659\n",
      "Trained batch 1325 batch loss 0.302387804 epoch total loss 0.307460845\n",
      "Trained batch 1326 batch loss 0.300058186 epoch total loss 0.307455242\n",
      "Trained batch 1327 batch loss 0.252152264 epoch total loss 0.307413578\n",
      "Trained batch 1328 batch loss 0.332499951 epoch total loss 0.307432473\n",
      "Trained batch 1329 batch loss 0.332921416 epoch total loss 0.307451636\n",
      "Trained batch 1330 batch loss 0.328068167 epoch total loss 0.307467133\n",
      "Trained batch 1331 batch loss 0.308517367 epoch total loss 0.307467937\n",
      "Trained batch 1332 batch loss 0.317829788 epoch total loss 0.307475716\n",
      "Trained batch 1333 batch loss 0.318519622 epoch total loss 0.307484\n",
      "Trained batch 1334 batch loss 0.30756402 epoch total loss 0.307484031\n",
      "Trained batch 1335 batch loss 0.314908922 epoch total loss 0.307489604\n",
      "Trained batch 1336 batch loss 0.289401889 epoch total loss 0.307476074\n",
      "Trained batch 1337 batch loss 0.287195206 epoch total loss 0.307460904\n",
      "Trained batch 1338 batch loss 0.303562343 epoch total loss 0.307457983\n",
      "Trained batch 1339 batch loss 0.310729235 epoch total loss 0.307460427\n",
      "Trained batch 1340 batch loss 0.303418577 epoch total loss 0.307457417\n",
      "Trained batch 1341 batch loss 0.306112617 epoch total loss 0.307456404\n",
      "Trained batch 1342 batch loss 0.306475878 epoch total loss 0.307455689\n",
      "Trained batch 1343 batch loss 0.323729247 epoch total loss 0.307467818\n",
      "Trained batch 1344 batch loss 0.330278486 epoch total loss 0.307484776\n",
      "Trained batch 1345 batch loss 0.322010219 epoch total loss 0.307495594\n",
      "Trained batch 1346 batch loss 0.326284051 epoch total loss 0.307509571\n",
      "Trained batch 1347 batch loss 0.313595176 epoch total loss 0.307514071\n",
      "Trained batch 1348 batch loss 0.320029438 epoch total loss 0.30752337\n",
      "Trained batch 1349 batch loss 0.322211504 epoch total loss 0.307534248\n",
      "Trained batch 1350 batch loss 0.305513591 epoch total loss 0.307532758\n",
      "Trained batch 1351 batch loss 0.318013072 epoch total loss 0.307540506\n",
      "Trained batch 1352 batch loss 0.302155346 epoch total loss 0.307536542\n",
      "Trained batch 1353 batch loss 0.303266555 epoch total loss 0.307533383\n",
      "Trained batch 1354 batch loss 0.301312566 epoch total loss 0.307528764\n",
      "Trained batch 1355 batch loss 0.298744738 epoch total loss 0.307522267\n",
      "Trained batch 1356 batch loss 0.306503117 epoch total loss 0.307521522\n",
      "Trained batch 1357 batch loss 0.296121776 epoch total loss 0.307513118\n",
      "Trained batch 1358 batch loss 0.282748401 epoch total loss 0.307494879\n",
      "Trained batch 1359 batch loss 0.284056842 epoch total loss 0.307477623\n",
      "Trained batch 1360 batch loss 0.262786925 epoch total loss 0.307444751\n",
      "Trained batch 1361 batch loss 0.273016155 epoch total loss 0.307419449\n",
      "Trained batch 1362 batch loss 0.299767494 epoch total loss 0.307413846\n",
      "Trained batch 1363 batch loss 0.325015 epoch total loss 0.307426751\n",
      "Trained batch 1364 batch loss 0.295000285 epoch total loss 0.307417661\n",
      "Trained batch 1365 batch loss 0.308345288 epoch total loss 0.307418346\n",
      "Trained batch 1366 batch loss 0.330895185 epoch total loss 0.307435542\n",
      "Trained batch 1367 batch loss 0.298244983 epoch total loss 0.307428807\n",
      "Trained batch 1368 batch loss 0.308579743 epoch total loss 0.307429671\n",
      "Trained batch 1369 batch loss 0.328625053 epoch total loss 0.307445139\n",
      "Trained batch 1370 batch loss 0.331802636 epoch total loss 0.307462931\n",
      "Trained batch 1371 batch loss 0.329569787 epoch total loss 0.307479054\n",
      "Trained batch 1372 batch loss 0.368640572 epoch total loss 0.307523638\n",
      "Trained batch 1373 batch loss 0.366254538 epoch total loss 0.307566404\n",
      "Trained batch 1374 batch loss 0.314286232 epoch total loss 0.307571292\n",
      "Trained batch 1375 batch loss 0.278865427 epoch total loss 0.30755043\n",
      "Trained batch 1376 batch loss 0.290293813 epoch total loss 0.307537884\n",
      "Trained batch 1377 batch loss 0.296024561 epoch total loss 0.307529509\n",
      "Trained batch 1378 batch loss 0.282548845 epoch total loss 0.307511389\n",
      "Trained batch 1379 batch loss 0.254335821 epoch total loss 0.307472825\n",
      "Trained batch 1380 batch loss 0.295596868 epoch total loss 0.307464212\n",
      "Trained batch 1381 batch loss 0.282387733 epoch total loss 0.307446063\n",
      "Trained batch 1382 batch loss 0.281923234 epoch total loss 0.307427585\n",
      "Trained batch 1383 batch loss 0.251096517 epoch total loss 0.307386875\n",
      "Trained batch 1384 batch loss 0.282991618 epoch total loss 0.307369232\n",
      "Trained batch 1385 batch loss 0.311727852 epoch total loss 0.307372391\n",
      "Trained batch 1386 batch loss 0.280861884 epoch total loss 0.307353258\n",
      "Trained batch 1387 batch loss 0.283673584 epoch total loss 0.307336181\n",
      "Trained batch 1388 batch loss 0.258320749 epoch total loss 0.307300866\n",
      "Epoch 2 train loss 0.307300865650177 and time 675.2834525108337\n",
      "Validated batch 1 batch loss 0.349701554\n",
      "Validated batch 2 batch loss 0.326974273\n",
      "Validated batch 3 batch loss 0.29827553\n",
      "Validated batch 4 batch loss 0.319246769\n",
      "Validated batch 5 batch loss 0.30097121\n",
      "Validated batch 6 batch loss 0.323784381\n",
      "Validated batch 7 batch loss 0.331188083\n",
      "Validated batch 8 batch loss 0.297314435\n",
      "Validated batch 9 batch loss 0.328187764\n",
      "Validated batch 10 batch loss 0.311251581\n",
      "Validated batch 11 batch loss 0.324873447\n",
      "Validated batch 12 batch loss 0.312159121\n",
      "Validated batch 13 batch loss 0.318857521\n",
      "Validated batch 14 batch loss 0.293078959\n",
      "Validated batch 15 batch loss 0.29959029\n",
      "Validated batch 16 batch loss 0.311234355\n",
      "Validated batch 17 batch loss 0.305790365\n",
      "Validated batch 18 batch loss 0.323873609\n",
      "Validated batch 19 batch loss 0.34108752\n",
      "Validated batch 20 batch loss 0.384694248\n",
      "Validated batch 21 batch loss 0.328597903\n",
      "Validated batch 22 batch loss 0.314413\n",
      "Validated batch 23 batch loss 0.28765431\n",
      "Validated batch 24 batch loss 0.29802376\n",
      "Validated batch 25 batch loss 0.29058063\n",
      "Validated batch 26 batch loss 0.304226607\n",
      "Validated batch 27 batch loss 0.295770347\n",
      "Validated batch 28 batch loss 0.308768392\n",
      "Validated batch 29 batch loss 0.305809677\n",
      "Validated batch 30 batch loss 0.31797111\n",
      "Validated batch 31 batch loss 0.303796619\n",
      "Validated batch 32 batch loss 0.305065364\n",
      "Validated batch 33 batch loss 0.308928\n",
      "Validated batch 34 batch loss 0.312784135\n",
      "Validated batch 35 batch loss 0.308622926\n",
      "Validated batch 36 batch loss 0.302455425\n",
      "Validated batch 37 batch loss 0.311872423\n",
      "Validated batch 38 batch loss 0.31199345\n",
      "Validated batch 39 batch loss 0.308365792\n",
      "Validated batch 40 batch loss 0.348656297\n",
      "Validated batch 41 batch loss 0.324009\n",
      "Validated batch 42 batch loss 0.282518864\n",
      "Validated batch 43 batch loss 0.337285399\n",
      "Validated batch 44 batch loss 0.309274554\n",
      "Validated batch 45 batch loss 0.290669948\n",
      "Validated batch 46 batch loss 0.321311563\n",
      "Validated batch 47 batch loss 0.298126817\n",
      "Validated batch 48 batch loss 0.312461406\n",
      "Validated batch 49 batch loss 0.317919612\n",
      "Validated batch 50 batch loss 0.292951494\n",
      "Validated batch 51 batch loss 0.334494352\n",
      "Validated batch 52 batch loss 0.367409289\n",
      "Validated batch 53 batch loss 0.288895965\n",
      "Validated batch 54 batch loss 0.32171309\n",
      "Validated batch 55 batch loss 0.31072703\n",
      "Validated batch 56 batch loss 0.330524892\n",
      "Validated batch 57 batch loss 0.320727021\n",
      "Validated batch 58 batch loss 0.280805409\n",
      "Validated batch 59 batch loss 0.271252215\n",
      "Validated batch 60 batch loss 0.304534346\n",
      "Validated batch 61 batch loss 0.306367368\n",
      "Validated batch 62 batch loss 0.296441257\n",
      "Validated batch 63 batch loss 0.312533438\n",
      "Validated batch 64 batch loss 0.277362525\n",
      "Validated batch 65 batch loss 0.323319644\n",
      "Validated batch 66 batch loss 0.324619114\n",
      "Validated batch 67 batch loss 0.324331433\n",
      "Validated batch 68 batch loss 0.312367618\n",
      "Validated batch 69 batch loss 0.285446346\n",
      "Validated batch 70 batch loss 0.287509233\n",
      "Validated batch 71 batch loss 0.300581664\n",
      "Validated batch 72 batch loss 0.305140972\n",
      "Validated batch 73 batch loss 0.28727898\n",
      "Validated batch 74 batch loss 0.305571228\n",
      "Validated batch 75 batch loss 0.338104248\n",
      "Validated batch 76 batch loss 0.295918494\n",
      "Validated batch 77 batch loss 0.27128\n",
      "Validated batch 78 batch loss 0.281702787\n",
      "Validated batch 79 batch loss 0.302687347\n",
      "Validated batch 80 batch loss 0.282614827\n",
      "Validated batch 81 batch loss 0.321659982\n",
      "Validated batch 82 batch loss 0.293332458\n",
      "Validated batch 83 batch loss 0.296461105\n",
      "Validated batch 84 batch loss 0.314175516\n",
      "Validated batch 85 batch loss 0.34566915\n",
      "Validated batch 86 batch loss 0.287310362\n",
      "Validated batch 87 batch loss 0.334815145\n",
      "Validated batch 88 batch loss 0.254696131\n",
      "Validated batch 89 batch loss 0.281720281\n",
      "Validated batch 90 batch loss 0.276219457\n",
      "Validated batch 91 batch loss 0.298290849\n",
      "Validated batch 92 batch loss 0.359404057\n",
      "Validated batch 93 batch loss 0.319432437\n",
      "Validated batch 94 batch loss 0.324163765\n",
      "Validated batch 95 batch loss 0.309581816\n",
      "Validated batch 96 batch loss 0.318763494\n",
      "Validated batch 97 batch loss 0.31563583\n",
      "Validated batch 98 batch loss 0.357121766\n",
      "Validated batch 99 batch loss 0.308179945\n",
      "Validated batch 100 batch loss 0.316858053\n",
      "Validated batch 101 batch loss 0.298253119\n",
      "Validated batch 102 batch loss 0.323862463\n",
      "Validated batch 103 batch loss 0.323750228\n",
      "Validated batch 104 batch loss 0.300163388\n",
      "Validated batch 105 batch loss 0.341569275\n",
      "Validated batch 106 batch loss 0.327832\n",
      "Validated batch 107 batch loss 0.32822147\n",
      "Validated batch 108 batch loss 0.308011591\n",
      "Validated batch 109 batch loss 0.326006234\n",
      "Validated batch 110 batch loss 0.297725797\n",
      "Validated batch 111 batch loss 0.319423974\n",
      "Validated batch 112 batch loss 0.30568\n",
      "Validated batch 113 batch loss 0.301083028\n",
      "Validated batch 114 batch loss 0.321943104\n",
      "Validated batch 115 batch loss 0.315044135\n",
      "Validated batch 116 batch loss 0.324629933\n",
      "Validated batch 117 batch loss 0.302907974\n",
      "Validated batch 118 batch loss 0.298085183\n",
      "Validated batch 119 batch loss 0.281705081\n",
      "Validated batch 120 batch loss 0.293246984\n",
      "Validated batch 121 batch loss 0.341599286\n",
      "Validated batch 122 batch loss 0.30146727\n",
      "Validated batch 123 batch loss 0.333823085\n",
      "Validated batch 124 batch loss 0.333483696\n",
      "Validated batch 125 batch loss 0.33839792\n",
      "Validated batch 126 batch loss 0.312232733\n",
      "Validated batch 127 batch loss 0.351580143\n",
      "Validated batch 128 batch loss 0.313451916\n",
      "Validated batch 129 batch loss 0.335987657\n",
      "Validated batch 130 batch loss 0.330395043\n",
      "Validated batch 131 batch loss 0.359403729\n",
      "Validated batch 132 batch loss 0.330708027\n",
      "Validated batch 133 batch loss 0.291977048\n",
      "Validated batch 134 batch loss 0.311859787\n",
      "Validated batch 135 batch loss 0.333127201\n",
      "Validated batch 136 batch loss 0.335331559\n",
      "Validated batch 137 batch loss 0.30554074\n",
      "Validated batch 138 batch loss 0.3211824\n",
      "Validated batch 139 batch loss 0.300603837\n",
      "Validated batch 140 batch loss 0.32666\n",
      "Validated batch 141 batch loss 0.317463905\n",
      "Validated batch 142 batch loss 0.287917554\n",
      "Validated batch 143 batch loss 0.329601765\n",
      "Validated batch 144 batch loss 0.322843015\n",
      "Validated batch 145 batch loss 0.346458852\n",
      "Validated batch 146 batch loss 0.341039479\n",
      "Validated batch 147 batch loss 0.319506854\n",
      "Validated batch 148 batch loss 0.307397783\n",
      "Validated batch 149 batch loss 0.334747732\n",
      "Validated batch 150 batch loss 0.326911688\n",
      "Validated batch 151 batch loss 0.30295366\n",
      "Validated batch 152 batch loss 0.332765579\n",
      "Validated batch 153 batch loss 0.342613518\n",
      "Validated batch 154 batch loss 0.317001969\n",
      "Validated batch 155 batch loss 0.341881871\n",
      "Validated batch 156 batch loss 0.301693678\n",
      "Validated batch 157 batch loss 0.305501372\n",
      "Validated batch 158 batch loss 0.29817754\n",
      "Validated batch 159 batch loss 0.284051865\n",
      "Validated batch 160 batch loss 0.3394458\n",
      "Validated batch 161 batch loss 0.300364524\n",
      "Validated batch 162 batch loss 0.320552617\n",
      "Validated batch 163 batch loss 0.324984\n",
      "Validated batch 164 batch loss 0.300305486\n",
      "Validated batch 165 batch loss 0.315927595\n",
      "Validated batch 166 batch loss 0.318666846\n",
      "Validated batch 167 batch loss 0.310989738\n",
      "Validated batch 168 batch loss 0.319579422\n",
      "Validated batch 169 batch loss 0.306367934\n",
      "Validated batch 170 batch loss 0.29207015\n",
      "Validated batch 171 batch loss 0.343158573\n",
      "Validated batch 172 batch loss 0.303401768\n",
      "Validated batch 173 batch loss 0.271392465\n",
      "Validated batch 174 batch loss 0.298410267\n",
      "Validated batch 175 batch loss 0.345636189\n",
      "Validated batch 176 batch loss 0.341168672\n",
      "Validated batch 177 batch loss 0.332155287\n",
      "Validated batch 178 batch loss 0.311736941\n",
      "Validated batch 179 batch loss 0.353378773\n",
      "Validated batch 180 batch loss 0.302713692\n",
      "Validated batch 181 batch loss 0.337745458\n",
      "Validated batch 182 batch loss 0.320784926\n",
      "Validated batch 183 batch loss 0.265555412\n",
      "Validated batch 184 batch loss 0.297801048\n",
      "Validated batch 185 batch loss 0.35511592\n",
      "Epoch 2 val loss 0.3139820098876953\n",
      "Model /aiffel/aiffel/CV-PoseEstimation/models/model-epoch-2-loss-0.3140.h5 saved.\n",
      "Start epoch 3 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.321914226 epoch total loss 0.321914226\n",
      "Trained batch 2 batch loss 0.326667964 epoch total loss 0.32429111\n",
      "Trained batch 3 batch loss 0.323406368 epoch total loss 0.323996186\n",
      "Trained batch 4 batch loss 0.2997078 epoch total loss 0.317924082\n",
      "Trained batch 5 batch loss 0.305031508 epoch total loss 0.315345585\n",
      "Trained batch 6 batch loss 0.31634596 epoch total loss 0.3155123\n",
      "Trained batch 7 batch loss 0.307478607 epoch total loss 0.314364642\n",
      "Trained batch 8 batch loss 0.301102132 epoch total loss 0.312706828\n",
      "Trained batch 9 batch loss 0.346207619 epoch total loss 0.316429138\n",
      "Trained batch 10 batch loss 0.315147936 epoch total loss 0.316301018\n",
      "Trained batch 11 batch loss 0.32255 epoch total loss 0.31686911\n",
      "Trained batch 12 batch loss 0.324278116 epoch total loss 0.317486525\n",
      "Trained batch 13 batch loss 0.304428458 epoch total loss 0.316482067\n",
      "Trained batch 14 batch loss 0.299411744 epoch total loss 0.315262765\n",
      "Trained batch 15 batch loss 0.287592709 epoch total loss 0.31341809\n",
      "Trained batch 16 batch loss 0.309298277 epoch total loss 0.313160598\n",
      "Trained batch 17 batch loss 0.321460098 epoch total loss 0.31364882\n",
      "Trained batch 18 batch loss 0.308901936 epoch total loss 0.313385099\n",
      "Trained batch 19 batch loss 0.303859979 epoch total loss 0.312883765\n",
      "Trained batch 20 batch loss 0.30294168 epoch total loss 0.312386692\n",
      "Trained batch 21 batch loss 0.310708255 epoch total loss 0.312306732\n",
      "Trained batch 22 batch loss 0.309959233 epoch total loss 0.31220004\n",
      "Trained batch 23 batch loss 0.333488613 epoch total loss 0.31312564\n",
      "Trained batch 24 batch loss 0.27800554 epoch total loss 0.311662287\n",
      "Trained batch 25 batch loss 0.29664737 epoch total loss 0.31106171\n",
      "Trained batch 26 batch loss 0.307127684 epoch total loss 0.310910404\n",
      "Trained batch 27 batch loss 0.260154784 epoch total loss 0.309030563\n",
      "Trained batch 28 batch loss 0.269775808 epoch total loss 0.307628602\n",
      "Trained batch 29 batch loss 0.253487349 epoch total loss 0.305761665\n",
      "Trained batch 30 batch loss 0.292069018 epoch total loss 0.305305272\n",
      "Trained batch 31 batch loss 0.263501734 epoch total loss 0.303956777\n",
      "Trained batch 32 batch loss 0.272308826 epoch total loss 0.302967787\n",
      "Trained batch 33 batch loss 0.26753214 epoch total loss 0.301893979\n",
      "Trained batch 34 batch loss 0.2706846 epoch total loss 0.300976038\n",
      "Trained batch 35 batch loss 0.286605775 epoch total loss 0.300565481\n",
      "Trained batch 36 batch loss 0.351410508 epoch total loss 0.301977843\n",
      "Trained batch 37 batch loss 0.282497942 epoch total loss 0.301451385\n",
      "Trained batch 38 batch loss 0.291287512 epoch total loss 0.301183909\n",
      "Trained batch 39 batch loss 0.306922913 epoch total loss 0.301331043\n",
      "Trained batch 40 batch loss 0.291674614 epoch total loss 0.301089644\n",
      "Trained batch 41 batch loss 0.272003591 epoch total loss 0.30038023\n",
      "Trained batch 42 batch loss 0.314706236 epoch total loss 0.300721318\n",
      "Trained batch 43 batch loss 0.304608703 epoch total loss 0.300811708\n",
      "Trained batch 44 batch loss 0.294685721 epoch total loss 0.300672472\n",
      "Trained batch 45 batch loss 0.301900506 epoch total loss 0.30069977\n",
      "Trained batch 46 batch loss 0.310091197 epoch total loss 0.300903916\n",
      "Trained batch 47 batch loss 0.258869827 epoch total loss 0.300009578\n",
      "Trained batch 48 batch loss 0.270300508 epoch total loss 0.299390644\n",
      "Trained batch 49 batch loss 0.284564942 epoch total loss 0.299088091\n",
      "Trained batch 50 batch loss 0.27943 epoch total loss 0.298694938\n",
      "Trained batch 51 batch loss 0.339592725 epoch total loss 0.299496859\n",
      "Trained batch 52 batch loss 0.285946637 epoch total loss 0.299236268\n",
      "Trained batch 53 batch loss 0.297209501 epoch total loss 0.299198031\n",
      "Trained batch 54 batch loss 0.27581346 epoch total loss 0.298765\n",
      "Trained batch 55 batch loss 0.313673675 epoch total loss 0.299036056\n",
      "Trained batch 56 batch loss 0.308278352 epoch total loss 0.299201101\n",
      "Trained batch 57 batch loss 0.314613581 epoch total loss 0.299471498\n",
      "Trained batch 58 batch loss 0.287255824 epoch total loss 0.299260885\n",
      "Trained batch 59 batch loss 0.292948306 epoch total loss 0.299153894\n",
      "Trained batch 60 batch loss 0.292772 epoch total loss 0.29904753\n",
      "Trained batch 61 batch loss 0.277065694 epoch total loss 0.29868716\n",
      "Trained batch 62 batch loss 0.288335681 epoch total loss 0.298520207\n",
      "Trained batch 63 batch loss 0.305811435 epoch total loss 0.29863593\n",
      "Trained batch 64 batch loss 0.301947236 epoch total loss 0.298687667\n",
      "Trained batch 65 batch loss 0.280995607 epoch total loss 0.298415482\n",
      "Trained batch 66 batch loss 0.285270274 epoch total loss 0.298216343\n",
      "Trained batch 67 batch loss 0.314679146 epoch total loss 0.298462033\n",
      "Trained batch 68 batch loss 0.319675058 epoch total loss 0.298774\n",
      "Trained batch 69 batch loss 0.282066524 epoch total loss 0.29853186\n",
      "Trained batch 70 batch loss 0.371302247 epoch total loss 0.299571425\n",
      "Trained batch 71 batch loss 0.365686327 epoch total loss 0.300502628\n",
      "Trained batch 72 batch loss 0.303153336 epoch total loss 0.300539434\n",
      "Trained batch 73 batch loss 0.304419458 epoch total loss 0.300592571\n",
      "Trained batch 74 batch loss 0.256349325 epoch total loss 0.299994707\n",
      "Trained batch 75 batch loss 0.238490745 epoch total loss 0.299174666\n",
      "Trained batch 76 batch loss 0.279359907 epoch total loss 0.298913926\n",
      "Trained batch 77 batch loss 0.268337369 epoch total loss 0.29851684\n",
      "Trained batch 78 batch loss 0.241040215 epoch total loss 0.297779948\n",
      "Trained batch 79 batch loss 0.227558732 epoch total loss 0.296891063\n",
      "Trained batch 80 batch loss 0.240765706 epoch total loss 0.296189487\n",
      "Trained batch 81 batch loss 0.272672921 epoch total loss 0.295899153\n",
      "Trained batch 82 batch loss 0.288326502 epoch total loss 0.295806825\n",
      "Trained batch 83 batch loss 0.279460371 epoch total loss 0.295609862\n",
      "Trained batch 84 batch loss 0.324232161 epoch total loss 0.295950621\n",
      "Trained batch 85 batch loss 0.305939615 epoch total loss 0.296068132\n",
      "Trained batch 86 batch loss 0.300385624 epoch total loss 0.296118349\n",
      "Trained batch 87 batch loss 0.309634775 epoch total loss 0.296273708\n",
      "Trained batch 88 batch loss 0.306536585 epoch total loss 0.296390325\n",
      "Trained batch 89 batch loss 0.302283525 epoch total loss 0.296456546\n",
      "Trained batch 90 batch loss 0.302651912 epoch total loss 0.296525389\n",
      "Trained batch 91 batch loss 0.321294725 epoch total loss 0.296797574\n",
      "Trained batch 92 batch loss 0.31706807 epoch total loss 0.297017902\n",
      "Trained batch 93 batch loss 0.294325769 epoch total loss 0.296988934\n",
      "Trained batch 94 batch loss 0.299520105 epoch total loss 0.297015876\n",
      "Trained batch 95 batch loss 0.30720073 epoch total loss 0.297123104\n",
      "Trained batch 96 batch loss 0.289446592 epoch total loss 0.297043115\n",
      "Trained batch 97 batch loss 0.272554696 epoch total loss 0.296790659\n",
      "Trained batch 98 batch loss 0.279863268 epoch total loss 0.296617925\n",
      "Trained batch 99 batch loss 0.298313737 epoch total loss 0.296635062\n",
      "Trained batch 100 batch loss 0.284072459 epoch total loss 0.296509445\n",
      "Trained batch 101 batch loss 0.253023297 epoch total loss 0.296078891\n",
      "Trained batch 102 batch loss 0.248648733 epoch total loss 0.295613885\n",
      "Trained batch 103 batch loss 0.275085092 epoch total loss 0.295414597\n",
      "Trained batch 104 batch loss 0.275123477 epoch total loss 0.295219481\n",
      "Trained batch 105 batch loss 0.297374696 epoch total loss 0.29524\n",
      "Trained batch 106 batch loss 0.293325096 epoch total loss 0.295221955\n",
      "Trained batch 107 batch loss 0.31229037 epoch total loss 0.295381457\n",
      "Trained batch 108 batch loss 0.297690153 epoch total loss 0.295402825\n",
      "Trained batch 109 batch loss 0.314903975 epoch total loss 0.295581758\n",
      "Trained batch 110 batch loss 0.296114951 epoch total loss 0.295586616\n",
      "Trained batch 111 batch loss 0.297266632 epoch total loss 0.295601755\n",
      "Trained batch 112 batch loss 0.324956477 epoch total loss 0.295863837\n",
      "Trained batch 113 batch loss 0.316495359 epoch total loss 0.296046406\n",
      "Trained batch 114 batch loss 0.248535424 epoch total loss 0.295629621\n",
      "Trained batch 115 batch loss 0.322338372 epoch total loss 0.29586187\n",
      "Trained batch 116 batch loss 0.3269113 epoch total loss 0.296129555\n",
      "Trained batch 117 batch loss 0.31240052 epoch total loss 0.296268612\n",
      "Trained batch 118 batch loss 0.265984505 epoch total loss 0.296011984\n",
      "Trained batch 119 batch loss 0.27669394 epoch total loss 0.295849651\n",
      "Trained batch 120 batch loss 0.254672706 epoch total loss 0.295506507\n",
      "Trained batch 121 batch loss 0.271494597 epoch total loss 0.295308083\n",
      "Trained batch 122 batch loss 0.270125717 epoch total loss 0.295101672\n",
      "Trained batch 123 batch loss 0.272277683 epoch total loss 0.294916093\n",
      "Trained batch 124 batch loss 0.262059629 epoch total loss 0.294651121\n",
      "Trained batch 125 batch loss 0.289973408 epoch total loss 0.294613719\n",
      "Trained batch 126 batch loss 0.28692 epoch total loss 0.294552624\n",
      "Trained batch 127 batch loss 0.293046057 epoch total loss 0.294540763\n",
      "Trained batch 128 batch loss 0.285001 epoch total loss 0.294466227\n",
      "Trained batch 129 batch loss 0.303237051 epoch total loss 0.294534236\n",
      "Trained batch 130 batch loss 0.308637589 epoch total loss 0.294642687\n",
      "Trained batch 131 batch loss 0.297295958 epoch total loss 0.294662952\n",
      "Trained batch 132 batch loss 0.298871666 epoch total loss 0.294694811\n",
      "Trained batch 133 batch loss 0.295127451 epoch total loss 0.29469806\n",
      "Trained batch 134 batch loss 0.306901962 epoch total loss 0.294789165\n",
      "Trained batch 135 batch loss 0.354132652 epoch total loss 0.29522875\n",
      "Trained batch 136 batch loss 0.310206831 epoch total loss 0.295338869\n",
      "Trained batch 137 batch loss 0.314800203 epoch total loss 0.295480937\n",
      "Trained batch 138 batch loss 0.338370383 epoch total loss 0.295791745\n",
      "Trained batch 139 batch loss 0.330626637 epoch total loss 0.296042353\n",
      "Trained batch 140 batch loss 0.340307683 epoch total loss 0.296358556\n",
      "Trained batch 141 batch loss 0.292513162 epoch total loss 0.296331286\n",
      "Trained batch 142 batch loss 0.283654213 epoch total loss 0.296242\n",
      "Trained batch 143 batch loss 0.275931239 epoch total loss 0.2961\n",
      "Trained batch 144 batch loss 0.295768887 epoch total loss 0.296097666\n",
      "Trained batch 145 batch loss 0.308365703 epoch total loss 0.296182275\n",
      "Trained batch 146 batch loss 0.316070557 epoch total loss 0.296318501\n",
      "Trained batch 147 batch loss 0.293664455 epoch total loss 0.296300441\n",
      "Trained batch 148 batch loss 0.292673141 epoch total loss 0.296275944\n",
      "Trained batch 149 batch loss 0.311434597 epoch total loss 0.296377689\n",
      "Trained batch 150 batch loss 0.289869 epoch total loss 0.296334267\n",
      "Trained batch 151 batch loss 0.291371733 epoch total loss 0.296301395\n",
      "Trained batch 152 batch loss 0.291786373 epoch total loss 0.296271712\n",
      "Trained batch 153 batch loss 0.28208831 epoch total loss 0.296179\n",
      "Trained batch 154 batch loss 0.274325192 epoch total loss 0.296037108\n",
      "Trained batch 155 batch loss 0.286348939 epoch total loss 0.295974612\n",
      "Trained batch 156 batch loss 0.302446783 epoch total loss 0.296016097\n",
      "Trained batch 157 batch loss 0.314094603 epoch total loss 0.296131253\n",
      "Trained batch 158 batch loss 0.296517491 epoch total loss 0.296133697\n",
      "Trained batch 159 batch loss 0.32198894 epoch total loss 0.296296299\n",
      "Trained batch 160 batch loss 0.26598382 epoch total loss 0.296106845\n",
      "Trained batch 161 batch loss 0.273730278 epoch total loss 0.295967847\n",
      "Trained batch 162 batch loss 0.274738431 epoch total loss 0.295836806\n",
      "Trained batch 163 batch loss 0.272358686 epoch total loss 0.295692772\n",
      "Trained batch 164 batch loss 0.288009077 epoch total loss 0.295645922\n",
      "Trained batch 165 batch loss 0.335558772 epoch total loss 0.295887828\n",
      "Trained batch 166 batch loss 0.314940035 epoch total loss 0.296002597\n",
      "Trained batch 167 batch loss 0.304178476 epoch total loss 0.296051562\n",
      "Trained batch 168 batch loss 0.316506 epoch total loss 0.296173334\n",
      "Trained batch 169 batch loss 0.297179222 epoch total loss 0.296179295\n",
      "Trained batch 170 batch loss 0.275488138 epoch total loss 0.296057582\n",
      "Trained batch 171 batch loss 0.283148944 epoch total loss 0.295982093\n",
      "Trained batch 172 batch loss 0.287544191 epoch total loss 0.295933038\n",
      "Trained batch 173 batch loss 0.297271639 epoch total loss 0.295940787\n",
      "Trained batch 174 batch loss 0.27502653 epoch total loss 0.295820594\n",
      "Trained batch 175 batch loss 0.299734801 epoch total loss 0.295842975\n",
      "Trained batch 176 batch loss 0.270066857 epoch total loss 0.295696497\n",
      "Trained batch 177 batch loss 0.275280565 epoch total loss 0.295581162\n",
      "Trained batch 178 batch loss 0.277364016 epoch total loss 0.295478791\n",
      "Trained batch 179 batch loss 0.284775585 epoch total loss 0.295419\n",
      "Trained batch 180 batch loss 0.248719186 epoch total loss 0.295159549\n",
      "Trained batch 181 batch loss 0.264540583 epoch total loss 0.294990391\n",
      "Trained batch 182 batch loss 0.275536388 epoch total loss 0.29488349\n",
      "Trained batch 183 batch loss 0.268408954 epoch total loss 0.294738829\n",
      "Trained batch 184 batch loss 0.273186564 epoch total loss 0.294621706\n",
      "Trained batch 185 batch loss 0.282661259 epoch total loss 0.294557035\n",
      "Trained batch 186 batch loss 0.279816687 epoch total loss 0.294477791\n",
      "Trained batch 187 batch loss 0.292395175 epoch total loss 0.294466674\n",
      "Trained batch 188 batch loss 0.369430691 epoch total loss 0.2948654\n",
      "Trained batch 189 batch loss 0.29557994 epoch total loss 0.294869184\n",
      "Trained batch 190 batch loss 0.328207701 epoch total loss 0.295044661\n",
      "Trained batch 191 batch loss 0.308883697 epoch total loss 0.29511711\n",
      "Trained batch 192 batch loss 0.304685771 epoch total loss 0.295166969\n",
      "Trained batch 193 batch loss 0.33427313 epoch total loss 0.295369595\n",
      "Trained batch 194 batch loss 0.317699045 epoch total loss 0.295484692\n",
      "Trained batch 195 batch loss 0.273887604 epoch total loss 0.295373946\n",
      "Trained batch 196 batch loss 0.250014752 epoch total loss 0.295142531\n",
      "Trained batch 197 batch loss 0.24117516 epoch total loss 0.294868588\n",
      "Trained batch 198 batch loss 0.286279768 epoch total loss 0.294825226\n",
      "Trained batch 199 batch loss 0.273723722 epoch total loss 0.294719189\n",
      "Trained batch 200 batch loss 0.291835457 epoch total loss 0.294704765\n",
      "Trained batch 201 batch loss 0.276403725 epoch total loss 0.294613719\n",
      "Trained batch 202 batch loss 0.276526034 epoch total loss 0.294524193\n",
      "Trained batch 203 batch loss 0.290639937 epoch total loss 0.29450506\n",
      "Trained batch 204 batch loss 0.299832702 epoch total loss 0.294531167\n",
      "Trained batch 205 batch loss 0.280195296 epoch total loss 0.29446125\n",
      "Trained batch 206 batch loss 0.298679411 epoch total loss 0.294481725\n",
      "Trained batch 207 batch loss 0.240186706 epoch total loss 0.294219434\n",
      "Trained batch 208 batch loss 0.296008945 epoch total loss 0.294228047\n",
      "Trained batch 209 batch loss 0.282620728 epoch total loss 0.294172496\n",
      "Trained batch 210 batch loss 0.278232813 epoch total loss 0.294096589\n",
      "Trained batch 211 batch loss 0.321249396 epoch total loss 0.294225276\n",
      "Trained batch 212 batch loss 0.328813374 epoch total loss 0.294388443\n",
      "Trained batch 213 batch loss 0.335477114 epoch total loss 0.294581324\n",
      "Trained batch 214 batch loss 0.289235592 epoch total loss 0.29455635\n",
      "Trained batch 215 batch loss 0.293896377 epoch total loss 0.29455328\n",
      "Trained batch 216 batch loss 0.264861375 epoch total loss 0.294415802\n",
      "Trained batch 217 batch loss 0.307077676 epoch total loss 0.294474155\n",
      "Trained batch 218 batch loss 0.312710255 epoch total loss 0.29455784\n",
      "Trained batch 219 batch loss 0.287819833 epoch total loss 0.294527054\n",
      "Trained batch 220 batch loss 0.302756071 epoch total loss 0.294564486\n",
      "Trained batch 221 batch loss 0.313197792 epoch total loss 0.294648767\n",
      "Trained batch 222 batch loss 0.327324122 epoch total loss 0.29479596\n",
      "Trained batch 223 batch loss 0.29965958 epoch total loss 0.294817775\n",
      "Trained batch 224 batch loss 0.291838467 epoch total loss 0.294804484\n",
      "Trained batch 225 batch loss 0.278877944 epoch total loss 0.294733673\n",
      "Trained batch 226 batch loss 0.279708177 epoch total loss 0.294667214\n",
      "Trained batch 227 batch loss 0.294883907 epoch total loss 0.294668168\n",
      "Trained batch 228 batch loss 0.317215979 epoch total loss 0.294767052\n",
      "Trained batch 229 batch loss 0.332238972 epoch total loss 0.294930667\n",
      "Trained batch 230 batch loss 0.291994035 epoch total loss 0.294917881\n",
      "Trained batch 231 batch loss 0.291389406 epoch total loss 0.294902623\n",
      "Trained batch 232 batch loss 0.318842888 epoch total loss 0.295005798\n",
      "Trained batch 233 batch loss 0.313916922 epoch total loss 0.29508698\n",
      "Trained batch 234 batch loss 0.303516984 epoch total loss 0.295123\n",
      "Trained batch 235 batch loss 0.264546812 epoch total loss 0.294992924\n",
      "Trained batch 236 batch loss 0.304135323 epoch total loss 0.295031667\n",
      "Trained batch 237 batch loss 0.272288054 epoch total loss 0.294935673\n",
      "Trained batch 238 batch loss 0.283357114 epoch total loss 0.294887036\n",
      "Trained batch 239 batch loss 0.291391641 epoch total loss 0.294872403\n",
      "Trained batch 240 batch loss 0.306176305 epoch total loss 0.294919491\n",
      "Trained batch 241 batch loss 0.29843989 epoch total loss 0.294934094\n",
      "Trained batch 242 batch loss 0.305184603 epoch total loss 0.294976443\n",
      "Trained batch 243 batch loss 0.298799187 epoch total loss 0.294992179\n",
      "Trained batch 244 batch loss 0.288900763 epoch total loss 0.294967204\n",
      "Trained batch 245 batch loss 0.314201534 epoch total loss 0.295045733\n",
      "Trained batch 246 batch loss 0.307295501 epoch total loss 0.295095533\n",
      "Trained batch 247 batch loss 0.326665938 epoch total loss 0.295223355\n",
      "Trained batch 248 batch loss 0.284346819 epoch total loss 0.295179486\n",
      "Trained batch 249 batch loss 0.239740521 epoch total loss 0.294956833\n",
      "Trained batch 250 batch loss 0.264533579 epoch total loss 0.29483515\n",
      "Trained batch 251 batch loss 0.297754407 epoch total loss 0.294846773\n",
      "Trained batch 252 batch loss 0.262924075 epoch total loss 0.294720083\n",
      "Trained batch 253 batch loss 0.272410512 epoch total loss 0.294631898\n",
      "Trained batch 254 batch loss 0.331052274 epoch total loss 0.294775307\n",
      "Trained batch 255 batch loss 0.291981637 epoch total loss 0.29476434\n",
      "Trained batch 256 batch loss 0.318199724 epoch total loss 0.294855893\n",
      "Trained batch 257 batch loss 0.306001693 epoch total loss 0.294899255\n",
      "Trained batch 258 batch loss 0.32429722 epoch total loss 0.295013189\n",
      "Trained batch 259 batch loss 0.333851814 epoch total loss 0.295163155\n",
      "Trained batch 260 batch loss 0.333549052 epoch total loss 0.295310795\n",
      "Trained batch 261 batch loss 0.280968368 epoch total loss 0.29525584\n",
      "Trained batch 262 batch loss 0.266834676 epoch total loss 0.295147389\n",
      "Trained batch 263 batch loss 0.286974907 epoch total loss 0.295116305\n",
      "Trained batch 264 batch loss 0.32280457 epoch total loss 0.29522118\n",
      "Trained batch 265 batch loss 0.309581697 epoch total loss 0.29527536\n",
      "Trained batch 266 batch loss 0.304743826 epoch total loss 0.295310944\n",
      "Trained batch 267 batch loss 0.331594467 epoch total loss 0.295446843\n",
      "Trained batch 268 batch loss 0.334038675 epoch total loss 0.295590848\n",
      "Trained batch 269 batch loss 0.289241135 epoch total loss 0.295567214\n",
      "Trained batch 270 batch loss 0.325537205 epoch total loss 0.295678228\n",
      "Trained batch 271 batch loss 0.342244416 epoch total loss 0.295850068\n",
      "Trained batch 272 batch loss 0.296717852 epoch total loss 0.295853257\n",
      "Trained batch 273 batch loss 0.278931081 epoch total loss 0.295791268\n",
      "Trained batch 274 batch loss 0.284695238 epoch total loss 0.295750767\n",
      "Trained batch 275 batch loss 0.244634777 epoch total loss 0.29556492\n",
      "Trained batch 276 batch loss 0.272326678 epoch total loss 0.295480698\n",
      "Trained batch 277 batch loss 0.285452306 epoch total loss 0.295444489\n",
      "Trained batch 278 batch loss 0.271321237 epoch total loss 0.295357734\n",
      "Trained batch 279 batch loss 0.306585968 epoch total loss 0.295398\n",
      "Trained batch 280 batch loss 0.322169691 epoch total loss 0.295493603\n",
      "Trained batch 281 batch loss 0.301059544 epoch total loss 0.295513391\n",
      "Trained batch 282 batch loss 0.269915164 epoch total loss 0.295422614\n",
      "Trained batch 283 batch loss 0.286205351 epoch total loss 0.29539004\n",
      "Trained batch 284 batch loss 0.265627921 epoch total loss 0.295285225\n",
      "Trained batch 285 batch loss 0.30934456 epoch total loss 0.295334548\n",
      "Trained batch 286 batch loss 0.280474186 epoch total loss 0.295282602\n",
      "Trained batch 287 batch loss 0.296919405 epoch total loss 0.295288295\n",
      "Trained batch 288 batch loss 0.303757042 epoch total loss 0.295317709\n",
      "Trained batch 289 batch loss 0.285818696 epoch total loss 0.295284837\n",
      "Trained batch 290 batch loss 0.280071 epoch total loss 0.295232356\n",
      "Trained batch 291 batch loss 0.317010075 epoch total loss 0.295307189\n",
      "Trained batch 292 batch loss 0.284831107 epoch total loss 0.295271307\n",
      "Trained batch 293 batch loss 0.27207464 epoch total loss 0.295192122\n",
      "Trained batch 294 batch loss 0.24911128 epoch total loss 0.295035422\n",
      "Trained batch 295 batch loss 0.306317598 epoch total loss 0.295073658\n",
      "Trained batch 296 batch loss 0.290611595 epoch total loss 0.295058578\n",
      "Trained batch 297 batch loss 0.318817288 epoch total loss 0.295138568\n",
      "Trained batch 298 batch loss 0.289181352 epoch total loss 0.2951186\n",
      "Trained batch 299 batch loss 0.262734413 epoch total loss 0.295010298\n",
      "Trained batch 300 batch loss 0.235885292 epoch total loss 0.294813216\n",
      "Trained batch 301 batch loss 0.246465847 epoch total loss 0.294652581\n",
      "Trained batch 302 batch loss 0.237846494 epoch total loss 0.294464499\n",
      "Trained batch 303 batch loss 0.263043821 epoch total loss 0.294360787\n",
      "Trained batch 304 batch loss 0.257861733 epoch total loss 0.294240713\n",
      "Trained batch 305 batch loss 0.305843979 epoch total loss 0.294278771\n",
      "Trained batch 306 batch loss 0.316327572 epoch total loss 0.294350833\n",
      "Trained batch 307 batch loss 0.293579847 epoch total loss 0.294348329\n",
      "Trained batch 308 batch loss 0.291852325 epoch total loss 0.294340223\n",
      "Trained batch 309 batch loss 0.309439778 epoch total loss 0.294389099\n",
      "Trained batch 310 batch loss 0.299788892 epoch total loss 0.294406533\n",
      "Trained batch 311 batch loss 0.297890782 epoch total loss 0.294417709\n",
      "Trained batch 312 batch loss 0.304775089 epoch total loss 0.294450909\n",
      "Trained batch 313 batch loss 0.331382811 epoch total loss 0.294568896\n",
      "Trained batch 314 batch loss 0.30819267 epoch total loss 0.294612288\n",
      "Trained batch 315 batch loss 0.293551505 epoch total loss 0.294608891\n",
      "Trained batch 316 batch loss 0.306901276 epoch total loss 0.294647783\n",
      "Trained batch 317 batch loss 0.308238745 epoch total loss 0.294690669\n",
      "Trained batch 318 batch loss 0.299968123 epoch total loss 0.294707239\n",
      "Trained batch 319 batch loss 0.306057304 epoch total loss 0.294742823\n",
      "Trained batch 320 batch loss 0.297200263 epoch total loss 0.294750512\n",
      "Trained batch 321 batch loss 0.309887052 epoch total loss 0.294797689\n",
      "Trained batch 322 batch loss 0.284705639 epoch total loss 0.294766337\n",
      "Trained batch 323 batch loss 0.312449455 epoch total loss 0.294821084\n",
      "Trained batch 324 batch loss 0.285207629 epoch total loss 0.29479143\n",
      "Trained batch 325 batch loss 0.288190603 epoch total loss 0.294771105\n",
      "Trained batch 326 batch loss 0.282494456 epoch total loss 0.294733465\n",
      "Trained batch 327 batch loss 0.281012148 epoch total loss 0.294691503\n",
      "Trained batch 328 batch loss 0.261993468 epoch total loss 0.294591814\n",
      "Trained batch 329 batch loss 0.32006377 epoch total loss 0.294669211\n",
      "Trained batch 330 batch loss 0.274967045 epoch total loss 0.294609517\n",
      "Trained batch 331 batch loss 0.3000696 epoch total loss 0.294626\n",
      "Trained batch 332 batch loss 0.268910021 epoch total loss 0.294548571\n",
      "Trained batch 333 batch loss 0.285377741 epoch total loss 0.294521034\n",
      "Trained batch 334 batch loss 0.281923383 epoch total loss 0.294483304\n",
      "Trained batch 335 batch loss 0.318146139 epoch total loss 0.294553936\n",
      "Trained batch 336 batch loss 0.304319 epoch total loss 0.294583\n",
      "Trained batch 337 batch loss 0.275800526 epoch total loss 0.294527262\n",
      "Trained batch 338 batch loss 0.274449766 epoch total loss 0.294467866\n",
      "Trained batch 339 batch loss 0.304753542 epoch total loss 0.294498235\n",
      "Trained batch 340 batch loss 0.301499307 epoch total loss 0.294518828\n",
      "Trained batch 341 batch loss 0.294981241 epoch total loss 0.294520169\n",
      "Trained batch 342 batch loss 0.2994681 epoch total loss 0.294534653\n",
      "Trained batch 343 batch loss 0.273051083 epoch total loss 0.294472\n",
      "Trained batch 344 batch loss 0.276995599 epoch total loss 0.294421196\n",
      "Trained batch 345 batch loss 0.255669683 epoch total loss 0.294308871\n",
      "Trained batch 346 batch loss 0.291246444 epoch total loss 0.29430002\n",
      "Trained batch 347 batch loss 0.271156907 epoch total loss 0.294233322\n",
      "Trained batch 348 batch loss 0.280863047 epoch total loss 0.294194877\n",
      "Trained batch 349 batch loss 0.25222519 epoch total loss 0.294074655\n",
      "Trained batch 350 batch loss 0.283210188 epoch total loss 0.294043601\n",
      "Trained batch 351 batch loss 0.270458162 epoch total loss 0.293976396\n",
      "Trained batch 352 batch loss 0.26902616 epoch total loss 0.293905526\n",
      "Trained batch 353 batch loss 0.287923872 epoch total loss 0.293888569\n",
      "Trained batch 354 batch loss 0.300046086 epoch total loss 0.293905973\n",
      "Trained batch 355 batch loss 0.256312 epoch total loss 0.293800086\n",
      "Trained batch 356 batch loss 0.262404203 epoch total loss 0.293711901\n",
      "Trained batch 357 batch loss 0.238554209 epoch total loss 0.293557376\n",
      "Trained batch 358 batch loss 0.216996208 epoch total loss 0.293343514\n",
      "Trained batch 359 batch loss 0.335154027 epoch total loss 0.293459982\n",
      "Trained batch 360 batch loss 0.290209115 epoch total loss 0.293450952\n",
      "Trained batch 361 batch loss 0.295822501 epoch total loss 0.293457508\n",
      "Trained batch 362 batch loss 0.293686569 epoch total loss 0.293458134\n",
      "Trained batch 363 batch loss 0.245551482 epoch total loss 0.293326169\n",
      "Trained batch 364 batch loss 0.251577556 epoch total loss 0.29321149\n",
      "Trained batch 365 batch loss 0.293642163 epoch total loss 0.293212652\n",
      "Trained batch 366 batch loss 0.286864817 epoch total loss 0.293195307\n",
      "Trained batch 367 batch loss 0.270593 epoch total loss 0.293133736\n",
      "Trained batch 368 batch loss 0.291733652 epoch total loss 0.293129921\n",
      "Trained batch 369 batch loss 0.316007763 epoch total loss 0.29319194\n",
      "Trained batch 370 batch loss 0.291761577 epoch total loss 0.293188065\n",
      "Trained batch 371 batch loss 0.30838725 epoch total loss 0.293229043\n",
      "Trained batch 372 batch loss 0.311616153 epoch total loss 0.293278456\n",
      "Trained batch 373 batch loss 0.32166487 epoch total loss 0.293354571\n",
      "Trained batch 374 batch loss 0.334643602 epoch total loss 0.293464959\n",
      "Trained batch 375 batch loss 0.324377179 epoch total loss 0.293547392\n",
      "Trained batch 376 batch loss 0.279479235 epoch total loss 0.29350996\n",
      "Trained batch 377 batch loss 0.27606523 epoch total loss 0.293463677\n",
      "Trained batch 378 batch loss 0.327737302 epoch total loss 0.293554366\n",
      "Trained batch 379 batch loss 0.30126828 epoch total loss 0.293574721\n",
      "Trained batch 380 batch loss 0.339653522 epoch total loss 0.293696\n",
      "Trained batch 381 batch loss 0.293710947 epoch total loss 0.293696016\n",
      "Trained batch 382 batch loss 0.303248167 epoch total loss 0.293721\n",
      "Trained batch 383 batch loss 0.31617716 epoch total loss 0.293779641\n",
      "Trained batch 384 batch loss 0.297937602 epoch total loss 0.29379046\n",
      "Trained batch 385 batch loss 0.310726225 epoch total loss 0.293834448\n",
      "Trained batch 386 batch loss 0.341552 epoch total loss 0.293958068\n",
      "Trained batch 387 batch loss 0.335628092 epoch total loss 0.294065744\n",
      "Trained batch 388 batch loss 0.310345858 epoch total loss 0.294107705\n",
      "Trained batch 389 batch loss 0.29181844 epoch total loss 0.294101834\n",
      "Trained batch 390 batch loss 0.266387343 epoch total loss 0.294030756\n",
      "Trained batch 391 batch loss 0.28801471 epoch total loss 0.294015378\n",
      "Trained batch 392 batch loss 0.29251492 epoch total loss 0.294011563\n",
      "Trained batch 393 batch loss 0.361642212 epoch total loss 0.294183642\n",
      "Trained batch 394 batch loss 0.326380253 epoch total loss 0.29426536\n",
      "Trained batch 395 batch loss 0.320249975 epoch total loss 0.294331133\n",
      "Trained batch 396 batch loss 0.329265 epoch total loss 0.294419348\n",
      "Trained batch 397 batch loss 0.287003458 epoch total loss 0.294400662\n",
      "Trained batch 398 batch loss 0.282894462 epoch total loss 0.294371784\n",
      "Trained batch 399 batch loss 0.286054 epoch total loss 0.294350922\n",
      "Trained batch 400 batch loss 0.292596459 epoch total loss 0.294346541\n",
      "Trained batch 401 batch loss 0.308467597 epoch total loss 0.294381738\n",
      "Trained batch 402 batch loss 0.28281635 epoch total loss 0.294352978\n",
      "Trained batch 403 batch loss 0.271388233 epoch total loss 0.294295967\n",
      "Trained batch 404 batch loss 0.233518302 epoch total loss 0.294145554\n",
      "Trained batch 405 batch loss 0.25109908 epoch total loss 0.294039249\n",
      "Trained batch 406 batch loss 0.321683973 epoch total loss 0.294107348\n",
      "Trained batch 407 batch loss 0.369655699 epoch total loss 0.294293\n",
      "Trained batch 408 batch loss 0.338020563 epoch total loss 0.294400156\n",
      "Trained batch 409 batch loss 0.351742208 epoch total loss 0.294540375\n",
      "Trained batch 410 batch loss 0.313209385 epoch total loss 0.294585913\n",
      "Trained batch 411 batch loss 0.340323806 epoch total loss 0.294697195\n",
      "Trained batch 412 batch loss 0.312556148 epoch total loss 0.294740528\n",
      "Trained batch 413 batch loss 0.299266517 epoch total loss 0.294751465\n",
      "Trained batch 414 batch loss 0.288592458 epoch total loss 0.294736594\n",
      "Trained batch 415 batch loss 0.264636815 epoch total loss 0.294664055\n",
      "Trained batch 416 batch loss 0.323316574 epoch total loss 0.294732928\n",
      "Trained batch 417 batch loss 0.319473207 epoch total loss 0.294792265\n",
      "Trained batch 418 batch loss 0.316429198 epoch total loss 0.294844031\n",
      "Trained batch 419 batch loss 0.305294693 epoch total loss 0.294868976\n",
      "Trained batch 420 batch loss 0.307270706 epoch total loss 0.29489851\n",
      "Trained batch 421 batch loss 0.310640514 epoch total loss 0.294935912\n",
      "Trained batch 422 batch loss 0.347881109 epoch total loss 0.29506135\n",
      "Trained batch 423 batch loss 0.304884672 epoch total loss 0.295084596\n",
      "Trained batch 424 batch loss 0.273462951 epoch total loss 0.295033574\n",
      "Trained batch 425 batch loss 0.295291901 epoch total loss 0.29503417\n",
      "Trained batch 426 batch loss 0.297600269 epoch total loss 0.29504019\n",
      "Trained batch 427 batch loss 0.253523886 epoch total loss 0.294942975\n",
      "Trained batch 428 batch loss 0.274660349 epoch total loss 0.294895589\n",
      "Trained batch 429 batch loss 0.289625 epoch total loss 0.294883311\n",
      "Trained batch 430 batch loss 0.279197901 epoch total loss 0.294846833\n",
      "Trained batch 431 batch loss 0.282352 epoch total loss 0.294817835\n",
      "Trained batch 432 batch loss 0.267016649 epoch total loss 0.294753462\n",
      "Trained batch 433 batch loss 0.274595708 epoch total loss 0.294706911\n",
      "Trained batch 434 batch loss 0.254173428 epoch total loss 0.29461351\n",
      "Trained batch 435 batch loss 0.306224108 epoch total loss 0.294640213\n",
      "Trained batch 436 batch loss 0.319941252 epoch total loss 0.294698238\n",
      "Trained batch 437 batch loss 0.340348423 epoch total loss 0.294802696\n",
      "Trained batch 438 batch loss 0.330180824 epoch total loss 0.29488349\n",
      "Trained batch 439 batch loss 0.323386937 epoch total loss 0.294948399\n",
      "Trained batch 440 batch loss 0.34162277 epoch total loss 0.295054495\n",
      "Trained batch 441 batch loss 0.324337482 epoch total loss 0.295120895\n",
      "Trained batch 442 batch loss 0.280690968 epoch total loss 0.295088232\n",
      "Trained batch 443 batch loss 0.292268217 epoch total loss 0.295081854\n",
      "Trained batch 444 batch loss 0.283981442 epoch total loss 0.29505688\n",
      "Trained batch 445 batch loss 0.289861619 epoch total loss 0.295045167\n",
      "Trained batch 446 batch loss 0.324802041 epoch total loss 0.295111895\n",
      "Trained batch 447 batch loss 0.308612645 epoch total loss 0.295142084\n",
      "Trained batch 448 batch loss 0.278600186 epoch total loss 0.295105159\n",
      "Trained batch 449 batch loss 0.29022187 epoch total loss 0.295094281\n",
      "Trained batch 450 batch loss 0.255930543 epoch total loss 0.295007259\n",
      "Trained batch 451 batch loss 0.269495457 epoch total loss 0.294950694\n",
      "Trained batch 452 batch loss 0.293793231 epoch total loss 0.294948131\n",
      "Trained batch 453 batch loss 0.279313773 epoch total loss 0.29491362\n",
      "Trained batch 454 batch loss 0.26373288 epoch total loss 0.294844955\n",
      "Trained batch 455 batch loss 0.287718564 epoch total loss 0.294829279\n",
      "Trained batch 456 batch loss 0.294634163 epoch total loss 0.294828862\n",
      "Trained batch 457 batch loss 0.300014377 epoch total loss 0.294840217\n",
      "Trained batch 458 batch loss 0.322881818 epoch total loss 0.294901431\n",
      "Trained batch 459 batch loss 0.280128151 epoch total loss 0.294869214\n",
      "Trained batch 460 batch loss 0.277320504 epoch total loss 0.294831038\n",
      "Trained batch 461 batch loss 0.303115845 epoch total loss 0.294849038\n",
      "Trained batch 462 batch loss 0.289088845 epoch total loss 0.294836551\n",
      "Trained batch 463 batch loss 0.270584315 epoch total loss 0.294784188\n",
      "Trained batch 464 batch loss 0.296493292 epoch total loss 0.294787854\n",
      "Trained batch 465 batch loss 0.289639592 epoch total loss 0.294776797\n",
      "Trained batch 466 batch loss 0.284360081 epoch total loss 0.294754446\n",
      "Trained batch 467 batch loss 0.2864663 epoch total loss 0.294736713\n",
      "Trained batch 468 batch loss 0.268923193 epoch total loss 0.294681549\n",
      "Trained batch 469 batch loss 0.283953428 epoch total loss 0.294658661\n",
      "Trained batch 470 batch loss 0.272123814 epoch total loss 0.294610739\n",
      "Trained batch 471 batch loss 0.29007569 epoch total loss 0.294601083\n",
      "Trained batch 472 batch loss 0.281911731 epoch total loss 0.294574201\n",
      "Trained batch 473 batch loss 0.291208446 epoch total loss 0.294567078\n",
      "Trained batch 474 batch loss 0.298755 epoch total loss 0.2945759\n",
      "Trained batch 475 batch loss 0.260895729 epoch total loss 0.294505\n",
      "Trained batch 476 batch loss 0.312635601 epoch total loss 0.294543087\n",
      "Trained batch 477 batch loss 0.310051 epoch total loss 0.294575632\n",
      "Trained batch 478 batch loss 0.274602979 epoch total loss 0.294533819\n",
      "Trained batch 479 batch loss 0.29156968 epoch total loss 0.29452762\n",
      "Trained batch 480 batch loss 0.290150702 epoch total loss 0.294518501\n",
      "Trained batch 481 batch loss 0.289297551 epoch total loss 0.294507623\n",
      "Trained batch 482 batch loss 0.263872236 epoch total loss 0.294444084\n",
      "Trained batch 483 batch loss 0.279938728 epoch total loss 0.294414043\n",
      "Trained batch 484 batch loss 0.294246078 epoch total loss 0.294413686\n",
      "Trained batch 485 batch loss 0.313842565 epoch total loss 0.29445377\n",
      "Trained batch 486 batch loss 0.283173472 epoch total loss 0.294430554\n",
      "Trained batch 487 batch loss 0.26159972 epoch total loss 0.294363141\n",
      "Trained batch 488 batch loss 0.341381878 epoch total loss 0.294459492\n",
      "Trained batch 489 batch loss 0.264527023 epoch total loss 0.294398278\n",
      "Trained batch 490 batch loss 0.293730259 epoch total loss 0.294396907\n",
      "Trained batch 491 batch loss 0.278682739 epoch total loss 0.294364899\n",
      "Trained batch 492 batch loss 0.283745348 epoch total loss 0.294343352\n",
      "Trained batch 493 batch loss 0.311314821 epoch total loss 0.294377744\n",
      "Trained batch 494 batch loss 0.314658493 epoch total loss 0.294418812\n",
      "Trained batch 495 batch loss 0.303856671 epoch total loss 0.294437885\n",
      "Trained batch 496 batch loss 0.295251757 epoch total loss 0.294439524\n",
      "Trained batch 497 batch loss 0.249089718 epoch total loss 0.29434827\n",
      "Trained batch 498 batch loss 0.30938828 epoch total loss 0.294378459\n",
      "Trained batch 499 batch loss 0.296059906 epoch total loss 0.294381857\n",
      "Trained batch 500 batch loss 0.312703 epoch total loss 0.294418484\n",
      "Trained batch 501 batch loss 0.265649229 epoch total loss 0.294361085\n",
      "Trained batch 502 batch loss 0.317782611 epoch total loss 0.294407725\n",
      "Trained batch 503 batch loss 0.289846748 epoch total loss 0.294398636\n",
      "Trained batch 504 batch loss 0.320635 epoch total loss 0.2944507\n",
      "Trained batch 505 batch loss 0.299742848 epoch total loss 0.294461191\n",
      "Trained batch 506 batch loss 0.285249 epoch total loss 0.294442981\n",
      "Trained batch 507 batch loss 0.270555675 epoch total loss 0.294395864\n",
      "Trained batch 508 batch loss 0.289523512 epoch total loss 0.294386268\n",
      "Trained batch 509 batch loss 0.296203762 epoch total loss 0.294389814\n",
      "Trained batch 510 batch loss 0.311445534 epoch total loss 0.294423282\n",
      "Trained batch 511 batch loss 0.30546546 epoch total loss 0.294444889\n",
      "Trained batch 512 batch loss 0.297366142 epoch total loss 0.294450581\n",
      "Trained batch 513 batch loss 0.298386663 epoch total loss 0.29445824\n",
      "Trained batch 514 batch loss 0.300341547 epoch total loss 0.294469684\n",
      "Trained batch 515 batch loss 0.266175121 epoch total loss 0.294414759\n",
      "Trained batch 516 batch loss 0.25146547 epoch total loss 0.294331521\n",
      "Trained batch 517 batch loss 0.292603493 epoch total loss 0.294328183\n",
      "Trained batch 518 batch loss 0.325813174 epoch total loss 0.29438895\n",
      "Trained batch 519 batch loss 0.305607766 epoch total loss 0.294410557\n",
      "Trained batch 520 batch loss 0.307537 epoch total loss 0.294435799\n",
      "Trained batch 521 batch loss 0.29060334 epoch total loss 0.294428438\n",
      "Trained batch 522 batch loss 0.320192933 epoch total loss 0.294477791\n",
      "Trained batch 523 batch loss 0.302451164 epoch total loss 0.29449302\n",
      "Trained batch 524 batch loss 0.300925285 epoch total loss 0.294505298\n",
      "Trained batch 525 batch loss 0.317437023 epoch total loss 0.294549\n",
      "Trained batch 526 batch loss 0.291659743 epoch total loss 0.294543475\n",
      "Trained batch 527 batch loss 0.275591612 epoch total loss 0.294507504\n",
      "Trained batch 528 batch loss 0.298837513 epoch total loss 0.294515729\n",
      "Trained batch 529 batch loss 0.282299578 epoch total loss 0.294492632\n",
      "Trained batch 530 batch loss 0.278922021 epoch total loss 0.294463247\n",
      "Trained batch 531 batch loss 0.26768747 epoch total loss 0.294412822\n",
      "Trained batch 532 batch loss 0.282605708 epoch total loss 0.294390619\n",
      "Trained batch 533 batch loss 0.289348423 epoch total loss 0.294381171\n",
      "Trained batch 534 batch loss 0.312332243 epoch total loss 0.294414788\n",
      "Trained batch 535 batch loss 0.357983738 epoch total loss 0.29453361\n",
      "Trained batch 536 batch loss 0.32246536 epoch total loss 0.294585735\n",
      "Trained batch 537 batch loss 0.317021191 epoch total loss 0.294627488\n",
      "Trained batch 538 batch loss 0.291980535 epoch total loss 0.29462257\n",
      "Trained batch 539 batch loss 0.254637241 epoch total loss 0.294548392\n",
      "Trained batch 540 batch loss 0.243042141 epoch total loss 0.294453\n",
      "Trained batch 541 batch loss 0.233697146 epoch total loss 0.29434073\n",
      "Trained batch 542 batch loss 0.266437799 epoch total loss 0.294289231\n",
      "Trained batch 543 batch loss 0.291824281 epoch total loss 0.294284701\n",
      "Trained batch 544 batch loss 0.328569323 epoch total loss 0.294347703\n",
      "Trained batch 545 batch loss 0.264835358 epoch total loss 0.294293553\n",
      "Trained batch 546 batch loss 0.263854861 epoch total loss 0.294237792\n",
      "Trained batch 547 batch loss 0.296646 epoch total loss 0.294242203\n",
      "Trained batch 548 batch loss 0.262074232 epoch total loss 0.294183493\n",
      "Trained batch 549 batch loss 0.282176495 epoch total loss 0.294161618\n",
      "Trained batch 550 batch loss 0.275778413 epoch total loss 0.294128209\n",
      "Trained batch 551 batch loss 0.308582097 epoch total loss 0.294154435\n",
      "Trained batch 552 batch loss 0.276082635 epoch total loss 0.294121683\n",
      "Trained batch 553 batch loss 0.307048798 epoch total loss 0.294145048\n",
      "Trained batch 554 batch loss 0.287647605 epoch total loss 0.294133335\n",
      "Trained batch 555 batch loss 0.337595105 epoch total loss 0.294211626\n",
      "Trained batch 556 batch loss 0.343299508 epoch total loss 0.294299901\n",
      "Trained batch 557 batch loss 0.371288627 epoch total loss 0.294438154\n",
      "Trained batch 558 batch loss 0.354599237 epoch total loss 0.294545949\n",
      "Trained batch 559 batch loss 0.274724126 epoch total loss 0.294510484\n",
      "Trained batch 560 batch loss 0.285650611 epoch total loss 0.294494659\n",
      "Trained batch 561 batch loss 0.304910541 epoch total loss 0.294513226\n",
      "Trained batch 562 batch loss 0.360699207 epoch total loss 0.294631\n",
      "Trained batch 563 batch loss 0.307906 epoch total loss 0.294654578\n",
      "Trained batch 564 batch loss 0.31542629 epoch total loss 0.294691414\n",
      "Trained batch 565 batch loss 0.318294972 epoch total loss 0.294733196\n",
      "Trained batch 566 batch loss 0.305671871 epoch total loss 0.294752538\n",
      "Trained batch 567 batch loss 0.310787737 epoch total loss 0.294780821\n",
      "Trained batch 568 batch loss 0.288404197 epoch total loss 0.294769615\n",
      "Trained batch 569 batch loss 0.282905 epoch total loss 0.294748753\n",
      "Trained batch 570 batch loss 0.277750909 epoch total loss 0.294718921\n",
      "Trained batch 571 batch loss 0.27787286 epoch total loss 0.294689447\n",
      "Trained batch 572 batch loss 0.319894284 epoch total loss 0.294733524\n",
      "Trained batch 573 batch loss 0.307660639 epoch total loss 0.294756085\n",
      "Trained batch 574 batch loss 0.296574503 epoch total loss 0.294759244\n",
      "Trained batch 575 batch loss 0.294920027 epoch total loss 0.294759512\n",
      "Trained batch 576 batch loss 0.32024008 epoch total loss 0.294803739\n",
      "Trained batch 577 batch loss 0.291388422 epoch total loss 0.294797808\n",
      "Trained batch 578 batch loss 0.277384639 epoch total loss 0.294767708\n",
      "Trained batch 579 batch loss 0.310306817 epoch total loss 0.29479453\n",
      "Trained batch 580 batch loss 0.287854165 epoch total loss 0.294782579\n",
      "Trained batch 581 batch loss 0.308090538 epoch total loss 0.294805467\n",
      "Trained batch 582 batch loss 0.304246873 epoch total loss 0.294821709\n",
      "Trained batch 583 batch loss 0.263341069 epoch total loss 0.294767678\n",
      "Trained batch 584 batch loss 0.294968784 epoch total loss 0.294768035\n",
      "Trained batch 585 batch loss 0.299555451 epoch total loss 0.294776231\n",
      "Trained batch 586 batch loss 0.278761923 epoch total loss 0.294748902\n",
      "Trained batch 587 batch loss 0.315857112 epoch total loss 0.294784844\n",
      "Trained batch 588 batch loss 0.300386 epoch total loss 0.294794381\n",
      "Trained batch 589 batch loss 0.301946402 epoch total loss 0.29480651\n",
      "Trained batch 590 batch loss 0.320700079 epoch total loss 0.294850379\n",
      "Trained batch 591 batch loss 0.315397561 epoch total loss 0.294885159\n",
      "Trained batch 592 batch loss 0.281972498 epoch total loss 0.294863343\n",
      "Trained batch 593 batch loss 0.256833285 epoch total loss 0.294799209\n",
      "Trained batch 594 batch loss 0.276357532 epoch total loss 0.294768155\n",
      "Trained batch 595 batch loss 0.259745806 epoch total loss 0.294709295\n",
      "Trained batch 596 batch loss 0.27835235 epoch total loss 0.294681847\n",
      "Trained batch 597 batch loss 0.268764347 epoch total loss 0.294638455\n",
      "Trained batch 598 batch loss 0.28116256 epoch total loss 0.294615895\n",
      "Trained batch 599 batch loss 0.286637723 epoch total loss 0.294602573\n",
      "Trained batch 600 batch loss 0.285916537 epoch total loss 0.294588119\n",
      "Trained batch 601 batch loss 0.272732973 epoch total loss 0.29455176\n",
      "Trained batch 602 batch loss 0.260219187 epoch total loss 0.294494718\n",
      "Trained batch 603 batch loss 0.295024574 epoch total loss 0.294495612\n",
      "Trained batch 604 batch loss 0.297037393 epoch total loss 0.294499844\n",
      "Trained batch 605 batch loss 0.314303339 epoch total loss 0.294532567\n",
      "Trained batch 606 batch loss 0.306836188 epoch total loss 0.294552863\n",
      "Trained batch 607 batch loss 0.292857051 epoch total loss 0.294550091\n",
      "Trained batch 608 batch loss 0.311676562 epoch total loss 0.294578254\n",
      "Trained batch 609 batch loss 0.290568709 epoch total loss 0.294571668\n",
      "Trained batch 610 batch loss 0.311641157 epoch total loss 0.294599652\n",
      "Trained batch 611 batch loss 0.311855018 epoch total loss 0.294627905\n",
      "Trained batch 612 batch loss 0.294850767 epoch total loss 0.294628263\n",
      "Trained batch 613 batch loss 0.30156675 epoch total loss 0.294639587\n",
      "Trained batch 614 batch loss 0.274034739 epoch total loss 0.294606\n",
      "Trained batch 615 batch loss 0.26287514 epoch total loss 0.294554412\n",
      "Trained batch 616 batch loss 0.286789656 epoch total loss 0.294541806\n",
      "Trained batch 617 batch loss 0.269357681 epoch total loss 0.294501\n",
      "Trained batch 618 batch loss 0.302481562 epoch total loss 0.294513911\n",
      "Trained batch 619 batch loss 0.285466462 epoch total loss 0.294499278\n",
      "Trained batch 620 batch loss 0.275218815 epoch total loss 0.294468194\n",
      "Trained batch 621 batch loss 0.268229485 epoch total loss 0.294425964\n",
      "Trained batch 622 batch loss 0.295030385 epoch total loss 0.294426918\n",
      "Trained batch 623 batch loss 0.335547328 epoch total loss 0.2944929\n",
      "Trained batch 624 batch loss 0.306130826 epoch total loss 0.294511586\n",
      "Trained batch 625 batch loss 0.294714719 epoch total loss 0.294511884\n",
      "Trained batch 626 batch loss 0.23817122 epoch total loss 0.294421881\n",
      "Trained batch 627 batch loss 0.235301659 epoch total loss 0.294327617\n",
      "Trained batch 628 batch loss 0.212488517 epoch total loss 0.294197291\n",
      "Trained batch 629 batch loss 0.281395465 epoch total loss 0.294176966\n",
      "Trained batch 630 batch loss 0.26030004 epoch total loss 0.294123173\n",
      "Trained batch 631 batch loss 0.314622045 epoch total loss 0.294155657\n",
      "Trained batch 632 batch loss 0.277106613 epoch total loss 0.294128686\n",
      "Trained batch 633 batch loss 0.344942808 epoch total loss 0.294208944\n",
      "Trained batch 634 batch loss 0.326649219 epoch total loss 0.294260114\n",
      "Trained batch 635 batch loss 0.354508579 epoch total loss 0.294355\n",
      "Trained batch 636 batch loss 0.302153766 epoch total loss 0.294367254\n",
      "Trained batch 637 batch loss 0.304654658 epoch total loss 0.294383407\n",
      "Trained batch 638 batch loss 0.29606849 epoch total loss 0.294386059\n",
      "Trained batch 639 batch loss 0.306249559 epoch total loss 0.294404596\n",
      "Trained batch 640 batch loss 0.305850893 epoch total loss 0.294422477\n",
      "Trained batch 641 batch loss 0.314191937 epoch total loss 0.294453323\n",
      "Trained batch 642 batch loss 0.340702683 epoch total loss 0.294525355\n",
      "Trained batch 643 batch loss 0.312490761 epoch total loss 0.29455328\n",
      "Trained batch 644 batch loss 0.346107841 epoch total loss 0.294633359\n",
      "Trained batch 645 batch loss 0.357568681 epoch total loss 0.294730932\n",
      "Trained batch 646 batch loss 0.335670143 epoch total loss 0.294794291\n",
      "Trained batch 647 batch loss 0.341063291 epoch total loss 0.294865817\n",
      "Trained batch 648 batch loss 0.324352086 epoch total loss 0.294911325\n",
      "Trained batch 649 batch loss 0.30779162 epoch total loss 0.294931173\n",
      "Trained batch 650 batch loss 0.330338895 epoch total loss 0.294985622\n",
      "Trained batch 651 batch loss 0.32772693 epoch total loss 0.295035928\n",
      "Trained batch 652 batch loss 0.327029943 epoch total loss 0.295084983\n",
      "Trained batch 653 batch loss 0.332124263 epoch total loss 0.295141727\n",
      "Trained batch 654 batch loss 0.299075723 epoch total loss 0.295147717\n",
      "Trained batch 655 batch loss 0.284572721 epoch total loss 0.295131594\n",
      "Trained batch 656 batch loss 0.282856882 epoch total loss 0.295112878\n",
      "Trained batch 657 batch loss 0.258183151 epoch total loss 0.295056641\n",
      "Trained batch 658 batch loss 0.31601283 epoch total loss 0.2950885\n",
      "Trained batch 659 batch loss 0.296395421 epoch total loss 0.295090497\n",
      "Trained batch 660 batch loss 0.288984418 epoch total loss 0.295081228\n",
      "Trained batch 661 batch loss 0.297424287 epoch total loss 0.295084774\n",
      "Trained batch 662 batch loss 0.303923935 epoch total loss 0.295098126\n",
      "Trained batch 663 batch loss 0.277261347 epoch total loss 0.295071244\n",
      "Trained batch 664 batch loss 0.291828901 epoch total loss 0.295066357\n",
      "Trained batch 665 batch loss 0.273112357 epoch total loss 0.295033336\n",
      "Trained batch 666 batch loss 0.262025207 epoch total loss 0.294983774\n",
      "Trained batch 667 batch loss 0.304696828 epoch total loss 0.294998348\n",
      "Trained batch 668 batch loss 0.295770824 epoch total loss 0.29499951\n",
      "Trained batch 669 batch loss 0.284563899 epoch total loss 0.294983923\n",
      "Trained batch 670 batch loss 0.299996167 epoch total loss 0.294991404\n",
      "Trained batch 671 batch loss 0.284270108 epoch total loss 0.29497543\n",
      "Trained batch 672 batch loss 0.237566739 epoch total loss 0.29489\n",
      "Trained batch 673 batch loss 0.271676928 epoch total loss 0.294855505\n",
      "Trained batch 674 batch loss 0.356609 epoch total loss 0.294947147\n",
      "Trained batch 675 batch loss 0.33132109 epoch total loss 0.29500103\n",
      "Trained batch 676 batch loss 0.347929835 epoch total loss 0.295079321\n",
      "Trained batch 677 batch loss 0.342930138 epoch total loss 0.295149982\n",
      "Trained batch 678 batch loss 0.315526664 epoch total loss 0.295180023\n",
      "Trained batch 679 batch loss 0.319024712 epoch total loss 0.29521516\n",
      "Trained batch 680 batch loss 0.294355303 epoch total loss 0.295213908\n",
      "Trained batch 681 batch loss 0.280970871 epoch total loss 0.295193\n",
      "Trained batch 682 batch loss 0.302002549 epoch total loss 0.295202971\n",
      "Trained batch 683 batch loss 0.295894772 epoch total loss 0.295203984\n",
      "Trained batch 684 batch loss 0.306492269 epoch total loss 0.295220494\n",
      "Trained batch 685 batch loss 0.313286841 epoch total loss 0.295246869\n",
      "Trained batch 686 batch loss 0.292025656 epoch total loss 0.29524219\n",
      "Trained batch 687 batch loss 0.272097 epoch total loss 0.295208484\n",
      "Trained batch 688 batch loss 0.272692204 epoch total loss 0.295175761\n",
      "Trained batch 689 batch loss 0.248738497 epoch total loss 0.295108348\n",
      "Trained batch 690 batch loss 0.290128052 epoch total loss 0.295101136\n",
      "Trained batch 691 batch loss 0.318034619 epoch total loss 0.295134336\n",
      "Trained batch 692 batch loss 0.311394542 epoch total loss 0.29515785\n",
      "Trained batch 693 batch loss 0.307652652 epoch total loss 0.29517585\n",
      "Trained batch 694 batch loss 0.313052237 epoch total loss 0.2952016\n",
      "Trained batch 695 batch loss 0.29079634 epoch total loss 0.295195282\n",
      "Trained batch 696 batch loss 0.297487885 epoch total loss 0.29519856\n",
      "Trained batch 697 batch loss 0.308470309 epoch total loss 0.295217603\n",
      "Trained batch 698 batch loss 0.294919223 epoch total loss 0.295217186\n",
      "Trained batch 699 batch loss 0.301460296 epoch total loss 0.295226127\n",
      "Trained batch 700 batch loss 0.285339952 epoch total loss 0.295212\n",
      "Trained batch 701 batch loss 0.283274323 epoch total loss 0.295194983\n",
      "Trained batch 702 batch loss 0.306652397 epoch total loss 0.295211315\n",
      "Trained batch 703 batch loss 0.302502394 epoch total loss 0.295221686\n",
      "Trained batch 704 batch loss 0.326671451 epoch total loss 0.29526636\n",
      "Trained batch 705 batch loss 0.298960894 epoch total loss 0.295271605\n",
      "Trained batch 706 batch loss 0.270767689 epoch total loss 0.295236915\n",
      "Trained batch 707 batch loss 0.280374587 epoch total loss 0.295215905\n",
      "Trained batch 708 batch loss 0.280048579 epoch total loss 0.295194477\n",
      "Trained batch 709 batch loss 0.30438605 epoch total loss 0.295207411\n",
      "Trained batch 710 batch loss 0.305861264 epoch total loss 0.295222431\n",
      "Trained batch 711 batch loss 0.317255944 epoch total loss 0.295253426\n",
      "Trained batch 712 batch loss 0.339288712 epoch total loss 0.295315295\n",
      "Trained batch 713 batch loss 0.319152683 epoch total loss 0.295348704\n",
      "Trained batch 714 batch loss 0.334879607 epoch total loss 0.295404077\n",
      "Trained batch 715 batch loss 0.276441514 epoch total loss 0.295377582\n",
      "Trained batch 716 batch loss 0.286680698 epoch total loss 0.295365423\n",
      "Trained batch 717 batch loss 0.298302948 epoch total loss 0.295369536\n",
      "Trained batch 718 batch loss 0.298099309 epoch total loss 0.295373321\n",
      "Trained batch 719 batch loss 0.319188952 epoch total loss 0.295406431\n",
      "Trained batch 720 batch loss 0.297915548 epoch total loss 0.295409918\n",
      "Trained batch 721 batch loss 0.25370571 epoch total loss 0.295352072\n",
      "Trained batch 722 batch loss 0.249057323 epoch total loss 0.295287967\n",
      "Trained batch 723 batch loss 0.270280719 epoch total loss 0.295253366\n",
      "Trained batch 724 batch loss 0.320607781 epoch total loss 0.295288384\n",
      "Trained batch 725 batch loss 0.347015768 epoch total loss 0.295359731\n",
      "Trained batch 726 batch loss 0.305384874 epoch total loss 0.295373529\n",
      "Trained batch 727 batch loss 0.33356297 epoch total loss 0.295426071\n",
      "Trained batch 728 batch loss 0.335535794 epoch total loss 0.295481175\n",
      "Trained batch 729 batch loss 0.31340915 epoch total loss 0.295505762\n",
      "Trained batch 730 batch loss 0.299271464 epoch total loss 0.295510918\n",
      "Trained batch 731 batch loss 0.299051821 epoch total loss 0.295515776\n",
      "Trained batch 732 batch loss 0.302685052 epoch total loss 0.295525581\n",
      "Trained batch 733 batch loss 0.316705883 epoch total loss 0.295554489\n",
      "Trained batch 734 batch loss 0.316914082 epoch total loss 0.295583576\n",
      "Trained batch 735 batch loss 0.316514403 epoch total loss 0.295612037\n",
      "Trained batch 736 batch loss 0.294509232 epoch total loss 0.295610547\n",
      "Trained batch 737 batch loss 0.317485 epoch total loss 0.29564023\n",
      "Trained batch 738 batch loss 0.335112214 epoch total loss 0.295693725\n",
      "Trained batch 739 batch loss 0.331765 epoch total loss 0.295742542\n",
      "Trained batch 740 batch loss 0.264454603 epoch total loss 0.295700252\n",
      "Trained batch 741 batch loss 0.254982114 epoch total loss 0.295645326\n",
      "Trained batch 742 batch loss 0.307886332 epoch total loss 0.295661837\n",
      "Trained batch 743 batch loss 0.278318346 epoch total loss 0.295638472\n",
      "Trained batch 744 batch loss 0.312271982 epoch total loss 0.295660853\n",
      "Trained batch 745 batch loss 0.311309785 epoch total loss 0.295681834\n",
      "Trained batch 746 batch loss 0.317294776 epoch total loss 0.295710802\n",
      "Trained batch 747 batch loss 0.308095098 epoch total loss 0.295727372\n",
      "Trained batch 748 batch loss 0.299713641 epoch total loss 0.295732707\n",
      "Trained batch 749 batch loss 0.279078841 epoch total loss 0.295710474\n",
      "Trained batch 750 batch loss 0.30577749 epoch total loss 0.295723885\n",
      "Trained batch 751 batch loss 0.273014903 epoch total loss 0.295693666\n",
      "Trained batch 752 batch loss 0.299263507 epoch total loss 0.295698404\n",
      "Trained batch 753 batch loss 0.29575935 epoch total loss 0.295698494\n",
      "Trained batch 754 batch loss 0.288508177 epoch total loss 0.295688957\n",
      "Trained batch 755 batch loss 0.308488309 epoch total loss 0.295705914\n",
      "Trained batch 756 batch loss 0.304930508 epoch total loss 0.295718104\n",
      "Trained batch 757 batch loss 0.295546949 epoch total loss 0.295717895\n",
      "Trained batch 758 batch loss 0.323519558 epoch total loss 0.295754552\n",
      "Trained batch 759 batch loss 0.312109381 epoch total loss 0.295776099\n",
      "Trained batch 760 batch loss 0.306447357 epoch total loss 0.295790136\n",
      "Trained batch 761 batch loss 0.317797 epoch total loss 0.295819044\n",
      "Trained batch 762 batch loss 0.325660795 epoch total loss 0.295858234\n",
      "Trained batch 763 batch loss 0.27389586 epoch total loss 0.295829445\n",
      "Trained batch 764 batch loss 0.289281249 epoch total loss 0.295820862\n",
      "Trained batch 765 batch loss 0.287005365 epoch total loss 0.295809329\n",
      "Trained batch 766 batch loss 0.277903676 epoch total loss 0.295785964\n",
      "Trained batch 767 batch loss 0.287507 epoch total loss 0.295775175\n",
      "Trained batch 768 batch loss 0.316095412 epoch total loss 0.29580164\n",
      "Trained batch 769 batch loss 0.282267123 epoch total loss 0.295784056\n",
      "Trained batch 770 batch loss 0.333749741 epoch total loss 0.295833349\n",
      "Trained batch 771 batch loss 0.32540676 epoch total loss 0.295871735\n",
      "Trained batch 772 batch loss 0.301263958 epoch total loss 0.295878708\n",
      "Trained batch 773 batch loss 0.298662961 epoch total loss 0.295882314\n",
      "Trained batch 774 batch loss 0.321939498 epoch total loss 0.295916\n",
      "Trained batch 775 batch loss 0.313629448 epoch total loss 0.295938849\n",
      "Trained batch 776 batch loss 0.300894886 epoch total loss 0.295945227\n",
      "Trained batch 777 batch loss 0.311513 epoch total loss 0.295965254\n",
      "Trained batch 778 batch loss 0.268829376 epoch total loss 0.295930356\n",
      "Trained batch 779 batch loss 0.27411902 epoch total loss 0.295902371\n",
      "Trained batch 780 batch loss 0.285503983 epoch total loss 0.29588905\n",
      "Trained batch 781 batch loss 0.319251686 epoch total loss 0.295918941\n",
      "Trained batch 782 batch loss 0.29110077 epoch total loss 0.295912802\n",
      "Trained batch 783 batch loss 0.290265501 epoch total loss 0.29590559\n",
      "Trained batch 784 batch loss 0.298142225 epoch total loss 0.295908451\n",
      "Trained batch 785 batch loss 0.317990243 epoch total loss 0.295936584\n",
      "Trained batch 786 batch loss 0.284619361 epoch total loss 0.29592219\n",
      "Trained batch 787 batch loss 0.303971797 epoch total loss 0.295932412\n",
      "Trained batch 788 batch loss 0.306837261 epoch total loss 0.29594624\n",
      "Trained batch 789 batch loss 0.307626903 epoch total loss 0.295961052\n",
      "Trained batch 790 batch loss 0.293805778 epoch total loss 0.29595834\n",
      "Trained batch 791 batch loss 0.26568073 epoch total loss 0.295920074\n",
      "Trained batch 792 batch loss 0.284423739 epoch total loss 0.29590556\n",
      "Trained batch 793 batch loss 0.309424251 epoch total loss 0.295922577\n",
      "Trained batch 794 batch loss 0.304508775 epoch total loss 0.295933396\n",
      "Trained batch 795 batch loss 0.280955166 epoch total loss 0.295914561\n",
      "Trained batch 796 batch loss 0.251416594 epoch total loss 0.295858651\n",
      "Trained batch 797 batch loss 0.239516869 epoch total loss 0.29578796\n",
      "Trained batch 798 batch loss 0.269443542 epoch total loss 0.295754939\n",
      "Trained batch 799 batch loss 0.265806198 epoch total loss 0.295717478\n",
      "Trained batch 800 batch loss 0.266862035 epoch total loss 0.295681387\n",
      "Trained batch 801 batch loss 0.254431278 epoch total loss 0.295629889\n",
      "Trained batch 802 batch loss 0.266545653 epoch total loss 0.295593619\n",
      "Trained batch 803 batch loss 0.352854609 epoch total loss 0.295664936\n",
      "Trained batch 804 batch loss 0.335435748 epoch total loss 0.295714408\n",
      "Trained batch 805 batch loss 0.33029297 epoch total loss 0.295757353\n",
      "Trained batch 806 batch loss 0.298974514 epoch total loss 0.295761347\n",
      "Trained batch 807 batch loss 0.282310486 epoch total loss 0.295744687\n",
      "Trained batch 808 batch loss 0.290006131 epoch total loss 0.295737565\n",
      "Trained batch 809 batch loss 0.292125314 epoch total loss 0.295733124\n",
      "Trained batch 810 batch loss 0.305186808 epoch total loss 0.295744807\n",
      "Trained batch 811 batch loss 0.314931095 epoch total loss 0.29576844\n",
      "Trained batch 812 batch loss 0.301495343 epoch total loss 0.295775503\n",
      "Trained batch 813 batch loss 0.335103393 epoch total loss 0.295823872\n",
      "Trained batch 814 batch loss 0.349404126 epoch total loss 0.295889705\n",
      "Trained batch 815 batch loss 0.326070487 epoch total loss 0.29592672\n",
      "Trained batch 816 batch loss 0.312109232 epoch total loss 0.295946538\n",
      "Trained batch 817 batch loss 0.278973401 epoch total loss 0.295925766\n",
      "Trained batch 818 batch loss 0.289923251 epoch total loss 0.295918435\n",
      "Trained batch 819 batch loss 0.304813236 epoch total loss 0.295929283\n",
      "Trained batch 820 batch loss 0.307888895 epoch total loss 0.295943886\n",
      "Trained batch 821 batch loss 0.276270509 epoch total loss 0.295919925\n",
      "Trained batch 822 batch loss 0.29339689 epoch total loss 0.295916855\n",
      "Trained batch 823 batch loss 0.286042333 epoch total loss 0.295904845\n",
      "Trained batch 824 batch loss 0.275075287 epoch total loss 0.295879573\n",
      "Trained batch 825 batch loss 0.274065018 epoch total loss 0.295853138\n",
      "Trained batch 826 batch loss 0.286616743 epoch total loss 0.295841932\n",
      "Trained batch 827 batch loss 0.281412184 epoch total loss 0.295824498\n",
      "Trained batch 828 batch loss 0.264111072 epoch total loss 0.295786202\n",
      "Trained batch 829 batch loss 0.29087317 epoch total loss 0.295780301\n",
      "Trained batch 830 batch loss 0.332472175 epoch total loss 0.295824498\n",
      "Trained batch 831 batch loss 0.35127756 epoch total loss 0.295891225\n",
      "Trained batch 832 batch loss 0.293330967 epoch total loss 0.295888156\n",
      "Trained batch 833 batch loss 0.323748857 epoch total loss 0.295921594\n",
      "Trained batch 834 batch loss 0.30648306 epoch total loss 0.29593426\n",
      "Trained batch 835 batch loss 0.308825731 epoch total loss 0.295949697\n",
      "Trained batch 836 batch loss 0.308669776 epoch total loss 0.295964926\n",
      "Trained batch 837 batch loss 0.288073212 epoch total loss 0.295955479\n",
      "Trained batch 838 batch loss 0.301719755 epoch total loss 0.295962363\n",
      "Trained batch 839 batch loss 0.266551256 epoch total loss 0.295927316\n",
      "Trained batch 840 batch loss 0.280767262 epoch total loss 0.295909256\n",
      "Trained batch 841 batch loss 0.305377513 epoch total loss 0.295920521\n",
      "Trained batch 842 batch loss 0.291709363 epoch total loss 0.295915514\n",
      "Trained batch 843 batch loss 0.293307394 epoch total loss 0.295912415\n",
      "Trained batch 844 batch loss 0.275067031 epoch total loss 0.295887709\n",
      "Trained batch 845 batch loss 0.284209371 epoch total loss 0.29587391\n",
      "Trained batch 846 batch loss 0.254817605 epoch total loss 0.295825362\n",
      "Trained batch 847 batch loss 0.271068037 epoch total loss 0.295796156\n",
      "Trained batch 848 batch loss 0.267753273 epoch total loss 0.295763075\n",
      "Trained batch 849 batch loss 0.259597629 epoch total loss 0.295720458\n",
      "Trained batch 850 batch loss 0.296339273 epoch total loss 0.295721203\n",
      "Trained batch 851 batch loss 0.270832479 epoch total loss 0.295691937\n",
      "Trained batch 852 batch loss 0.311482519 epoch total loss 0.295710474\n",
      "Trained batch 853 batch loss 0.307845175 epoch total loss 0.29572472\n",
      "Trained batch 854 batch loss 0.318719745 epoch total loss 0.295751631\n",
      "Trained batch 855 batch loss 0.284155 epoch total loss 0.295738071\n",
      "Trained batch 856 batch loss 0.309457481 epoch total loss 0.295754105\n",
      "Trained batch 857 batch loss 0.285138905 epoch total loss 0.295741707\n",
      "Trained batch 858 batch loss 0.274806529 epoch total loss 0.295717329\n",
      "Trained batch 859 batch loss 0.312140435 epoch total loss 0.295736432\n",
      "Trained batch 860 batch loss 0.328405172 epoch total loss 0.29577443\n",
      "Trained batch 861 batch loss 0.305128306 epoch total loss 0.295785278\n",
      "Trained batch 862 batch loss 0.277991652 epoch total loss 0.295764625\n",
      "Trained batch 863 batch loss 0.295880109 epoch total loss 0.295764774\n",
      "Trained batch 864 batch loss 0.32615456 epoch total loss 0.295799941\n",
      "Trained batch 865 batch loss 0.346985877 epoch total loss 0.295859128\n",
      "Trained batch 866 batch loss 0.298110247 epoch total loss 0.295861721\n",
      "Trained batch 867 batch loss 0.268479854 epoch total loss 0.29583016\n",
      "Trained batch 868 batch loss 0.306724489 epoch total loss 0.295842707\n",
      "Trained batch 869 batch loss 0.287188172 epoch total loss 0.295832753\n",
      "Trained batch 870 batch loss 0.298915654 epoch total loss 0.295836329\n",
      "Trained batch 871 batch loss 0.311322451 epoch total loss 0.295854092\n",
      "Trained batch 872 batch loss 0.32490328 epoch total loss 0.295887381\n",
      "Trained batch 873 batch loss 0.324010611 epoch total loss 0.295919597\n",
      "Trained batch 874 batch loss 0.298430562 epoch total loss 0.295922458\n",
      "Trained batch 875 batch loss 0.323317826 epoch total loss 0.295953751\n",
      "Trained batch 876 batch loss 0.306109905 epoch total loss 0.295965374\n",
      "Trained batch 877 batch loss 0.31533125 epoch total loss 0.295987457\n",
      "Trained batch 878 batch loss 0.32043767 epoch total loss 0.296015292\n",
      "Trained batch 879 batch loss 0.311962962 epoch total loss 0.296033412\n",
      "Trained batch 880 batch loss 0.298105419 epoch total loss 0.296035767\n",
      "Trained batch 881 batch loss 0.307414412 epoch total loss 0.296048671\n",
      "Trained batch 882 batch loss 0.319319874 epoch total loss 0.296075046\n",
      "Trained batch 883 batch loss 0.3073228 epoch total loss 0.296087772\n",
      "Trained batch 884 batch loss 0.304943115 epoch total loss 0.296097755\n",
      "Trained batch 885 batch loss 0.305428386 epoch total loss 0.296108305\n",
      "Trained batch 886 batch loss 0.295122296 epoch total loss 0.296107203\n",
      "Trained batch 887 batch loss 0.309582263 epoch total loss 0.296122372\n",
      "Trained batch 888 batch loss 0.292132735 epoch total loss 0.296117902\n",
      "Trained batch 889 batch loss 0.289328068 epoch total loss 0.296110272\n",
      "Trained batch 890 batch loss 0.363571376 epoch total loss 0.29618609\n",
      "Trained batch 891 batch loss 0.307407856 epoch total loss 0.296198696\n",
      "Trained batch 892 batch loss 0.278316438 epoch total loss 0.296178639\n",
      "Trained batch 893 batch loss 0.311730474 epoch total loss 0.296196073\n",
      "Trained batch 894 batch loss 0.331006765 epoch total loss 0.296235\n",
      "Trained batch 895 batch loss 0.286036 epoch total loss 0.296223581\n",
      "Trained batch 896 batch loss 0.306984782 epoch total loss 0.296235591\n",
      "Trained batch 897 batch loss 0.30021283 epoch total loss 0.29624\n",
      "Trained batch 898 batch loss 0.297575682 epoch total loss 0.296241492\n",
      "Trained batch 899 batch loss 0.326774418 epoch total loss 0.296275467\n",
      "Trained batch 900 batch loss 0.306192756 epoch total loss 0.296286494\n",
      "Trained batch 901 batch loss 0.281449795 epoch total loss 0.296270043\n",
      "Trained batch 902 batch loss 0.322246432 epoch total loss 0.296298832\n",
      "Trained batch 903 batch loss 0.296588778 epoch total loss 0.29629916\n",
      "Trained batch 904 batch loss 0.311085373 epoch total loss 0.296315521\n",
      "Trained batch 905 batch loss 0.314418823 epoch total loss 0.296335518\n",
      "Trained batch 906 batch loss 0.252541721 epoch total loss 0.296287179\n",
      "Trained batch 907 batch loss 0.273832679 epoch total loss 0.296262413\n",
      "Trained batch 908 batch loss 0.287830532 epoch total loss 0.296253145\n",
      "Trained batch 909 batch loss 0.297091603 epoch total loss 0.296254069\n",
      "Trained batch 910 batch loss 0.285313427 epoch total loss 0.296242058\n",
      "Trained batch 911 batch loss 0.328089 epoch total loss 0.296277016\n",
      "Trained batch 912 batch loss 0.323305905 epoch total loss 0.29630664\n",
      "Trained batch 913 batch loss 0.310113817 epoch total loss 0.296321779\n",
      "Trained batch 914 batch loss 0.308616698 epoch total loss 0.29633522\n",
      "Trained batch 915 batch loss 0.271704704 epoch total loss 0.296308309\n",
      "Trained batch 916 batch loss 0.277998537 epoch total loss 0.296288311\n",
      "Trained batch 917 batch loss 0.292872667 epoch total loss 0.296284586\n",
      "Trained batch 918 batch loss 0.280097246 epoch total loss 0.296266943\n",
      "Trained batch 919 batch loss 0.269881338 epoch total loss 0.296238214\n",
      "Trained batch 920 batch loss 0.236958116 epoch total loss 0.296173781\n",
      "Trained batch 921 batch loss 0.263101 epoch total loss 0.296137869\n",
      "Trained batch 922 batch loss 0.266997397 epoch total loss 0.296106279\n",
      "Trained batch 923 batch loss 0.260213912 epoch total loss 0.296067387\n",
      "Trained batch 924 batch loss 0.256535053 epoch total loss 0.296024591\n",
      "Trained batch 925 batch loss 0.271887481 epoch total loss 0.295998514\n",
      "Trained batch 926 batch loss 0.318685025 epoch total loss 0.296023\n",
      "Trained batch 927 batch loss 0.287636489 epoch total loss 0.296013951\n",
      "Trained batch 928 batch loss 0.288579077 epoch total loss 0.296005934\n",
      "Trained batch 929 batch loss 0.29203856 epoch total loss 0.296001673\n",
      "Trained batch 930 batch loss 0.312854111 epoch total loss 0.296019822\n",
      "Trained batch 931 batch loss 0.308802634 epoch total loss 0.296033561\n",
      "Trained batch 932 batch loss 0.292522281 epoch total loss 0.296029776\n",
      "Trained batch 933 batch loss 0.291359931 epoch total loss 0.29602477\n",
      "Trained batch 934 batch loss 0.296631455 epoch total loss 0.296025395\n",
      "Trained batch 935 batch loss 0.31888482 epoch total loss 0.296049863\n",
      "Trained batch 936 batch loss 0.31519708 epoch total loss 0.296070307\n",
      "Trained batch 937 batch loss 0.309087664 epoch total loss 0.296084195\n",
      "Trained batch 938 batch loss 0.307561874 epoch total loss 0.296096414\n",
      "Trained batch 939 batch loss 0.315708935 epoch total loss 0.296117306\n",
      "Trained batch 940 batch loss 0.299858391 epoch total loss 0.296121269\n",
      "Trained batch 941 batch loss 0.310637146 epoch total loss 0.296136707\n",
      "Trained batch 942 batch loss 0.306232333 epoch total loss 0.296147436\n",
      "Trained batch 943 batch loss 0.288080364 epoch total loss 0.296138883\n",
      "Trained batch 944 batch loss 0.328984678 epoch total loss 0.296173692\n",
      "Trained batch 945 batch loss 0.311205983 epoch total loss 0.296189606\n",
      "Trained batch 946 batch loss 0.321456701 epoch total loss 0.296216279\n",
      "Trained batch 947 batch loss 0.288877279 epoch total loss 0.296208531\n",
      "Trained batch 948 batch loss 0.293436348 epoch total loss 0.29620561\n",
      "Trained batch 949 batch loss 0.245361984 epoch total loss 0.296152025\n",
      "Trained batch 950 batch loss 0.281709135 epoch total loss 0.296136826\n",
      "Trained batch 951 batch loss 0.285461932 epoch total loss 0.296125591\n",
      "Trained batch 952 batch loss 0.292393178 epoch total loss 0.296121687\n",
      "Trained batch 953 batch loss 0.290425837 epoch total loss 0.296115696\n",
      "Trained batch 954 batch loss 0.31998986 epoch total loss 0.29614073\n",
      "Trained batch 955 batch loss 0.297341138 epoch total loss 0.296141982\n",
      "Trained batch 956 batch loss 0.3137182 epoch total loss 0.29616037\n",
      "Trained batch 957 batch loss 0.315521598 epoch total loss 0.296180576\n",
      "Trained batch 958 batch loss 0.303487182 epoch total loss 0.296188235\n",
      "Trained batch 959 batch loss 0.280345798 epoch total loss 0.296171695\n",
      "Trained batch 960 batch loss 0.271876037 epoch total loss 0.296146393\n",
      "Trained batch 961 batch loss 0.266504705 epoch total loss 0.296115547\n",
      "Trained batch 962 batch loss 0.307195 epoch total loss 0.296127051\n",
      "Trained batch 963 batch loss 0.329445779 epoch total loss 0.296161652\n",
      "Trained batch 964 batch loss 0.318439573 epoch total loss 0.296184778\n",
      "Trained batch 965 batch loss 0.29046607 epoch total loss 0.296178848\n",
      "Trained batch 966 batch loss 0.289558232 epoch total loss 0.296172\n",
      "Trained batch 967 batch loss 0.288752109 epoch total loss 0.296164334\n",
      "Trained batch 968 batch loss 0.287466139 epoch total loss 0.296155334\n",
      "Trained batch 969 batch loss 0.294657379 epoch total loss 0.296153784\n",
      "Trained batch 970 batch loss 0.322728604 epoch total loss 0.296181172\n",
      "Trained batch 971 batch loss 0.328246057 epoch total loss 0.296214193\n",
      "Trained batch 972 batch loss 0.278011292 epoch total loss 0.296195477\n",
      "Trained batch 973 batch loss 0.284115762 epoch total loss 0.296183079\n",
      "Trained batch 974 batch loss 0.267577529 epoch total loss 0.296153694\n",
      "Trained batch 975 batch loss 0.269174933 epoch total loss 0.296126\n",
      "Trained batch 976 batch loss 0.314362139 epoch total loss 0.296144694\n",
      "Trained batch 977 batch loss 0.309577733 epoch total loss 0.296158433\n",
      "Trained batch 978 batch loss 0.278910667 epoch total loss 0.29614079\n",
      "Trained batch 979 batch loss 0.270990759 epoch total loss 0.29611513\n",
      "Trained batch 980 batch loss 0.289871961 epoch total loss 0.296108752\n",
      "Trained batch 981 batch loss 0.294710487 epoch total loss 0.296107322\n",
      "Trained batch 982 batch loss 0.299681604 epoch total loss 0.296111\n",
      "Trained batch 983 batch loss 0.282439917 epoch total loss 0.29609707\n",
      "Trained batch 984 batch loss 0.292780101 epoch total loss 0.296093702\n",
      "Trained batch 985 batch loss 0.308350354 epoch total loss 0.29610613\n",
      "Trained batch 986 batch loss 0.327457786 epoch total loss 0.296137929\n",
      "Trained batch 987 batch loss 0.320904106 epoch total loss 0.296163023\n",
      "Trained batch 988 batch loss 0.314389974 epoch total loss 0.29618147\n",
      "Trained batch 989 batch loss 0.320685387 epoch total loss 0.296206236\n",
      "Trained batch 990 batch loss 0.328099281 epoch total loss 0.296238452\n",
      "Trained batch 991 batch loss 0.311602831 epoch total loss 0.296253949\n",
      "Trained batch 992 batch loss 0.270181984 epoch total loss 0.296227664\n",
      "Trained batch 993 batch loss 0.291026264 epoch total loss 0.296222419\n",
      "Trained batch 994 batch loss 0.286349386 epoch total loss 0.296212494\n",
      "Trained batch 995 batch loss 0.25224787 epoch total loss 0.296168298\n",
      "Trained batch 996 batch loss 0.273409903 epoch total loss 0.296145469\n",
      "Trained batch 997 batch loss 0.272988915 epoch total loss 0.296122223\n",
      "Trained batch 998 batch loss 0.285179883 epoch total loss 0.296111256\n",
      "Trained batch 999 batch loss 0.288294882 epoch total loss 0.296103448\n",
      "Trained batch 1000 batch loss 0.259914696 epoch total loss 0.296067268\n",
      "Trained batch 1001 batch loss 0.258313656 epoch total loss 0.296029538\n",
      "Trained batch 1002 batch loss 0.27145195 epoch total loss 0.296005\n",
      "Trained batch 1003 batch loss 0.282862186 epoch total loss 0.295991898\n",
      "Trained batch 1004 batch loss 0.298393071 epoch total loss 0.295994312\n",
      "Trained batch 1005 batch loss 0.308922648 epoch total loss 0.296007186\n",
      "Trained batch 1006 batch loss 0.296458781 epoch total loss 0.296007603\n",
      "Trained batch 1007 batch loss 0.345532 epoch total loss 0.296056777\n",
      "Trained batch 1008 batch loss 0.303812 epoch total loss 0.296064466\n",
      "Trained batch 1009 batch loss 0.27795881 epoch total loss 0.296046525\n",
      "Trained batch 1010 batch loss 0.274404049 epoch total loss 0.296025097\n",
      "Trained batch 1011 batch loss 0.29890275 epoch total loss 0.296027929\n",
      "Trained batch 1012 batch loss 0.267446607 epoch total loss 0.295999706\n",
      "Trained batch 1013 batch loss 0.26536864 epoch total loss 0.295969486\n",
      "Trained batch 1014 batch loss 0.20563361 epoch total loss 0.295880377\n",
      "Trained batch 1015 batch loss 0.261010885 epoch total loss 0.295846045\n",
      "Trained batch 1016 batch loss 0.293684155 epoch total loss 0.295843899\n",
      "Trained batch 1017 batch loss 0.335345417 epoch total loss 0.295882732\n",
      "Trained batch 1018 batch loss 0.331484497 epoch total loss 0.29591772\n",
      "Trained batch 1019 batch loss 0.316954613 epoch total loss 0.295938373\n",
      "Trained batch 1020 batch loss 0.304986596 epoch total loss 0.295947224\n",
      "Trained batch 1021 batch loss 0.30362612 epoch total loss 0.295954764\n",
      "Trained batch 1022 batch loss 0.303877175 epoch total loss 0.295962483\n",
      "Trained batch 1023 batch loss 0.290682346 epoch total loss 0.295957327\n",
      "Trained batch 1024 batch loss 0.30719772 epoch total loss 0.295968294\n",
      "Trained batch 1025 batch loss 0.339989066 epoch total loss 0.296011239\n",
      "Trained batch 1026 batch loss 0.304731578 epoch total loss 0.296019733\n",
      "Trained batch 1027 batch loss 0.311440825 epoch total loss 0.296034753\n",
      "Trained batch 1028 batch loss 0.292157024 epoch total loss 0.296030968\n",
      "Trained batch 1029 batch loss 0.28319037 epoch total loss 0.296018481\n",
      "Trained batch 1030 batch loss 0.28613928 epoch total loss 0.296008885\n",
      "Trained batch 1031 batch loss 0.313634545 epoch total loss 0.296026\n",
      "Trained batch 1032 batch loss 0.358796477 epoch total loss 0.296086818\n",
      "Trained batch 1033 batch loss 0.367664784 epoch total loss 0.296156108\n",
      "Trained batch 1034 batch loss 0.317078829 epoch total loss 0.296176344\n",
      "Trained batch 1035 batch loss 0.265632331 epoch total loss 0.29614681\n",
      "Trained batch 1036 batch loss 0.3128528 epoch total loss 0.296162963\n",
      "Trained batch 1037 batch loss 0.304088652 epoch total loss 0.296170592\n",
      "Trained batch 1038 batch loss 0.334130883 epoch total loss 0.29620716\n",
      "Trained batch 1039 batch loss 0.316366911 epoch total loss 0.296226591\n",
      "Trained batch 1040 batch loss 0.279848129 epoch total loss 0.296210825\n",
      "Trained batch 1041 batch loss 0.274538308 epoch total loss 0.296190023\n",
      "Trained batch 1042 batch loss 0.303392291 epoch total loss 0.296196938\n",
      "Trained batch 1043 batch loss 0.279068321 epoch total loss 0.296180516\n",
      "Trained batch 1044 batch loss 0.29393065 epoch total loss 0.296178401\n",
      "Trained batch 1045 batch loss 0.331900597 epoch total loss 0.296212584\n",
      "Trained batch 1046 batch loss 0.283994019 epoch total loss 0.296200901\n",
      "Trained batch 1047 batch loss 0.297831357 epoch total loss 0.296202451\n",
      "Trained batch 1048 batch loss 0.353268087 epoch total loss 0.2962569\n",
      "Trained batch 1049 batch loss 0.288182646 epoch total loss 0.296249211\n",
      "Trained batch 1050 batch loss 0.296917349 epoch total loss 0.296249837\n",
      "Trained batch 1051 batch loss 0.301243454 epoch total loss 0.296254575\n",
      "Trained batch 1052 batch loss 0.312402815 epoch total loss 0.296269923\n",
      "Trained batch 1053 batch loss 0.292273521 epoch total loss 0.296266139\n",
      "Trained batch 1054 batch loss 0.277492732 epoch total loss 0.296248317\n",
      "Trained batch 1055 batch loss 0.298224539 epoch total loss 0.296250194\n",
      "Trained batch 1056 batch loss 0.320569605 epoch total loss 0.296273202\n",
      "Trained batch 1057 batch loss 0.327887475 epoch total loss 0.296303093\n",
      "Trained batch 1058 batch loss 0.313157678 epoch total loss 0.296319038\n",
      "Trained batch 1059 batch loss 0.295868248 epoch total loss 0.29631862\n",
      "Trained batch 1060 batch loss 0.326549768 epoch total loss 0.296347141\n",
      "Trained batch 1061 batch loss 0.305299073 epoch total loss 0.296355575\n",
      "Trained batch 1062 batch loss 0.315027505 epoch total loss 0.296373159\n",
      "Trained batch 1063 batch loss 0.306750953 epoch total loss 0.296382934\n",
      "Trained batch 1064 batch loss 0.264744252 epoch total loss 0.296353191\n",
      "Trained batch 1065 batch loss 0.306296855 epoch total loss 0.296362519\n",
      "Trained batch 1066 batch loss 0.276699364 epoch total loss 0.296344101\n",
      "Trained batch 1067 batch loss 0.285063267 epoch total loss 0.296333522\n",
      "Trained batch 1068 batch loss 0.247100204 epoch total loss 0.296287417\n",
      "Trained batch 1069 batch loss 0.285168856 epoch total loss 0.296277016\n",
      "Trained batch 1070 batch loss 0.268085867 epoch total loss 0.296250671\n",
      "Trained batch 1071 batch loss 0.286218554 epoch total loss 0.296241313\n",
      "Trained batch 1072 batch loss 0.277400255 epoch total loss 0.29622373\n",
      "Trained batch 1073 batch loss 0.27914837 epoch total loss 0.296207815\n",
      "Trained batch 1074 batch loss 0.268084735 epoch total loss 0.296181649\n",
      "Trained batch 1075 batch loss 0.269835 epoch total loss 0.296157151\n",
      "Trained batch 1076 batch loss 0.271086276 epoch total loss 0.296133846\n",
      "Trained batch 1077 batch loss 0.302165627 epoch total loss 0.296139419\n",
      "Trained batch 1078 batch loss 0.308309138 epoch total loss 0.296150744\n",
      "Trained batch 1079 batch loss 0.285940111 epoch total loss 0.296141267\n",
      "Trained batch 1080 batch loss 0.306980044 epoch total loss 0.29615131\n",
      "Trained batch 1081 batch loss 0.304721892 epoch total loss 0.296159238\n",
      "Trained batch 1082 batch loss 0.317771673 epoch total loss 0.296179205\n",
      "Trained batch 1083 batch loss 0.329351 epoch total loss 0.296209842\n",
      "Trained batch 1084 batch loss 0.281299055 epoch total loss 0.296196103\n",
      "Trained batch 1085 batch loss 0.284747899 epoch total loss 0.296185553\n",
      "Trained batch 1086 batch loss 0.266439438 epoch total loss 0.296158165\n",
      "Trained batch 1087 batch loss 0.27553606 epoch total loss 0.29613921\n",
      "Trained batch 1088 batch loss 0.293470263 epoch total loss 0.296136737\n",
      "Trained batch 1089 batch loss 0.299195379 epoch total loss 0.296139538\n",
      "Trained batch 1090 batch loss 0.307039589 epoch total loss 0.296149552\n",
      "Trained batch 1091 batch loss 0.277088225 epoch total loss 0.296132088\n",
      "Trained batch 1092 batch loss 0.2826702 epoch total loss 0.296119779\n",
      "Trained batch 1093 batch loss 0.335206687 epoch total loss 0.296155542\n",
      "Trained batch 1094 batch loss 0.30714494 epoch total loss 0.296165586\n",
      "Trained batch 1095 batch loss 0.320928365 epoch total loss 0.296188205\n",
      "Trained batch 1096 batch loss 0.281004131 epoch total loss 0.296174347\n",
      "Trained batch 1097 batch loss 0.28328383 epoch total loss 0.296162605\n",
      "Trained batch 1098 batch loss 0.278121114 epoch total loss 0.296146154\n",
      "Trained batch 1099 batch loss 0.275954902 epoch total loss 0.296127766\n",
      "Trained batch 1100 batch loss 0.309580505 epoch total loss 0.29614\n",
      "Trained batch 1101 batch loss 0.321911216 epoch total loss 0.29616338\n",
      "Trained batch 1102 batch loss 0.322915 epoch total loss 0.296187669\n",
      "Trained batch 1103 batch loss 0.310740352 epoch total loss 0.296200842\n",
      "Trained batch 1104 batch loss 0.271106 epoch total loss 0.296178132\n",
      "Trained batch 1105 batch loss 0.291320145 epoch total loss 0.296173722\n",
      "Trained batch 1106 batch loss 0.273056209 epoch total loss 0.29615283\n",
      "Trained batch 1107 batch loss 0.241436899 epoch total loss 0.296103418\n",
      "Trained batch 1108 batch loss 0.284728616 epoch total loss 0.296093136\n",
      "Trained batch 1109 batch loss 0.311635256 epoch total loss 0.296107173\n",
      "Trained batch 1110 batch loss 0.313621908 epoch total loss 0.296122938\n",
      "Trained batch 1111 batch loss 0.301086336 epoch total loss 0.296127409\n",
      "Trained batch 1112 batch loss 0.307934791 epoch total loss 0.296138018\n",
      "Trained batch 1113 batch loss 0.303340197 epoch total loss 0.296144485\n",
      "Trained batch 1114 batch loss 0.286906481 epoch total loss 0.2961362\n",
      "Trained batch 1115 batch loss 0.250468314 epoch total loss 0.296095222\n",
      "Trained batch 1116 batch loss 0.282939792 epoch total loss 0.296083421\n",
      "Trained batch 1117 batch loss 0.304903448 epoch total loss 0.296091318\n",
      "Trained batch 1118 batch loss 0.28055042 epoch total loss 0.29607743\n",
      "Trained batch 1119 batch loss 0.32177949 epoch total loss 0.296100378\n",
      "Trained batch 1120 batch loss 0.306360453 epoch total loss 0.296109557\n",
      "Trained batch 1121 batch loss 0.302818328 epoch total loss 0.296115547\n",
      "Trained batch 1122 batch loss 0.346179545 epoch total loss 0.296160161\n",
      "Trained batch 1123 batch loss 0.315751433 epoch total loss 0.296177626\n",
      "Trained batch 1124 batch loss 0.335163265 epoch total loss 0.296212316\n",
      "Trained batch 1125 batch loss 0.324842334 epoch total loss 0.296237767\n",
      "Trained batch 1126 batch loss 0.334430605 epoch total loss 0.296271682\n",
      "Trained batch 1127 batch loss 0.305592746 epoch total loss 0.296279967\n",
      "Trained batch 1128 batch loss 0.316304862 epoch total loss 0.296297729\n",
      "Trained batch 1129 batch loss 0.317442834 epoch total loss 0.296316475\n",
      "Trained batch 1130 batch loss 0.278898239 epoch total loss 0.296301067\n",
      "Trained batch 1131 batch loss 0.286422372 epoch total loss 0.296292305\n",
      "Trained batch 1132 batch loss 0.240946501 epoch total loss 0.296243399\n",
      "Trained batch 1133 batch loss 0.269818187 epoch total loss 0.296220064\n",
      "Trained batch 1134 batch loss 0.325368345 epoch total loss 0.296245784\n",
      "Trained batch 1135 batch loss 0.331048042 epoch total loss 0.29627645\n",
      "Trained batch 1136 batch loss 0.289348841 epoch total loss 0.296270341\n",
      "Trained batch 1137 batch loss 0.275013 epoch total loss 0.296251655\n",
      "Trained batch 1138 batch loss 0.278945267 epoch total loss 0.296236426\n",
      "Trained batch 1139 batch loss 0.272583783 epoch total loss 0.296215683\n",
      "Trained batch 1140 batch loss 0.27145189 epoch total loss 0.296193957\n",
      "Trained batch 1141 batch loss 0.288500339 epoch total loss 0.296187222\n",
      "Trained batch 1142 batch loss 0.298773348 epoch total loss 0.296189487\n",
      "Trained batch 1143 batch loss 0.287664771 epoch total loss 0.296182\n",
      "Trained batch 1144 batch loss 0.295666128 epoch total loss 0.29618156\n",
      "Trained batch 1145 batch loss 0.284552634 epoch total loss 0.296171397\n",
      "Trained batch 1146 batch loss 0.281534076 epoch total loss 0.296158612\n",
      "Trained batch 1147 batch loss 0.275841296 epoch total loss 0.296140909\n",
      "Trained batch 1148 batch loss 0.257672608 epoch total loss 0.296107382\n",
      "Trained batch 1149 batch loss 0.296213984 epoch total loss 0.296107471\n",
      "Trained batch 1150 batch loss 0.303491175 epoch total loss 0.296113878\n",
      "Trained batch 1151 batch loss 0.307711661 epoch total loss 0.296123952\n",
      "Trained batch 1152 batch loss 0.257468373 epoch total loss 0.296090424\n",
      "Trained batch 1153 batch loss 0.275783062 epoch total loss 0.296072811\n",
      "Trained batch 1154 batch loss 0.265207648 epoch total loss 0.296046048\n",
      "Trained batch 1155 batch loss 0.274546623 epoch total loss 0.296027422\n",
      "Trained batch 1156 batch loss 0.275448918 epoch total loss 0.29600963\n",
      "Trained batch 1157 batch loss 0.259182096 epoch total loss 0.295977801\n",
      "Trained batch 1158 batch loss 0.272017956 epoch total loss 0.295957088\n",
      "Trained batch 1159 batch loss 0.273956776 epoch total loss 0.295938104\n",
      "Trained batch 1160 batch loss 0.270963132 epoch total loss 0.295916587\n",
      "Trained batch 1161 batch loss 0.260885477 epoch total loss 0.295886427\n",
      "Trained batch 1162 batch loss 0.306756943 epoch total loss 0.295895785\n",
      "Trained batch 1163 batch loss 0.28090772 epoch total loss 0.29588291\n",
      "Trained batch 1164 batch loss 0.299455762 epoch total loss 0.29588598\n",
      "Trained batch 1165 batch loss 0.300622582 epoch total loss 0.295890063\n",
      "Trained batch 1166 batch loss 0.328879565 epoch total loss 0.295918345\n",
      "Trained batch 1167 batch loss 0.279752254 epoch total loss 0.295904517\n",
      "Trained batch 1168 batch loss 0.317738 epoch total loss 0.295923203\n",
      "Trained batch 1169 batch loss 0.287031174 epoch total loss 0.295915604\n",
      "Trained batch 1170 batch loss 0.278408885 epoch total loss 0.295900643\n",
      "Trained batch 1171 batch loss 0.276855588 epoch total loss 0.295884371\n",
      "Trained batch 1172 batch loss 0.296719134 epoch total loss 0.295885086\n",
      "Trained batch 1173 batch loss 0.288689315 epoch total loss 0.295878947\n",
      "Trained batch 1174 batch loss 0.302284867 epoch total loss 0.295884401\n",
      "Trained batch 1175 batch loss 0.31180349 epoch total loss 0.295897931\n",
      "Trained batch 1176 batch loss 0.275827169 epoch total loss 0.295880884\n",
      "Trained batch 1177 batch loss 0.277162939 epoch total loss 0.295864969\n",
      "Trained batch 1178 batch loss 0.284716368 epoch total loss 0.295855522\n",
      "Trained batch 1179 batch loss 0.260962665 epoch total loss 0.295825899\n",
      "Trained batch 1180 batch loss 0.244200513 epoch total loss 0.295782149\n",
      "Trained batch 1181 batch loss 0.248114213 epoch total loss 0.295741796\n",
      "Trained batch 1182 batch loss 0.248835132 epoch total loss 0.2957021\n",
      "Trained batch 1183 batch loss 0.27235505 epoch total loss 0.2956824\n",
      "Trained batch 1184 batch loss 0.254717827 epoch total loss 0.2956478\n",
      "Trained batch 1185 batch loss 0.287793487 epoch total loss 0.295641154\n",
      "Trained batch 1186 batch loss 0.246569991 epoch total loss 0.295599788\n",
      "Trained batch 1187 batch loss 0.263627648 epoch total loss 0.295572877\n",
      "Trained batch 1188 batch loss 0.296588242 epoch total loss 0.295573741\n",
      "Trained batch 1189 batch loss 0.330608308 epoch total loss 0.295603186\n",
      "Trained batch 1190 batch loss 0.297399253 epoch total loss 0.295604706\n",
      "Trained batch 1191 batch loss 0.310750395 epoch total loss 0.295617431\n",
      "Trained batch 1192 batch loss 0.309750766 epoch total loss 0.295629293\n",
      "Trained batch 1193 batch loss 0.294167876 epoch total loss 0.295628041\n",
      "Trained batch 1194 batch loss 0.309484631 epoch total loss 0.295639664\n",
      "Trained batch 1195 batch loss 0.309232622 epoch total loss 0.295651019\n",
      "Trained batch 1196 batch loss 0.262565374 epoch total loss 0.295623362\n",
      "Trained batch 1197 batch loss 0.246856466 epoch total loss 0.295582622\n",
      "Trained batch 1198 batch loss 0.23305884 epoch total loss 0.295530438\n",
      "Trained batch 1199 batch loss 0.269916803 epoch total loss 0.2955091\n",
      "Trained batch 1200 batch loss 0.281317592 epoch total loss 0.295497268\n",
      "Trained batch 1201 batch loss 0.304282933 epoch total loss 0.29550457\n",
      "Trained batch 1202 batch loss 0.347231686 epoch total loss 0.295547605\n",
      "Trained batch 1203 batch loss 0.344004691 epoch total loss 0.295587897\n",
      "Trained batch 1204 batch loss 0.317366123 epoch total loss 0.295605958\n",
      "Trained batch 1205 batch loss 0.318492 epoch total loss 0.295624942\n",
      "Trained batch 1206 batch loss 0.283962965 epoch total loss 0.295615286\n",
      "Trained batch 1207 batch loss 0.268376082 epoch total loss 0.295592695\n",
      "Trained batch 1208 batch loss 0.300587773 epoch total loss 0.295596838\n",
      "Trained batch 1209 batch loss 0.290531904 epoch total loss 0.295592666\n",
      "Trained batch 1210 batch loss 0.304270118 epoch total loss 0.295599818\n",
      "Trained batch 1211 batch loss 0.291377783 epoch total loss 0.295596331\n",
      "Trained batch 1212 batch loss 0.30696705 epoch total loss 0.295605719\n",
      "Trained batch 1213 batch loss 0.303408623 epoch total loss 0.295612156\n",
      "Trained batch 1214 batch loss 0.2781277 epoch total loss 0.295597762\n",
      "Trained batch 1215 batch loss 0.242985949 epoch total loss 0.295554459\n",
      "Trained batch 1216 batch loss 0.239499494 epoch total loss 0.295508355\n",
      "Trained batch 1217 batch loss 0.269744784 epoch total loss 0.295487195\n",
      "Trained batch 1218 batch loss 0.293364108 epoch total loss 0.295485437\n",
      "Trained batch 1219 batch loss 0.336731911 epoch total loss 0.295519292\n",
      "Trained batch 1220 batch loss 0.358876586 epoch total loss 0.295571238\n",
      "Trained batch 1221 batch loss 0.32478869 epoch total loss 0.295595169\n",
      "Trained batch 1222 batch loss 0.283900172 epoch total loss 0.295585603\n",
      "Trained batch 1223 batch loss 0.293121248 epoch total loss 0.295583576\n",
      "Trained batch 1224 batch loss 0.295972884 epoch total loss 0.295583874\n",
      "Trained batch 1225 batch loss 0.307145119 epoch total loss 0.295593351\n",
      "Trained batch 1226 batch loss 0.306911856 epoch total loss 0.29560256\n",
      "Trained batch 1227 batch loss 0.31584397 epoch total loss 0.295619071\n",
      "Trained batch 1228 batch loss 0.303501487 epoch total loss 0.295625508\n",
      "Trained batch 1229 batch loss 0.28567642 epoch total loss 0.295617402\n",
      "Trained batch 1230 batch loss 0.31149897 epoch total loss 0.295630306\n",
      "Trained batch 1231 batch loss 0.269133955 epoch total loss 0.295608789\n",
      "Trained batch 1232 batch loss 0.288144469 epoch total loss 0.295602739\n",
      "Trained batch 1233 batch loss 0.278623521 epoch total loss 0.29558894\n",
      "Trained batch 1234 batch loss 0.296969473 epoch total loss 0.295590073\n",
      "Trained batch 1235 batch loss 0.25796172 epoch total loss 0.295559615\n",
      "Trained batch 1236 batch loss 0.259238839 epoch total loss 0.29553023\n",
      "Trained batch 1237 batch loss 0.256771982 epoch total loss 0.295498908\n",
      "Trained batch 1238 batch loss 0.266062468 epoch total loss 0.295475125\n",
      "Trained batch 1239 batch loss 0.271390736 epoch total loss 0.295455664\n",
      "Trained batch 1240 batch loss 0.268880546 epoch total loss 0.295434237\n",
      "Trained batch 1241 batch loss 0.286850154 epoch total loss 0.295427352\n",
      "Trained batch 1242 batch loss 0.2918185 epoch total loss 0.295424432\n",
      "Trained batch 1243 batch loss 0.315134645 epoch total loss 0.295440286\n",
      "Trained batch 1244 batch loss 0.303586781 epoch total loss 0.295446843\n",
      "Trained batch 1245 batch loss 0.337473512 epoch total loss 0.295480579\n",
      "Trained batch 1246 batch loss 0.288456559 epoch total loss 0.295474946\n",
      "Trained batch 1247 batch loss 0.277547926 epoch total loss 0.295460582\n",
      "Trained batch 1248 batch loss 0.25861311 epoch total loss 0.295431048\n",
      "Trained batch 1249 batch loss 0.280055 epoch total loss 0.295418739\n",
      "Trained batch 1250 batch loss 0.272856563 epoch total loss 0.295400679\n",
      "Trained batch 1251 batch loss 0.268616557 epoch total loss 0.295379281\n",
      "Trained batch 1252 batch loss 0.322888941 epoch total loss 0.295401245\n",
      "Trained batch 1253 batch loss 0.320532292 epoch total loss 0.295421273\n",
      "Trained batch 1254 batch loss 0.298470825 epoch total loss 0.295423716\n",
      "Trained batch 1255 batch loss 0.279658318 epoch total loss 0.29541114\n",
      "Trained batch 1256 batch loss 0.289747804 epoch total loss 0.29540664\n",
      "Trained batch 1257 batch loss 0.265805721 epoch total loss 0.295383096\n",
      "Trained batch 1258 batch loss 0.272877395 epoch total loss 0.295365214\n",
      "Trained batch 1259 batch loss 0.25046581 epoch total loss 0.295329541\n",
      "Trained batch 1260 batch loss 0.2603392 epoch total loss 0.295301765\n",
      "Trained batch 1261 batch loss 0.29766503 epoch total loss 0.295303643\n",
      "Trained batch 1262 batch loss 0.289778143 epoch total loss 0.295299262\n",
      "Trained batch 1263 batch loss 0.305595249 epoch total loss 0.295307428\n",
      "Trained batch 1264 batch loss 0.299773902 epoch total loss 0.295310944\n",
      "Trained batch 1265 batch loss 0.329450697 epoch total loss 0.295337915\n",
      "Trained batch 1266 batch loss 0.324759871 epoch total loss 0.295361161\n",
      "Trained batch 1267 batch loss 0.349249184 epoch total loss 0.295403689\n",
      "Trained batch 1268 batch loss 0.337687433 epoch total loss 0.295437038\n",
      "Trained batch 1269 batch loss 0.303283244 epoch total loss 0.295443237\n",
      "Trained batch 1270 batch loss 0.28065455 epoch total loss 0.295431554\n",
      "Trained batch 1271 batch loss 0.304676443 epoch total loss 0.295438856\n",
      "Trained batch 1272 batch loss 0.301048368 epoch total loss 0.295443267\n",
      "Trained batch 1273 batch loss 0.299943626 epoch total loss 0.295446813\n",
      "Trained batch 1274 batch loss 0.277345896 epoch total loss 0.295432597\n",
      "Trained batch 1275 batch loss 0.298751354 epoch total loss 0.29543519\n",
      "Trained batch 1276 batch loss 0.275031 epoch total loss 0.295419186\n",
      "Trained batch 1277 batch loss 0.268505692 epoch total loss 0.295398116\n",
      "Trained batch 1278 batch loss 0.273399323 epoch total loss 0.29538089\n",
      "Trained batch 1279 batch loss 0.288254797 epoch total loss 0.295375347\n",
      "Trained batch 1280 batch loss 0.304558724 epoch total loss 0.295382529\n",
      "Trained batch 1281 batch loss 0.284067 epoch total loss 0.295373678\n",
      "Trained batch 1282 batch loss 0.268897474 epoch total loss 0.295353025\n",
      "Trained batch 1283 batch loss 0.260193139 epoch total loss 0.295325607\n",
      "Trained batch 1284 batch loss 0.241334468 epoch total loss 0.295283556\n",
      "Trained batch 1285 batch loss 0.2869789 epoch total loss 0.295277119\n",
      "Trained batch 1286 batch loss 0.286930174 epoch total loss 0.295270622\n",
      "Trained batch 1287 batch loss 0.309788108 epoch total loss 0.295281887\n",
      "Trained batch 1288 batch loss 0.316001147 epoch total loss 0.29529798\n",
      "Trained batch 1289 batch loss 0.280479729 epoch total loss 0.295286506\n",
      "Trained batch 1290 batch loss 0.282381862 epoch total loss 0.295276493\n",
      "Trained batch 1291 batch loss 0.297228634 epoch total loss 0.295278\n",
      "Trained batch 1292 batch loss 0.272687465 epoch total loss 0.295260519\n",
      "Trained batch 1293 batch loss 0.298793465 epoch total loss 0.295263261\n",
      "Trained batch 1294 batch loss 0.333793133 epoch total loss 0.295293033\n",
      "Trained batch 1295 batch loss 0.294743359 epoch total loss 0.295292616\n",
      "Trained batch 1296 batch loss 0.335195273 epoch total loss 0.295323402\n",
      "Trained batch 1297 batch loss 0.303013623 epoch total loss 0.295329332\n",
      "Trained batch 1298 batch loss 0.309789181 epoch total loss 0.295340478\n",
      "Trained batch 1299 batch loss 0.303324491 epoch total loss 0.295346618\n",
      "Trained batch 1300 batch loss 0.267893493 epoch total loss 0.295325488\n",
      "Trained batch 1301 batch loss 0.27224949 epoch total loss 0.295307755\n",
      "Trained batch 1302 batch loss 0.281565309 epoch total loss 0.295297176\n",
      "Trained batch 1303 batch loss 0.306556761 epoch total loss 0.295305818\n",
      "Trained batch 1304 batch loss 0.313897133 epoch total loss 0.295320064\n",
      "Trained batch 1305 batch loss 0.301135391 epoch total loss 0.295324534\n",
      "Trained batch 1306 batch loss 0.32796371 epoch total loss 0.295349538\n",
      "Trained batch 1307 batch loss 0.344356358 epoch total loss 0.29538703\n",
      "Trained batch 1308 batch loss 0.383411199 epoch total loss 0.295454353\n",
      "Trained batch 1309 batch loss 0.303282648 epoch total loss 0.295460314\n",
      "Trained batch 1310 batch loss 0.250870019 epoch total loss 0.295426309\n",
      "Trained batch 1311 batch loss 0.301451176 epoch total loss 0.295430899\n",
      "Trained batch 1312 batch loss 0.286485791 epoch total loss 0.295424104\n",
      "Trained batch 1313 batch loss 0.270741642 epoch total loss 0.295405298\n",
      "Trained batch 1314 batch loss 0.263448417 epoch total loss 0.29538098\n",
      "Trained batch 1315 batch loss 0.255435228 epoch total loss 0.295350611\n",
      "Trained batch 1316 batch loss 0.25636971 epoch total loss 0.295321\n",
      "Trained batch 1317 batch loss 0.246170074 epoch total loss 0.295283675\n",
      "Trained batch 1318 batch loss 0.252699882 epoch total loss 0.295251369\n",
      "Trained batch 1319 batch loss 0.265509576 epoch total loss 0.295228809\n",
      "Trained batch 1320 batch loss 0.289987177 epoch total loss 0.295224845\n",
      "Trained batch 1321 batch loss 0.276867 epoch total loss 0.295210928\n",
      "Trained batch 1322 batch loss 0.272248745 epoch total loss 0.295193553\n",
      "Trained batch 1323 batch loss 0.258416057 epoch total loss 0.295165747\n",
      "Trained batch 1324 batch loss 0.31186071 epoch total loss 0.295178384\n",
      "Trained batch 1325 batch loss 0.334079385 epoch total loss 0.295207739\n",
      "Trained batch 1326 batch loss 0.31557107 epoch total loss 0.295223087\n",
      "Trained batch 1327 batch loss 0.294525683 epoch total loss 0.29522258\n",
      "Trained batch 1328 batch loss 0.305425256 epoch total loss 0.29523024\n",
      "Trained batch 1329 batch loss 0.279967964 epoch total loss 0.295218766\n",
      "Trained batch 1330 batch loss 0.307257414 epoch total loss 0.295227796\n",
      "Trained batch 1331 batch loss 0.278662413 epoch total loss 0.295215368\n",
      "Trained batch 1332 batch loss 0.30460006 epoch total loss 0.295222402\n",
      "Trained batch 1333 batch loss 0.348412871 epoch total loss 0.295262307\n",
      "Trained batch 1334 batch loss 0.286710978 epoch total loss 0.295255899\n",
      "Trained batch 1335 batch loss 0.3026371 epoch total loss 0.295261443\n",
      "Trained batch 1336 batch loss 0.296590567 epoch total loss 0.295262426\n",
      "Trained batch 1337 batch loss 0.276491106 epoch total loss 0.295248389\n",
      "Trained batch 1338 batch loss 0.259945184 epoch total loss 0.295222\n",
      "Trained batch 1339 batch loss 0.287594557 epoch total loss 0.295216322\n",
      "Trained batch 1340 batch loss 0.268249929 epoch total loss 0.295196205\n",
      "Trained batch 1341 batch loss 0.272700369 epoch total loss 0.295179427\n",
      "Trained batch 1342 batch loss 0.261484444 epoch total loss 0.295154303\n",
      "Trained batch 1343 batch loss 0.266495049 epoch total loss 0.295132965\n",
      "Trained batch 1344 batch loss 0.297705084 epoch total loss 0.295134872\n",
      "Trained batch 1345 batch loss 0.321695685 epoch total loss 0.295154631\n",
      "Trained batch 1346 batch loss 0.328243107 epoch total loss 0.295179218\n",
      "Trained batch 1347 batch loss 0.314561188 epoch total loss 0.295193613\n",
      "Trained batch 1348 batch loss 0.294094235 epoch total loss 0.295192808\n",
      "Trained batch 1349 batch loss 0.319563717 epoch total loss 0.295210838\n",
      "Trained batch 1350 batch loss 0.29211545 epoch total loss 0.295208573\n",
      "Trained batch 1351 batch loss 0.291184187 epoch total loss 0.295205593\n",
      "Trained batch 1352 batch loss 0.294530541 epoch total loss 0.295205086\n",
      "Trained batch 1353 batch loss 0.254074067 epoch total loss 0.295174688\n",
      "Trained batch 1354 batch loss 0.260519534 epoch total loss 0.295149088\n",
      "Trained batch 1355 batch loss 0.256915271 epoch total loss 0.295120895\n",
      "Trained batch 1356 batch loss 0.248177201 epoch total loss 0.295086265\n",
      "Trained batch 1357 batch loss 0.262260735 epoch total loss 0.295062065\n",
      "Trained batch 1358 batch loss 0.228306308 epoch total loss 0.295012921\n",
      "Trained batch 1359 batch loss 0.22106564 epoch total loss 0.294958502\n",
      "Trained batch 1360 batch loss 0.207962126 epoch total loss 0.294894546\n",
      "Trained batch 1361 batch loss 0.241732776 epoch total loss 0.294855475\n",
      "Trained batch 1362 batch loss 0.265838385 epoch total loss 0.294834167\n",
      "Trained batch 1363 batch loss 0.273220122 epoch total loss 0.294818312\n",
      "Trained batch 1364 batch loss 0.28364861 epoch total loss 0.294810146\n",
      "Trained batch 1365 batch loss 0.282509089 epoch total loss 0.294801116\n",
      "Trained batch 1366 batch loss 0.285971314 epoch total loss 0.294794679\n",
      "Trained batch 1367 batch loss 0.301431 epoch total loss 0.294799507\n",
      "Trained batch 1368 batch loss 0.338435113 epoch total loss 0.294831425\n",
      "Trained batch 1369 batch loss 0.258672357 epoch total loss 0.294805\n",
      "Trained batch 1370 batch loss 0.239109427 epoch total loss 0.29476434\n",
      "Trained batch 1371 batch loss 0.239099979 epoch total loss 0.294723749\n",
      "Trained batch 1372 batch loss 0.25409317 epoch total loss 0.294694126\n",
      "Trained batch 1373 batch loss 0.288215697 epoch total loss 0.294689417\n",
      "Trained batch 1374 batch loss 0.266261697 epoch total loss 0.294668704\n",
      "Trained batch 1375 batch loss 0.272967041 epoch total loss 0.294652939\n",
      "Trained batch 1376 batch loss 0.313419878 epoch total loss 0.294666588\n",
      "Trained batch 1377 batch loss 0.303329706 epoch total loss 0.294672877\n",
      "Trained batch 1378 batch loss 0.31640774 epoch total loss 0.294688642\n",
      "Trained batch 1379 batch loss 0.326888829 epoch total loss 0.294711977\n",
      "Trained batch 1380 batch loss 0.292472422 epoch total loss 0.294710368\n",
      "Trained batch 1381 batch loss 0.273623884 epoch total loss 0.294695109\n",
      "Trained batch 1382 batch loss 0.283271551 epoch total loss 0.294686824\n",
      "Trained batch 1383 batch loss 0.284648955 epoch total loss 0.294679552\n",
      "Trained batch 1384 batch loss 0.331414372 epoch total loss 0.294706106\n",
      "Trained batch 1385 batch loss 0.324933082 epoch total loss 0.294727921\n",
      "Trained batch 1386 batch loss 0.301097453 epoch total loss 0.294732511\n",
      "Trained batch 1387 batch loss 0.285594612 epoch total loss 0.294725925\n",
      "Trained batch 1388 batch loss 0.261746824 epoch total loss 0.294702172\n",
      "Epoch 3 train loss 0.2947021722793579 and time 684.1360676288605\n",
      "Validated batch 1 batch loss 0.29138273\n",
      "Validated batch 2 batch loss 0.287284702\n",
      "Validated batch 3 batch loss 0.283813268\n",
      "Validated batch 4 batch loss 0.297345787\n",
      "Validated batch 5 batch loss 0.288201362\n",
      "Validated batch 6 batch loss 0.328813165\n",
      "Validated batch 7 batch loss 0.29723841\n",
      "Validated batch 8 batch loss 0.246060923\n",
      "Validated batch 9 batch loss 0.282033443\n",
      "Validated batch 10 batch loss 0.295968562\n",
      "Validated batch 11 batch loss 0.284685731\n",
      "Validated batch 12 batch loss 0.297699243\n",
      "Validated batch 13 batch loss 0.299168527\n",
      "Validated batch 14 batch loss 0.29931587\n",
      "Validated batch 15 batch loss 0.32757324\n",
      "Validated batch 16 batch loss 0.332634747\n",
      "Validated batch 17 batch loss 0.292278975\n",
      "Validated batch 18 batch loss 0.316840231\n",
      "Validated batch 19 batch loss 0.256566256\n",
      "Validated batch 20 batch loss 0.288506508\n",
      "Validated batch 21 batch loss 0.266774952\n",
      "Validated batch 22 batch loss 0.321217656\n",
      "Validated batch 23 batch loss 0.329891831\n",
      "Validated batch 24 batch loss 0.318567246\n",
      "Validated batch 25 batch loss 0.31523183\n",
      "Validated batch 26 batch loss 0.299352914\n",
      "Validated batch 27 batch loss 0.298936099\n",
      "Validated batch 28 batch loss 0.316485763\n",
      "Validated batch 29 batch loss 0.346489847\n",
      "Validated batch 30 batch loss 0.298363894\n",
      "Validated batch 31 batch loss 0.324528933\n",
      "Validated batch 32 batch loss 0.316604614\n",
      "Validated batch 33 batch loss 0.314823806\n",
      "Validated batch 34 batch loss 0.309035838\n",
      "Validated batch 35 batch loss 0.277570963\n",
      "Validated batch 36 batch loss 0.346332252\n",
      "Validated batch 37 batch loss 0.281892747\n",
      "Validated batch 38 batch loss 0.316319764\n",
      "Validated batch 39 batch loss 0.310875773\n",
      "Validated batch 40 batch loss 0.328281283\n",
      "Validated batch 41 batch loss 0.267458141\n",
      "Validated batch 42 batch loss 0.316475272\n",
      "Validated batch 43 batch loss 0.295548856\n",
      "Validated batch 44 batch loss 0.320316732\n",
      "Validated batch 45 batch loss 0.300228953\n",
      "Validated batch 46 batch loss 0.303031147\n",
      "Validated batch 47 batch loss 0.306335479\n",
      "Validated batch 48 batch loss 0.275477946\n",
      "Validated batch 49 batch loss 0.289373517\n",
      "Validated batch 50 batch loss 0.278718174\n",
      "Validated batch 51 batch loss 0.300361067\n",
      "Validated batch 52 batch loss 0.304785699\n",
      "Validated batch 53 batch loss 0.308442175\n",
      "Validated batch 54 batch loss 0.288387805\n",
      "Validated batch 55 batch loss 0.29994303\n",
      "Validated batch 56 batch loss 0.300934613\n",
      "Validated batch 57 batch loss 0.293686718\n",
      "Validated batch 58 batch loss 0.318769693\n",
      "Validated batch 59 batch loss 0.291232556\n",
      "Validated batch 60 batch loss 0.289039016\n",
      "Validated batch 61 batch loss 0.301710755\n",
      "Validated batch 62 batch loss 0.296371728\n",
      "Validated batch 63 batch loss 0.341152\n",
      "Validated batch 64 batch loss 0.313294917\n",
      "Validated batch 65 batch loss 0.267279\n",
      "Validated batch 66 batch loss 0.318407863\n",
      "Validated batch 67 batch loss 0.29504317\n",
      "Validated batch 68 batch loss 0.280952662\n",
      "Validated batch 69 batch loss 0.301550388\n",
      "Validated batch 70 batch loss 0.327805102\n",
      "Validated batch 71 batch loss 0.308445781\n",
      "Validated batch 72 batch loss 0.289643347\n",
      "Validated batch 73 batch loss 0.301075071\n",
      "Validated batch 74 batch loss 0.293306679\n",
      "Validated batch 75 batch loss 0.317421854\n",
      "Validated batch 76 batch loss 0.305939317\n",
      "Validated batch 77 batch loss 0.285771251\n",
      "Validated batch 78 batch loss 0.296529859\n",
      "Validated batch 79 batch loss 0.310554892\n",
      "Validated batch 80 batch loss 0.315472543\n",
      "Validated batch 81 batch loss 0.320101798\n",
      "Validated batch 82 batch loss 0.295817286\n",
      "Validated batch 83 batch loss 0.282229125\n",
      "Validated batch 84 batch loss 0.299611747\n",
      "Validated batch 85 batch loss 0.318441182\n",
      "Validated batch 86 batch loss 0.308394849\n",
      "Validated batch 87 batch loss 0.31219852\n",
      "Validated batch 88 batch loss 0.319184244\n",
      "Validated batch 89 batch loss 0.375917256\n",
      "Validated batch 90 batch loss 0.329112053\n",
      "Validated batch 91 batch loss 0.301596373\n",
      "Validated batch 92 batch loss 0.287535042\n",
      "Validated batch 93 batch loss 0.271210343\n",
      "Validated batch 94 batch loss 0.302920312\n",
      "Validated batch 95 batch loss 0.296831459\n",
      "Validated batch 96 batch loss 0.281056851\n",
      "Validated batch 97 batch loss 0.299887508\n",
      "Validated batch 98 batch loss 0.318933785\n",
      "Validated batch 99 batch loss 0.321682632\n",
      "Validated batch 100 batch loss 0.320591331\n",
      "Validated batch 101 batch loss 0.309747517\n",
      "Validated batch 102 batch loss 0.292005062\n",
      "Validated batch 103 batch loss 0.3127276\n",
      "Validated batch 104 batch loss 0.307519525\n",
      "Validated batch 105 batch loss 0.290792465\n",
      "Validated batch 106 batch loss 0.335515946\n",
      "Validated batch 107 batch loss 0.332858771\n",
      "Validated batch 108 batch loss 0.317587733\n",
      "Validated batch 109 batch loss 0.350893736\n",
      "Validated batch 110 batch loss 0.26980114\n",
      "Validated batch 111 batch loss 0.308960885\n",
      "Validated batch 112 batch loss 0.292399168\n",
      "Validated batch 113 batch loss 0.282671422\n",
      "Validated batch 114 batch loss 0.331316948\n",
      "Validated batch 115 batch loss 0.290151417\n",
      "Validated batch 116 batch loss 0.285133034\n",
      "Validated batch 117 batch loss 0.286997408\n",
      "Validated batch 118 batch loss 0.316879809\n",
      "Validated batch 119 batch loss 0.293543339\n",
      "Validated batch 120 batch loss 0.318075895\n",
      "Validated batch 121 batch loss 0.35109365\n",
      "Validated batch 122 batch loss 0.281504422\n",
      "Validated batch 123 batch loss 0.298431844\n",
      "Validated batch 124 batch loss 0.306688756\n",
      "Validated batch 125 batch loss 0.32069847\n",
      "Validated batch 126 batch loss 0.316107631\n",
      "Validated batch 127 batch loss 0.284405589\n",
      "Validated batch 128 batch loss 0.243314967\n",
      "Validated batch 129 batch loss 0.300880581\n",
      "Validated batch 130 batch loss 0.288142174\n",
      "Validated batch 131 batch loss 0.303444028\n",
      "Validated batch 132 batch loss 0.315366328\n",
      "Validated batch 133 batch loss 0.26994431\n",
      "Validated batch 134 batch loss 0.309077561\n",
      "Validated batch 135 batch loss 0.333355218\n",
      "Validated batch 136 batch loss 0.317762822\n",
      "Validated batch 137 batch loss 0.310032755\n",
      "Validated batch 138 batch loss 0.270000309\n",
      "Validated batch 139 batch loss 0.303380042\n",
      "Validated batch 140 batch loss 0.320489854\n",
      "Validated batch 141 batch loss 0.293013275\n",
      "Validated batch 142 batch loss 0.293224335\n",
      "Validated batch 143 batch loss 0.296475679\n",
      "Validated batch 144 batch loss 0.30163613\n",
      "Validated batch 145 batch loss 0.29777807\n",
      "Validated batch 146 batch loss 0.300127178\n",
      "Validated batch 147 batch loss 0.277325898\n",
      "Validated batch 148 batch loss 0.330419958\n",
      "Validated batch 149 batch loss 0.280870169\n",
      "Validated batch 150 batch loss 0.261999\n",
      "Validated batch 151 batch loss 0.295968443\n",
      "Validated batch 152 batch loss 0.331462264\n",
      "Validated batch 153 batch loss 0.325757086\n",
      "Validated batch 154 batch loss 0.329454184\n",
      "Validated batch 155 batch loss 0.308443308\n",
      "Validated batch 156 batch loss 0.330449551\n",
      "Validated batch 157 batch loss 0.302382678\n",
      "Validated batch 158 batch loss 0.328030229\n",
      "Validated batch 159 batch loss 0.306858152\n",
      "Validated batch 160 batch loss 0.252918452\n",
      "Validated batch 161 batch loss 0.298160195\n",
      "Validated batch 162 batch loss 0.308542669\n",
      "Validated batch 163 batch loss 0.287603319\n",
      "Validated batch 164 batch loss 0.289521784\n",
      "Validated batch 165 batch loss 0.282987297\n",
      "Validated batch 166 batch loss 0.294735849\n",
      "Validated batch 167 batch loss 0.313110739\n",
      "Validated batch 168 batch loss 0.30195424\n",
      "Validated batch 169 batch loss 0.318502158\n",
      "Validated batch 170 batch loss 0.330220222\n",
      "Validated batch 171 batch loss 0.321809143\n",
      "Validated batch 172 batch loss 0.305984288\n",
      "Validated batch 173 batch loss 0.334338\n",
      "Validated batch 174 batch loss 0.311670154\n",
      "Validated batch 175 batch loss 0.326408893\n",
      "Validated batch 176 batch loss 0.318291754\n",
      "Validated batch 177 batch loss 0.347679675\n",
      "Validated batch 178 batch loss 0.329743803\n",
      "Validated batch 179 batch loss 0.28941521\n",
      "Validated batch 180 batch loss 0.288985729\n",
      "Validated batch 181 batch loss 0.315565646\n",
      "Validated batch 182 batch loss 0.32825008\n",
      "Validated batch 183 batch loss 0.29821378\n",
      "Validated batch 184 batch loss 0.315205336\n",
      "Validated batch 185 batch loss 0.301915407\n",
      "Epoch 3 val loss 0.30423569679260254\n",
      "Model /aiffel/aiffel/CV-PoseEstimation/models/model-epoch-3-loss-0.3042.h5 saved.\n",
      "Start epoch 4 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.293838412 epoch total loss 0.293838412\n",
      "Trained batch 2 batch loss 0.292569101 epoch total loss 0.293203771\n",
      "Trained batch 3 batch loss 0.30397892 epoch total loss 0.296795487\n",
      "Trained batch 4 batch loss 0.306456506 epoch total loss 0.299210727\n",
      "Trained batch 5 batch loss 0.252537221 epoch total loss 0.289876044\n",
      "Trained batch 6 batch loss 0.260434568 epoch total loss 0.284969121\n",
      "Trained batch 7 batch loss 0.265314341 epoch total loss 0.282161295\n",
      "Trained batch 8 batch loss 0.288424581 epoch total loss 0.282944202\n",
      "Trained batch 9 batch loss 0.292693466 epoch total loss 0.284027457\n",
      "Trained batch 10 batch loss 0.307169229 epoch total loss 0.286341608\n",
      "Trained batch 11 batch loss 0.310264468 epoch total loss 0.288516432\n",
      "Trained batch 12 batch loss 0.313666433 epoch total loss 0.290612251\n",
      "Trained batch 13 batch loss 0.302905023 epoch total loss 0.291557848\n",
      "Trained batch 14 batch loss 0.33138895 epoch total loss 0.294402927\n",
      "Trained batch 15 batch loss 0.286360085 epoch total loss 0.293866754\n",
      "Trained batch 16 batch loss 0.287396938 epoch total loss 0.293462396\n",
      "Trained batch 17 batch loss 0.321119606 epoch total loss 0.295089304\n",
      "Trained batch 18 batch loss 0.309669435 epoch total loss 0.295899302\n",
      "Trained batch 19 batch loss 0.328151137 epoch total loss 0.297596782\n",
      "Trained batch 20 batch loss 0.284671873 epoch total loss 0.296950519\n",
      "Trained batch 21 batch loss 0.289340496 epoch total loss 0.296588153\n",
      "Trained batch 22 batch loss 0.290569663 epoch total loss 0.296314597\n",
      "Trained batch 23 batch loss 0.287457287 epoch total loss 0.295929492\n",
      "Trained batch 24 batch loss 0.299275905 epoch total loss 0.296068937\n",
      "Trained batch 25 batch loss 0.289468467 epoch total loss 0.295804888\n",
      "Trained batch 26 batch loss 0.298995256 epoch total loss 0.295927584\n",
      "Trained batch 27 batch loss 0.351358801 epoch total loss 0.297980577\n",
      "Trained batch 28 batch loss 0.299144983 epoch total loss 0.298022181\n",
      "Trained batch 29 batch loss 0.291484356 epoch total loss 0.297796696\n",
      "Trained batch 30 batch loss 0.290600091 epoch total loss 0.297556818\n",
      "Trained batch 31 batch loss 0.242044762 epoch total loss 0.295766085\n",
      "Trained batch 32 batch loss 0.236414433 epoch total loss 0.293911338\n",
      "Trained batch 33 batch loss 0.269505531 epoch total loss 0.293171763\n",
      "Trained batch 34 batch loss 0.261561096 epoch total loss 0.29224205\n",
      "Trained batch 35 batch loss 0.208941296 epoch total loss 0.289862037\n",
      "Trained batch 36 batch loss 0.216570809 epoch total loss 0.28782618\n",
      "Trained batch 37 batch loss 0.243785143 epoch total loss 0.286635876\n",
      "Trained batch 38 batch loss 0.237236515 epoch total loss 0.285335898\n",
      "Trained batch 39 batch loss 0.280797422 epoch total loss 0.28521952\n",
      "Trained batch 40 batch loss 0.296131611 epoch total loss 0.285492331\n",
      "Trained batch 41 batch loss 0.27965489 epoch total loss 0.285349935\n",
      "Trained batch 42 batch loss 0.286681861 epoch total loss 0.285381645\n",
      "Trained batch 43 batch loss 0.305205971 epoch total loss 0.285842687\n",
      "Trained batch 44 batch loss 0.28585878 epoch total loss 0.285843074\n",
      "Trained batch 45 batch loss 0.297244191 epoch total loss 0.286096424\n",
      "Trained batch 46 batch loss 0.283943832 epoch total loss 0.286049634\n",
      "Trained batch 47 batch loss 0.315887243 epoch total loss 0.286684483\n",
      "Trained batch 48 batch loss 0.273088872 epoch total loss 0.286401242\n",
      "Trained batch 49 batch loss 0.305149555 epoch total loss 0.286783844\n",
      "Trained batch 50 batch loss 0.299016118 epoch total loss 0.287028491\n",
      "Trained batch 51 batch loss 0.300412774 epoch total loss 0.287290931\n",
      "Trained batch 52 batch loss 0.274183273 epoch total loss 0.287038863\n",
      "Trained batch 53 batch loss 0.288829058 epoch total loss 0.287072629\n",
      "Trained batch 54 batch loss 0.303462416 epoch total loss 0.287376136\n",
      "Trained batch 55 batch loss 0.294507384 epoch total loss 0.287505805\n",
      "Trained batch 56 batch loss 0.28717646 epoch total loss 0.287499905\n",
      "Trained batch 57 batch loss 0.286215752 epoch total loss 0.287477374\n",
      "Trained batch 58 batch loss 0.284883976 epoch total loss 0.287432641\n",
      "Trained batch 59 batch loss 0.292298853 epoch total loss 0.287515134\n",
      "Trained batch 60 batch loss 0.310419142 epoch total loss 0.287896842\n",
      "Trained batch 61 batch loss 0.307104856 epoch total loss 0.288211733\n",
      "Trained batch 62 batch loss 0.332101226 epoch total loss 0.288919628\n",
      "Trained batch 63 batch loss 0.309067219 epoch total loss 0.289239436\n",
      "Trained batch 64 batch loss 0.302373022 epoch total loss 0.289444655\n",
      "Trained batch 65 batch loss 0.282014877 epoch total loss 0.289330363\n",
      "Trained batch 66 batch loss 0.274784923 epoch total loss 0.289109945\n",
      "Trained batch 67 batch loss 0.300079584 epoch total loss 0.289273679\n",
      "Trained batch 68 batch loss 0.295100272 epoch total loss 0.289359361\n",
      "Trained batch 69 batch loss 0.299762547 epoch total loss 0.289510161\n",
      "Trained batch 70 batch loss 0.309117764 epoch total loss 0.289790273\n",
      "Trained batch 71 batch loss 0.276354462 epoch total loss 0.289601028\n",
      "Trained batch 72 batch loss 0.283184558 epoch total loss 0.289511889\n",
      "Trained batch 73 batch loss 0.255066782 epoch total loss 0.289040029\n",
      "Trained batch 74 batch loss 0.265353501 epoch total loss 0.288719952\n",
      "Trained batch 75 batch loss 0.250083208 epoch total loss 0.288204789\n",
      "Trained batch 76 batch loss 0.25879997 epoch total loss 0.287817895\n",
      "Trained batch 77 batch loss 0.291576326 epoch total loss 0.287866712\n",
      "Trained batch 78 batch loss 0.298676759 epoch total loss 0.288005322\n",
      "Trained batch 79 batch loss 0.253930509 epoch total loss 0.287574\n",
      "Trained batch 80 batch loss 0.24860543 epoch total loss 0.287086904\n",
      "Trained batch 81 batch loss 0.281558692 epoch total loss 0.287018657\n",
      "Trained batch 82 batch loss 0.268582463 epoch total loss 0.286793828\n",
      "Trained batch 83 batch loss 0.280650616 epoch total loss 0.286719829\n",
      "Trained batch 84 batch loss 0.28148666 epoch total loss 0.286657512\n",
      "Trained batch 85 batch loss 0.296606213 epoch total loss 0.286774546\n",
      "Trained batch 86 batch loss 0.296918571 epoch total loss 0.286892503\n",
      "Trained batch 87 batch loss 0.300808638 epoch total loss 0.287052453\n",
      "Trained batch 88 batch loss 0.309781164 epoch total loss 0.287310749\n",
      "Trained batch 89 batch loss 0.274028122 epoch total loss 0.287161529\n",
      "Trained batch 90 batch loss 0.278998435 epoch total loss 0.287070811\n",
      "Trained batch 91 batch loss 0.280341744 epoch total loss 0.286996871\n",
      "Trained batch 92 batch loss 0.256993651 epoch total loss 0.286670774\n",
      "Trained batch 93 batch loss 0.259754568 epoch total loss 0.286381334\n",
      "Trained batch 94 batch loss 0.266060293 epoch total loss 0.286165148\n",
      "Trained batch 95 batch loss 0.245334193 epoch total loss 0.285735369\n",
      "Trained batch 96 batch loss 0.266212583 epoch total loss 0.285532\n",
      "Trained batch 97 batch loss 0.23718369 epoch total loss 0.285033584\n",
      "Trained batch 98 batch loss 0.265877396 epoch total loss 0.28483808\n",
      "Trained batch 99 batch loss 0.245428517 epoch total loss 0.28444\n",
      "Trained batch 100 batch loss 0.313214481 epoch total loss 0.284727752\n",
      "Trained batch 101 batch loss 0.328329086 epoch total loss 0.285159469\n",
      "Trained batch 102 batch loss 0.269290149 epoch total loss 0.285003901\n",
      "Trained batch 103 batch loss 0.287994087 epoch total loss 0.285032928\n",
      "Trained batch 104 batch loss 0.298060298 epoch total loss 0.285158187\n",
      "Trained batch 105 batch loss 0.257017314 epoch total loss 0.284890175\n",
      "Trained batch 106 batch loss 0.263566345 epoch total loss 0.284689\n",
      "Trained batch 107 batch loss 0.30891645 epoch total loss 0.284915417\n",
      "Trained batch 108 batch loss 0.293738037 epoch total loss 0.284997106\n",
      "Trained batch 109 batch loss 0.317533493 epoch total loss 0.285295606\n",
      "Trained batch 110 batch loss 0.2857081 epoch total loss 0.285299361\n",
      "Trained batch 111 batch loss 0.28066352 epoch total loss 0.285257608\n",
      "Trained batch 112 batch loss 0.288639158 epoch total loss 0.285287797\n",
      "Trained batch 113 batch loss 0.28528142 epoch total loss 0.285287738\n",
      "Trained batch 114 batch loss 0.254185051 epoch total loss 0.285014898\n",
      "Trained batch 115 batch loss 0.310690522 epoch total loss 0.285238177\n",
      "Trained batch 116 batch loss 0.325904191 epoch total loss 0.285588771\n",
      "Trained batch 117 batch loss 0.313783 epoch total loss 0.285829723\n",
      "Trained batch 118 batch loss 0.255257159 epoch total loss 0.285570621\n",
      "Trained batch 119 batch loss 0.254329383 epoch total loss 0.285308093\n",
      "Trained batch 120 batch loss 0.241969123 epoch total loss 0.284946948\n",
      "Trained batch 121 batch loss 0.262600183 epoch total loss 0.284762263\n",
      "Trained batch 122 batch loss 0.250525236 epoch total loss 0.284481645\n",
      "Trained batch 123 batch loss 0.246289119 epoch total loss 0.284171134\n",
      "Trained batch 124 batch loss 0.246979639 epoch total loss 0.283871204\n",
      "Trained batch 125 batch loss 0.264023781 epoch total loss 0.283712417\n",
      "Trained batch 126 batch loss 0.278641671 epoch total loss 0.283672154\n",
      "Trained batch 127 batch loss 0.288967848 epoch total loss 0.283713847\n",
      "Trained batch 128 batch loss 0.281613082 epoch total loss 0.283697426\n",
      "Trained batch 129 batch loss 0.300433874 epoch total loss 0.283827156\n",
      "Trained batch 130 batch loss 0.308396399 epoch total loss 0.284016162\n",
      "Trained batch 131 batch loss 0.30447498 epoch total loss 0.284172326\n",
      "Trained batch 132 batch loss 0.29822737 epoch total loss 0.28427881\n",
      "Trained batch 133 batch loss 0.286074758 epoch total loss 0.28429231\n",
      "Trained batch 134 batch loss 0.309923768 epoch total loss 0.284483612\n",
      "Trained batch 135 batch loss 0.284899145 epoch total loss 0.284486711\n",
      "Trained batch 136 batch loss 0.284825921 epoch total loss 0.284489185\n",
      "Trained batch 137 batch loss 0.301657379 epoch total loss 0.284614503\n",
      "Trained batch 138 batch loss 0.309360892 epoch total loss 0.284793824\n",
      "Trained batch 139 batch loss 0.272293061 epoch total loss 0.284703881\n",
      "Trained batch 140 batch loss 0.266471028 epoch total loss 0.284573674\n",
      "Trained batch 141 batch loss 0.289426804 epoch total loss 0.284608066\n",
      "Trained batch 142 batch loss 0.293762624 epoch total loss 0.284672529\n",
      "Trained batch 143 batch loss 0.281447053 epoch total loss 0.28465\n",
      "Trained batch 144 batch loss 0.281606376 epoch total loss 0.284628838\n",
      "Trained batch 145 batch loss 0.265297741 epoch total loss 0.284495533\n",
      "Trained batch 146 batch loss 0.236855865 epoch total loss 0.284169197\n",
      "Trained batch 147 batch loss 0.271899492 epoch total loss 0.284085751\n",
      "Trained batch 148 batch loss 0.252462894 epoch total loss 0.283872098\n",
      "Trained batch 149 batch loss 0.261935443 epoch total loss 0.283724874\n",
      "Trained batch 150 batch loss 0.257743627 epoch total loss 0.283551663\n",
      "Trained batch 151 batch loss 0.239480242 epoch total loss 0.283259779\n",
      "Trained batch 152 batch loss 0.262027204 epoch total loss 0.283120096\n",
      "Trained batch 153 batch loss 0.276631445 epoch total loss 0.283077687\n",
      "Trained batch 154 batch loss 0.254372299 epoch total loss 0.282891273\n",
      "Trained batch 155 batch loss 0.216361701 epoch total loss 0.28246206\n",
      "Trained batch 156 batch loss 0.235870704 epoch total loss 0.282163411\n",
      "Trained batch 157 batch loss 0.232426554 epoch total loss 0.281846613\n",
      "Trained batch 158 batch loss 0.296188146 epoch total loss 0.281937361\n",
      "Trained batch 159 batch loss 0.307644546 epoch total loss 0.282099038\n",
      "Trained batch 160 batch loss 0.293191731 epoch total loss 0.282168359\n",
      "Trained batch 161 batch loss 0.274216086 epoch total loss 0.282118976\n",
      "Trained batch 162 batch loss 0.262739122 epoch total loss 0.28199932\n",
      "Trained batch 163 batch loss 0.261838377 epoch total loss 0.28187564\n",
      "Trained batch 164 batch loss 0.284019947 epoch total loss 0.281888694\n",
      "Trained batch 165 batch loss 0.2666637 epoch total loss 0.281796426\n",
      "Trained batch 166 batch loss 0.281408936 epoch total loss 0.281794101\n",
      "Trained batch 167 batch loss 0.284522235 epoch total loss 0.281810433\n",
      "Trained batch 168 batch loss 0.288560063 epoch total loss 0.281850606\n",
      "Trained batch 169 batch loss 0.321592331 epoch total loss 0.282085747\n",
      "Trained batch 170 batch loss 0.271458238 epoch total loss 0.282023251\n",
      "Trained batch 171 batch loss 0.302571177 epoch total loss 0.282143384\n",
      "Trained batch 172 batch loss 0.247859031 epoch total loss 0.281944066\n",
      "Trained batch 173 batch loss 0.272036165 epoch total loss 0.281886816\n",
      "Trained batch 174 batch loss 0.284245491 epoch total loss 0.281900376\n",
      "Trained batch 175 batch loss 0.278616786 epoch total loss 0.281881601\n",
      "Trained batch 176 batch loss 0.27109161 epoch total loss 0.281820297\n",
      "Trained batch 177 batch loss 0.302051574 epoch total loss 0.281934589\n",
      "Trained batch 178 batch loss 0.283092827 epoch total loss 0.281941116\n",
      "Trained batch 179 batch loss 0.274582982 epoch total loss 0.2819\n",
      "Trained batch 180 batch loss 0.277052045 epoch total loss 0.281873077\n",
      "Trained batch 181 batch loss 0.294148952 epoch total loss 0.281940877\n",
      "Trained batch 182 batch loss 0.306334853 epoch total loss 0.282074928\n",
      "Trained batch 183 batch loss 0.266884446 epoch total loss 0.281991899\n",
      "Trained batch 184 batch loss 0.275080204 epoch total loss 0.281954348\n",
      "Trained batch 185 batch loss 0.31116 epoch total loss 0.282112211\n",
      "Trained batch 186 batch loss 0.26946032 epoch total loss 0.282044202\n",
      "Trained batch 187 batch loss 0.268999606 epoch total loss 0.281974435\n",
      "Trained batch 188 batch loss 0.282083541 epoch total loss 0.281975031\n",
      "Trained batch 189 batch loss 0.284163684 epoch total loss 0.281986624\n",
      "Trained batch 190 batch loss 0.294425696 epoch total loss 0.2820521\n",
      "Trained batch 191 batch loss 0.316953659 epoch total loss 0.282234818\n",
      "Trained batch 192 batch loss 0.277437091 epoch total loss 0.282209843\n",
      "Trained batch 193 batch loss 0.24191384 epoch total loss 0.282001048\n",
      "Trained batch 194 batch loss 0.294452339 epoch total loss 0.282065213\n",
      "Trained batch 195 batch loss 0.306877941 epoch total loss 0.282192469\n",
      "Trained batch 196 batch loss 0.262073666 epoch total loss 0.282089829\n",
      "Trained batch 197 batch loss 0.279434115 epoch total loss 0.282076329\n",
      "Trained batch 198 batch loss 0.285063 epoch total loss 0.282091439\n",
      "Trained batch 199 batch loss 0.27499181 epoch total loss 0.282055736\n",
      "Trained batch 200 batch loss 0.273751259 epoch total loss 0.282014221\n",
      "Trained batch 201 batch loss 0.280675024 epoch total loss 0.282007545\n",
      "Trained batch 202 batch loss 0.261432528 epoch total loss 0.281905681\n",
      "Trained batch 203 batch loss 0.276461214 epoch total loss 0.281878889\n",
      "Trained batch 204 batch loss 0.249796778 epoch total loss 0.281721622\n",
      "Trained batch 205 batch loss 0.236766592 epoch total loss 0.281502336\n",
      "Trained batch 206 batch loss 0.227247253 epoch total loss 0.281238973\n",
      "Trained batch 207 batch loss 0.270416439 epoch total loss 0.28118667\n",
      "Trained batch 208 batch loss 0.25037545 epoch total loss 0.281038553\n",
      "Trained batch 209 batch loss 0.252156824 epoch total loss 0.280900329\n",
      "Trained batch 210 batch loss 0.25231415 epoch total loss 0.280764222\n",
      "Trained batch 211 batch loss 0.257273018 epoch total loss 0.28065291\n",
      "Trained batch 212 batch loss 0.276616037 epoch total loss 0.280633867\n",
      "Trained batch 213 batch loss 0.272445202 epoch total loss 0.280595422\n",
      "Trained batch 214 batch loss 0.291638404 epoch total loss 0.280647\n",
      "Trained batch 215 batch loss 0.290039152 epoch total loss 0.2806907\n",
      "Trained batch 216 batch loss 0.309009194 epoch total loss 0.2808218\n",
      "Trained batch 217 batch loss 0.280343652 epoch total loss 0.280819595\n",
      "Trained batch 218 batch loss 0.313386083 epoch total loss 0.280968964\n",
      "Trained batch 219 batch loss 0.29172188 epoch total loss 0.281018078\n",
      "Trained batch 220 batch loss 0.285901785 epoch total loss 0.281040251\n",
      "Trained batch 221 batch loss 0.308768541 epoch total loss 0.281165719\n",
      "Trained batch 222 batch loss 0.301969469 epoch total loss 0.281259447\n",
      "Trained batch 223 batch loss 0.291100085 epoch total loss 0.281303555\n",
      "Trained batch 224 batch loss 0.278244 epoch total loss 0.281289905\n",
      "Trained batch 225 batch loss 0.287812293 epoch total loss 0.281318873\n",
      "Trained batch 226 batch loss 0.261361629 epoch total loss 0.281230569\n",
      "Trained batch 227 batch loss 0.272707939 epoch total loss 0.281193018\n",
      "Trained batch 228 batch loss 0.27757585 epoch total loss 0.281177163\n",
      "Trained batch 229 batch loss 0.325917125 epoch total loss 0.281372547\n",
      "Trained batch 230 batch loss 0.302063 epoch total loss 0.281462491\n",
      "Trained batch 231 batch loss 0.288894981 epoch total loss 0.281494677\n",
      "Trained batch 232 batch loss 0.335273802 epoch total loss 0.28172648\n",
      "Trained batch 233 batch loss 0.288159847 epoch total loss 0.281754106\n",
      "Trained batch 234 batch loss 0.288359553 epoch total loss 0.281782329\n",
      "Trained batch 235 batch loss 0.28206867 epoch total loss 0.281783551\n",
      "Trained batch 236 batch loss 0.278399616 epoch total loss 0.281769186\n",
      "Trained batch 237 batch loss 0.261945963 epoch total loss 0.281685561\n",
      "Trained batch 238 batch loss 0.270436049 epoch total loss 0.281638294\n",
      "Trained batch 239 batch loss 0.281964213 epoch total loss 0.281639665\n",
      "Trained batch 240 batch loss 0.261547238 epoch total loss 0.28155598\n",
      "Trained batch 241 batch loss 0.303900629 epoch total loss 0.281648695\n",
      "Trained batch 242 batch loss 0.314974457 epoch total loss 0.281786382\n",
      "Trained batch 243 batch loss 0.307758242 epoch total loss 0.281893253\n",
      "Trained batch 244 batch loss 0.311817169 epoch total loss 0.28201589\n",
      "Trained batch 245 batch loss 0.320800662 epoch total loss 0.28217417\n",
      "Trained batch 246 batch loss 0.337330073 epoch total loss 0.282398403\n",
      "Trained batch 247 batch loss 0.23992908 epoch total loss 0.282226473\n",
      "Trained batch 248 batch loss 0.253634363 epoch total loss 0.282111168\n",
      "Trained batch 249 batch loss 0.307274252 epoch total loss 0.282212228\n",
      "Trained batch 250 batch loss 0.234115198 epoch total loss 0.282019824\n",
      "Trained batch 251 batch loss 0.25411272 epoch total loss 0.281908661\n",
      "Trained batch 252 batch loss 0.242113978 epoch total loss 0.281750739\n",
      "Trained batch 253 batch loss 0.247573256 epoch total loss 0.281615645\n",
      "Trained batch 254 batch loss 0.256585509 epoch total loss 0.281517088\n",
      "Trained batch 255 batch loss 0.240919277 epoch total loss 0.281357884\n",
      "Trained batch 256 batch loss 0.286119521 epoch total loss 0.281376481\n",
      "Trained batch 257 batch loss 0.239043385 epoch total loss 0.281211764\n",
      "Trained batch 258 batch loss 0.274867803 epoch total loss 0.281187147\n",
      "Trained batch 259 batch loss 0.230575606 epoch total loss 0.280991763\n",
      "Trained batch 260 batch loss 0.24310638 epoch total loss 0.28084603\n",
      "Trained batch 261 batch loss 0.299300402 epoch total loss 0.280916721\n",
      "Trained batch 262 batch loss 0.301849961 epoch total loss 0.280996621\n",
      "Trained batch 263 batch loss 0.293174744 epoch total loss 0.281042933\n",
      "Trained batch 264 batch loss 0.264998108 epoch total loss 0.280982167\n",
      "Trained batch 265 batch loss 0.261050701 epoch total loss 0.280906945\n",
      "Trained batch 266 batch loss 0.281740904 epoch total loss 0.280910075\n",
      "Trained batch 267 batch loss 0.295058489 epoch total loss 0.280963063\n",
      "Trained batch 268 batch loss 0.302995682 epoch total loss 0.281045258\n",
      "Trained batch 269 batch loss 0.290134758 epoch total loss 0.281079054\n",
      "Trained batch 270 batch loss 0.30169946 epoch total loss 0.281155437\n",
      "Trained batch 271 batch loss 0.318651468 epoch total loss 0.28129378\n",
      "Trained batch 272 batch loss 0.299802154 epoch total loss 0.281361818\n",
      "Trained batch 273 batch loss 0.314726979 epoch total loss 0.281484038\n",
      "Trained batch 274 batch loss 0.32079792 epoch total loss 0.281627536\n",
      "Trained batch 275 batch loss 0.297351092 epoch total loss 0.281684697\n",
      "Trained batch 276 batch loss 0.289083779 epoch total loss 0.281711519\n",
      "Trained batch 277 batch loss 0.281157941 epoch total loss 0.281709522\n",
      "Trained batch 278 batch loss 0.280823767 epoch total loss 0.281706333\n",
      "Trained batch 279 batch loss 0.260828108 epoch total loss 0.2816315\n",
      "Trained batch 280 batch loss 0.289690524 epoch total loss 0.281660259\n",
      "Trained batch 281 batch loss 0.274899125 epoch total loss 0.281636208\n",
      "Trained batch 282 batch loss 0.287789106 epoch total loss 0.281658024\n",
      "Trained batch 283 batch loss 0.30682537 epoch total loss 0.281746954\n",
      "Trained batch 284 batch loss 0.279380441 epoch total loss 0.281738639\n",
      "Trained batch 285 batch loss 0.323532611 epoch total loss 0.281885266\n",
      "Trained batch 286 batch loss 0.302764058 epoch total loss 0.281958282\n",
      "Trained batch 287 batch loss 0.312230468 epoch total loss 0.282063752\n",
      "Trained batch 288 batch loss 0.292824388 epoch total loss 0.282101125\n",
      "Trained batch 289 batch loss 0.293055505 epoch total loss 0.282139033\n",
      "Trained batch 290 batch loss 0.28491056 epoch total loss 0.2821486\n",
      "Trained batch 291 batch loss 0.285125434 epoch total loss 0.282158822\n",
      "Trained batch 292 batch loss 0.273549467 epoch total loss 0.282129347\n",
      "Trained batch 293 batch loss 0.269587666 epoch total loss 0.282086521\n",
      "Trained batch 294 batch loss 0.289297 epoch total loss 0.282111049\n",
      "Trained batch 295 batch loss 0.278532088 epoch total loss 0.282098919\n",
      "Trained batch 296 batch loss 0.264980406 epoch total loss 0.282041103\n",
      "Trained batch 297 batch loss 0.252848387 epoch total loss 0.281942815\n",
      "Trained batch 298 batch loss 0.255708903 epoch total loss 0.281854779\n",
      "Trained batch 299 batch loss 0.289915353 epoch total loss 0.28188172\n",
      "Trained batch 300 batch loss 0.268697053 epoch total loss 0.281837791\n",
      "Trained batch 301 batch loss 0.293001 epoch total loss 0.281874865\n",
      "Trained batch 302 batch loss 0.295695782 epoch total loss 0.281920642\n",
      "Trained batch 303 batch loss 0.28827998 epoch total loss 0.281941593\n",
      "Trained batch 304 batch loss 0.293758 epoch total loss 0.281980455\n",
      "Trained batch 305 batch loss 0.308075666 epoch total loss 0.282066017\n",
      "Trained batch 306 batch loss 0.29688257 epoch total loss 0.282114446\n",
      "Trained batch 307 batch loss 0.237230539 epoch total loss 0.281968236\n",
      "Trained batch 308 batch loss 0.294305563 epoch total loss 0.28200829\n",
      "Trained batch 309 batch loss 0.24537912 epoch total loss 0.281889737\n",
      "Trained batch 310 batch loss 0.265238583 epoch total loss 0.281836\n",
      "Trained batch 311 batch loss 0.254306316 epoch total loss 0.28174749\n",
      "Trained batch 312 batch loss 0.300774157 epoch total loss 0.281808466\n",
      "Trained batch 313 batch loss 0.27668038 epoch total loss 0.281792074\n",
      "Trained batch 314 batch loss 0.276732117 epoch total loss 0.281775981\n",
      "Trained batch 315 batch loss 0.318966359 epoch total loss 0.281894028\n",
      "Trained batch 316 batch loss 0.296512097 epoch total loss 0.281940281\n",
      "Trained batch 317 batch loss 0.339658648 epoch total loss 0.282122374\n",
      "Trained batch 318 batch loss 0.330405861 epoch total loss 0.282274216\n",
      "Trained batch 319 batch loss 0.355361879 epoch total loss 0.282503337\n",
      "Trained batch 320 batch loss 0.283126414 epoch total loss 0.282505274\n",
      "Trained batch 321 batch loss 0.255197614 epoch total loss 0.282420188\n",
      "Trained batch 322 batch loss 0.280564636 epoch total loss 0.282414436\n",
      "Trained batch 323 batch loss 0.344496459 epoch total loss 0.282606632\n",
      "Trained batch 324 batch loss 0.310968459 epoch total loss 0.282694161\n",
      "Trained batch 325 batch loss 0.280828983 epoch total loss 0.282688439\n",
      "Trained batch 326 batch loss 0.275366694 epoch total loss 0.282665968\n",
      "Trained batch 327 batch loss 0.301095277 epoch total loss 0.282722324\n",
      "Trained batch 328 batch loss 0.345924795 epoch total loss 0.282915026\n",
      "Trained batch 329 batch loss 0.294742882 epoch total loss 0.282951\n",
      "Trained batch 330 batch loss 0.284056485 epoch total loss 0.282954335\n",
      "Trained batch 331 batch loss 0.236382499 epoch total loss 0.282813638\n",
      "Trained batch 332 batch loss 0.265553087 epoch total loss 0.282761663\n",
      "Trained batch 333 batch loss 0.290436208 epoch total loss 0.2827847\n",
      "Trained batch 334 batch loss 0.310277939 epoch total loss 0.282867\n",
      "Trained batch 335 batch loss 0.313563526 epoch total loss 0.282958657\n",
      "Trained batch 336 batch loss 0.293767422 epoch total loss 0.282990813\n",
      "Trained batch 337 batch loss 0.271342844 epoch total loss 0.282956243\n",
      "Trained batch 338 batch loss 0.278454632 epoch total loss 0.282942921\n",
      "Trained batch 339 batch loss 0.276281297 epoch total loss 0.282923281\n",
      "Trained batch 340 batch loss 0.280795187 epoch total loss 0.282917023\n",
      "Trained batch 341 batch loss 0.310968459 epoch total loss 0.282999277\n",
      "Trained batch 342 batch loss 0.301249743 epoch total loss 0.283052623\n",
      "Trained batch 343 batch loss 0.275988519 epoch total loss 0.28303203\n",
      "Trained batch 344 batch loss 0.260989845 epoch total loss 0.282967955\n",
      "Trained batch 345 batch loss 0.267034739 epoch total loss 0.282921761\n",
      "Trained batch 346 batch loss 0.265074193 epoch total loss 0.282870173\n",
      "Trained batch 347 batch loss 0.304400384 epoch total loss 0.282932222\n",
      "Trained batch 348 batch loss 0.273311853 epoch total loss 0.282904595\n",
      "Trained batch 349 batch loss 0.288122177 epoch total loss 0.282919556\n",
      "Trained batch 350 batch loss 0.279820055 epoch total loss 0.282910705\n",
      "Trained batch 351 batch loss 0.270218194 epoch total loss 0.282874525\n",
      "Trained batch 352 batch loss 0.282013029 epoch total loss 0.282872081\n",
      "Trained batch 353 batch loss 0.280241638 epoch total loss 0.28286463\n",
      "Trained batch 354 batch loss 0.281746447 epoch total loss 0.282861471\n",
      "Trained batch 355 batch loss 0.280448884 epoch total loss 0.282854676\n",
      "Trained batch 356 batch loss 0.274645805 epoch total loss 0.282831609\n",
      "Trained batch 357 batch loss 0.275521278 epoch total loss 0.282811135\n",
      "Trained batch 358 batch loss 0.259320676 epoch total loss 0.28274554\n",
      "Trained batch 359 batch loss 0.253420085 epoch total loss 0.282663852\n",
      "Trained batch 360 batch loss 0.277175307 epoch total loss 0.282648593\n",
      "Trained batch 361 batch loss 0.289129257 epoch total loss 0.282666564\n",
      "Trained batch 362 batch loss 0.283875525 epoch total loss 0.282669902\n",
      "Trained batch 363 batch loss 0.297834277 epoch total loss 0.282711685\n",
      "Trained batch 364 batch loss 0.288275629 epoch total loss 0.282726973\n",
      "Trained batch 365 batch loss 0.304037035 epoch total loss 0.282785356\n",
      "Trained batch 366 batch loss 0.300834149 epoch total loss 0.282834649\n",
      "Trained batch 367 batch loss 0.316028476 epoch total loss 0.282925099\n",
      "Trained batch 368 batch loss 0.298409522 epoch total loss 0.28296718\n",
      "Trained batch 369 batch loss 0.318866849 epoch total loss 0.283064485\n",
      "Trained batch 370 batch loss 0.319083452 epoch total loss 0.283161819\n",
      "Trained batch 371 batch loss 0.329024374 epoch total loss 0.283285439\n",
      "Trained batch 372 batch loss 0.316811889 epoch total loss 0.283375561\n",
      "Trained batch 373 batch loss 0.273809701 epoch total loss 0.283349931\n",
      "Trained batch 374 batch loss 0.277107775 epoch total loss 0.283333242\n",
      "Trained batch 375 batch loss 0.294409871 epoch total loss 0.283362776\n",
      "Trained batch 376 batch loss 0.280678689 epoch total loss 0.283355623\n",
      "Trained batch 377 batch loss 0.265983015 epoch total loss 0.283309549\n",
      "Trained batch 378 batch loss 0.299041331 epoch total loss 0.283351183\n",
      "Trained batch 379 batch loss 0.321831197 epoch total loss 0.28345269\n",
      "Trained batch 380 batch loss 0.290656179 epoch total loss 0.283471674\n",
      "Trained batch 381 batch loss 0.276224971 epoch total loss 0.28345263\n",
      "Trained batch 382 batch loss 0.288272828 epoch total loss 0.283465236\n",
      "Trained batch 383 batch loss 0.259695709 epoch total loss 0.283403188\n",
      "Trained batch 384 batch loss 0.277892709 epoch total loss 0.283388823\n",
      "Trained batch 385 batch loss 0.267091602 epoch total loss 0.283346504\n",
      "Trained batch 386 batch loss 0.266115397 epoch total loss 0.28330186\n",
      "Trained batch 387 batch loss 0.24447307 epoch total loss 0.283201516\n",
      "Trained batch 388 batch loss 0.24309282 epoch total loss 0.283098161\n",
      "Trained batch 389 batch loss 0.279316187 epoch total loss 0.283088446\n",
      "Trained batch 390 batch loss 0.300391734 epoch total loss 0.283132821\n",
      "Trained batch 391 batch loss 0.286398053 epoch total loss 0.283141166\n",
      "Trained batch 392 batch loss 0.29889065 epoch total loss 0.28318134\n",
      "Trained batch 393 batch loss 0.290707111 epoch total loss 0.283200502\n",
      "Trained batch 394 batch loss 0.275462031 epoch total loss 0.283180863\n",
      "Trained batch 395 batch loss 0.289363801 epoch total loss 0.283196509\n",
      "Trained batch 396 batch loss 0.279201388 epoch total loss 0.283186406\n",
      "Trained batch 397 batch loss 0.271655321 epoch total loss 0.283157349\n",
      "Trained batch 398 batch loss 0.268259346 epoch total loss 0.283119917\n",
      "Trained batch 399 batch loss 0.292598575 epoch total loss 0.283143669\n",
      "Trained batch 400 batch loss 0.31388706 epoch total loss 0.28322053\n",
      "Trained batch 401 batch loss 0.312087506 epoch total loss 0.283292502\n",
      "Trained batch 402 batch loss 0.326291174 epoch total loss 0.283399463\n",
      "Trained batch 403 batch loss 0.320011139 epoch total loss 0.28349033\n",
      "Trained batch 404 batch loss 0.293314457 epoch total loss 0.283514619\n",
      "Trained batch 405 batch loss 0.312604278 epoch total loss 0.283586472\n",
      "Trained batch 406 batch loss 0.296441197 epoch total loss 0.283618122\n",
      "Trained batch 407 batch loss 0.274934262 epoch total loss 0.283596784\n",
      "Trained batch 408 batch loss 0.296234 epoch total loss 0.283627748\n",
      "Trained batch 409 batch loss 0.26055342 epoch total loss 0.283571333\n",
      "Trained batch 410 batch loss 0.260851026 epoch total loss 0.2835159\n",
      "Trained batch 411 batch loss 0.268654 epoch total loss 0.28347975\n",
      "Trained batch 412 batch loss 0.280260742 epoch total loss 0.283471942\n",
      "Trained batch 413 batch loss 0.257171452 epoch total loss 0.283408254\n",
      "Trained batch 414 batch loss 0.287231117 epoch total loss 0.283417493\n",
      "Trained batch 415 batch loss 0.287739038 epoch total loss 0.283427894\n",
      "Trained batch 416 batch loss 0.317234218 epoch total loss 0.283509195\n",
      "Trained batch 417 batch loss 0.300986588 epoch total loss 0.283551097\n",
      "Trained batch 418 batch loss 0.307002 epoch total loss 0.283607185\n",
      "Trained batch 419 batch loss 0.282633573 epoch total loss 0.28360486\n",
      "Trained batch 420 batch loss 0.311993957 epoch total loss 0.283672452\n",
      "Trained batch 421 batch loss 0.283675969 epoch total loss 0.283672482\n",
      "Trained batch 422 batch loss 0.329493612 epoch total loss 0.283781052\n",
      "Trained batch 423 batch loss 0.313966334 epoch total loss 0.283852398\n",
      "Trained batch 424 batch loss 0.304116428 epoch total loss 0.283900201\n",
      "Trained batch 425 batch loss 0.294698894 epoch total loss 0.283925593\n",
      "Trained batch 426 batch loss 0.292929292 epoch total loss 0.283946753\n",
      "Trained batch 427 batch loss 0.317854255 epoch total loss 0.284026146\n",
      "Trained batch 428 batch loss 0.291336596 epoch total loss 0.284043223\n",
      "Trained batch 429 batch loss 0.302439213 epoch total loss 0.284086108\n",
      "Trained batch 430 batch loss 0.297976434 epoch total loss 0.284118414\n",
      "Trained batch 431 batch loss 0.255494297 epoch total loss 0.284051985\n",
      "Trained batch 432 batch loss 0.268180728 epoch total loss 0.284015238\n",
      "Trained batch 433 batch loss 0.276195049 epoch total loss 0.283997178\n",
      "Trained batch 434 batch loss 0.315281749 epoch total loss 0.28406927\n",
      "Trained batch 435 batch loss 0.311108291 epoch total loss 0.284131438\n",
      "Trained batch 436 batch loss 0.284313709 epoch total loss 0.284131855\n",
      "Trained batch 437 batch loss 0.254598886 epoch total loss 0.284064293\n",
      "Trained batch 438 batch loss 0.269687682 epoch total loss 0.284031481\n",
      "Trained batch 439 batch loss 0.285796 epoch total loss 0.284035504\n",
      "Trained batch 440 batch loss 0.324763 epoch total loss 0.28412804\n",
      "Trained batch 441 batch loss 0.294058889 epoch total loss 0.284150571\n",
      "Trained batch 442 batch loss 0.298308 epoch total loss 0.284182608\n",
      "Trained batch 443 batch loss 0.319129735 epoch total loss 0.284261495\n",
      "Trained batch 444 batch loss 0.278932899 epoch total loss 0.284249485\n",
      "Trained batch 445 batch loss 0.304627776 epoch total loss 0.284295291\n",
      "Trained batch 446 batch loss 0.300778329 epoch total loss 0.284332246\n",
      "Trained batch 447 batch loss 0.25331 epoch total loss 0.284262836\n",
      "Trained batch 448 batch loss 0.289703846 epoch total loss 0.284275\n",
      "Trained batch 449 batch loss 0.289802045 epoch total loss 0.284287304\n",
      "Trained batch 450 batch loss 0.292312622 epoch total loss 0.284305125\n",
      "Trained batch 451 batch loss 0.286092579 epoch total loss 0.284309089\n",
      "Trained batch 452 batch loss 0.295927733 epoch total loss 0.284334809\n",
      "Trained batch 453 batch loss 0.296775758 epoch total loss 0.284362257\n",
      "Trained batch 454 batch loss 0.302956551 epoch total loss 0.284403235\n",
      "Trained batch 455 batch loss 0.300593346 epoch total loss 0.284438819\n",
      "Trained batch 456 batch loss 0.280030698 epoch total loss 0.284429163\n",
      "Trained batch 457 batch loss 0.284972042 epoch total loss 0.284430325\n",
      "Trained batch 458 batch loss 0.285341173 epoch total loss 0.284432322\n",
      "Trained batch 459 batch loss 0.276009977 epoch total loss 0.284414\n",
      "Trained batch 460 batch loss 0.282574087 epoch total loss 0.28441\n",
      "Trained batch 461 batch loss 0.307461262 epoch total loss 0.28446\n",
      "Trained batch 462 batch loss 0.280235678 epoch total loss 0.284450889\n",
      "Trained batch 463 batch loss 0.280763179 epoch total loss 0.284442902\n",
      "Trained batch 464 batch loss 0.320635706 epoch total loss 0.284520894\n",
      "Trained batch 465 batch loss 0.290323973 epoch total loss 0.284533381\n",
      "Trained batch 466 batch loss 0.317728192 epoch total loss 0.284604639\n",
      "Trained batch 467 batch loss 0.30284 epoch total loss 0.28464368\n",
      "Trained batch 468 batch loss 0.286652625 epoch total loss 0.284647971\n",
      "Trained batch 469 batch loss 0.264371693 epoch total loss 0.284604758\n",
      "Trained batch 470 batch loss 0.272677958 epoch total loss 0.284579366\n",
      "Trained batch 471 batch loss 0.290285438 epoch total loss 0.284591466\n",
      "Trained batch 472 batch loss 0.298208922 epoch total loss 0.284620315\n",
      "Trained batch 473 batch loss 0.318794966 epoch total loss 0.284692585\n",
      "Trained batch 474 batch loss 0.312333077 epoch total loss 0.284750909\n",
      "Trained batch 475 batch loss 0.266739786 epoch total loss 0.28471297\n",
      "Trained batch 476 batch loss 0.270981073 epoch total loss 0.284684122\n",
      "Trained batch 477 batch loss 0.27050221 epoch total loss 0.284654409\n",
      "Trained batch 478 batch loss 0.305132896 epoch total loss 0.284697235\n",
      "Trained batch 479 batch loss 0.282143116 epoch total loss 0.28469193\n",
      "Trained batch 480 batch loss 0.318963706 epoch total loss 0.284763336\n",
      "Trained batch 481 batch loss 0.287786633 epoch total loss 0.284769595\n",
      "Trained batch 482 batch loss 0.274353355 epoch total loss 0.284748\n",
      "Trained batch 483 batch loss 0.31121403 epoch total loss 0.284802794\n",
      "Trained batch 484 batch loss 0.294315815 epoch total loss 0.284822434\n",
      "Trained batch 485 batch loss 0.318051815 epoch total loss 0.28489098\n",
      "Trained batch 486 batch loss 0.281987876 epoch total loss 0.284885\n",
      "Trained batch 487 batch loss 0.261842519 epoch total loss 0.284837663\n",
      "Trained batch 488 batch loss 0.242528647 epoch total loss 0.284750968\n",
      "Trained batch 489 batch loss 0.256347805 epoch total loss 0.284692883\n",
      "Trained batch 490 batch loss 0.294022173 epoch total loss 0.284711897\n",
      "Trained batch 491 batch loss 0.272338152 epoch total loss 0.284686714\n",
      "Trained batch 492 batch loss 0.276122898 epoch total loss 0.28466931\n",
      "Trained batch 493 batch loss 0.278217137 epoch total loss 0.284656197\n",
      "Trained batch 494 batch loss 0.310456157 epoch total loss 0.28470844\n",
      "Trained batch 495 batch loss 0.307690352 epoch total loss 0.284754872\n",
      "Trained batch 496 batch loss 0.281268239 epoch total loss 0.284747839\n",
      "Trained batch 497 batch loss 0.335844487 epoch total loss 0.284850657\n",
      "Trained batch 498 batch loss 0.343668371 epoch total loss 0.284968764\n",
      "Trained batch 499 batch loss 0.307777941 epoch total loss 0.28501448\n",
      "Trained batch 500 batch loss 0.285548329 epoch total loss 0.285015553\n",
      "Trained batch 501 batch loss 0.28439492 epoch total loss 0.285014331\n",
      "Trained batch 502 batch loss 0.238215476 epoch total loss 0.28492111\n",
      "Trained batch 503 batch loss 0.241303176 epoch total loss 0.284834385\n",
      "Trained batch 504 batch loss 0.274927735 epoch total loss 0.284814745\n",
      "Trained batch 505 batch loss 0.292830288 epoch total loss 0.28483063\n",
      "Trained batch 506 batch loss 0.294133902 epoch total loss 0.284849\n",
      "Trained batch 507 batch loss 0.294520497 epoch total loss 0.284868091\n",
      "Trained batch 508 batch loss 0.305402428 epoch total loss 0.284908503\n",
      "Trained batch 509 batch loss 0.297801912 epoch total loss 0.284933835\n",
      "Trained batch 510 batch loss 0.277826279 epoch total loss 0.284919918\n",
      "Trained batch 511 batch loss 0.283349305 epoch total loss 0.284916848\n",
      "Trained batch 512 batch loss 0.301905483 epoch total loss 0.284950048\n",
      "Trained batch 513 batch loss 0.267210275 epoch total loss 0.284915477\n",
      "Trained batch 514 batch loss 0.258327842 epoch total loss 0.28486374\n",
      "Trained batch 515 batch loss 0.205168843 epoch total loss 0.284709\n",
      "Trained batch 516 batch loss 0.261535853 epoch total loss 0.284664094\n",
      "Trained batch 517 batch loss 0.292031407 epoch total loss 0.28467837\n",
      "Trained batch 518 batch loss 0.290966362 epoch total loss 0.284690499\n",
      "Trained batch 519 batch loss 0.310718536 epoch total loss 0.284740657\n",
      "Trained batch 520 batch loss 0.31672138 epoch total loss 0.284802169\n",
      "Trained batch 521 batch loss 0.292404532 epoch total loss 0.284816742\n",
      "Trained batch 522 batch loss 0.302162409 epoch total loss 0.28485\n",
      "Trained batch 523 batch loss 0.329550952 epoch total loss 0.284935445\n",
      "Trained batch 524 batch loss 0.304431349 epoch total loss 0.284972638\n",
      "Trained batch 525 batch loss 0.30926156 epoch total loss 0.285018921\n",
      "Trained batch 526 batch loss 0.312373817 epoch total loss 0.285070926\n",
      "Trained batch 527 batch loss 0.28058058 epoch total loss 0.285062402\n",
      "Trained batch 528 batch loss 0.287572652 epoch total loss 0.285067141\n",
      "Trained batch 529 batch loss 0.282988101 epoch total loss 0.285063237\n",
      "Trained batch 530 batch loss 0.288260043 epoch total loss 0.285069257\n",
      "Trained batch 531 batch loss 0.290554911 epoch total loss 0.285079569\n",
      "Trained batch 532 batch loss 0.287281036 epoch total loss 0.285083711\n",
      "Trained batch 533 batch loss 0.230594411 epoch total loss 0.284981489\n",
      "Trained batch 534 batch loss 0.250027418 epoch total loss 0.284916\n",
      "Trained batch 535 batch loss 0.221161589 epoch total loss 0.284796864\n",
      "Trained batch 536 batch loss 0.312931687 epoch total loss 0.284849346\n",
      "Trained batch 537 batch loss 0.352047145 epoch total loss 0.284974486\n",
      "Trained batch 538 batch loss 0.3381899 epoch total loss 0.2850734\n",
      "Trained batch 539 batch loss 0.318329185 epoch total loss 0.28513509\n",
      "Trained batch 540 batch loss 0.300619185 epoch total loss 0.28516376\n",
      "Trained batch 541 batch loss 0.338266253 epoch total loss 0.285261929\n",
      "Trained batch 542 batch loss 0.303260416 epoch total loss 0.285295129\n",
      "Trained batch 543 batch loss 0.314118922 epoch total loss 0.285348207\n",
      "Trained batch 544 batch loss 0.29207471 epoch total loss 0.285360575\n",
      "Trained batch 545 batch loss 0.267082632 epoch total loss 0.285327047\n",
      "Trained batch 546 batch loss 0.263740927 epoch total loss 0.285287529\n",
      "Trained batch 547 batch loss 0.24858132 epoch total loss 0.285220414\n",
      "Trained batch 548 batch loss 0.235763282 epoch total loss 0.285130173\n",
      "Trained batch 549 batch loss 0.269944847 epoch total loss 0.285102487\n",
      "Trained batch 550 batch loss 0.289147049 epoch total loss 0.285109878\n",
      "Trained batch 551 batch loss 0.343027294 epoch total loss 0.285215\n",
      "Trained batch 552 batch loss 0.322343439 epoch total loss 0.285282254\n",
      "Trained batch 553 batch loss 0.316761434 epoch total loss 0.285339177\n",
      "Trained batch 554 batch loss 0.323434651 epoch total loss 0.285407931\n",
      "Trained batch 555 batch loss 0.296315968 epoch total loss 0.28542757\n",
      "Trained batch 556 batch loss 0.257821262 epoch total loss 0.285377949\n",
      "Trained batch 557 batch loss 0.270362407 epoch total loss 0.285350978\n",
      "Trained batch 558 batch loss 0.269873798 epoch total loss 0.285323232\n",
      "Trained batch 559 batch loss 0.289140016 epoch total loss 0.285330057\n",
      "Trained batch 560 batch loss 0.269439906 epoch total loss 0.285301685\n",
      "Trained batch 561 batch loss 0.287952185 epoch total loss 0.285306394\n",
      "Trained batch 562 batch loss 0.298787475 epoch total loss 0.285330355\n",
      "Trained batch 563 batch loss 0.300387442 epoch total loss 0.285357118\n",
      "Trained batch 564 batch loss 0.272851 epoch total loss 0.285334945\n",
      "Trained batch 565 batch loss 0.282335162 epoch total loss 0.28532964\n",
      "Trained batch 566 batch loss 0.309990972 epoch total loss 0.285373211\n",
      "Trained batch 567 batch loss 0.306895673 epoch total loss 0.285411179\n",
      "Trained batch 568 batch loss 0.29322502 epoch total loss 0.285424948\n",
      "Trained batch 569 batch loss 0.268759459 epoch total loss 0.285395652\n",
      "Trained batch 570 batch loss 0.294961542 epoch total loss 0.285412431\n",
      "Trained batch 571 batch loss 0.282096207 epoch total loss 0.285406619\n",
      "Trained batch 572 batch loss 0.257639825 epoch total loss 0.285358071\n",
      "Trained batch 573 batch loss 0.282714784 epoch total loss 0.285353482\n",
      "Trained batch 574 batch loss 0.264898568 epoch total loss 0.285317808\n",
      "Trained batch 575 batch loss 0.295888841 epoch total loss 0.285336196\n",
      "Trained batch 576 batch loss 0.27587083 epoch total loss 0.285319746\n",
      "Trained batch 577 batch loss 0.269741476 epoch total loss 0.285292745\n",
      "Trained batch 578 batch loss 0.268832058 epoch total loss 0.285264283\n",
      "Trained batch 579 batch loss 0.279197782 epoch total loss 0.285253823\n",
      "Trained batch 580 batch loss 0.287814796 epoch total loss 0.285258234\n",
      "Trained batch 581 batch loss 0.275945544 epoch total loss 0.28524217\n",
      "Trained batch 582 batch loss 0.284917027 epoch total loss 0.285241604\n",
      "Trained batch 583 batch loss 0.276400387 epoch total loss 0.285226434\n",
      "Trained batch 584 batch loss 0.30843839 epoch total loss 0.285266191\n",
      "Trained batch 585 batch loss 0.29564181 epoch total loss 0.285283923\n",
      "Trained batch 586 batch loss 0.296568543 epoch total loss 0.285303175\n",
      "Trained batch 587 batch loss 0.287565172 epoch total loss 0.28530705\n",
      "Trained batch 588 batch loss 0.282341212 epoch total loss 0.285302\n",
      "Trained batch 589 batch loss 0.287150443 epoch total loss 0.285305172\n",
      "Trained batch 590 batch loss 0.313992679 epoch total loss 0.28535378\n",
      "Trained batch 591 batch loss 0.329351574 epoch total loss 0.285428226\n",
      "Trained batch 592 batch loss 0.355597973 epoch total loss 0.28554675\n",
      "Trained batch 593 batch loss 0.271933407 epoch total loss 0.285523772\n",
      "Trained batch 594 batch loss 0.295514137 epoch total loss 0.285540611\n",
      "Trained batch 595 batch loss 0.277829349 epoch total loss 0.285527647\n",
      "Trained batch 596 batch loss 0.281515211 epoch total loss 0.285520911\n",
      "Trained batch 597 batch loss 0.293864101 epoch total loss 0.285534889\n",
      "Trained batch 598 batch loss 0.320684612 epoch total loss 0.285593659\n",
      "Trained batch 599 batch loss 0.317911595 epoch total loss 0.285647601\n",
      "Trained batch 600 batch loss 0.331365347 epoch total loss 0.285723805\n",
      "Trained batch 601 batch loss 0.307831317 epoch total loss 0.285760581\n",
      "Trained batch 602 batch loss 0.330810845 epoch total loss 0.285835415\n",
      "Trained batch 603 batch loss 0.334091961 epoch total loss 0.285915434\n",
      "Trained batch 604 batch loss 0.321396291 epoch total loss 0.285974175\n",
      "Trained batch 605 batch loss 0.318441272 epoch total loss 0.286027849\n",
      "Trained batch 606 batch loss 0.304368615 epoch total loss 0.286058098\n",
      "Trained batch 607 batch loss 0.281474948 epoch total loss 0.286050558\n",
      "Trained batch 608 batch loss 0.268539846 epoch total loss 0.286021769\n",
      "Trained batch 609 batch loss 0.236427918 epoch total loss 0.285940349\n",
      "Trained batch 610 batch loss 0.266112298 epoch total loss 0.285907835\n",
      "Trained batch 611 batch loss 0.267643362 epoch total loss 0.285877943\n",
      "Trained batch 612 batch loss 0.275153369 epoch total loss 0.285860389\n",
      "Trained batch 613 batch loss 0.26754725 epoch total loss 0.285830528\n",
      "Trained batch 614 batch loss 0.258938402 epoch total loss 0.285786718\n",
      "Trained batch 615 batch loss 0.284011602 epoch total loss 0.285783857\n",
      "Trained batch 616 batch loss 0.287614137 epoch total loss 0.285786808\n",
      "Trained batch 617 batch loss 0.271227837 epoch total loss 0.285763204\n",
      "Trained batch 618 batch loss 0.298222184 epoch total loss 0.28578338\n",
      "Trained batch 619 batch loss 0.244724452 epoch total loss 0.28571704\n",
      "Trained batch 620 batch loss 0.275532097 epoch total loss 0.285700589\n",
      "Trained batch 621 batch loss 0.258263975 epoch total loss 0.285656422\n",
      "Trained batch 622 batch loss 0.268331349 epoch total loss 0.285628557\n",
      "Trained batch 623 batch loss 0.297013283 epoch total loss 0.285646826\n",
      "Trained batch 624 batch loss 0.347213537 epoch total loss 0.285745502\n",
      "Trained batch 625 batch loss 0.324704707 epoch total loss 0.285807848\n",
      "Trained batch 626 batch loss 0.29286927 epoch total loss 0.285819113\n",
      "Trained batch 627 batch loss 0.284159958 epoch total loss 0.285816461\n",
      "Trained batch 628 batch loss 0.24919796 epoch total loss 0.285758138\n",
      "Trained batch 629 batch loss 0.291232914 epoch total loss 0.28576684\n",
      "Trained batch 630 batch loss 0.313185781 epoch total loss 0.285810381\n",
      "Trained batch 631 batch loss 0.314066708 epoch total loss 0.285855144\n",
      "Trained batch 632 batch loss 0.312981188 epoch total loss 0.285898089\n",
      "Trained batch 633 batch loss 0.260045588 epoch total loss 0.28585723\n",
      "Trained batch 634 batch loss 0.273654163 epoch total loss 0.285837978\n",
      "Trained batch 635 batch loss 0.264814794 epoch total loss 0.285804868\n",
      "Trained batch 636 batch loss 0.279752403 epoch total loss 0.285795361\n",
      "Trained batch 637 batch loss 0.305263638 epoch total loss 0.285825938\n",
      "Trained batch 638 batch loss 0.30565834 epoch total loss 0.285857022\n",
      "Trained batch 639 batch loss 0.300746232 epoch total loss 0.285880327\n",
      "Trained batch 640 batch loss 0.282549441 epoch total loss 0.285875142\n",
      "Trained batch 641 batch loss 0.294335216 epoch total loss 0.285888344\n",
      "Trained batch 642 batch loss 0.279634625 epoch total loss 0.285878599\n",
      "Trained batch 643 batch loss 0.282925159 epoch total loss 0.285874\n",
      "Trained batch 644 batch loss 0.251220435 epoch total loss 0.285820186\n",
      "Trained batch 645 batch loss 0.289247572 epoch total loss 0.285825521\n",
      "Trained batch 646 batch loss 0.271258563 epoch total loss 0.28580296\n",
      "Trained batch 647 batch loss 0.292783171 epoch total loss 0.285813749\n",
      "Trained batch 648 batch loss 0.290504247 epoch total loss 0.285820961\n",
      "Trained batch 649 batch loss 0.277111948 epoch total loss 0.28580755\n",
      "Trained batch 650 batch loss 0.245161161 epoch total loss 0.285745025\n",
      "Trained batch 651 batch loss 0.256759733 epoch total loss 0.2857005\n",
      "Trained batch 652 batch loss 0.265154958 epoch total loss 0.285669\n",
      "Trained batch 653 batch loss 0.261721909 epoch total loss 0.285632312\n",
      "Trained batch 654 batch loss 0.274029732 epoch total loss 0.28561458\n",
      "Trained batch 655 batch loss 0.268165648 epoch total loss 0.285587937\n",
      "Trained batch 656 batch loss 0.277457803 epoch total loss 0.285575539\n",
      "Trained batch 657 batch loss 0.317503273 epoch total loss 0.285624146\n",
      "Trained batch 658 batch loss 0.316435486 epoch total loss 0.285670966\n",
      "Trained batch 659 batch loss 0.310988307 epoch total loss 0.285709381\n",
      "Trained batch 660 batch loss 0.297320575 epoch total loss 0.285726964\n",
      "Trained batch 661 batch loss 0.267528445 epoch total loss 0.285699457\n",
      "Trained batch 662 batch loss 0.289187461 epoch total loss 0.285704702\n",
      "Trained batch 663 batch loss 0.255541146 epoch total loss 0.285659224\n",
      "Trained batch 664 batch loss 0.255348474 epoch total loss 0.285613567\n",
      "Trained batch 665 batch loss 0.256475151 epoch total loss 0.285569757\n",
      "Trained batch 666 batch loss 0.305787563 epoch total loss 0.285600096\n",
      "Trained batch 667 batch loss 0.314359903 epoch total loss 0.28564322\n",
      "Trained batch 668 batch loss 0.274353147 epoch total loss 0.285626322\n",
      "Trained batch 669 batch loss 0.264183819 epoch total loss 0.285594285\n",
      "Trained batch 670 batch loss 0.286100775 epoch total loss 0.28559503\n",
      "Trained batch 671 batch loss 0.286554754 epoch total loss 0.28559649\n",
      "Trained batch 672 batch loss 0.245768771 epoch total loss 0.285537213\n",
      "Trained batch 673 batch loss 0.280554295 epoch total loss 0.285529792\n",
      "Trained batch 674 batch loss 0.312426269 epoch total loss 0.285569698\n",
      "Trained batch 675 batch loss 0.282591373 epoch total loss 0.285565287\n",
      "Trained batch 676 batch loss 0.296360016 epoch total loss 0.285581261\n",
      "Trained batch 677 batch loss 0.305891275 epoch total loss 0.285611272\n",
      "Trained batch 678 batch loss 0.321290404 epoch total loss 0.285663873\n",
      "Trained batch 679 batch loss 0.274604142 epoch total loss 0.285647601\n",
      "Trained batch 680 batch loss 0.291682154 epoch total loss 0.285656482\n",
      "Trained batch 681 batch loss 0.244581342 epoch total loss 0.285596162\n",
      "Trained batch 682 batch loss 0.241246641 epoch total loss 0.285531133\n",
      "Trained batch 683 batch loss 0.233818382 epoch total loss 0.285455406\n",
      "Trained batch 684 batch loss 0.247647509 epoch total loss 0.285400152\n",
      "Trained batch 685 batch loss 0.215783522 epoch total loss 0.285298526\n",
      "Trained batch 686 batch loss 0.215196908 epoch total loss 0.285196334\n",
      "Trained batch 687 batch loss 0.218656167 epoch total loss 0.285099477\n",
      "Trained batch 688 batch loss 0.207024783 epoch total loss 0.284986019\n",
      "Trained batch 689 batch loss 0.242187738 epoch total loss 0.284923881\n",
      "Trained batch 690 batch loss 0.271037251 epoch total loss 0.284903765\n",
      "Trained batch 691 batch loss 0.263169795 epoch total loss 0.284872323\n",
      "Trained batch 692 batch loss 0.27079162 epoch total loss 0.284851968\n",
      "Trained batch 693 batch loss 0.257411748 epoch total loss 0.284812391\n",
      "Trained batch 694 batch loss 0.281196952 epoch total loss 0.284807175\n",
      "Trained batch 695 batch loss 0.239957869 epoch total loss 0.284742653\n",
      "Trained batch 696 batch loss 0.262968451 epoch total loss 0.284711391\n",
      "Trained batch 697 batch loss 0.265662879 epoch total loss 0.284684032\n",
      "Trained batch 698 batch loss 0.269572288 epoch total loss 0.284662396\n",
      "Trained batch 699 batch loss 0.278990299 epoch total loss 0.284654289\n",
      "Trained batch 700 batch loss 0.298663616 epoch total loss 0.284674287\n",
      "Trained batch 701 batch loss 0.311567426 epoch total loss 0.284712642\n",
      "Trained batch 702 batch loss 0.307471901 epoch total loss 0.284745067\n",
      "Trained batch 703 batch loss 0.284383327 epoch total loss 0.284744531\n",
      "Trained batch 704 batch loss 0.278141171 epoch total loss 0.284735173\n",
      "Trained batch 705 batch loss 0.276113838 epoch total loss 0.284722924\n",
      "Trained batch 706 batch loss 0.284191549 epoch total loss 0.284722179\n",
      "Trained batch 707 batch loss 0.292326391 epoch total loss 0.284732938\n",
      "Trained batch 708 batch loss 0.315802306 epoch total loss 0.284776807\n",
      "Trained batch 709 batch loss 0.303613 epoch total loss 0.284803391\n",
      "Trained batch 710 batch loss 0.294219643 epoch total loss 0.284816653\n",
      "Trained batch 711 batch loss 0.275491387 epoch total loss 0.28480354\n",
      "Trained batch 712 batch loss 0.316344351 epoch total loss 0.284847826\n",
      "Trained batch 713 batch loss 0.331781626 epoch total loss 0.284913659\n",
      "Trained batch 714 batch loss 0.295687646 epoch total loss 0.284928769\n",
      "Trained batch 715 batch loss 0.280607969 epoch total loss 0.284922719\n",
      "Trained batch 716 batch loss 0.275244832 epoch total loss 0.284909189\n",
      "Trained batch 717 batch loss 0.264552 epoch total loss 0.284880817\n",
      "Trained batch 718 batch loss 0.244520158 epoch total loss 0.28482458\n",
      "Trained batch 719 batch loss 0.284466475 epoch total loss 0.284824103\n",
      "Trained batch 720 batch loss 0.276458859 epoch total loss 0.28481248\n",
      "Trained batch 721 batch loss 0.298327923 epoch total loss 0.284831226\n",
      "Trained batch 722 batch loss 0.305774152 epoch total loss 0.284860224\n",
      "Trained batch 723 batch loss 0.324714184 epoch total loss 0.284915328\n",
      "Trained batch 724 batch loss 0.321123362 epoch total loss 0.284965336\n",
      "Trained batch 725 batch loss 0.297342479 epoch total loss 0.284982413\n",
      "Trained batch 726 batch loss 0.303421468 epoch total loss 0.285007834\n",
      "Trained batch 727 batch loss 0.276119441 epoch total loss 0.284995615\n",
      "Trained batch 728 batch loss 0.29720968 epoch total loss 0.285012394\n",
      "Trained batch 729 batch loss 0.274366677 epoch total loss 0.284997791\n",
      "Trained batch 730 batch loss 0.276180148 epoch total loss 0.284985721\n",
      "Trained batch 731 batch loss 0.281994849 epoch total loss 0.284981608\n",
      "Trained batch 732 batch loss 0.284714788 epoch total loss 0.284981251\n",
      "Trained batch 733 batch loss 0.287869513 epoch total loss 0.284985185\n",
      "Trained batch 734 batch loss 0.263710082 epoch total loss 0.284956217\n",
      "Trained batch 735 batch loss 0.277141392 epoch total loss 0.284945607\n",
      "Trained batch 736 batch loss 0.27501449 epoch total loss 0.284932107\n",
      "Trained batch 737 batch loss 0.266724318 epoch total loss 0.284907401\n",
      "Trained batch 738 batch loss 0.242659405 epoch total loss 0.28485015\n",
      "Trained batch 739 batch loss 0.245390594 epoch total loss 0.284796745\n",
      "Trained batch 740 batch loss 0.2844235 epoch total loss 0.284796238\n",
      "Trained batch 741 batch loss 0.325165659 epoch total loss 0.284850717\n",
      "Trained batch 742 batch loss 0.312872767 epoch total loss 0.284888476\n",
      "Trained batch 743 batch loss 0.303743899 epoch total loss 0.284913868\n",
      "Trained batch 744 batch loss 0.318714589 epoch total loss 0.284959286\n",
      "Trained batch 745 batch loss 0.289110869 epoch total loss 0.284964859\n",
      "Trained batch 746 batch loss 0.314969122 epoch total loss 0.285005063\n",
      "Trained batch 747 batch loss 0.299124867 epoch total loss 0.285023957\n",
      "Trained batch 748 batch loss 0.322559237 epoch total loss 0.285074145\n",
      "Trained batch 749 batch loss 0.283396304 epoch total loss 0.285071909\n",
      "Trained batch 750 batch loss 0.268462867 epoch total loss 0.285049766\n",
      "Trained batch 751 batch loss 0.264855802 epoch total loss 0.285022885\n",
      "Trained batch 752 batch loss 0.256745368 epoch total loss 0.284985274\n",
      "Trained batch 753 batch loss 0.238654658 epoch total loss 0.284923732\n",
      "Trained batch 754 batch loss 0.267234355 epoch total loss 0.284900278\n",
      "Trained batch 755 batch loss 0.289711833 epoch total loss 0.284906656\n",
      "Trained batch 756 batch loss 0.286046714 epoch total loss 0.284908146\n",
      "Trained batch 757 batch loss 0.329273582 epoch total loss 0.284966767\n",
      "Trained batch 758 batch loss 0.304694831 epoch total loss 0.284992784\n",
      "Trained batch 759 batch loss 0.285580158 epoch total loss 0.284993559\n",
      "Trained batch 760 batch loss 0.318329334 epoch total loss 0.285037398\n",
      "Trained batch 761 batch loss 0.291508794 epoch total loss 0.285045922\n",
      "Trained batch 762 batch loss 0.305064797 epoch total loss 0.285072178\n",
      "Trained batch 763 batch loss 0.274127722 epoch total loss 0.285057843\n",
      "Trained batch 764 batch loss 0.276883066 epoch total loss 0.285047144\n",
      "Trained batch 765 batch loss 0.315628856 epoch total loss 0.285087109\n",
      "Trained batch 766 batch loss 0.296338767 epoch total loss 0.285101801\n",
      "Trained batch 767 batch loss 0.271981299 epoch total loss 0.285084724\n",
      "Trained batch 768 batch loss 0.250313 epoch total loss 0.285039455\n",
      "Trained batch 769 batch loss 0.284875333 epoch total loss 0.285039246\n",
      "Trained batch 770 batch loss 0.311635643 epoch total loss 0.285073787\n",
      "Trained batch 771 batch loss 0.313560098 epoch total loss 0.285110712\n",
      "Trained batch 772 batch loss 0.293895483 epoch total loss 0.285122097\n",
      "Trained batch 773 batch loss 0.276144683 epoch total loss 0.285110474\n",
      "Trained batch 774 batch loss 0.301942 epoch total loss 0.285132229\n",
      "Trained batch 775 batch loss 0.278891355 epoch total loss 0.285124153\n",
      "Trained batch 776 batch loss 0.270395726 epoch total loss 0.285105199\n",
      "Trained batch 777 batch loss 0.252410293 epoch total loss 0.285063118\n",
      "Trained batch 778 batch loss 0.298488349 epoch total loss 0.285080373\n",
      "Trained batch 779 batch loss 0.30319494 epoch total loss 0.285103619\n",
      "Trained batch 780 batch loss 0.305781245 epoch total loss 0.285130143\n",
      "Trained batch 781 batch loss 0.267792314 epoch total loss 0.28510794\n",
      "Trained batch 782 batch loss 0.271162242 epoch total loss 0.285090089\n",
      "Trained batch 783 batch loss 0.266758 epoch total loss 0.285066694\n",
      "Trained batch 784 batch loss 0.259446412 epoch total loss 0.285034\n",
      "Trained batch 785 batch loss 0.26384446 epoch total loss 0.285007\n",
      "Trained batch 786 batch loss 0.264502227 epoch total loss 0.284980923\n",
      "Trained batch 787 batch loss 0.253375977 epoch total loss 0.284940749\n",
      "Trained batch 788 batch loss 0.279607892 epoch total loss 0.284933984\n",
      "Trained batch 789 batch loss 0.246695131 epoch total loss 0.284885496\n",
      "Trained batch 790 batch loss 0.26927653 epoch total loss 0.284865737\n",
      "Trained batch 791 batch loss 0.258312255 epoch total loss 0.28483218\n",
      "Trained batch 792 batch loss 0.266061962 epoch total loss 0.284808487\n",
      "Trained batch 793 batch loss 0.264711261 epoch total loss 0.284783125\n",
      "Trained batch 794 batch loss 0.292601496 epoch total loss 0.284793\n",
      "Trained batch 795 batch loss 0.336182892 epoch total loss 0.284857631\n",
      "Trained batch 796 batch loss 0.285658479 epoch total loss 0.284858614\n",
      "Trained batch 797 batch loss 0.289941639 epoch total loss 0.284865022\n",
      "Trained batch 798 batch loss 0.334785283 epoch total loss 0.284927547\n",
      "Trained batch 799 batch loss 0.287187934 epoch total loss 0.284930378\n",
      "Trained batch 800 batch loss 0.303757608 epoch total loss 0.284953922\n",
      "Trained batch 801 batch loss 0.27476871 epoch total loss 0.284941196\n",
      "Trained batch 802 batch loss 0.246977329 epoch total loss 0.28489387\n",
      "Trained batch 803 batch loss 0.284488797 epoch total loss 0.284893364\n",
      "Trained batch 804 batch loss 0.283511788 epoch total loss 0.284891635\n",
      "Trained batch 805 batch loss 0.283864439 epoch total loss 0.284890354\n",
      "Trained batch 806 batch loss 0.302997947 epoch total loss 0.284912825\n",
      "Trained batch 807 batch loss 0.253199697 epoch total loss 0.284873515\n",
      "Trained batch 808 batch loss 0.276319236 epoch total loss 0.284862936\n",
      "Trained batch 809 batch loss 0.270015299 epoch total loss 0.284844577\n",
      "Trained batch 810 batch loss 0.276169449 epoch total loss 0.284833878\n",
      "Trained batch 811 batch loss 0.286704302 epoch total loss 0.284836173\n",
      "Trained batch 812 batch loss 0.292414188 epoch total loss 0.284845501\n",
      "Trained batch 813 batch loss 0.305702269 epoch total loss 0.284871161\n",
      "Trained batch 814 batch loss 0.268125683 epoch total loss 0.284850597\n",
      "Trained batch 815 batch loss 0.282862127 epoch total loss 0.284848183\n",
      "Trained batch 816 batch loss 0.291834444 epoch total loss 0.284856737\n",
      "Trained batch 817 batch loss 0.278234035 epoch total loss 0.28484863\n",
      "Trained batch 818 batch loss 0.297165245 epoch total loss 0.284863681\n",
      "Trained batch 819 batch loss 0.3295331 epoch total loss 0.284918219\n",
      "Trained batch 820 batch loss 0.257377774 epoch total loss 0.284884632\n",
      "Trained batch 821 batch loss 0.290758193 epoch total loss 0.284891784\n",
      "Trained batch 822 batch loss 0.261449665 epoch total loss 0.284863263\n",
      "Trained batch 823 batch loss 0.256561309 epoch total loss 0.284828871\n",
      "Trained batch 824 batch loss 0.279111743 epoch total loss 0.284821957\n",
      "Trained batch 825 batch loss 0.256691635 epoch total loss 0.284787863\n",
      "Trained batch 826 batch loss 0.27450344 epoch total loss 0.284775406\n",
      "Trained batch 827 batch loss 0.304201066 epoch total loss 0.28479889\n",
      "Trained batch 828 batch loss 0.293359816 epoch total loss 0.284809232\n",
      "Trained batch 829 batch loss 0.273797154 epoch total loss 0.28479597\n",
      "Trained batch 830 batch loss 0.320691854 epoch total loss 0.284839213\n",
      "Trained batch 831 batch loss 0.299952477 epoch total loss 0.284857422\n",
      "Trained batch 832 batch loss 0.2582 epoch total loss 0.284825355\n",
      "Trained batch 833 batch loss 0.258559 epoch total loss 0.284793824\n",
      "Trained batch 834 batch loss 0.273169339 epoch total loss 0.284779876\n",
      "Trained batch 835 batch loss 0.271687865 epoch total loss 0.2847642\n",
      "Trained batch 836 batch loss 0.298127174 epoch total loss 0.284780174\n",
      "Trained batch 837 batch loss 0.314471692 epoch total loss 0.284815639\n",
      "Trained batch 838 batch loss 0.305576712 epoch total loss 0.284840435\n",
      "Trained batch 839 batch loss 0.309011191 epoch total loss 0.284869224\n",
      "Trained batch 840 batch loss 0.307876229 epoch total loss 0.284896612\n",
      "Trained batch 841 batch loss 0.299469203 epoch total loss 0.284913927\n",
      "Trained batch 842 batch loss 0.321290612 epoch total loss 0.284957141\n",
      "Trained batch 843 batch loss 0.311743855 epoch total loss 0.28498891\n",
      "Trained batch 844 batch loss 0.340279758 epoch total loss 0.285054415\n",
      "Trained batch 845 batch loss 0.306080282 epoch total loss 0.2850793\n",
      "Trained batch 846 batch loss 0.327604353 epoch total loss 0.285129577\n",
      "Trained batch 847 batch loss 0.282976329 epoch total loss 0.285127044\n",
      "Trained batch 848 batch loss 0.290726691 epoch total loss 0.28513363\n",
      "Trained batch 849 batch loss 0.250010967 epoch total loss 0.285092264\n",
      "Trained batch 850 batch loss 0.255051225 epoch total loss 0.285056919\n",
      "Trained batch 851 batch loss 0.243606672 epoch total loss 0.285008222\n",
      "Trained batch 852 batch loss 0.306874156 epoch total loss 0.285033882\n",
      "Trained batch 853 batch loss 0.311417937 epoch total loss 0.285064816\n",
      "Trained batch 854 batch loss 0.28742528 epoch total loss 0.285067588\n",
      "Trained batch 855 batch loss 0.267967701 epoch total loss 0.285047591\n",
      "Trained batch 856 batch loss 0.294787318 epoch total loss 0.285058945\n",
      "Trained batch 857 batch loss 0.262936175 epoch total loss 0.285033137\n",
      "Trained batch 858 batch loss 0.278263062 epoch total loss 0.285025239\n",
      "Trained batch 859 batch loss 0.272851288 epoch total loss 0.285011083\n",
      "Trained batch 860 batch loss 0.285302579 epoch total loss 0.285011441\n",
      "Trained batch 861 batch loss 0.29109022 epoch total loss 0.285018504\n",
      "Trained batch 862 batch loss 0.300194204 epoch total loss 0.285036117\n",
      "Trained batch 863 batch loss 0.278578341 epoch total loss 0.285028636\n",
      "Trained batch 864 batch loss 0.265486538 epoch total loss 0.285006016\n",
      "Trained batch 865 batch loss 0.267934769 epoch total loss 0.284986258\n",
      "Trained batch 866 batch loss 0.27142176 epoch total loss 0.284970611\n",
      "Trained batch 867 batch loss 0.269850343 epoch total loss 0.284953177\n",
      "Trained batch 868 batch loss 0.268244863 epoch total loss 0.284933925\n",
      "Trained batch 869 batch loss 0.262577653 epoch total loss 0.284908205\n",
      "Trained batch 870 batch loss 0.262158453 epoch total loss 0.284882039\n",
      "Trained batch 871 batch loss 0.276035249 epoch total loss 0.284871876\n",
      "Trained batch 872 batch loss 0.301198393 epoch total loss 0.284890592\n",
      "Trained batch 873 batch loss 0.295199037 epoch total loss 0.284902424\n",
      "Trained batch 874 batch loss 0.284384 epoch total loss 0.284901798\n",
      "Trained batch 875 batch loss 0.276776135 epoch total loss 0.284892529\n",
      "Trained batch 876 batch loss 0.265255421 epoch total loss 0.284870118\n",
      "Trained batch 877 batch loss 0.257518 epoch total loss 0.284838945\n",
      "Trained batch 878 batch loss 0.279003412 epoch total loss 0.284832299\n",
      "Trained batch 879 batch loss 0.278535604 epoch total loss 0.284825116\n",
      "Trained batch 880 batch loss 0.31058836 epoch total loss 0.284854412\n",
      "Trained batch 881 batch loss 0.295174509 epoch total loss 0.284866124\n",
      "Trained batch 882 batch loss 0.300194144 epoch total loss 0.284883499\n",
      "Trained batch 883 batch loss 0.298494339 epoch total loss 0.284898937\n",
      "Trained batch 884 batch loss 0.258185297 epoch total loss 0.284868687\n",
      "Trained batch 885 batch loss 0.283924192 epoch total loss 0.284867615\n",
      "Trained batch 886 batch loss 0.28743273 epoch total loss 0.284870505\n",
      "Trained batch 887 batch loss 0.310934037 epoch total loss 0.28489989\n",
      "Trained batch 888 batch loss 0.279165834 epoch total loss 0.284893423\n",
      "Trained batch 889 batch loss 0.298561931 epoch total loss 0.284908801\n",
      "Trained batch 890 batch loss 0.288504779 epoch total loss 0.284912854\n",
      "Trained batch 891 batch loss 0.296058595 epoch total loss 0.284925342\n",
      "Trained batch 892 batch loss 0.35231179 epoch total loss 0.28500089\n",
      "Trained batch 893 batch loss 0.270844042 epoch total loss 0.284985036\n",
      "Trained batch 894 batch loss 0.288325638 epoch total loss 0.284988791\n",
      "Trained batch 895 batch loss 0.336887091 epoch total loss 0.285046756\n",
      "Trained batch 896 batch loss 0.274565756 epoch total loss 0.285035074\n",
      "Trained batch 897 batch loss 0.278479218 epoch total loss 0.285027742\n",
      "Trained batch 898 batch loss 0.276246697 epoch total loss 0.285017967\n",
      "Trained batch 899 batch loss 0.315063894 epoch total loss 0.285051376\n",
      "Trained batch 900 batch loss 0.325247526 epoch total loss 0.285096049\n",
      "Trained batch 901 batch loss 0.300832272 epoch total loss 0.285113543\n",
      "Trained batch 902 batch loss 0.302520126 epoch total loss 0.285132825\n",
      "Trained batch 903 batch loss 0.292597175 epoch total loss 0.28514111\n",
      "Trained batch 904 batch loss 0.299725 epoch total loss 0.285157233\n",
      "Trained batch 905 batch loss 0.284036607 epoch total loss 0.285155982\n",
      "Trained batch 906 batch loss 0.329463869 epoch total loss 0.285204887\n",
      "Trained batch 907 batch loss 0.33120048 epoch total loss 0.285255611\n",
      "Trained batch 908 batch loss 0.333194494 epoch total loss 0.285308391\n",
      "Trained batch 909 batch loss 0.278364182 epoch total loss 0.285300761\n",
      "Trained batch 910 batch loss 0.243884638 epoch total loss 0.285255253\n",
      "Trained batch 911 batch loss 0.30184257 epoch total loss 0.285273463\n",
      "Trained batch 912 batch loss 0.341765404 epoch total loss 0.285335422\n",
      "Trained batch 913 batch loss 0.324949205 epoch total loss 0.285378784\n",
      "Trained batch 914 batch loss 0.288001746 epoch total loss 0.285381645\n",
      "Trained batch 915 batch loss 0.27777338 epoch total loss 0.28537333\n",
      "Trained batch 916 batch loss 0.26729551 epoch total loss 0.285353601\n",
      "Trained batch 917 batch loss 0.300919682 epoch total loss 0.285370618\n",
      "Trained batch 918 batch loss 0.294755042 epoch total loss 0.28538084\n",
      "Trained batch 919 batch loss 0.290491581 epoch total loss 0.285386413\n",
      "Trained batch 920 batch loss 0.318014354 epoch total loss 0.285421878\n",
      "Trained batch 921 batch loss 0.32787478 epoch total loss 0.285467982\n",
      "Trained batch 922 batch loss 0.332679659 epoch total loss 0.285519183\n",
      "Trained batch 923 batch loss 0.328033119 epoch total loss 0.285565257\n",
      "Trained batch 924 batch loss 0.283579141 epoch total loss 0.285563082\n",
      "Trained batch 925 batch loss 0.285699 epoch total loss 0.285563231\n",
      "Trained batch 926 batch loss 0.272385269 epoch total loss 0.285549\n",
      "Trained batch 927 batch loss 0.291011631 epoch total loss 0.285554916\n",
      "Trained batch 928 batch loss 0.310536653 epoch total loss 0.285581857\n",
      "Trained batch 929 batch loss 0.295382589 epoch total loss 0.285592407\n",
      "Trained batch 930 batch loss 0.281485945 epoch total loss 0.285588\n",
      "Trained batch 931 batch loss 0.274085194 epoch total loss 0.285575628\n",
      "Trained batch 932 batch loss 0.286930382 epoch total loss 0.285577089\n",
      "Trained batch 933 batch loss 0.34782818 epoch total loss 0.285643816\n",
      "Trained batch 934 batch loss 0.30317542 epoch total loss 0.285662562\n",
      "Trained batch 935 batch loss 0.305537194 epoch total loss 0.285683841\n",
      "Trained batch 936 batch loss 0.301751167 epoch total loss 0.285701\n",
      "Trained batch 937 batch loss 0.338339448 epoch total loss 0.285757184\n",
      "Trained batch 938 batch loss 0.301070243 epoch total loss 0.285773486\n",
      "Trained batch 939 batch loss 0.287998796 epoch total loss 0.28577587\n",
      "Trained batch 940 batch loss 0.271764249 epoch total loss 0.285760939\n",
      "Trained batch 941 batch loss 0.292415559 epoch total loss 0.285768032\n",
      "Trained batch 942 batch loss 0.292129904 epoch total loss 0.285774797\n",
      "Trained batch 943 batch loss 0.294190258 epoch total loss 0.285783708\n",
      "Trained batch 944 batch loss 0.273480237 epoch total loss 0.285770684\n",
      "Trained batch 945 batch loss 0.311075449 epoch total loss 0.285797447\n",
      "Trained batch 946 batch loss 0.304696262 epoch total loss 0.285817415\n",
      "Trained batch 947 batch loss 0.307324648 epoch total loss 0.285840094\n",
      "Trained batch 948 batch loss 0.297107697 epoch total loss 0.285852015\n",
      "Trained batch 949 batch loss 0.252194583 epoch total loss 0.28581655\n",
      "Trained batch 950 batch loss 0.256306678 epoch total loss 0.285785496\n",
      "Trained batch 951 batch loss 0.257424921 epoch total loss 0.285755664\n",
      "Trained batch 952 batch loss 0.303553045 epoch total loss 0.28577435\n",
      "Trained batch 953 batch loss 0.298651278 epoch total loss 0.285787851\n",
      "Trained batch 954 batch loss 0.292751759 epoch total loss 0.285795182\n",
      "Trained batch 955 batch loss 0.312393636 epoch total loss 0.285823047\n",
      "Trained batch 956 batch loss 0.294344246 epoch total loss 0.285831958\n",
      "Trained batch 957 batch loss 0.31173557 epoch total loss 0.285859019\n",
      "Trained batch 958 batch loss 0.259703338 epoch total loss 0.28583172\n",
      "Trained batch 959 batch loss 0.277435899 epoch total loss 0.285822958\n",
      "Trained batch 960 batch loss 0.290157884 epoch total loss 0.285827488\n",
      "Trained batch 961 batch loss 0.285593212 epoch total loss 0.285827219\n",
      "Trained batch 962 batch loss 0.25272128 epoch total loss 0.285792798\n",
      "Trained batch 963 batch loss 0.238419369 epoch total loss 0.285743624\n",
      "Trained batch 964 batch loss 0.254205823 epoch total loss 0.285710931\n",
      "Trained batch 965 batch loss 0.253878951 epoch total loss 0.28567794\n",
      "Trained batch 966 batch loss 0.254234254 epoch total loss 0.285645396\n",
      "Trained batch 967 batch loss 0.243799224 epoch total loss 0.285602123\n",
      "Trained batch 968 batch loss 0.268434197 epoch total loss 0.28558439\n",
      "Trained batch 969 batch loss 0.288789123 epoch total loss 0.285587698\n",
      "Trained batch 970 batch loss 0.2940754 epoch total loss 0.28559643\n",
      "Trained batch 971 batch loss 0.26537323 epoch total loss 0.285575598\n",
      "Trained batch 972 batch loss 0.257368147 epoch total loss 0.285546571\n",
      "Trained batch 973 batch loss 0.296536028 epoch total loss 0.285557866\n",
      "Trained batch 974 batch loss 0.328697264 epoch total loss 0.285602182\n",
      "Trained batch 975 batch loss 0.292754024 epoch total loss 0.285609514\n",
      "Trained batch 976 batch loss 0.248025939 epoch total loss 0.285570979\n",
      "Trained batch 977 batch loss 0.259130806 epoch total loss 0.285543919\n",
      "Trained batch 978 batch loss 0.261677086 epoch total loss 0.28551954\n",
      "Trained batch 979 batch loss 0.276050925 epoch total loss 0.285509855\n",
      "Trained batch 980 batch loss 0.291186273 epoch total loss 0.285515666\n",
      "Trained batch 981 batch loss 0.284609914 epoch total loss 0.285514742\n",
      "Trained batch 982 batch loss 0.29260993 epoch total loss 0.285521954\n",
      "Trained batch 983 batch loss 0.310563207 epoch total loss 0.285547465\n",
      "Trained batch 984 batch loss 0.3091 epoch total loss 0.285571396\n",
      "Trained batch 985 batch loss 0.351198465 epoch total loss 0.285638034\n",
      "Trained batch 986 batch loss 0.323409677 epoch total loss 0.28567633\n",
      "Trained batch 987 batch loss 0.302199811 epoch total loss 0.285693049\n",
      "Trained batch 988 batch loss 0.283228 epoch total loss 0.285690546\n",
      "Trained batch 989 batch loss 0.312511653 epoch total loss 0.285717666\n",
      "Trained batch 990 batch loss 0.32162562 epoch total loss 0.285753936\n",
      "Trained batch 991 batch loss 0.294341505 epoch total loss 0.285762608\n",
      "Trained batch 992 batch loss 0.2515288 epoch total loss 0.285728097\n",
      "Trained batch 993 batch loss 0.272375077 epoch total loss 0.285714626\n",
      "Trained batch 994 batch loss 0.259482861 epoch total loss 0.285688251\n",
      "Trained batch 995 batch loss 0.268117309 epoch total loss 0.285670608\n",
      "Trained batch 996 batch loss 0.270932972 epoch total loss 0.285655797\n",
      "Trained batch 997 batch loss 0.265203059 epoch total loss 0.285635293\n",
      "Trained batch 998 batch loss 0.298445225 epoch total loss 0.285648108\n",
      "Trained batch 999 batch loss 0.294047982 epoch total loss 0.285656512\n",
      "Trained batch 1000 batch loss 0.31461972 epoch total loss 0.28568545\n",
      "Trained batch 1001 batch loss 0.309333891 epoch total loss 0.285709083\n",
      "Trained batch 1002 batch loss 0.299327374 epoch total loss 0.285722643\n",
      "Trained batch 1003 batch loss 0.30354619 epoch total loss 0.285740435\n",
      "Trained batch 1004 batch loss 0.312380701 epoch total loss 0.285766959\n",
      "Trained batch 1005 batch loss 0.307855248 epoch total loss 0.285788953\n",
      "Trained batch 1006 batch loss 0.303420186 epoch total loss 0.285806477\n",
      "Trained batch 1007 batch loss 0.29465282 epoch total loss 0.285815239\n",
      "Trained batch 1008 batch loss 0.276488602 epoch total loss 0.285806\n",
      "Trained batch 1009 batch loss 0.303372383 epoch total loss 0.285823405\n",
      "Trained batch 1010 batch loss 0.304688841 epoch total loss 0.285842091\n",
      "Trained batch 1011 batch loss 0.310249686 epoch total loss 0.285866201\n",
      "Trained batch 1012 batch loss 0.309832156 epoch total loss 0.285889894\n",
      "Trained batch 1013 batch loss 0.280221343 epoch total loss 0.285884291\n",
      "Trained batch 1014 batch loss 0.270569533 epoch total loss 0.285869211\n",
      "Trained batch 1015 batch loss 0.244358987 epoch total loss 0.285828292\n",
      "Trained batch 1016 batch loss 0.266905755 epoch total loss 0.285809666\n",
      "Trained batch 1017 batch loss 0.28695637 epoch total loss 0.285810798\n",
      "Trained batch 1018 batch loss 0.305616617 epoch total loss 0.285830259\n",
      "Trained batch 1019 batch loss 0.296285 epoch total loss 0.285840511\n",
      "Trained batch 1020 batch loss 0.306819946 epoch total loss 0.285861075\n",
      "Trained batch 1021 batch loss 0.293407202 epoch total loss 0.285868466\n",
      "Trained batch 1022 batch loss 0.283579797 epoch total loss 0.285866231\n",
      "Trained batch 1023 batch loss 0.302675575 epoch total loss 0.285882652\n",
      "Trained batch 1024 batch loss 0.290187985 epoch total loss 0.285886854\n",
      "Trained batch 1025 batch loss 0.273131877 epoch total loss 0.285874397\n",
      "Trained batch 1026 batch loss 0.283014208 epoch total loss 0.285871625\n",
      "Trained batch 1027 batch loss 0.303088069 epoch total loss 0.285888404\n",
      "Trained batch 1028 batch loss 0.27928409 epoch total loss 0.285882\n",
      "Trained batch 1029 batch loss 0.335564464 epoch total loss 0.285930276\n",
      "Trained batch 1030 batch loss 0.281741112 epoch total loss 0.285926223\n",
      "Trained batch 1031 batch loss 0.290008903 epoch total loss 0.285930157\n",
      "Trained batch 1032 batch loss 0.28382203 epoch total loss 0.28592813\n",
      "Trained batch 1033 batch loss 0.26331234 epoch total loss 0.285906225\n",
      "Trained batch 1034 batch loss 0.301344037 epoch total loss 0.285921127\n",
      "Trained batch 1035 batch loss 0.301056236 epoch total loss 0.28593576\n",
      "Trained batch 1036 batch loss 0.310233474 epoch total loss 0.285959214\n",
      "Trained batch 1037 batch loss 0.314658582 epoch total loss 0.2859869\n",
      "Trained batch 1038 batch loss 0.324580759 epoch total loss 0.286024094\n",
      "Trained batch 1039 batch loss 0.306533933 epoch total loss 0.286043853\n",
      "Trained batch 1040 batch loss 0.289618671 epoch total loss 0.28604728\n",
      "Trained batch 1041 batch loss 0.285144866 epoch total loss 0.286046416\n",
      "Trained batch 1042 batch loss 0.284167856 epoch total loss 0.286044627\n",
      "Trained batch 1043 batch loss 0.284633219 epoch total loss 0.286043286\n",
      "Trained batch 1044 batch loss 0.284312069 epoch total loss 0.286041617\n",
      "Trained batch 1045 batch loss 0.301589787 epoch total loss 0.286056489\n",
      "Trained batch 1046 batch loss 0.310998172 epoch total loss 0.286080331\n",
      "Trained batch 1047 batch loss 0.278573304 epoch total loss 0.286073148\n",
      "Trained batch 1048 batch loss 0.269025058 epoch total loss 0.286056876\n",
      "Trained batch 1049 batch loss 0.269460618 epoch total loss 0.286041051\n",
      "Trained batch 1050 batch loss 0.294422448 epoch total loss 0.286049038\n",
      "Trained batch 1051 batch loss 0.247178167 epoch total loss 0.286012083\n",
      "Trained batch 1052 batch loss 0.286627591 epoch total loss 0.28601265\n",
      "Trained batch 1053 batch loss 0.281167567 epoch total loss 0.28600806\n",
      "Trained batch 1054 batch loss 0.307005376 epoch total loss 0.286027968\n",
      "Trained batch 1055 batch loss 0.30669862 epoch total loss 0.286047578\n",
      "Trained batch 1056 batch loss 0.338337183 epoch total loss 0.28609708\n",
      "Trained batch 1057 batch loss 0.322289407 epoch total loss 0.286131352\n",
      "Trained batch 1058 batch loss 0.309565604 epoch total loss 0.286153495\n",
      "Trained batch 1059 batch loss 0.263941497 epoch total loss 0.286132514\n",
      "Trained batch 1060 batch loss 0.240579307 epoch total loss 0.28608954\n",
      "Trained batch 1061 batch loss 0.223586723 epoch total loss 0.28603062\n",
      "Trained batch 1062 batch loss 0.234627813 epoch total loss 0.285982221\n",
      "Trained batch 1063 batch loss 0.221607208 epoch total loss 0.285921663\n",
      "Trained batch 1064 batch loss 0.217070401 epoch total loss 0.285856962\n",
      "Trained batch 1065 batch loss 0.231928676 epoch total loss 0.285806328\n",
      "Trained batch 1066 batch loss 0.290909171 epoch total loss 0.285811126\n",
      "Trained batch 1067 batch loss 0.284014314 epoch total loss 0.285809457\n",
      "Trained batch 1068 batch loss 0.366072297 epoch total loss 0.285884589\n",
      "Trained batch 1069 batch loss 0.296805024 epoch total loss 0.285894811\n",
      "Trained batch 1070 batch loss 0.298159152 epoch total loss 0.285906255\n",
      "Trained batch 1071 batch loss 0.266347498 epoch total loss 0.285888016\n",
      "Trained batch 1072 batch loss 0.26808846 epoch total loss 0.285871416\n",
      "Trained batch 1073 batch loss 0.302155405 epoch total loss 0.285886586\n",
      "Trained batch 1074 batch loss 0.298599482 epoch total loss 0.285898447\n",
      "Trained batch 1075 batch loss 0.292508423 epoch total loss 0.285904586\n",
      "Trained batch 1076 batch loss 0.278826296 epoch total loss 0.28589803\n",
      "Trained batch 1077 batch loss 0.306239843 epoch total loss 0.285916924\n",
      "Trained batch 1078 batch loss 0.288083464 epoch total loss 0.285918921\n",
      "Trained batch 1079 batch loss 0.274597943 epoch total loss 0.285908431\n",
      "Trained batch 1080 batch loss 0.26280582 epoch total loss 0.285887063\n",
      "Trained batch 1081 batch loss 0.277047366 epoch total loss 0.285878867\n",
      "Trained batch 1082 batch loss 0.294138 epoch total loss 0.285886496\n",
      "Trained batch 1083 batch loss 0.256930709 epoch total loss 0.285859764\n",
      "Trained batch 1084 batch loss 0.22680977 epoch total loss 0.285805285\n",
      "Trained batch 1085 batch loss 0.254782438 epoch total loss 0.285776705\n",
      "Trained batch 1086 batch loss 0.29406023 epoch total loss 0.285784334\n",
      "Trained batch 1087 batch loss 0.300097644 epoch total loss 0.285797507\n",
      "Trained batch 1088 batch loss 0.33766517 epoch total loss 0.28584519\n",
      "Trained batch 1089 batch loss 0.331926405 epoch total loss 0.28588751\n",
      "Trained batch 1090 batch loss 0.302604258 epoch total loss 0.285902858\n",
      "Trained batch 1091 batch loss 0.317436039 epoch total loss 0.285931766\n",
      "Trained batch 1092 batch loss 0.305621415 epoch total loss 0.285949826\n",
      "Trained batch 1093 batch loss 0.271467328 epoch total loss 0.285936564\n",
      "Trained batch 1094 batch loss 0.261632532 epoch total loss 0.285914332\n",
      "Trained batch 1095 batch loss 0.270139635 epoch total loss 0.285899937\n",
      "Trained batch 1096 batch loss 0.289397746 epoch total loss 0.285903126\n",
      "Trained batch 1097 batch loss 0.316106468 epoch total loss 0.285930663\n",
      "Trained batch 1098 batch loss 0.282432258 epoch total loss 0.285927474\n",
      "Trained batch 1099 batch loss 0.26645878 epoch total loss 0.285909742\n",
      "Trained batch 1100 batch loss 0.282776743 epoch total loss 0.285906911\n",
      "Trained batch 1101 batch loss 0.234929025 epoch total loss 0.285860598\n",
      "Trained batch 1102 batch loss 0.244108856 epoch total loss 0.285822719\n",
      "Trained batch 1103 batch loss 0.265121579 epoch total loss 0.285803944\n",
      "Trained batch 1104 batch loss 0.260532618 epoch total loss 0.285781056\n",
      "Trained batch 1105 batch loss 0.259468377 epoch total loss 0.285757244\n",
      "Trained batch 1106 batch loss 0.271773487 epoch total loss 0.285744578\n",
      "Trained batch 1107 batch loss 0.300354809 epoch total loss 0.28575778\n",
      "Trained batch 1108 batch loss 0.267171532 epoch total loss 0.285741\n",
      "Trained batch 1109 batch loss 0.277736962 epoch total loss 0.285733789\n",
      "Trained batch 1110 batch loss 0.250001431 epoch total loss 0.285701603\n",
      "Trained batch 1111 batch loss 0.248154044 epoch total loss 0.285667837\n",
      "Trained batch 1112 batch loss 0.286085606 epoch total loss 0.285668194\n",
      "Trained batch 1113 batch loss 0.282398731 epoch total loss 0.285665274\n",
      "Trained batch 1114 batch loss 0.30388549 epoch total loss 0.285681635\n",
      "Trained batch 1115 batch loss 0.295571834 epoch total loss 0.285690486\n",
      "Trained batch 1116 batch loss 0.273200303 epoch total loss 0.285679281\n",
      "Trained batch 1117 batch loss 0.291610837 epoch total loss 0.285684615\n",
      "Trained batch 1118 batch loss 0.317515463 epoch total loss 0.285713077\n",
      "Trained batch 1119 batch loss 0.291418642 epoch total loss 0.285718173\n",
      "Trained batch 1120 batch loss 0.28056556 epoch total loss 0.285713583\n",
      "Trained batch 1121 batch loss 0.283572733 epoch total loss 0.285711676\n",
      "Trained batch 1122 batch loss 0.289465278 epoch total loss 0.285715\n",
      "Trained batch 1123 batch loss 0.270895422 epoch total loss 0.285701811\n",
      "Trained batch 1124 batch loss 0.259677291 epoch total loss 0.285678655\n",
      "Trained batch 1125 batch loss 0.304320365 epoch total loss 0.285695225\n",
      "Trained batch 1126 batch loss 0.2960307 epoch total loss 0.285704404\n",
      "Trained batch 1127 batch loss 0.286349207 epoch total loss 0.28570497\n",
      "Trained batch 1128 batch loss 0.277133137 epoch total loss 0.285697371\n",
      "Trained batch 1129 batch loss 0.279948413 epoch total loss 0.285692275\n",
      "Trained batch 1130 batch loss 0.277498752 epoch total loss 0.285685\n",
      "Trained batch 1131 batch loss 0.274004966 epoch total loss 0.285674691\n",
      "Trained batch 1132 batch loss 0.2712273 epoch total loss 0.285661936\n",
      "Trained batch 1133 batch loss 0.272324681 epoch total loss 0.285650194\n",
      "Trained batch 1134 batch loss 0.287029326 epoch total loss 0.285651386\n",
      "Trained batch 1135 batch loss 0.278664172 epoch total loss 0.285645217\n",
      "Trained batch 1136 batch loss 0.282511503 epoch total loss 0.285642475\n",
      "Trained batch 1137 batch loss 0.224676937 epoch total loss 0.285588831\n",
      "Trained batch 1138 batch loss 0.24284786 epoch total loss 0.28555128\n",
      "Trained batch 1139 batch loss 0.270326018 epoch total loss 0.285537928\n",
      "Trained batch 1140 batch loss 0.296900451 epoch total loss 0.285547882\n",
      "Trained batch 1141 batch loss 0.308692366 epoch total loss 0.285568178\n",
      "Trained batch 1142 batch loss 0.288513422 epoch total loss 0.285570741\n",
      "Trained batch 1143 batch loss 0.281283021 epoch total loss 0.285567\n",
      "Trained batch 1144 batch loss 0.260122567 epoch total loss 0.285544753\n",
      "Trained batch 1145 batch loss 0.256599754 epoch total loss 0.285519481\n",
      "Trained batch 1146 batch loss 0.245814025 epoch total loss 0.285484821\n",
      "Trained batch 1147 batch loss 0.286016345 epoch total loss 0.285485297\n",
      "Trained batch 1148 batch loss 0.30097276 epoch total loss 0.285498768\n",
      "Trained batch 1149 batch loss 0.307098269 epoch total loss 0.285517573\n",
      "Trained batch 1150 batch loss 0.285092384 epoch total loss 0.285517216\n",
      "Trained batch 1151 batch loss 0.302856177 epoch total loss 0.285532266\n",
      "Trained batch 1152 batch loss 0.306336075 epoch total loss 0.285550326\n",
      "Trained batch 1153 batch loss 0.297855407 epoch total loss 0.285561\n",
      "Trained batch 1154 batch loss 0.319881916 epoch total loss 0.285590738\n",
      "Trained batch 1155 batch loss 0.377471715 epoch total loss 0.28567028\n",
      "Trained batch 1156 batch loss 0.289429784 epoch total loss 0.285673559\n",
      "Trained batch 1157 batch loss 0.312119961 epoch total loss 0.285696417\n",
      "Trained batch 1158 batch loss 0.304264307 epoch total loss 0.285712451\n",
      "Trained batch 1159 batch loss 0.323329955 epoch total loss 0.285744905\n",
      "Trained batch 1160 batch loss 0.279600531 epoch total loss 0.285739601\n",
      "Trained batch 1161 batch loss 0.294552177 epoch total loss 0.2857472\n",
      "Trained batch 1162 batch loss 0.275559247 epoch total loss 0.285738438\n",
      "Trained batch 1163 batch loss 0.268027782 epoch total loss 0.285723239\n",
      "Trained batch 1164 batch loss 0.291032463 epoch total loss 0.285727799\n",
      "Trained batch 1165 batch loss 0.300063342 epoch total loss 0.285740077\n",
      "Trained batch 1166 batch loss 0.308424115 epoch total loss 0.285759538\n",
      "Trained batch 1167 batch loss 0.275552273 epoch total loss 0.285750777\n",
      "Trained batch 1168 batch loss 0.273860157 epoch total loss 0.285740614\n",
      "Trained batch 1169 batch loss 0.285528839 epoch total loss 0.285740405\n",
      "Trained batch 1170 batch loss 0.258791 epoch total loss 0.285717368\n",
      "Trained batch 1171 batch loss 0.292993635 epoch total loss 0.285723597\n",
      "Trained batch 1172 batch loss 0.275653332 epoch total loss 0.285715\n",
      "Trained batch 1173 batch loss 0.304362625 epoch total loss 0.285730898\n",
      "Trained batch 1174 batch loss 0.247948617 epoch total loss 0.285698742\n",
      "Trained batch 1175 batch loss 0.238379285 epoch total loss 0.285658449\n",
      "Trained batch 1176 batch loss 0.243794829 epoch total loss 0.285622865\n",
      "Trained batch 1177 batch loss 0.263333857 epoch total loss 0.28560394\n",
      "Trained batch 1178 batch loss 0.273246884 epoch total loss 0.28559345\n",
      "Trained batch 1179 batch loss 0.262078881 epoch total loss 0.285573512\n",
      "Trained batch 1180 batch loss 0.279670626 epoch total loss 0.285568506\n",
      "Trained batch 1181 batch loss 0.310819566 epoch total loss 0.285589874\n",
      "Trained batch 1182 batch loss 0.307194591 epoch total loss 0.285608143\n",
      "Trained batch 1183 batch loss 0.291056812 epoch total loss 0.285612762\n",
      "Trained batch 1184 batch loss 0.314442754 epoch total loss 0.28563711\n",
      "Trained batch 1185 batch loss 0.273372084 epoch total loss 0.285626769\n",
      "Trained batch 1186 batch loss 0.273132414 epoch total loss 0.285616219\n",
      "Trained batch 1187 batch loss 0.286428213 epoch total loss 0.285616904\n",
      "Trained batch 1188 batch loss 0.284643441 epoch total loss 0.2856161\n",
      "Trained batch 1189 batch loss 0.309738696 epoch total loss 0.285636395\n",
      "Trained batch 1190 batch loss 0.300813556 epoch total loss 0.285649151\n",
      "Trained batch 1191 batch loss 0.286437541 epoch total loss 0.285649806\n",
      "Trained batch 1192 batch loss 0.276261359 epoch total loss 0.285641938\n",
      "Trained batch 1193 batch loss 0.245540753 epoch total loss 0.285608321\n",
      "Trained batch 1194 batch loss 0.274686724 epoch total loss 0.285599202\n",
      "Trained batch 1195 batch loss 0.255957514 epoch total loss 0.285574377\n",
      "Trained batch 1196 batch loss 0.311760843 epoch total loss 0.285596281\n",
      "Trained batch 1197 batch loss 0.303526 epoch total loss 0.285611272\n",
      "Trained batch 1198 batch loss 0.29297623 epoch total loss 0.285617411\n",
      "Trained batch 1199 batch loss 0.269059658 epoch total loss 0.285603613\n",
      "Trained batch 1200 batch loss 0.288553208 epoch total loss 0.285606056\n",
      "Trained batch 1201 batch loss 0.296289176 epoch total loss 0.285614967\n",
      "Trained batch 1202 batch loss 0.29262203 epoch total loss 0.285620779\n",
      "Trained batch 1203 batch loss 0.279651493 epoch total loss 0.285615832\n",
      "Trained batch 1204 batch loss 0.24190715 epoch total loss 0.285579532\n",
      "Trained batch 1205 batch loss 0.257851154 epoch total loss 0.285556525\n",
      "Trained batch 1206 batch loss 0.302752435 epoch total loss 0.2855708\n",
      "Trained batch 1207 batch loss 0.303265959 epoch total loss 0.285585433\n",
      "Trained batch 1208 batch loss 0.273337334 epoch total loss 0.2855753\n",
      "Trained batch 1209 batch loss 0.278252 epoch total loss 0.285569251\n",
      "Trained batch 1210 batch loss 0.254864216 epoch total loss 0.285543859\n",
      "Trained batch 1211 batch loss 0.223615274 epoch total loss 0.285492718\n",
      "Trained batch 1212 batch loss 0.232985556 epoch total loss 0.285449386\n",
      "Trained batch 1213 batch loss 0.234646291 epoch total loss 0.285407513\n",
      "Trained batch 1214 batch loss 0.240408167 epoch total loss 0.285370439\n",
      "Trained batch 1215 batch loss 0.248929232 epoch total loss 0.285340458\n",
      "Trained batch 1216 batch loss 0.314944327 epoch total loss 0.285364807\n",
      "Trained batch 1217 batch loss 0.358863026 epoch total loss 0.285425186\n",
      "Trained batch 1218 batch loss 0.317596287 epoch total loss 0.285451591\n",
      "Trained batch 1219 batch loss 0.33684209 epoch total loss 0.285493761\n",
      "Trained batch 1220 batch loss 0.313076556 epoch total loss 0.285516381\n",
      "Trained batch 1221 batch loss 0.302470535 epoch total loss 0.285530269\n",
      "Trained batch 1222 batch loss 0.295790374 epoch total loss 0.285538644\n",
      "Trained batch 1223 batch loss 0.300702602 epoch total loss 0.285551041\n",
      "Trained batch 1224 batch loss 0.318105459 epoch total loss 0.285577625\n",
      "Trained batch 1225 batch loss 0.270154119 epoch total loss 0.285565048\n",
      "Trained batch 1226 batch loss 0.294100493 epoch total loss 0.285572\n",
      "Trained batch 1227 batch loss 0.293740839 epoch total loss 0.285578638\n",
      "Trained batch 1228 batch loss 0.289324254 epoch total loss 0.285581708\n",
      "Trained batch 1229 batch loss 0.289544702 epoch total loss 0.285584927\n",
      "Trained batch 1230 batch loss 0.249688551 epoch total loss 0.28555575\n",
      "Trained batch 1231 batch loss 0.235924661 epoch total loss 0.285515457\n",
      "Trained batch 1232 batch loss 0.263914496 epoch total loss 0.285497904\n",
      "Trained batch 1233 batch loss 0.284398437 epoch total loss 0.285497\n",
      "Trained batch 1234 batch loss 0.315433234 epoch total loss 0.285521269\n",
      "Trained batch 1235 batch loss 0.328043699 epoch total loss 0.285555691\n",
      "Trained batch 1236 batch loss 0.305689901 epoch total loss 0.285572\n",
      "Trained batch 1237 batch loss 0.330092251 epoch total loss 0.285607964\n",
      "Trained batch 1238 batch loss 0.297289968 epoch total loss 0.285617411\n",
      "Trained batch 1239 batch loss 0.295009613 epoch total loss 0.285625\n",
      "Trained batch 1240 batch loss 0.301362693 epoch total loss 0.285637677\n",
      "Trained batch 1241 batch loss 0.306276828 epoch total loss 0.285654306\n",
      "Trained batch 1242 batch loss 0.275002599 epoch total loss 0.285645723\n",
      "Trained batch 1243 batch loss 0.299712837 epoch total loss 0.285657048\n",
      "Trained batch 1244 batch loss 0.29970485 epoch total loss 0.285668343\n",
      "Trained batch 1245 batch loss 0.315018833 epoch total loss 0.285691947\n",
      "Trained batch 1246 batch loss 0.324833632 epoch total loss 0.285723358\n",
      "Trained batch 1247 batch loss 0.30906567 epoch total loss 0.285742044\n",
      "Trained batch 1248 batch loss 0.313401401 epoch total loss 0.285764217\n",
      "Trained batch 1249 batch loss 0.295265436 epoch total loss 0.285771817\n",
      "Trained batch 1250 batch loss 0.280039 epoch total loss 0.285767227\n",
      "Trained batch 1251 batch loss 0.27649647 epoch total loss 0.285759807\n",
      "Trained batch 1252 batch loss 0.294876695 epoch total loss 0.285767108\n",
      "Trained batch 1253 batch loss 0.296927899 epoch total loss 0.285776019\n",
      "Trained batch 1254 batch loss 0.286489606 epoch total loss 0.285776615\n",
      "Trained batch 1255 batch loss 0.306668401 epoch total loss 0.285793245\n",
      "Trained batch 1256 batch loss 0.289853871 epoch total loss 0.285796493\n",
      "Trained batch 1257 batch loss 0.291474313 epoch total loss 0.285801\n",
      "Trained batch 1258 batch loss 0.306949824 epoch total loss 0.285817802\n",
      "Trained batch 1259 batch loss 0.280000836 epoch total loss 0.285813183\n",
      "Trained batch 1260 batch loss 0.273757428 epoch total loss 0.285803616\n",
      "Trained batch 1261 batch loss 0.288966149 epoch total loss 0.285806119\n",
      "Trained batch 1262 batch loss 0.297782749 epoch total loss 0.285815626\n",
      "Trained batch 1263 batch loss 0.261905104 epoch total loss 0.285796672\n",
      "Trained batch 1264 batch loss 0.279370606 epoch total loss 0.285791576\n",
      "Trained batch 1265 batch loss 0.257722974 epoch total loss 0.285769403\n",
      "Trained batch 1266 batch loss 0.305865347 epoch total loss 0.285785288\n",
      "Trained batch 1267 batch loss 0.277402818 epoch total loss 0.285778672\n",
      "Trained batch 1268 batch loss 0.310746938 epoch total loss 0.285798371\n",
      "Trained batch 1269 batch loss 0.300860584 epoch total loss 0.285810262\n",
      "Trained batch 1270 batch loss 0.246346444 epoch total loss 0.285779178\n",
      "Trained batch 1271 batch loss 0.27984643 epoch total loss 0.285774499\n",
      "Trained batch 1272 batch loss 0.280907393 epoch total loss 0.285770684\n",
      "Trained batch 1273 batch loss 0.289041817 epoch total loss 0.285773247\n",
      "Trained batch 1274 batch loss 0.292548925 epoch total loss 0.285778552\n",
      "Trained batch 1275 batch loss 0.289010882 epoch total loss 0.285781085\n",
      "Trained batch 1276 batch loss 0.265909433 epoch total loss 0.285765499\n",
      "Trained batch 1277 batch loss 0.263886631 epoch total loss 0.285748363\n",
      "Trained batch 1278 batch loss 0.274742216 epoch total loss 0.28573975\n",
      "Trained batch 1279 batch loss 0.24533312 epoch total loss 0.285708159\n",
      "Trained batch 1280 batch loss 0.276350379 epoch total loss 0.285700858\n",
      "Trained batch 1281 batch loss 0.294187427 epoch total loss 0.285707474\n",
      "Trained batch 1282 batch loss 0.311245382 epoch total loss 0.285727382\n",
      "Trained batch 1283 batch loss 0.270374894 epoch total loss 0.285715431\n",
      "Trained batch 1284 batch loss 0.329579026 epoch total loss 0.285749614\n",
      "Trained batch 1285 batch loss 0.284018219 epoch total loss 0.285748273\n",
      "Trained batch 1286 batch loss 0.325463057 epoch total loss 0.285779148\n",
      "Trained batch 1287 batch loss 0.288904667 epoch total loss 0.285781592\n",
      "Trained batch 1288 batch loss 0.323289156 epoch total loss 0.285810709\n",
      "Trained batch 1289 batch loss 0.324984312 epoch total loss 0.285841107\n",
      "Trained batch 1290 batch loss 0.294023842 epoch total loss 0.285847455\n",
      "Trained batch 1291 batch loss 0.305203557 epoch total loss 0.285862446\n",
      "Trained batch 1292 batch loss 0.306228101 epoch total loss 0.285878211\n",
      "Trained batch 1293 batch loss 0.26245591 epoch total loss 0.285860091\n",
      "Trained batch 1294 batch loss 0.305019796 epoch total loss 0.285874903\n",
      "Trained batch 1295 batch loss 0.293956518 epoch total loss 0.285881132\n",
      "Trained batch 1296 batch loss 0.27840665 epoch total loss 0.28587538\n",
      "Trained batch 1297 batch loss 0.286061764 epoch total loss 0.285875529\n",
      "Trained batch 1298 batch loss 0.289909244 epoch total loss 0.285878628\n",
      "Trained batch 1299 batch loss 0.293633699 epoch total loss 0.285884619\n",
      "Trained batch 1300 batch loss 0.300266445 epoch total loss 0.285895675\n",
      "Trained batch 1301 batch loss 0.271942973 epoch total loss 0.285884947\n",
      "Trained batch 1302 batch loss 0.307050973 epoch total loss 0.285901189\n",
      "Trained batch 1303 batch loss 0.284184545 epoch total loss 0.285899878\n",
      "Trained batch 1304 batch loss 0.278243482 epoch total loss 0.285893977\n",
      "Trained batch 1305 batch loss 0.29147 epoch total loss 0.285898268\n",
      "Trained batch 1306 batch loss 0.337170571 epoch total loss 0.285937518\n",
      "Trained batch 1307 batch loss 0.327823222 epoch total loss 0.285969555\n",
      "Trained batch 1308 batch loss 0.303999364 epoch total loss 0.285983324\n",
      "Trained batch 1309 batch loss 0.295538545 epoch total loss 0.285990626\n",
      "Trained batch 1310 batch loss 0.270678461 epoch total loss 0.285978943\n",
      "Trained batch 1311 batch loss 0.265178919 epoch total loss 0.285963058\n",
      "Trained batch 1312 batch loss 0.306615263 epoch total loss 0.285978794\n",
      "Trained batch 1313 batch loss 0.316562951 epoch total loss 0.2860021\n",
      "Trained batch 1314 batch loss 0.354919344 epoch total loss 0.286054552\n",
      "Trained batch 1315 batch loss 0.337654412 epoch total loss 0.286093771\n",
      "Trained batch 1316 batch loss 0.270353556 epoch total loss 0.286081821\n",
      "Trained batch 1317 batch loss 0.306363225 epoch total loss 0.286097229\n",
      "Trained batch 1318 batch loss 0.297923446 epoch total loss 0.286106199\n",
      "Trained batch 1319 batch loss 0.307074219 epoch total loss 0.286122084\n",
      "Trained batch 1320 batch loss 0.295052409 epoch total loss 0.286128849\n",
      "Trained batch 1321 batch loss 0.318042785 epoch total loss 0.286153\n",
      "Trained batch 1322 batch loss 0.264615685 epoch total loss 0.286136717\n",
      "Trained batch 1323 batch loss 0.264396638 epoch total loss 0.286120296\n",
      "Trained batch 1324 batch loss 0.286578059 epoch total loss 0.286120653\n",
      "Trained batch 1325 batch loss 0.233459786 epoch total loss 0.286080897\n",
      "Trained batch 1326 batch loss 0.265385836 epoch total loss 0.28606528\n",
      "Trained batch 1327 batch loss 0.284297 epoch total loss 0.286063969\n",
      "Trained batch 1328 batch loss 0.287789226 epoch total loss 0.286065251\n",
      "Trained batch 1329 batch loss 0.304199517 epoch total loss 0.2860789\n",
      "Trained batch 1330 batch loss 0.284632325 epoch total loss 0.286077797\n",
      "Trained batch 1331 batch loss 0.284729362 epoch total loss 0.286076784\n",
      "Trained batch 1332 batch loss 0.288952351 epoch total loss 0.28607896\n",
      "Trained batch 1333 batch loss 0.316382885 epoch total loss 0.286101669\n",
      "Trained batch 1334 batch loss 0.280298889 epoch total loss 0.286097318\n",
      "Trained batch 1335 batch loss 0.274068415 epoch total loss 0.286088318\n",
      "Trained batch 1336 batch loss 0.265618533 epoch total loss 0.286073\n",
      "Trained batch 1337 batch loss 0.288460821 epoch total loss 0.286074787\n",
      "Trained batch 1338 batch loss 0.255155981 epoch total loss 0.286051691\n",
      "Trained batch 1339 batch loss 0.230656952 epoch total loss 0.286010295\n",
      "Trained batch 1340 batch loss 0.295054197 epoch total loss 0.28601706\n",
      "Trained batch 1341 batch loss 0.250393301 epoch total loss 0.285990477\n",
      "Trained batch 1342 batch loss 0.25411433 epoch total loss 0.285966754\n",
      "Trained batch 1343 batch loss 0.23874034 epoch total loss 0.285931587\n",
      "Trained batch 1344 batch loss 0.284674 epoch total loss 0.285930634\n",
      "Trained batch 1345 batch loss 0.274828583 epoch total loss 0.285922378\n",
      "Trained batch 1346 batch loss 0.270079613 epoch total loss 0.285910606\n",
      "Trained batch 1347 batch loss 0.314378649 epoch total loss 0.285931766\n",
      "Trained batch 1348 batch loss 0.314551443 epoch total loss 0.285953\n",
      "Trained batch 1349 batch loss 0.297540694 epoch total loss 0.285961598\n",
      "Trained batch 1350 batch loss 0.27588585 epoch total loss 0.285954118\n",
      "Trained batch 1351 batch loss 0.276474208 epoch total loss 0.285947114\n",
      "Trained batch 1352 batch loss 0.274083227 epoch total loss 0.285938323\n",
      "Trained batch 1353 batch loss 0.260249376 epoch total loss 0.285919338\n",
      "Trained batch 1354 batch loss 0.274244279 epoch total loss 0.285910726\n",
      "Trained batch 1355 batch loss 0.282157093 epoch total loss 0.285907954\n",
      "Trained batch 1356 batch loss 0.282676 epoch total loss 0.28590557\n",
      "Trained batch 1357 batch loss 0.252440095 epoch total loss 0.285880923\n",
      "Trained batch 1358 batch loss 0.25708276 epoch total loss 0.285859704\n",
      "Trained batch 1359 batch loss 0.302533537 epoch total loss 0.285871953\n",
      "Trained batch 1360 batch loss 0.303416044 epoch total loss 0.285884857\n",
      "Trained batch 1361 batch loss 0.29453671 epoch total loss 0.285891205\n",
      "Trained batch 1362 batch loss 0.289025426 epoch total loss 0.2858935\n",
      "Trained batch 1363 batch loss 0.261950374 epoch total loss 0.285875946\n",
      "Trained batch 1364 batch loss 0.21697177 epoch total loss 0.285825431\n",
      "Trained batch 1365 batch loss 0.188645616 epoch total loss 0.285754263\n",
      "Trained batch 1366 batch loss 0.232054114 epoch total loss 0.285714954\n",
      "Trained batch 1367 batch loss 0.261195123 epoch total loss 0.285697\n",
      "Trained batch 1368 batch loss 0.290062875 epoch total loss 0.285700202\n",
      "Trained batch 1369 batch loss 0.240536585 epoch total loss 0.285667211\n",
      "Trained batch 1370 batch loss 0.259964526 epoch total loss 0.285648465\n",
      "Trained batch 1371 batch loss 0.251249909 epoch total loss 0.285623372\n",
      "Trained batch 1372 batch loss 0.263112634 epoch total loss 0.28560698\n",
      "Trained batch 1373 batch loss 0.244434237 epoch total loss 0.285577\n",
      "Trained batch 1374 batch loss 0.280541122 epoch total loss 0.285573334\n",
      "Trained batch 1375 batch loss 0.294769675 epoch total loss 0.285580039\n",
      "Trained batch 1376 batch loss 0.241394043 epoch total loss 0.285547912\n",
      "Trained batch 1377 batch loss 0.271734506 epoch total loss 0.285537899\n",
      "Trained batch 1378 batch loss 0.256174475 epoch total loss 0.28551656\n",
      "Trained batch 1379 batch loss 0.274597496 epoch total loss 0.285508662\n",
      "Trained batch 1380 batch loss 0.279123247 epoch total loss 0.285504\n",
      "Trained batch 1381 batch loss 0.312919736 epoch total loss 0.285523862\n",
      "Trained batch 1382 batch loss 0.284100831 epoch total loss 0.285522848\n",
      "Trained batch 1383 batch loss 0.304461241 epoch total loss 0.285536528\n",
      "Trained batch 1384 batch loss 0.255744368 epoch total loss 0.285515\n",
      "Trained batch 1385 batch loss 0.283434629 epoch total loss 0.28551352\n",
      "Trained batch 1386 batch loss 0.284309864 epoch total loss 0.285512626\n",
      "Trained batch 1387 batch loss 0.268310964 epoch total loss 0.285500228\n",
      "Trained batch 1388 batch loss 0.259662479 epoch total loss 0.285481632\n",
      "Epoch 4 train loss 0.28548163175582886 and time 669.9034190177917\n",
      "Validated batch 1 batch loss 0.307109594\n",
      "Validated batch 2 batch loss 0.28040719\n",
      "Validated batch 3 batch loss 0.285964072\n",
      "Validated batch 4 batch loss 0.278485894\n",
      "Validated batch 5 batch loss 0.280781388\n",
      "Validated batch 6 batch loss 0.302036643\n",
      "Validated batch 7 batch loss 0.284242183\n",
      "Validated batch 8 batch loss 0.288613826\n",
      "Validated batch 9 batch loss 0.316485316\n",
      "Validated batch 10 batch loss 0.29155153\n",
      "Validated batch 11 batch loss 0.260189\n",
      "Validated batch 12 batch loss 0.262070298\n",
      "Validated batch 13 batch loss 0.294068575\n",
      "Validated batch 14 batch loss 0.309906155\n",
      "Validated batch 15 batch loss 0.331078082\n",
      "Validated batch 16 batch loss 0.318928063\n",
      "Validated batch 17 batch loss 0.305469543\n",
      "Validated batch 18 batch loss 0.320971668\n",
      "Validated batch 19 batch loss 0.298880696\n",
      "Validated batch 20 batch loss 0.283826083\n",
      "Validated batch 21 batch loss 0.289836496\n",
      "Validated batch 22 batch loss 0.229969144\n",
      "Validated batch 23 batch loss 0.297094107\n",
      "Validated batch 24 batch loss 0.271495521\n",
      "Validated batch 25 batch loss 0.267709851\n",
      "Validated batch 26 batch loss 0.280004829\n",
      "Validated batch 27 batch loss 0.286043286\n",
      "Validated batch 28 batch loss 0.285021871\n",
      "Validated batch 29 batch loss 0.307872891\n",
      "Validated batch 30 batch loss 0.274445534\n",
      "Validated batch 31 batch loss 0.238357246\n",
      "Validated batch 32 batch loss 0.264628708\n",
      "Validated batch 33 batch loss 0.275496095\n",
      "Validated batch 34 batch loss 0.273642033\n",
      "Validated batch 35 batch loss 0.275250554\n",
      "Validated batch 36 batch loss 0.274739385\n",
      "Validated batch 37 batch loss 0.28555575\n",
      "Validated batch 38 batch loss 0.314865291\n",
      "Validated batch 39 batch loss 0.312902361\n",
      "Validated batch 40 batch loss 0.279158086\n",
      "Validated batch 41 batch loss 0.312783301\n",
      "Validated batch 42 batch loss 0.232143596\n",
      "Validated batch 43 batch loss 0.267129719\n",
      "Validated batch 44 batch loss 0.253526628\n",
      "Validated batch 45 batch loss 0.281768382\n",
      "Validated batch 46 batch loss 0.326780736\n",
      "Validated batch 47 batch loss 0.291469753\n",
      "Validated batch 48 batch loss 0.268840432\n",
      "Validated batch 49 batch loss 0.27841419\n",
      "Validated batch 50 batch loss 0.264018297\n",
      "Validated batch 51 batch loss 0.281840146\n",
      "Validated batch 52 batch loss 0.293290496\n",
      "Validated batch 53 batch loss 0.31365484\n",
      "Validated batch 54 batch loss 0.284320444\n",
      "Validated batch 55 batch loss 0.290126175\n",
      "Validated batch 56 batch loss 0.290515155\n",
      "Validated batch 57 batch loss 0.277168214\n",
      "Validated batch 58 batch loss 0.303920835\n",
      "Validated batch 59 batch loss 0.263799757\n",
      "Validated batch 60 batch loss 0.277888387\n",
      "Validated batch 61 batch loss 0.295249045\n",
      "Validated batch 62 batch loss 0.281948954\n",
      "Validated batch 63 batch loss 0.338565588\n",
      "Validated batch 64 batch loss 0.301401585\n",
      "Validated batch 65 batch loss 0.2677356\n",
      "Validated batch 66 batch loss 0.300641268\n",
      "Validated batch 67 batch loss 0.284748524\n",
      "Validated batch 68 batch loss 0.265186131\n",
      "Validated batch 69 batch loss 0.293642163\n",
      "Validated batch 70 batch loss 0.314123839\n",
      "Validated batch 71 batch loss 0.299843\n",
      "Validated batch 72 batch loss 0.296075344\n",
      "Validated batch 73 batch loss 0.280518055\n",
      "Validated batch 74 batch loss 0.312923878\n",
      "Validated batch 75 batch loss 0.354282111\n",
      "Validated batch 76 batch loss 0.284803271\n",
      "Validated batch 77 batch loss 0.321160674\n",
      "Validated batch 78 batch loss 0.280465364\n",
      "Validated batch 79 batch loss 0.313949347\n",
      "Validated batch 80 batch loss 0.303482056\n",
      "Validated batch 81 batch loss 0.277070969\n",
      "Validated batch 82 batch loss 0.332551569\n",
      "Validated batch 83 batch loss 0.29579705\n",
      "Validated batch 84 batch loss 0.320514441\n",
      "Validated batch 85 batch loss 0.30654344\n",
      "Validated batch 86 batch loss 0.317348421\n",
      "Validated batch 87 batch loss 0.275948048\n",
      "Validated batch 88 batch loss 0.299044877\n",
      "Validated batch 89 batch loss 0.290028155\n",
      "Validated batch 90 batch loss 0.299335\n",
      "Validated batch 91 batch loss 0.300721765\n",
      "Validated batch 92 batch loss 0.293997407\n",
      "Validated batch 93 batch loss 0.338033289\n",
      "Validated batch 94 batch loss 0.288849503\n",
      "Validated batch 95 batch loss 0.290252149\n",
      "Validated batch 96 batch loss 0.291592181\n",
      "Validated batch 97 batch loss 0.267017931\n",
      "Validated batch 98 batch loss 0.303575218\n",
      "Validated batch 99 batch loss 0.299275041\n",
      "Validated batch 100 batch loss 0.285947084\n",
      "Validated batch 101 batch loss 0.286686599\n",
      "Validated batch 102 batch loss 0.307501584\n",
      "Validated batch 103 batch loss 0.312565207\n",
      "Validated batch 104 batch loss 0.316445202\n",
      "Validated batch 105 batch loss 0.290088236\n",
      "Validated batch 106 batch loss 0.267197371\n",
      "Validated batch 107 batch loss 0.277534902\n",
      "Validated batch 108 batch loss 0.297495484\n",
      "Validated batch 109 batch loss 0.274448216\n",
      "Validated batch 110 batch loss 0.301547438\n",
      "Validated batch 111 batch loss 0.298174173\n",
      "Validated batch 112 batch loss 0.334554255\n",
      "Validated batch 113 batch loss 0.328585923\n",
      "Validated batch 114 batch loss 0.302427679\n",
      "Validated batch 115 batch loss 0.275135785\n",
      "Validated batch 116 batch loss 0.268660158\n",
      "Validated batch 117 batch loss 0.29789111\n",
      "Validated batch 118 batch loss 0.283058852\n",
      "Validated batch 119 batch loss 0.276314139\n",
      "Validated batch 120 batch loss 0.29736194\n",
      "Validated batch 121 batch loss 0.312075585\n",
      "Validated batch 122 batch loss 0.321378559\n",
      "Validated batch 123 batch loss 0.311393917\n",
      "Validated batch 124 batch loss 0.298378974\n",
      "Validated batch 125 batch loss 0.275488913\n",
      "Validated batch 126 batch loss 0.300271183\n",
      "Validated batch 127 batch loss 0.298220873\n",
      "Validated batch 128 batch loss 0.287153274\n",
      "Validated batch 129 batch loss 0.325737923\n",
      "Validated batch 130 batch loss 0.315130889\n",
      "Validated batch 131 batch loss 0.313988775\n",
      "Validated batch 132 batch loss 0.313395023\n",
      "Validated batch 133 batch loss 0.283146948\n",
      "Validated batch 134 batch loss 0.285294592\n",
      "Validated batch 135 batch loss 0.27881074\n",
      "Validated batch 136 batch loss 0.251624197\n",
      "Validated batch 137 batch loss 0.309574068\n",
      "Validated batch 138 batch loss 0.264973432\n",
      "Validated batch 139 batch loss 0.290085137\n",
      "Validated batch 140 batch loss 0.28518796\n",
      "Validated batch 141 batch loss 0.276747346\n",
      "Validated batch 142 batch loss 0.279765874\n",
      "Validated batch 143 batch loss 0.273799688\n",
      "Validated batch 144 batch loss 0.302781641\n",
      "Validated batch 145 batch loss 0.284090281\n",
      "Validated batch 146 batch loss 0.326271415\n",
      "Validated batch 147 batch loss 0.300912112\n",
      "Validated batch 148 batch loss 0.305530608\n",
      "Validated batch 149 batch loss 0.302959502\n",
      "Validated batch 150 batch loss 0.336199343\n",
      "Validated batch 151 batch loss 0.306166977\n",
      "Validated batch 152 batch loss 0.304916084\n",
      "Validated batch 153 batch loss 0.31021136\n",
      "Validated batch 154 batch loss 0.334055454\n",
      "Validated batch 155 batch loss 0.31201303\n",
      "Validated batch 156 batch loss 0.267418355\n",
      "Validated batch 157 batch loss 0.290811718\n",
      "Validated batch 158 batch loss 0.31753239\n",
      "Validated batch 159 batch loss 0.312642276\n",
      "Validated batch 160 batch loss 0.285744339\n",
      "Validated batch 161 batch loss 0.312413275\n",
      "Validated batch 162 batch loss 0.28095448\n",
      "Validated batch 163 batch loss 0.261496514\n",
      "Validated batch 164 batch loss 0.31015414\n",
      "Validated batch 165 batch loss 0.293241441\n",
      "Validated batch 166 batch loss 0.300523341\n",
      "Validated batch 167 batch loss 0.348459333\n",
      "Validated batch 168 batch loss 0.271707028\n",
      "Validated batch 169 batch loss 0.295547783\n",
      "Validated batch 170 batch loss 0.297373801\n",
      "Validated batch 171 batch loss 0.309338242\n",
      "Validated batch 172 batch loss 0.313768536\n",
      "Validated batch 173 batch loss 0.287318\n",
      "Validated batch 174 batch loss 0.231587\n",
      "Validated batch 175 batch loss 0.298221201\n",
      "Validated batch 176 batch loss 0.269909054\n",
      "Validated batch 177 batch loss 0.283580899\n",
      "Validated batch 178 batch loss 0.300268978\n",
      "Validated batch 179 batch loss 0.25415048\n",
      "Validated batch 180 batch loss 0.293919146\n",
      "Validated batch 181 batch loss 0.320077956\n",
      "Validated batch 182 batch loss 0.305661023\n",
      "Validated batch 183 batch loss 0.296360016\n",
      "Validated batch 184 batch loss 0.27062577\n",
      "Validated batch 185 batch loss 0.293614447\n",
      "Epoch 4 val loss 0.29323554039001465\n",
      "Model /aiffel/aiffel/CV-PoseEstimation/models/model-epoch-4-loss-0.2932.h5 saved.\n",
      "Start epoch 5 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.310584307 epoch total loss 0.310584307\n",
      "Trained batch 2 batch loss 0.259017706 epoch total loss 0.284801\n",
      "Trained batch 3 batch loss 0.263775826 epoch total loss 0.277792603\n",
      "Trained batch 4 batch loss 0.240097374 epoch total loss 0.26836881\n",
      "Trained batch 5 batch loss 0.230997697 epoch total loss 0.260894597\n",
      "Trained batch 6 batch loss 0.303180844 epoch total loss 0.26794228\n",
      "Trained batch 7 batch loss 0.31951642 epoch total loss 0.27531\n",
      "Trained batch 8 batch loss 0.284811109 epoch total loss 0.276497662\n",
      "Trained batch 9 batch loss 0.267332435 epoch total loss 0.275479317\n",
      "Trained batch 10 batch loss 0.257539541 epoch total loss 0.273685336\n",
      "Trained batch 11 batch loss 0.261197239 epoch total loss 0.272550076\n",
      "Trained batch 12 batch loss 0.236198097 epoch total loss 0.26952073\n",
      "Trained batch 13 batch loss 0.264245719 epoch total loss 0.269114971\n",
      "Trained batch 14 batch loss 0.271932542 epoch total loss 0.269316226\n",
      "Trained batch 15 batch loss 0.289882749 epoch total loss 0.270687312\n",
      "Trained batch 16 batch loss 0.264575273 epoch total loss 0.270305336\n",
      "Trained batch 17 batch loss 0.288606644 epoch total loss 0.271381885\n",
      "Trained batch 18 batch loss 0.289761573 epoch total loss 0.272402972\n",
      "Trained batch 19 batch loss 0.274905801 epoch total loss 0.272534698\n",
      "Trained batch 20 batch loss 0.239918202 epoch total loss 0.270903885\n",
      "Trained batch 21 batch loss 0.272782475 epoch total loss 0.270993322\n",
      "Trained batch 22 batch loss 0.258503 epoch total loss 0.270425588\n",
      "Trained batch 23 batch loss 0.256957054 epoch total loss 0.26984\n",
      "Trained batch 24 batch loss 0.301379383 epoch total loss 0.271154135\n",
      "Trained batch 25 batch loss 0.294998854 epoch total loss 0.272107899\n",
      "Trained batch 26 batch loss 0.331799448 epoch total loss 0.274403751\n",
      "Trained batch 27 batch loss 0.291327685 epoch total loss 0.275030553\n",
      "Trained batch 28 batch loss 0.348694652 epoch total loss 0.277661413\n",
      "Trained batch 29 batch loss 0.336659044 epoch total loss 0.279695809\n",
      "Trained batch 30 batch loss 0.248915583 epoch total loss 0.278669804\n",
      "Trained batch 31 batch loss 0.258512706 epoch total loss 0.278019577\n",
      "Trained batch 32 batch loss 0.276125461 epoch total loss 0.27796039\n",
      "Trained batch 33 batch loss 0.250974119 epoch total loss 0.277142614\n",
      "Trained batch 34 batch loss 0.27337721 epoch total loss 0.277031869\n",
      "Trained batch 35 batch loss 0.251568466 epoch total loss 0.276304364\n",
      "Trained batch 36 batch loss 0.250883758 epoch total loss 0.275598228\n",
      "Trained batch 37 batch loss 0.22464107 epoch total loss 0.274221\n",
      "Trained batch 38 batch loss 0.245277688 epoch total loss 0.273459345\n",
      "Trained batch 39 batch loss 0.223782122 epoch total loss 0.272185564\n",
      "Trained batch 40 batch loss 0.255223155 epoch total loss 0.271761507\n",
      "Trained batch 41 batch loss 0.27850008 epoch total loss 0.271925867\n",
      "Trained batch 42 batch loss 0.234048218 epoch total loss 0.271024\n",
      "Trained batch 43 batch loss 0.246242076 epoch total loss 0.270447701\n",
      "Trained batch 44 batch loss 0.243139192 epoch total loss 0.269827038\n",
      "Trained batch 45 batch loss 0.287354 epoch total loss 0.270216525\n",
      "Trained batch 46 batch loss 0.295118928 epoch total loss 0.270757914\n",
      "Trained batch 47 batch loss 0.268788248 epoch total loss 0.270716\n",
      "Trained batch 48 batch loss 0.281106919 epoch total loss 0.270932466\n",
      "Trained batch 49 batch loss 0.287838548 epoch total loss 0.271277517\n",
      "Trained batch 50 batch loss 0.27431339 epoch total loss 0.271338224\n",
      "Trained batch 51 batch loss 0.282075644 epoch total loss 0.271548748\n",
      "Trained batch 52 batch loss 0.329620183 epoch total loss 0.27266553\n",
      "Trained batch 53 batch loss 0.329263747 epoch total loss 0.273733407\n",
      "Trained batch 54 batch loss 0.250741243 epoch total loss 0.273307621\n",
      "Trained batch 55 batch loss 0.285905331 epoch total loss 0.273536652\n",
      "Trained batch 56 batch loss 0.289855123 epoch total loss 0.273828059\n",
      "Trained batch 57 batch loss 0.27359876 epoch total loss 0.273824036\n",
      "Trained batch 58 batch loss 0.297213733 epoch total loss 0.274227321\n",
      "Trained batch 59 batch loss 0.283887982 epoch total loss 0.274391055\n",
      "Trained batch 60 batch loss 0.272599936 epoch total loss 0.274361193\n",
      "Trained batch 61 batch loss 0.287804425 epoch total loss 0.274581552\n",
      "Trained batch 62 batch loss 0.280653536 epoch total loss 0.274679482\n",
      "Trained batch 63 batch loss 0.2821697 epoch total loss 0.274798363\n",
      "Trained batch 64 batch loss 0.299284756 epoch total loss 0.275180966\n",
      "Trained batch 65 batch loss 0.260877222 epoch total loss 0.274960905\n",
      "Trained batch 66 batch loss 0.24834919 epoch total loss 0.27455768\n",
      "Trained batch 67 batch loss 0.281068265 epoch total loss 0.274654865\n",
      "Trained batch 68 batch loss 0.288705289 epoch total loss 0.274861515\n",
      "Trained batch 69 batch loss 0.290408492 epoch total loss 0.27508682\n",
      "Trained batch 70 batch loss 0.28286761 epoch total loss 0.275197983\n",
      "Trained batch 71 batch loss 0.294266164 epoch total loss 0.275466532\n",
      "Trained batch 72 batch loss 0.288978547 epoch total loss 0.275654197\n",
      "Trained batch 73 batch loss 0.300183475 epoch total loss 0.275990248\n",
      "Trained batch 74 batch loss 0.271812022 epoch total loss 0.275933772\n",
      "Trained batch 75 batch loss 0.294251621 epoch total loss 0.276178032\n",
      "Trained batch 76 batch loss 0.322592735 epoch total loss 0.276788771\n",
      "Trained batch 77 batch loss 0.268975 epoch total loss 0.276687264\n",
      "Trained batch 78 batch loss 0.306642592 epoch total loss 0.277071327\n",
      "Trained batch 79 batch loss 0.299372017 epoch total loss 0.277353615\n",
      "Trained batch 80 batch loss 0.276342303 epoch total loss 0.277340949\n",
      "Trained batch 81 batch loss 0.299248666 epoch total loss 0.277611405\n",
      "Trained batch 82 batch loss 0.271302938 epoch total loss 0.277534485\n",
      "Trained batch 83 batch loss 0.302320421 epoch total loss 0.277833104\n",
      "Trained batch 84 batch loss 0.286408931 epoch total loss 0.277935207\n",
      "Trained batch 85 batch loss 0.282861501 epoch total loss 0.277993172\n",
      "Trained batch 86 batch loss 0.239345849 epoch total loss 0.277543783\n",
      "Trained batch 87 batch loss 0.279000431 epoch total loss 0.277560532\n",
      "Trained batch 88 batch loss 0.323962152 epoch total loss 0.278087825\n",
      "Trained batch 89 batch loss 0.267262787 epoch total loss 0.277966201\n",
      "Trained batch 90 batch loss 0.242621556 epoch total loss 0.277573466\n",
      "Trained batch 91 batch loss 0.247034669 epoch total loss 0.277237892\n",
      "Trained batch 92 batch loss 0.266541243 epoch total loss 0.277121603\n",
      "Trained batch 93 batch loss 0.269651234 epoch total loss 0.277041286\n",
      "Trained batch 94 batch loss 0.241675511 epoch total loss 0.276665062\n",
      "Trained batch 95 batch loss 0.2645154 epoch total loss 0.27653715\n",
      "Trained batch 96 batch loss 0.2734963 epoch total loss 0.2765055\n",
      "Trained batch 97 batch loss 0.278828084 epoch total loss 0.276529431\n",
      "Trained batch 98 batch loss 0.282526523 epoch total loss 0.276590616\n",
      "Trained batch 99 batch loss 0.29219088 epoch total loss 0.27674818\n",
      "Trained batch 100 batch loss 0.314723253 epoch total loss 0.277127951\n",
      "Trained batch 101 batch loss 0.357967228 epoch total loss 0.277928352\n",
      "Trained batch 102 batch loss 0.348968565 epoch total loss 0.278624803\n",
      "Trained batch 103 batch loss 0.290738612 epoch total loss 0.278742433\n",
      "Trained batch 104 batch loss 0.251048326 epoch total loss 0.278476149\n",
      "Trained batch 105 batch loss 0.291993916 epoch total loss 0.278604895\n",
      "Trained batch 106 batch loss 0.296823263 epoch total loss 0.278776765\n",
      "Trained batch 107 batch loss 0.310465783 epoch total loss 0.279072911\n",
      "Trained batch 108 batch loss 0.308869541 epoch total loss 0.27934882\n",
      "Trained batch 109 batch loss 0.321230024 epoch total loss 0.279733032\n",
      "Trained batch 110 batch loss 0.285948157 epoch total loss 0.279789537\n",
      "Trained batch 111 batch loss 0.274350852 epoch total loss 0.279740542\n",
      "Trained batch 112 batch loss 0.298959702 epoch total loss 0.279912144\n",
      "Trained batch 113 batch loss 0.29048419 epoch total loss 0.280005693\n",
      "Trained batch 114 batch loss 0.269440234 epoch total loss 0.279913\n",
      "Trained batch 115 batch loss 0.291502625 epoch total loss 0.2800138\n",
      "Trained batch 116 batch loss 0.281881362 epoch total loss 0.280029923\n",
      "Trained batch 117 batch loss 0.312384337 epoch total loss 0.280306458\n",
      "Trained batch 118 batch loss 0.307714671 epoch total loss 0.280538768\n",
      "Trained batch 119 batch loss 0.301252931 epoch total loss 0.280712843\n",
      "Trained batch 120 batch loss 0.307493269 epoch total loss 0.280936033\n",
      "Trained batch 121 batch loss 0.267283797 epoch total loss 0.280823201\n",
      "Trained batch 122 batch loss 0.276698381 epoch total loss 0.280789405\n",
      "Trained batch 123 batch loss 0.285443395 epoch total loss 0.280827224\n",
      "Trained batch 124 batch loss 0.280587196 epoch total loss 0.280825287\n",
      "Trained batch 125 batch loss 0.276012421 epoch total loss 0.280786783\n",
      "Trained batch 126 batch loss 0.279799968 epoch total loss 0.280778944\n",
      "Trained batch 127 batch loss 0.290236652 epoch total loss 0.28085342\n",
      "Trained batch 128 batch loss 0.289568424 epoch total loss 0.280921519\n",
      "Trained batch 129 batch loss 0.282524556 epoch total loss 0.280933946\n",
      "Trained batch 130 batch loss 0.278446347 epoch total loss 0.280914813\n",
      "Trained batch 131 batch loss 0.281112 epoch total loss 0.280916303\n",
      "Trained batch 132 batch loss 0.334378272 epoch total loss 0.281321317\n",
      "Trained batch 133 batch loss 0.282649547 epoch total loss 0.281331301\n",
      "Trained batch 134 batch loss 0.272282362 epoch total loss 0.281263769\n",
      "Trained batch 135 batch loss 0.247835949 epoch total loss 0.281016171\n",
      "Trained batch 136 batch loss 0.260332 epoch total loss 0.28086406\n",
      "Trained batch 137 batch loss 0.249282449 epoch total loss 0.280633539\n",
      "Trained batch 138 batch loss 0.294550925 epoch total loss 0.28073442\n",
      "Trained batch 139 batch loss 0.307203144 epoch total loss 0.280924827\n",
      "Trained batch 140 batch loss 0.287651062 epoch total loss 0.280972868\n",
      "Trained batch 141 batch loss 0.290400922 epoch total loss 0.281039745\n",
      "Trained batch 142 batch loss 0.272533655 epoch total loss 0.280979842\n",
      "Trained batch 143 batch loss 0.274009645 epoch total loss 0.280931085\n",
      "Trained batch 144 batch loss 0.267113268 epoch total loss 0.280835122\n",
      "Trained batch 145 batch loss 0.285907745 epoch total loss 0.28087011\n",
      "Trained batch 146 batch loss 0.312032312 epoch total loss 0.281083524\n",
      "Trained batch 147 batch loss 0.298219949 epoch total loss 0.281200111\n",
      "Trained batch 148 batch loss 0.259889036 epoch total loss 0.281056106\n",
      "Trained batch 149 batch loss 0.24468483 epoch total loss 0.280812025\n",
      "Trained batch 150 batch loss 0.232328892 epoch total loss 0.280488819\n",
      "Trained batch 151 batch loss 0.259287626 epoch total loss 0.28034842\n",
      "Trained batch 152 batch loss 0.254028827 epoch total loss 0.280175269\n",
      "Trained batch 153 batch loss 0.260743111 epoch total loss 0.280048251\n",
      "Trained batch 154 batch loss 0.259354949 epoch total loss 0.279913872\n",
      "Trained batch 155 batch loss 0.287072748 epoch total loss 0.279960036\n",
      "Trained batch 156 batch loss 0.310912102 epoch total loss 0.28015846\n",
      "Trained batch 157 batch loss 0.310202181 epoch total loss 0.280349821\n",
      "Trained batch 158 batch loss 0.29735902 epoch total loss 0.280457497\n",
      "Trained batch 159 batch loss 0.263890922 epoch total loss 0.280353278\n",
      "Trained batch 160 batch loss 0.249688447 epoch total loss 0.280161619\n",
      "Trained batch 161 batch loss 0.240459055 epoch total loss 0.279915035\n",
      "Trained batch 162 batch loss 0.280275911 epoch total loss 0.27991727\n",
      "Trained batch 163 batch loss 0.251765072 epoch total loss 0.279744565\n",
      "Trained batch 164 batch loss 0.294668615 epoch total loss 0.279835552\n",
      "Trained batch 165 batch loss 0.291013271 epoch total loss 0.279903293\n",
      "Trained batch 166 batch loss 0.307043672 epoch total loss 0.280066788\n",
      "Trained batch 167 batch loss 0.302824348 epoch total loss 0.280203074\n",
      "Trained batch 168 batch loss 0.294837922 epoch total loss 0.280290186\n",
      "Trained batch 169 batch loss 0.304818571 epoch total loss 0.280435324\n",
      "Trained batch 170 batch loss 0.304349482 epoch total loss 0.280576\n",
      "Trained batch 171 batch loss 0.31806162 epoch total loss 0.280795217\n",
      "Trained batch 172 batch loss 0.311320186 epoch total loss 0.280972689\n",
      "Trained batch 173 batch loss 0.297358125 epoch total loss 0.281067401\n",
      "Trained batch 174 batch loss 0.276003301 epoch total loss 0.281038314\n",
      "Trained batch 175 batch loss 0.300761878 epoch total loss 0.281151026\n",
      "Trained batch 176 batch loss 0.267685264 epoch total loss 0.281074494\n",
      "Trained batch 177 batch loss 0.281531274 epoch total loss 0.281077087\n",
      "Trained batch 178 batch loss 0.258945405 epoch total loss 0.280952752\n",
      "Trained batch 179 batch loss 0.280163288 epoch total loss 0.280948341\n",
      "Trained batch 180 batch loss 0.277833581 epoch total loss 0.280931026\n",
      "Trained batch 181 batch loss 0.275388747 epoch total loss 0.280900419\n",
      "Trained batch 182 batch loss 0.295005441 epoch total loss 0.280977935\n",
      "Trained batch 183 batch loss 0.308358133 epoch total loss 0.281127542\n",
      "Trained batch 184 batch loss 0.298256785 epoch total loss 0.281220615\n",
      "Trained batch 185 batch loss 0.294258356 epoch total loss 0.281291097\n",
      "Trained batch 186 batch loss 0.32308358 epoch total loss 0.281515777\n",
      "Trained batch 187 batch loss 0.301784456 epoch total loss 0.281624168\n",
      "Trained batch 188 batch loss 0.318554282 epoch total loss 0.281820595\n",
      "Trained batch 189 batch loss 0.275845796 epoch total loss 0.281788975\n",
      "Trained batch 190 batch loss 0.248437271 epoch total loss 0.281613439\n",
      "Trained batch 191 batch loss 0.270666897 epoch total loss 0.281556129\n",
      "Trained batch 192 batch loss 0.254919291 epoch total loss 0.2814174\n",
      "Trained batch 193 batch loss 0.256326586 epoch total loss 0.281287402\n",
      "Trained batch 194 batch loss 0.271528512 epoch total loss 0.281237096\n",
      "Trained batch 195 batch loss 0.265509576 epoch total loss 0.281156451\n",
      "Trained batch 196 batch loss 0.236736953 epoch total loss 0.280929804\n",
      "Trained batch 197 batch loss 0.240629584 epoch total loss 0.280725271\n",
      "Trained batch 198 batch loss 0.287043661 epoch total loss 0.280757159\n",
      "Trained batch 199 batch loss 0.290524304 epoch total loss 0.280806243\n",
      "Trained batch 200 batch loss 0.317503154 epoch total loss 0.280989736\n",
      "Trained batch 201 batch loss 0.281901479 epoch total loss 0.280994296\n",
      "Trained batch 202 batch loss 0.309633732 epoch total loss 0.281136066\n",
      "Trained batch 203 batch loss 0.297543049 epoch total loss 0.28121689\n",
      "Trained batch 204 batch loss 0.307694405 epoch total loss 0.281346679\n",
      "Trained batch 205 batch loss 0.281362593 epoch total loss 0.281346768\n",
      "Trained batch 206 batch loss 0.311959237 epoch total loss 0.281495363\n",
      "Trained batch 207 batch loss 0.293318659 epoch total loss 0.281552494\n",
      "Trained batch 208 batch loss 0.264913559 epoch total loss 0.281472504\n",
      "Trained batch 209 batch loss 0.252415836 epoch total loss 0.281333476\n",
      "Trained batch 210 batch loss 0.232785404 epoch total loss 0.28110227\n",
      "Trained batch 211 batch loss 0.254742831 epoch total loss 0.280977339\n",
      "Trained batch 212 batch loss 0.276020318 epoch total loss 0.280953974\n",
      "Trained batch 213 batch loss 0.275655746 epoch total loss 0.280929089\n",
      "Trained batch 214 batch loss 0.281342655 epoch total loss 0.280931026\n",
      "Trained batch 215 batch loss 0.292683661 epoch total loss 0.280985683\n",
      "Trained batch 216 batch loss 0.294309676 epoch total loss 0.281047374\n",
      "Trained batch 217 batch loss 0.293661743 epoch total loss 0.281105518\n",
      "Trained batch 218 batch loss 0.290756106 epoch total loss 0.281149775\n",
      "Trained batch 219 batch loss 0.282741636 epoch total loss 0.281157047\n",
      "Trained batch 220 batch loss 0.276810437 epoch total loss 0.281137288\n",
      "Trained batch 221 batch loss 0.274097949 epoch total loss 0.281105429\n",
      "Trained batch 222 batch loss 0.27321735 epoch total loss 0.281069905\n",
      "Trained batch 223 batch loss 0.261945039 epoch total loss 0.280984133\n",
      "Trained batch 224 batch loss 0.259161472 epoch total loss 0.28088671\n",
      "Trained batch 225 batch loss 0.252095193 epoch total loss 0.280758739\n",
      "Trained batch 226 batch loss 0.2525931 epoch total loss 0.280634135\n",
      "Trained batch 227 batch loss 0.266213834 epoch total loss 0.280570596\n",
      "Trained batch 228 batch loss 0.267375916 epoch total loss 0.28051272\n",
      "Trained batch 229 batch loss 0.228472635 epoch total loss 0.280285478\n",
      "Trained batch 230 batch loss 0.284923255 epoch total loss 0.280305624\n",
      "Trained batch 231 batch loss 0.312134027 epoch total loss 0.2804434\n",
      "Trained batch 232 batch loss 0.281020403 epoch total loss 0.280445874\n",
      "Trained batch 233 batch loss 0.276955783 epoch total loss 0.280430913\n",
      "Trained batch 234 batch loss 0.287189215 epoch total loss 0.280459762\n",
      "Trained batch 235 batch loss 0.264007062 epoch total loss 0.280389756\n",
      "Trained batch 236 batch loss 0.265865803 epoch total loss 0.280328244\n",
      "Trained batch 237 batch loss 0.271926224 epoch total loss 0.280292779\n",
      "Trained batch 238 batch loss 0.306848228 epoch total loss 0.280404359\n",
      "Trained batch 239 batch loss 0.315927416 epoch total loss 0.280552983\n",
      "Trained batch 240 batch loss 0.274386942 epoch total loss 0.280527264\n",
      "Trained batch 241 batch loss 0.31924209 epoch total loss 0.280687928\n",
      "Trained batch 242 batch loss 0.300651073 epoch total loss 0.280770421\n",
      "Trained batch 243 batch loss 0.304094166 epoch total loss 0.280866385\n",
      "Trained batch 244 batch loss 0.263104588 epoch total loss 0.280793607\n",
      "Trained batch 245 batch loss 0.269859552 epoch total loss 0.280749\n",
      "Trained batch 246 batch loss 0.276962966 epoch total loss 0.280733585\n",
      "Trained batch 247 batch loss 0.287187278 epoch total loss 0.280759722\n",
      "Trained batch 248 batch loss 0.282379419 epoch total loss 0.280766249\n",
      "Trained batch 249 batch loss 0.264821768 epoch total loss 0.280702204\n",
      "Trained batch 250 batch loss 0.310043514 epoch total loss 0.280819595\n",
      "Trained batch 251 batch loss 0.272714496 epoch total loss 0.280787289\n",
      "Trained batch 252 batch loss 0.275058717 epoch total loss 0.28076452\n",
      "Trained batch 253 batch loss 0.267303795 epoch total loss 0.280711323\n",
      "Trained batch 254 batch loss 0.270958781 epoch total loss 0.280672938\n",
      "Trained batch 255 batch loss 0.294703245 epoch total loss 0.280727953\n",
      "Trained batch 256 batch loss 0.300483555 epoch total loss 0.280805111\n",
      "Trained batch 257 batch loss 0.279703707 epoch total loss 0.280800819\n",
      "Trained batch 258 batch loss 0.249610841 epoch total loss 0.280679911\n",
      "Trained batch 259 batch loss 0.282132626 epoch total loss 0.280685544\n",
      "Trained batch 260 batch loss 0.275267661 epoch total loss 0.280664712\n",
      "Trained batch 261 batch loss 0.272752225 epoch total loss 0.280634373\n",
      "Trained batch 262 batch loss 0.270046294 epoch total loss 0.280594\n",
      "Trained batch 263 batch loss 0.250250697 epoch total loss 0.280478626\n",
      "Trained batch 264 batch loss 0.285560936 epoch total loss 0.280497879\n",
      "Trained batch 265 batch loss 0.262265801 epoch total loss 0.280429065\n",
      "Trained batch 266 batch loss 0.274809241 epoch total loss 0.280407965\n",
      "Trained batch 267 batch loss 0.293220103 epoch total loss 0.280455947\n",
      "Trained batch 268 batch loss 0.253623605 epoch total loss 0.280355811\n",
      "Trained batch 269 batch loss 0.264362127 epoch total loss 0.280296355\n",
      "Trained batch 270 batch loss 0.202729478 epoch total loss 0.280009061\n",
      "Trained batch 271 batch loss 0.223631129 epoch total loss 0.279801041\n",
      "Trained batch 272 batch loss 0.298877686 epoch total loss 0.279871166\n",
      "Trained batch 273 batch loss 0.273938 epoch total loss 0.27984944\n",
      "Trained batch 274 batch loss 0.25696665 epoch total loss 0.279765904\n",
      "Trained batch 275 batch loss 0.282243431 epoch total loss 0.279774904\n",
      "Trained batch 276 batch loss 0.266199052 epoch total loss 0.27972573\n",
      "Trained batch 277 batch loss 0.232396662 epoch total loss 0.279554874\n",
      "Trained batch 278 batch loss 0.267141432 epoch total loss 0.27951023\n",
      "Trained batch 279 batch loss 0.257950664 epoch total loss 0.279432952\n",
      "Trained batch 280 batch loss 0.275973678 epoch total loss 0.279420584\n",
      "Trained batch 281 batch loss 0.247020766 epoch total loss 0.279305279\n",
      "Trained batch 282 batch loss 0.248576447 epoch total loss 0.279196322\n",
      "Trained batch 283 batch loss 0.268093884 epoch total loss 0.279157102\n",
      "Trained batch 284 batch loss 0.296592504 epoch total loss 0.279218495\n",
      "Trained batch 285 batch loss 0.315916538 epoch total loss 0.279347241\n",
      "Trained batch 286 batch loss 0.28371644 epoch total loss 0.27936253\n",
      "Trained batch 287 batch loss 0.295711547 epoch total loss 0.279419512\n",
      "Trained batch 288 batch loss 0.317624032 epoch total loss 0.279552162\n",
      "Trained batch 289 batch loss 0.282884657 epoch total loss 0.279563695\n",
      "Trained batch 290 batch loss 0.305880517 epoch total loss 0.279654443\n",
      "Trained batch 291 batch loss 0.290867448 epoch total loss 0.279692978\n",
      "Trained batch 292 batch loss 0.260473669 epoch total loss 0.279627174\n",
      "Trained batch 293 batch loss 0.313512862 epoch total loss 0.279742807\n",
      "Trained batch 294 batch loss 0.296302915 epoch total loss 0.279799134\n",
      "Trained batch 295 batch loss 0.301244 epoch total loss 0.279871851\n",
      "Trained batch 296 batch loss 0.297943294 epoch total loss 0.279932886\n",
      "Trained batch 297 batch loss 0.282454073 epoch total loss 0.27994138\n",
      "Trained batch 298 batch loss 0.236389071 epoch total loss 0.279795229\n",
      "Trained batch 299 batch loss 0.257310361 epoch total loss 0.279720038\n",
      "Trained batch 300 batch loss 0.268454075 epoch total loss 0.279682487\n",
      "Trained batch 301 batch loss 0.267634809 epoch total loss 0.279642463\n",
      "Trained batch 302 batch loss 0.324662119 epoch total loss 0.279791534\n",
      "Trained batch 303 batch loss 0.29363 epoch total loss 0.279837191\n",
      "Trained batch 304 batch loss 0.28802225 epoch total loss 0.279864132\n",
      "Trained batch 305 batch loss 0.288948596 epoch total loss 0.279893905\n",
      "Trained batch 306 batch loss 0.284355104 epoch total loss 0.279908508\n",
      "Trained batch 307 batch loss 0.276542157 epoch total loss 0.279897541\n",
      "Trained batch 308 batch loss 0.306551576 epoch total loss 0.279984057\n",
      "Trained batch 309 batch loss 0.278854549 epoch total loss 0.279980421\n",
      "Trained batch 310 batch loss 0.254746497 epoch total loss 0.279899\n",
      "Trained batch 311 batch loss 0.291498184 epoch total loss 0.279936284\n",
      "Trained batch 312 batch loss 0.291711479 epoch total loss 0.279974043\n",
      "Trained batch 313 batch loss 0.287899494 epoch total loss 0.279999375\n",
      "Trained batch 314 batch loss 0.285598695 epoch total loss 0.280017197\n",
      "Trained batch 315 batch loss 0.303887486 epoch total loss 0.280092984\n",
      "Trained batch 316 batch loss 0.234692901 epoch total loss 0.279949307\n",
      "Trained batch 317 batch loss 0.261652172 epoch total loss 0.27989158\n",
      "Trained batch 318 batch loss 0.274657786 epoch total loss 0.279875129\n",
      "Trained batch 319 batch loss 0.306374967 epoch total loss 0.279958189\n",
      "Trained batch 320 batch loss 0.295666158 epoch total loss 0.280007303\n",
      "Trained batch 321 batch loss 0.319402575 epoch total loss 0.280130029\n",
      "Trained batch 322 batch loss 0.290354043 epoch total loss 0.280161768\n",
      "Trained batch 323 batch loss 0.304595888 epoch total loss 0.280237406\n",
      "Trained batch 324 batch loss 0.286212534 epoch total loss 0.280255854\n",
      "Trained batch 325 batch loss 0.291157424 epoch total loss 0.280289412\n",
      "Trained batch 326 batch loss 0.285241514 epoch total loss 0.280304581\n",
      "Trained batch 327 batch loss 0.258650571 epoch total loss 0.28023836\n",
      "Trained batch 328 batch loss 0.261309147 epoch total loss 0.280180663\n",
      "Trained batch 329 batch loss 0.266938537 epoch total loss 0.2801404\n",
      "Trained batch 330 batch loss 0.253581315 epoch total loss 0.280059904\n",
      "Trained batch 331 batch loss 0.299664646 epoch total loss 0.280119151\n",
      "Trained batch 332 batch loss 0.253270626 epoch total loss 0.280038267\n",
      "Trained batch 333 batch loss 0.242362216 epoch total loss 0.279925138\n",
      "Trained batch 334 batch loss 0.269292027 epoch total loss 0.279893309\n",
      "Trained batch 335 batch loss 0.29714945 epoch total loss 0.279944837\n",
      "Trained batch 336 batch loss 0.24357675 epoch total loss 0.279836595\n",
      "Trained batch 337 batch loss 0.251860976 epoch total loss 0.279753566\n",
      "Trained batch 338 batch loss 0.246160716 epoch total loss 0.279654205\n",
      "Trained batch 339 batch loss 0.291096419 epoch total loss 0.279687941\n",
      "Trained batch 340 batch loss 0.269820273 epoch total loss 0.279658943\n",
      "Trained batch 341 batch loss 0.284447581 epoch total loss 0.27967298\n",
      "Trained batch 342 batch loss 0.276005477 epoch total loss 0.279662251\n",
      "Trained batch 343 batch loss 0.287100732 epoch total loss 0.279683948\n",
      "Trained batch 344 batch loss 0.280585766 epoch total loss 0.27968657\n",
      "Trained batch 345 batch loss 0.303407252 epoch total loss 0.279755324\n",
      "Trained batch 346 batch loss 0.307043463 epoch total loss 0.279834211\n",
      "Trained batch 347 batch loss 0.27877447 epoch total loss 0.279831141\n",
      "Trained batch 348 batch loss 0.276243091 epoch total loss 0.279820859\n",
      "Trained batch 349 batch loss 0.291973501 epoch total loss 0.279855669\n",
      "Trained batch 350 batch loss 0.277360499 epoch total loss 0.279848546\n",
      "Trained batch 351 batch loss 0.284451634 epoch total loss 0.279861659\n",
      "Trained batch 352 batch loss 0.243702963 epoch total loss 0.27975896\n",
      "Trained batch 353 batch loss 0.264785111 epoch total loss 0.279716522\n",
      "Trained batch 354 batch loss 0.271031708 epoch total loss 0.279692\n",
      "Trained batch 355 batch loss 0.246334493 epoch total loss 0.279598057\n",
      "Trained batch 356 batch loss 0.246688604 epoch total loss 0.27950561\n",
      "Trained batch 357 batch loss 0.237618551 epoch total loss 0.279388279\n",
      "Trained batch 358 batch loss 0.246246487 epoch total loss 0.279295713\n",
      "Trained batch 359 batch loss 0.267611712 epoch total loss 0.279263139\n",
      "Trained batch 360 batch loss 0.247157156 epoch total loss 0.27917397\n",
      "Trained batch 361 batch loss 0.252124041 epoch total loss 0.279099017\n",
      "Trained batch 362 batch loss 0.248417288 epoch total loss 0.27901426\n",
      "Trained batch 363 batch loss 0.263819098 epoch total loss 0.278972417\n",
      "Trained batch 364 batch loss 0.290498853 epoch total loss 0.279004067\n",
      "Trained batch 365 batch loss 0.289527476 epoch total loss 0.279032886\n",
      "Trained batch 366 batch loss 0.297393143 epoch total loss 0.279083073\n",
      "Trained batch 367 batch loss 0.2752783 epoch total loss 0.279072702\n",
      "Trained batch 368 batch loss 0.310763687 epoch total loss 0.279158801\n",
      "Trained batch 369 batch loss 0.279649884 epoch total loss 0.279160112\n",
      "Trained batch 370 batch loss 0.28295061 epoch total loss 0.279170364\n",
      "Trained batch 371 batch loss 0.278063029 epoch total loss 0.279167384\n",
      "Trained batch 372 batch loss 0.281740069 epoch total loss 0.279174298\n",
      "Trained batch 373 batch loss 0.294594556 epoch total loss 0.279215634\n",
      "Trained batch 374 batch loss 0.29439187 epoch total loss 0.279256225\n",
      "Trained batch 375 batch loss 0.268334359 epoch total loss 0.279227078\n",
      "Trained batch 376 batch loss 0.274905026 epoch total loss 0.279215604\n",
      "Trained batch 377 batch loss 0.269942462 epoch total loss 0.279191\n",
      "Trained batch 378 batch loss 0.254153609 epoch total loss 0.279124737\n",
      "Trained batch 379 batch loss 0.277686715 epoch total loss 0.279120952\n",
      "Trained batch 380 batch loss 0.26687932 epoch total loss 0.279088736\n",
      "Trained batch 381 batch loss 0.27851826 epoch total loss 0.279087245\n",
      "Trained batch 382 batch loss 0.295614541 epoch total loss 0.279130518\n",
      "Trained batch 383 batch loss 0.333749324 epoch total loss 0.279273123\n",
      "Trained batch 384 batch loss 0.314441979 epoch total loss 0.279364705\n",
      "Trained batch 385 batch loss 0.298368245 epoch total loss 0.279414058\n",
      "Trained batch 386 batch loss 0.286373824 epoch total loss 0.279432118\n",
      "Trained batch 387 batch loss 0.261616468 epoch total loss 0.279386073\n",
      "Trained batch 388 batch loss 0.229029283 epoch total loss 0.279256284\n",
      "Trained batch 389 batch loss 0.199837759 epoch total loss 0.279052138\n",
      "Trained batch 390 batch loss 0.253751338 epoch total loss 0.278987259\n",
      "Trained batch 391 batch loss 0.287583 epoch total loss 0.279009253\n",
      "Trained batch 392 batch loss 0.271754116 epoch total loss 0.278990716\n",
      "Trained batch 393 batch loss 0.303414315 epoch total loss 0.279052883\n",
      "Trained batch 394 batch loss 0.284008324 epoch total loss 0.27906546\n",
      "Trained batch 395 batch loss 0.28860122 epoch total loss 0.2790896\n",
      "Trained batch 396 batch loss 0.281090498 epoch total loss 0.279094666\n",
      "Trained batch 397 batch loss 0.286925912 epoch total loss 0.279114395\n",
      "Trained batch 398 batch loss 0.255139858 epoch total loss 0.279054165\n",
      "Trained batch 399 batch loss 0.273166239 epoch total loss 0.279039383\n",
      "Trained batch 400 batch loss 0.308830887 epoch total loss 0.279113859\n",
      "Trained batch 401 batch loss 0.285243899 epoch total loss 0.279129148\n",
      "Trained batch 402 batch loss 0.283537656 epoch total loss 0.279140115\n",
      "Trained batch 403 batch loss 0.283605844 epoch total loss 0.279151201\n",
      "Trained batch 404 batch loss 0.273284078 epoch total loss 0.279136688\n",
      "Trained batch 405 batch loss 0.238565385 epoch total loss 0.279036492\n",
      "Trained batch 406 batch loss 0.250505596 epoch total loss 0.278966218\n",
      "Trained batch 407 batch loss 0.263062924 epoch total loss 0.278927147\n",
      "Trained batch 408 batch loss 0.253305107 epoch total loss 0.278864324\n",
      "Trained batch 409 batch loss 0.274105489 epoch total loss 0.278852701\n",
      "Trained batch 410 batch loss 0.238278911 epoch total loss 0.278753757\n",
      "Trained batch 411 batch loss 0.270988107 epoch total loss 0.278734863\n",
      "Trained batch 412 batch loss 0.278494626 epoch total loss 0.278734267\n",
      "Trained batch 413 batch loss 0.274055153 epoch total loss 0.278722942\n",
      "Trained batch 414 batch loss 0.247006774 epoch total loss 0.27864635\n",
      "Trained batch 415 batch loss 0.249035582 epoch total loss 0.278575\n",
      "Trained batch 416 batch loss 0.293772787 epoch total loss 0.278611541\n",
      "Trained batch 417 batch loss 0.277646303 epoch total loss 0.278609216\n",
      "Trained batch 418 batch loss 0.282158077 epoch total loss 0.27861771\n",
      "Trained batch 419 batch loss 0.26996249 epoch total loss 0.278597057\n",
      "Trained batch 420 batch loss 0.275711447 epoch total loss 0.278590202\n",
      "Trained batch 421 batch loss 0.279805809 epoch total loss 0.278593093\n",
      "Trained batch 422 batch loss 0.310481101 epoch total loss 0.278668642\n",
      "Trained batch 423 batch loss 0.279589772 epoch total loss 0.278670818\n",
      "Trained batch 424 batch loss 0.253719568 epoch total loss 0.278612\n",
      "Trained batch 425 batch loss 0.267664284 epoch total loss 0.278586209\n",
      "Trained batch 426 batch loss 0.26514864 epoch total loss 0.278554678\n",
      "Trained batch 427 batch loss 0.264361739 epoch total loss 0.278521419\n",
      "Trained batch 428 batch loss 0.243304908 epoch total loss 0.278439134\n",
      "Trained batch 429 batch loss 0.252520323 epoch total loss 0.278378725\n",
      "Trained batch 430 batch loss 0.23871538 epoch total loss 0.278286487\n",
      "Trained batch 431 batch loss 0.244432226 epoch total loss 0.278207928\n",
      "Trained batch 432 batch loss 0.236891627 epoch total loss 0.278112292\n",
      "Trained batch 433 batch loss 0.250713944 epoch total loss 0.278049022\n",
      "Trained batch 434 batch loss 0.253523916 epoch total loss 0.277992517\n",
      "Trained batch 435 batch loss 0.274434835 epoch total loss 0.277984351\n",
      "Trained batch 436 batch loss 0.274093181 epoch total loss 0.27797541\n",
      "Trained batch 437 batch loss 0.262607783 epoch total loss 0.277940243\n",
      "Trained batch 438 batch loss 0.292999953 epoch total loss 0.277974635\n",
      "Trained batch 439 batch loss 0.265758127 epoch total loss 0.2779468\n",
      "Trained batch 440 batch loss 0.254673272 epoch total loss 0.277893931\n",
      "Trained batch 441 batch loss 0.254548371 epoch total loss 0.277840972\n",
      "Trained batch 442 batch loss 0.266397417 epoch total loss 0.277815074\n",
      "Trained batch 443 batch loss 0.286793619 epoch total loss 0.277835369\n",
      "Trained batch 444 batch loss 0.296379298 epoch total loss 0.277877122\n",
      "Trained batch 445 batch loss 0.253406584 epoch total loss 0.277822137\n",
      "Trained batch 446 batch loss 0.258371383 epoch total loss 0.277778536\n",
      "Trained batch 447 batch loss 0.265599877 epoch total loss 0.277751297\n",
      "Trained batch 448 batch loss 0.268259585 epoch total loss 0.277730078\n",
      "Trained batch 449 batch loss 0.275542289 epoch total loss 0.27772522\n",
      "Trained batch 450 batch loss 0.292887419 epoch total loss 0.277758896\n",
      "Trained batch 451 batch loss 0.28171128 epoch total loss 0.277767658\n",
      "Trained batch 452 batch loss 0.259748846 epoch total loss 0.277727813\n",
      "Trained batch 453 batch loss 0.245076299 epoch total loss 0.277655721\n",
      "Trained batch 454 batch loss 0.286428928 epoch total loss 0.277675062\n",
      "Trained batch 455 batch loss 0.238396198 epoch total loss 0.277588725\n",
      "Trained batch 456 batch loss 0.268811643 epoch total loss 0.277569473\n",
      "Trained batch 457 batch loss 0.297801703 epoch total loss 0.277613759\n",
      "Trained batch 458 batch loss 0.262088627 epoch total loss 0.277579844\n",
      "Trained batch 459 batch loss 0.259386361 epoch total loss 0.277540207\n",
      "Trained batch 460 batch loss 0.244028434 epoch total loss 0.27746734\n",
      "Trained batch 461 batch loss 0.235233516 epoch total loss 0.277375728\n",
      "Trained batch 462 batch loss 0.249259233 epoch total loss 0.277314872\n",
      "Trained batch 463 batch loss 0.255055249 epoch total loss 0.2772668\n",
      "Trained batch 464 batch loss 0.255352974 epoch total loss 0.277219564\n",
      "Trained batch 465 batch loss 0.261120319 epoch total loss 0.277184963\n",
      "Trained batch 466 batch loss 0.255633473 epoch total loss 0.27713871\n",
      "Trained batch 467 batch loss 0.247372121 epoch total loss 0.277074963\n",
      "Trained batch 468 batch loss 0.26685077 epoch total loss 0.277053118\n",
      "Trained batch 469 batch loss 0.273615032 epoch total loss 0.277045786\n",
      "Trained batch 470 batch loss 0.26037088 epoch total loss 0.277010322\n",
      "Trained batch 471 batch loss 0.286308 epoch total loss 0.277030051\n",
      "Trained batch 472 batch loss 0.281520367 epoch total loss 0.277039587\n",
      "Trained batch 473 batch loss 0.271647513 epoch total loss 0.277028173\n",
      "Trained batch 474 batch loss 0.274604529 epoch total loss 0.277023047\n",
      "Trained batch 475 batch loss 0.276517093 epoch total loss 0.277022\n",
      "Trained batch 476 batch loss 0.278083 epoch total loss 0.277024209\n",
      "Trained batch 477 batch loss 0.252546221 epoch total loss 0.27697289\n",
      "Trained batch 478 batch loss 0.273008525 epoch total loss 0.276964605\n",
      "Trained batch 479 batch loss 0.29270193 epoch total loss 0.276997477\n",
      "Trained batch 480 batch loss 0.279284954 epoch total loss 0.277002245\n",
      "Trained batch 481 batch loss 0.302779168 epoch total loss 0.27705583\n",
      "Trained batch 482 batch loss 0.281032473 epoch total loss 0.277064085\n",
      "Trained batch 483 batch loss 0.284068376 epoch total loss 0.277078599\n",
      "Trained batch 484 batch loss 0.312589884 epoch total loss 0.277151972\n",
      "Trained batch 485 batch loss 0.273664087 epoch total loss 0.27714479\n",
      "Trained batch 486 batch loss 0.241615549 epoch total loss 0.277071685\n",
      "Trained batch 487 batch loss 0.266183 epoch total loss 0.277049363\n",
      "Trained batch 488 batch loss 0.286599249 epoch total loss 0.277068943\n",
      "Trained batch 489 batch loss 0.310388148 epoch total loss 0.277137071\n",
      "Trained batch 490 batch loss 0.290079057 epoch total loss 0.277163506\n",
      "Trained batch 491 batch loss 0.271653146 epoch total loss 0.27715227\n",
      "Trained batch 492 batch loss 0.303592771 epoch total loss 0.277206\n",
      "Trained batch 493 batch loss 0.278518766 epoch total loss 0.277208686\n",
      "Trained batch 494 batch loss 0.239701331 epoch total loss 0.27713275\n",
      "Trained batch 495 batch loss 0.258110374 epoch total loss 0.277094334\n",
      "Trained batch 496 batch loss 0.269102752 epoch total loss 0.277078241\n",
      "Trained batch 497 batch loss 0.304875135 epoch total loss 0.27713415\n",
      "Trained batch 498 batch loss 0.302751243 epoch total loss 0.277185589\n",
      "Trained batch 499 batch loss 0.330840409 epoch total loss 0.277293116\n",
      "Trained batch 500 batch loss 0.326384157 epoch total loss 0.277391285\n",
      "Trained batch 501 batch loss 0.31388706 epoch total loss 0.277464151\n",
      "Trained batch 502 batch loss 0.282240272 epoch total loss 0.277473658\n",
      "Trained batch 503 batch loss 0.292245328 epoch total loss 0.277503043\n",
      "Trained batch 504 batch loss 0.256086707 epoch total loss 0.277460545\n",
      "Trained batch 505 batch loss 0.290809035 epoch total loss 0.27748698\n",
      "Trained batch 506 batch loss 0.285319269 epoch total loss 0.277502447\n",
      "Trained batch 507 batch loss 0.297599971 epoch total loss 0.277542114\n",
      "Trained batch 508 batch loss 0.269606 epoch total loss 0.277526498\n",
      "Trained batch 509 batch loss 0.313881516 epoch total loss 0.277597934\n",
      "Trained batch 510 batch loss 0.342303097 epoch total loss 0.277724802\n",
      "Trained batch 511 batch loss 0.313285381 epoch total loss 0.277794391\n",
      "Trained batch 512 batch loss 0.314988613 epoch total loss 0.277867019\n",
      "Trained batch 513 batch loss 0.286007375 epoch total loss 0.277882904\n",
      "Trained batch 514 batch loss 0.267134815 epoch total loss 0.277861983\n",
      "Trained batch 515 batch loss 0.28139466 epoch total loss 0.277868837\n",
      "Trained batch 516 batch loss 0.272006631 epoch total loss 0.277857453\n",
      "Trained batch 517 batch loss 0.292821288 epoch total loss 0.277886391\n",
      "Trained batch 518 batch loss 0.282244951 epoch total loss 0.277894795\n",
      "Trained batch 519 batch loss 0.26897189 epoch total loss 0.277877599\n",
      "Trained batch 520 batch loss 0.274567664 epoch total loss 0.277871221\n",
      "Trained batch 521 batch loss 0.270123363 epoch total loss 0.27785638\n",
      "Trained batch 522 batch loss 0.282648146 epoch total loss 0.277865559\n",
      "Trained batch 523 batch loss 0.296408832 epoch total loss 0.277901\n",
      "Trained batch 524 batch loss 0.29724139 epoch total loss 0.277937919\n",
      "Trained batch 525 batch loss 0.337226152 epoch total loss 0.27805084\n",
      "Trained batch 526 batch loss 0.310332298 epoch total loss 0.278112203\n",
      "Trained batch 527 batch loss 0.324607968 epoch total loss 0.278200448\n",
      "Trained batch 528 batch loss 0.296921253 epoch total loss 0.278235912\n",
      "Trained batch 529 batch loss 0.266033351 epoch total loss 0.278212845\n",
      "Trained batch 530 batch loss 0.219905704 epoch total loss 0.278102845\n",
      "Trained batch 531 batch loss 0.210761413 epoch total loss 0.277976\n",
      "Trained batch 532 batch loss 0.287776113 epoch total loss 0.277994424\n",
      "Trained batch 533 batch loss 0.21561715 epoch total loss 0.27787742\n",
      "Trained batch 534 batch loss 0.216394275 epoch total loss 0.277762294\n",
      "Trained batch 535 batch loss 0.209875211 epoch total loss 0.277635366\n",
      "Trained batch 536 batch loss 0.245361403 epoch total loss 0.277575165\n",
      "Trained batch 537 batch loss 0.26091671 epoch total loss 0.277544141\n",
      "Trained batch 538 batch loss 0.271727562 epoch total loss 0.277533323\n",
      "Trained batch 539 batch loss 0.263019115 epoch total loss 0.277506381\n",
      "Trained batch 540 batch loss 0.290219486 epoch total loss 0.277529925\n",
      "Trained batch 541 batch loss 0.290871292 epoch total loss 0.277554601\n",
      "Trained batch 542 batch loss 0.277660728 epoch total loss 0.27755481\n",
      "Trained batch 543 batch loss 0.230238169 epoch total loss 0.277467668\n",
      "Trained batch 544 batch loss 0.249559075 epoch total loss 0.277416378\n",
      "Trained batch 545 batch loss 0.26213634 epoch total loss 0.277388334\n",
      "Trained batch 546 batch loss 0.273267359 epoch total loss 0.277380764\n",
      "Trained batch 547 batch loss 0.284484506 epoch total loss 0.277393758\n",
      "Trained batch 548 batch loss 0.265701264 epoch total loss 0.27737242\n",
      "Trained batch 549 batch loss 0.288503885 epoch total loss 0.277392685\n",
      "Trained batch 550 batch loss 0.309489101 epoch total loss 0.277451068\n",
      "Trained batch 551 batch loss 0.287341803 epoch total loss 0.277469\n",
      "Trained batch 552 batch loss 0.294012725 epoch total loss 0.27749896\n",
      "Trained batch 553 batch loss 0.269818872 epoch total loss 0.277485073\n",
      "Trained batch 554 batch loss 0.254658967 epoch total loss 0.277443856\n",
      "Trained batch 555 batch loss 0.300433815 epoch total loss 0.277485281\n",
      "Trained batch 556 batch loss 0.28676188 epoch total loss 0.277501971\n",
      "Trained batch 557 batch loss 0.298878819 epoch total loss 0.277540326\n",
      "Trained batch 558 batch loss 0.279096723 epoch total loss 0.277543128\n",
      "Trained batch 559 batch loss 0.286657721 epoch total loss 0.277559429\n",
      "Trained batch 560 batch loss 0.302178413 epoch total loss 0.277603388\n",
      "Trained batch 561 batch loss 0.306182563 epoch total loss 0.27765435\n",
      "Trained batch 562 batch loss 0.301343381 epoch total loss 0.27769649\n",
      "Trained batch 563 batch loss 0.262289554 epoch total loss 0.277669132\n",
      "Trained batch 564 batch loss 0.256560147 epoch total loss 0.2776317\n",
      "Trained batch 565 batch loss 0.206033081 epoch total loss 0.277504981\n",
      "Trained batch 566 batch loss 0.224130407 epoch total loss 0.277410686\n",
      "Trained batch 567 batch loss 0.264344633 epoch total loss 0.277387649\n",
      "Trained batch 568 batch loss 0.310575068 epoch total loss 0.277446061\n",
      "Trained batch 569 batch loss 0.336926609 epoch total loss 0.277550608\n",
      "Trained batch 570 batch loss 0.310651571 epoch total loss 0.277608693\n",
      "Trained batch 571 batch loss 0.286744833 epoch total loss 0.277624696\n",
      "Trained batch 572 batch loss 0.274029493 epoch total loss 0.277618408\n",
      "Trained batch 573 batch loss 0.264213771 epoch total loss 0.277595\n",
      "Trained batch 574 batch loss 0.292956173 epoch total loss 0.277621776\n",
      "Trained batch 575 batch loss 0.302207053 epoch total loss 0.277664542\n",
      "Trained batch 576 batch loss 0.273512363 epoch total loss 0.27765733\n",
      "Trained batch 577 batch loss 0.287711918 epoch total loss 0.277674735\n",
      "Trained batch 578 batch loss 0.264355928 epoch total loss 0.277651697\n",
      "Trained batch 579 batch loss 0.260597706 epoch total loss 0.277622253\n",
      "Trained batch 580 batch loss 0.264548779 epoch total loss 0.277599692\n",
      "Trained batch 581 batch loss 0.267107904 epoch total loss 0.277581632\n",
      "Trained batch 582 batch loss 0.260754019 epoch total loss 0.277552724\n",
      "Trained batch 583 batch loss 0.286380291 epoch total loss 0.277567863\n",
      "Trained batch 584 batch loss 0.264683843 epoch total loss 0.27754581\n",
      "Trained batch 585 batch loss 0.232762277 epoch total loss 0.277469248\n",
      "Trained batch 586 batch loss 0.293427 epoch total loss 0.277496457\n",
      "Trained batch 587 batch loss 0.290190607 epoch total loss 0.277518094\n",
      "Trained batch 588 batch loss 0.294945359 epoch total loss 0.277547747\n",
      "Trained batch 589 batch loss 0.294949859 epoch total loss 0.277577281\n",
      "Trained batch 590 batch loss 0.306149721 epoch total loss 0.27762574\n",
      "Trained batch 591 batch loss 0.302684367 epoch total loss 0.277668148\n",
      "Trained batch 592 batch loss 0.304725468 epoch total loss 0.277713835\n",
      "Trained batch 593 batch loss 0.289572269 epoch total loss 0.277733803\n",
      "Trained batch 594 batch loss 0.285193026 epoch total loss 0.27774635\n",
      "Trained batch 595 batch loss 0.272309572 epoch total loss 0.27773723\n",
      "Trained batch 596 batch loss 0.258777767 epoch total loss 0.277705401\n",
      "Trained batch 597 batch loss 0.286046088 epoch total loss 0.277719378\n",
      "Trained batch 598 batch loss 0.270486295 epoch total loss 0.277707279\n",
      "Trained batch 599 batch loss 0.248247832 epoch total loss 0.277658105\n",
      "Trained batch 600 batch loss 0.2722103 epoch total loss 0.277649015\n",
      "Trained batch 601 batch loss 0.241541639 epoch total loss 0.277588964\n",
      "Trained batch 602 batch loss 0.241822 epoch total loss 0.277529538\n",
      "Trained batch 603 batch loss 0.274344444 epoch total loss 0.277524263\n",
      "Trained batch 604 batch loss 0.297922283 epoch total loss 0.277558029\n",
      "Trained batch 605 batch loss 0.27502951 epoch total loss 0.277553856\n",
      "Trained batch 606 batch loss 0.284684837 epoch total loss 0.277565598\n",
      "Trained batch 607 batch loss 0.290164173 epoch total loss 0.277586371\n",
      "Trained batch 608 batch loss 0.2584126 epoch total loss 0.27755481\n",
      "Trained batch 609 batch loss 0.265019357 epoch total loss 0.277534217\n",
      "Trained batch 610 batch loss 0.29834938 epoch total loss 0.27756834\n",
      "Trained batch 611 batch loss 0.27367425 epoch total loss 0.277562\n",
      "Trained batch 612 batch loss 0.286104828 epoch total loss 0.27757594\n",
      "Trained batch 613 batch loss 0.290009469 epoch total loss 0.277596235\n",
      "Trained batch 614 batch loss 0.258063227 epoch total loss 0.277564406\n",
      "Trained batch 615 batch loss 0.278987259 epoch total loss 0.277566731\n",
      "Trained batch 616 batch loss 0.292225838 epoch total loss 0.277590513\n",
      "Trained batch 617 batch loss 0.266119242 epoch total loss 0.277571917\n",
      "Trained batch 618 batch loss 0.275206536 epoch total loss 0.277568102\n",
      "Trained batch 619 batch loss 0.237532228 epoch total loss 0.277503401\n",
      "Trained batch 620 batch loss 0.263380349 epoch total loss 0.277480632\n",
      "Trained batch 621 batch loss 0.277009726 epoch total loss 0.277479887\n",
      "Trained batch 622 batch loss 0.284369141 epoch total loss 0.277490944\n",
      "Trained batch 623 batch loss 0.273322225 epoch total loss 0.277484238\n",
      "Trained batch 624 batch loss 0.272983938 epoch total loss 0.277477026\n",
      "Trained batch 625 batch loss 0.220813602 epoch total loss 0.277386367\n",
      "Trained batch 626 batch loss 0.219795316 epoch total loss 0.277294368\n",
      "Trained batch 627 batch loss 0.231025845 epoch total loss 0.277220577\n",
      "Trained batch 628 batch loss 0.249355972 epoch total loss 0.277176231\n",
      "Trained batch 629 batch loss 0.26142031 epoch total loss 0.277151167\n",
      "Trained batch 630 batch loss 0.284809411 epoch total loss 0.277163297\n",
      "Trained batch 631 batch loss 0.264876544 epoch total loss 0.277143836\n",
      "Trained batch 632 batch loss 0.298209935 epoch total loss 0.277177155\n",
      "Trained batch 633 batch loss 0.287829757 epoch total loss 0.277194\n",
      "Trained batch 634 batch loss 0.292215735 epoch total loss 0.277217686\n",
      "Trained batch 635 batch loss 0.311341017 epoch total loss 0.27727142\n",
      "Trained batch 636 batch loss 0.317654222 epoch total loss 0.277334929\n",
      "Trained batch 637 batch loss 0.266886324 epoch total loss 0.277318537\n",
      "Trained batch 638 batch loss 0.299007833 epoch total loss 0.277352542\n",
      "Trained batch 639 batch loss 0.283990502 epoch total loss 0.277362913\n",
      "Trained batch 640 batch loss 0.28656739 epoch total loss 0.277377307\n",
      "Trained batch 641 batch loss 0.288939714 epoch total loss 0.277395338\n",
      "Trained batch 642 batch loss 0.295702308 epoch total loss 0.277423859\n",
      "Trained batch 643 batch loss 0.28190577 epoch total loss 0.277430832\n",
      "Trained batch 644 batch loss 0.300151646 epoch total loss 0.277466118\n",
      "Trained batch 645 batch loss 0.320190847 epoch total loss 0.277532339\n",
      "Trained batch 646 batch loss 0.318520695 epoch total loss 0.277595818\n",
      "Trained batch 647 batch loss 0.304831743 epoch total loss 0.277637899\n",
      "Trained batch 648 batch loss 0.317036748 epoch total loss 0.277698696\n",
      "Trained batch 649 batch loss 0.275199145 epoch total loss 0.277694821\n",
      "Trained batch 650 batch loss 0.306804478 epoch total loss 0.277739614\n",
      "Trained batch 651 batch loss 0.279095888 epoch total loss 0.2777417\n",
      "Trained batch 652 batch loss 0.287509799 epoch total loss 0.277756661\n",
      "Trained batch 653 batch loss 0.237296194 epoch total loss 0.277694702\n",
      "Trained batch 654 batch loss 0.252866179 epoch total loss 0.277656734\n",
      "Trained batch 655 batch loss 0.230252713 epoch total loss 0.277584374\n",
      "Trained batch 656 batch loss 0.255048424 epoch total loss 0.27755\n",
      "Trained batch 657 batch loss 0.29509902 epoch total loss 0.277576745\n",
      "Trained batch 658 batch loss 0.315906227 epoch total loss 0.277634978\n",
      "Trained batch 659 batch loss 0.297214329 epoch total loss 0.277664691\n",
      "Trained batch 660 batch loss 0.27858597 epoch total loss 0.277666092\n",
      "Trained batch 661 batch loss 0.244959682 epoch total loss 0.27761662\n",
      "Trained batch 662 batch loss 0.287593812 epoch total loss 0.27763167\n",
      "Trained batch 663 batch loss 0.265755057 epoch total loss 0.277613789\n",
      "Trained batch 664 batch loss 0.285376 epoch total loss 0.277625471\n",
      "Trained batch 665 batch loss 0.273498565 epoch total loss 0.277619243\n",
      "Trained batch 666 batch loss 0.281170875 epoch total loss 0.277624607\n",
      "Trained batch 667 batch loss 0.326801717 epoch total loss 0.277698308\n",
      "Trained batch 668 batch loss 0.300417393 epoch total loss 0.277732313\n",
      "Trained batch 669 batch loss 0.280595362 epoch total loss 0.277736604\n",
      "Trained batch 670 batch loss 0.30373475 epoch total loss 0.277775407\n",
      "Trained batch 671 batch loss 0.245492518 epoch total loss 0.277727306\n",
      "Trained batch 672 batch loss 0.247243911 epoch total loss 0.277681947\n",
      "Trained batch 673 batch loss 0.29344818 epoch total loss 0.277705371\n",
      "Trained batch 674 batch loss 0.287507445 epoch total loss 0.277719885\n",
      "Trained batch 675 batch loss 0.277173877 epoch total loss 0.27771908\n",
      "Trained batch 676 batch loss 0.296502769 epoch total loss 0.277746886\n",
      "Trained batch 677 batch loss 0.297228038 epoch total loss 0.277775675\n",
      "Trained batch 678 batch loss 0.240792483 epoch total loss 0.277721137\n",
      "Trained batch 679 batch loss 0.307804674 epoch total loss 0.277765423\n",
      "Trained batch 680 batch loss 0.315630436 epoch total loss 0.277821094\n",
      "Trained batch 681 batch loss 0.283427417 epoch total loss 0.277829349\n",
      "Trained batch 682 batch loss 0.248394027 epoch total loss 0.277786195\n",
      "Trained batch 683 batch loss 0.250518322 epoch total loss 0.27774626\n",
      "Trained batch 684 batch loss 0.233620495 epoch total loss 0.277681768\n",
      "Trained batch 685 batch loss 0.255295247 epoch total loss 0.277649075\n",
      "Trained batch 686 batch loss 0.22907877 epoch total loss 0.277578294\n",
      "Trained batch 687 batch loss 0.22799769 epoch total loss 0.277506113\n",
      "Trained batch 688 batch loss 0.242765069 epoch total loss 0.277455628\n",
      "Trained batch 689 batch loss 0.267471313 epoch total loss 0.277441114\n",
      "Trained batch 690 batch loss 0.253440499 epoch total loss 0.277406335\n",
      "Trained batch 691 batch loss 0.292596757 epoch total loss 0.277428329\n",
      "Trained batch 692 batch loss 0.287212163 epoch total loss 0.277442455\n",
      "Trained batch 693 batch loss 0.266925544 epoch total loss 0.277427286\n",
      "Trained batch 694 batch loss 0.271093071 epoch total loss 0.277418166\n",
      "Trained batch 695 batch loss 0.264851511 epoch total loss 0.277400076\n",
      "Trained batch 696 batch loss 0.268998981 epoch total loss 0.277388\n",
      "Trained batch 697 batch loss 0.251069903 epoch total loss 0.277350217\n",
      "Trained batch 698 batch loss 0.290686369 epoch total loss 0.27736932\n",
      "Trained batch 699 batch loss 0.290477544 epoch total loss 0.277388096\n",
      "Trained batch 700 batch loss 0.287443757 epoch total loss 0.277402461\n",
      "Trained batch 701 batch loss 0.273863673 epoch total loss 0.277397394\n",
      "Trained batch 702 batch loss 0.291475236 epoch total loss 0.277417451\n",
      "Trained batch 703 batch loss 0.306710213 epoch total loss 0.277459145\n",
      "Trained batch 704 batch loss 0.312614858 epoch total loss 0.277509093\n",
      "Trained batch 705 batch loss 0.289678484 epoch total loss 0.277526349\n",
      "Trained batch 706 batch loss 0.268696517 epoch total loss 0.277513832\n",
      "Trained batch 707 batch loss 0.2779755 epoch total loss 0.277514458\n",
      "Trained batch 708 batch loss 0.246386796 epoch total loss 0.277470499\n",
      "Trained batch 709 batch loss 0.282484025 epoch total loss 0.277477562\n",
      "Trained batch 710 batch loss 0.283624083 epoch total loss 0.277486235\n",
      "Trained batch 711 batch loss 0.311233163 epoch total loss 0.27753371\n",
      "Trained batch 712 batch loss 0.286185 epoch total loss 0.27754584\n",
      "Trained batch 713 batch loss 0.295998305 epoch total loss 0.277571738\n",
      "Trained batch 714 batch loss 0.250323176 epoch total loss 0.277533561\n",
      "Trained batch 715 batch loss 0.290930063 epoch total loss 0.277552307\n",
      "Trained batch 716 batch loss 0.26774466 epoch total loss 0.277538598\n",
      "Trained batch 717 batch loss 0.27734682 epoch total loss 0.277538329\n",
      "Trained batch 718 batch loss 0.300934672 epoch total loss 0.277570903\n",
      "Trained batch 719 batch loss 0.298491567 epoch total loss 0.27760002\n",
      "Trained batch 720 batch loss 0.262645096 epoch total loss 0.277579248\n",
      "Trained batch 721 batch loss 0.290988326 epoch total loss 0.277597845\n",
      "Trained batch 722 batch loss 0.254815429 epoch total loss 0.277566284\n",
      "Trained batch 723 batch loss 0.250305831 epoch total loss 0.277528584\n",
      "Trained batch 724 batch loss 0.272146106 epoch total loss 0.277521133\n",
      "Trained batch 725 batch loss 0.259620219 epoch total loss 0.277496457\n",
      "Trained batch 726 batch loss 0.281047076 epoch total loss 0.277501345\n",
      "Trained batch 727 batch loss 0.267768234 epoch total loss 0.277487934\n",
      "Trained batch 728 batch loss 0.279501349 epoch total loss 0.277490705\n",
      "Trained batch 729 batch loss 0.238781318 epoch total loss 0.277437598\n",
      "Trained batch 730 batch loss 0.273591071 epoch total loss 0.277432323\n",
      "Trained batch 731 batch loss 0.27744931 epoch total loss 0.277432352\n",
      "Trained batch 732 batch loss 0.281952858 epoch total loss 0.277438521\n",
      "Trained batch 733 batch loss 0.251512706 epoch total loss 0.277403176\n",
      "Trained batch 734 batch loss 0.271941423 epoch total loss 0.277395725\n",
      "Trained batch 735 batch loss 0.239085525 epoch total loss 0.277343601\n",
      "Trained batch 736 batch loss 0.289134949 epoch total loss 0.277359635\n",
      "Trained batch 737 batch loss 0.285632133 epoch total loss 0.27737084\n",
      "Trained batch 738 batch loss 0.29682833 epoch total loss 0.277397215\n",
      "Trained batch 739 batch loss 0.295113683 epoch total loss 0.277421206\n",
      "Trained batch 740 batch loss 0.269467592 epoch total loss 0.277410448\n",
      "Trained batch 741 batch loss 0.292585909 epoch total loss 0.277430952\n",
      "Trained batch 742 batch loss 0.291854471 epoch total loss 0.277450383\n",
      "Trained batch 743 batch loss 0.263615459 epoch total loss 0.277431756\n",
      "Trained batch 744 batch loss 0.277293503 epoch total loss 0.277431577\n",
      "Trained batch 745 batch loss 0.245562255 epoch total loss 0.277388781\n",
      "Trained batch 746 batch loss 0.254921287 epoch total loss 0.277358681\n",
      "Trained batch 747 batch loss 0.273630112 epoch total loss 0.277353704\n",
      "Trained batch 748 batch loss 0.270518899 epoch total loss 0.277344555\n",
      "Trained batch 749 batch loss 0.274083823 epoch total loss 0.277340204\n",
      "Trained batch 750 batch loss 0.240606934 epoch total loss 0.277291209\n",
      "Trained batch 751 batch loss 0.233764321 epoch total loss 0.277233273\n",
      "Trained batch 752 batch loss 0.269827366 epoch total loss 0.277223408\n",
      "Trained batch 753 batch loss 0.310187936 epoch total loss 0.277267158\n",
      "Trained batch 754 batch loss 0.29074648 epoch total loss 0.277285039\n",
      "Trained batch 755 batch loss 0.263592541 epoch total loss 0.27726692\n",
      "Trained batch 756 batch loss 0.254404843 epoch total loss 0.27723667\n",
      "Trained batch 757 batch loss 0.188011244 epoch total loss 0.277118832\n",
      "Trained batch 758 batch loss 0.176823586 epoch total loss 0.27698651\n",
      "Trained batch 759 batch loss 0.254568368 epoch total loss 0.276956946\n",
      "Trained batch 760 batch loss 0.284819543 epoch total loss 0.276967287\n",
      "Trained batch 761 batch loss 0.253711045 epoch total loss 0.27693674\n",
      "Trained batch 762 batch loss 0.274171561 epoch total loss 0.276933104\n",
      "Trained batch 763 batch loss 0.274243116 epoch total loss 0.276929587\n",
      "Trained batch 764 batch loss 0.287541747 epoch total loss 0.276943475\n",
      "Trained batch 765 batch loss 0.263073742 epoch total loss 0.276925325\n",
      "Trained batch 766 batch loss 0.28674677 epoch total loss 0.27693817\n",
      "Trained batch 767 batch loss 0.276899248 epoch total loss 0.276938111\n",
      "Trained batch 768 batch loss 0.271116644 epoch total loss 0.276930541\n",
      "Trained batch 769 batch loss 0.268715739 epoch total loss 0.276919872\n",
      "Trained batch 770 batch loss 0.283004254 epoch total loss 0.276927769\n",
      "Trained batch 771 batch loss 0.307865143 epoch total loss 0.276967883\n",
      "Trained batch 772 batch loss 0.279796541 epoch total loss 0.276971549\n",
      "Trained batch 773 batch loss 0.300525784 epoch total loss 0.277002\n",
      "Trained batch 774 batch loss 0.284053773 epoch total loss 0.277011126\n",
      "Trained batch 775 batch loss 0.319502294 epoch total loss 0.277065963\n",
      "Trained batch 776 batch loss 0.268267393 epoch total loss 0.277054608\n",
      "Trained batch 777 batch loss 0.243120208 epoch total loss 0.277010947\n",
      "Trained batch 778 batch loss 0.278621167 epoch total loss 0.277013\n",
      "Trained batch 779 batch loss 0.239621341 epoch total loss 0.276965022\n",
      "Trained batch 780 batch loss 0.256008565 epoch total loss 0.27693817\n",
      "Trained batch 781 batch loss 0.298550129 epoch total loss 0.276965827\n",
      "Trained batch 782 batch loss 0.28772226 epoch total loss 0.276979595\n",
      "Trained batch 783 batch loss 0.286173254 epoch total loss 0.276991338\n",
      "Trained batch 784 batch loss 0.275769204 epoch total loss 0.276989788\n",
      "Trained batch 785 batch loss 0.275849819 epoch total loss 0.276988328\n",
      "Trained batch 786 batch loss 0.295141429 epoch total loss 0.277011424\n",
      "Trained batch 787 batch loss 0.249778956 epoch total loss 0.276976824\n",
      "Trained batch 788 batch loss 0.279801428 epoch total loss 0.2769804\n",
      "Trained batch 789 batch loss 0.283385634 epoch total loss 0.276988536\n",
      "Trained batch 790 batch loss 0.3010934 epoch total loss 0.277019024\n",
      "Trained batch 791 batch loss 0.289690137 epoch total loss 0.277035058\n",
      "Trained batch 792 batch loss 0.31230697 epoch total loss 0.277079582\n",
      "Trained batch 793 batch loss 0.311951041 epoch total loss 0.277123541\n",
      "Trained batch 794 batch loss 0.294601351 epoch total loss 0.277145565\n",
      "Trained batch 795 batch loss 0.304598033 epoch total loss 0.277180076\n",
      "Trained batch 796 batch loss 0.315810502 epoch total loss 0.277228624\n",
      "Trained batch 797 batch loss 0.283144534 epoch total loss 0.277236044\n",
      "Trained batch 798 batch loss 0.272434 epoch total loss 0.277230024\n",
      "Trained batch 799 batch loss 0.284512639 epoch total loss 0.277239144\n",
      "Trained batch 800 batch loss 0.265860468 epoch total loss 0.277224898\n",
      "Trained batch 801 batch loss 0.24837783 epoch total loss 0.277188897\n",
      "Trained batch 802 batch loss 0.264559418 epoch total loss 0.277173132\n",
      "Trained batch 803 batch loss 0.264061093 epoch total loss 0.27715683\n",
      "Trained batch 804 batch loss 0.322616905 epoch total loss 0.277213365\n",
      "Trained batch 805 batch loss 0.305455714 epoch total loss 0.277248442\n",
      "Trained batch 806 batch loss 0.310029596 epoch total loss 0.277289122\n",
      "Trained batch 807 batch loss 0.313347876 epoch total loss 0.277333796\n",
      "Trained batch 808 batch loss 0.29140389 epoch total loss 0.277351201\n",
      "Trained batch 809 batch loss 0.291948318 epoch total loss 0.277369261\n",
      "Trained batch 810 batch loss 0.297974706 epoch total loss 0.277394682\n",
      "Trained batch 811 batch loss 0.286697149 epoch total loss 0.277406156\n",
      "Trained batch 812 batch loss 0.269463807 epoch total loss 0.277396381\n",
      "Trained batch 813 batch loss 0.287781209 epoch total loss 0.277409166\n",
      "Trained batch 814 batch loss 0.298642933 epoch total loss 0.277435243\n",
      "Trained batch 815 batch loss 0.290534377 epoch total loss 0.277451307\n",
      "Trained batch 816 batch loss 0.268770844 epoch total loss 0.277440667\n",
      "Trained batch 817 batch loss 0.264005274 epoch total loss 0.277424216\n",
      "Trained batch 818 batch loss 0.237070426 epoch total loss 0.277374893\n",
      "Trained batch 819 batch loss 0.231427938 epoch total loss 0.277318805\n",
      "Trained batch 820 batch loss 0.269082606 epoch total loss 0.277308762\n",
      "Trained batch 821 batch loss 0.301849842 epoch total loss 0.277338654\n",
      "Trained batch 822 batch loss 0.288958848 epoch total loss 0.27735278\n",
      "Trained batch 823 batch loss 0.314681232 epoch total loss 0.277398139\n",
      "Trained batch 824 batch loss 0.296797901 epoch total loss 0.277421683\n",
      "Trained batch 825 batch loss 0.311911166 epoch total loss 0.277463496\n",
      "Trained batch 826 batch loss 0.293786943 epoch total loss 0.277483255\n",
      "Trained batch 827 batch loss 0.289462209 epoch total loss 0.277497739\n",
      "Trained batch 828 batch loss 0.2856583 epoch total loss 0.277507603\n",
      "Trained batch 829 batch loss 0.258477 epoch total loss 0.277484655\n",
      "Trained batch 830 batch loss 0.279478788 epoch total loss 0.27748704\n",
      "Trained batch 831 batch loss 0.242251649 epoch total loss 0.277444661\n",
      "Trained batch 832 batch loss 0.302973479 epoch total loss 0.277475327\n",
      "Trained batch 833 batch loss 0.278617918 epoch total loss 0.277476728\n",
      "Trained batch 834 batch loss 0.294745 epoch total loss 0.277497411\n",
      "Trained batch 835 batch loss 0.272442192 epoch total loss 0.277491361\n",
      "Trained batch 836 batch loss 0.280446351 epoch total loss 0.277494907\n",
      "Trained batch 837 batch loss 0.281364202 epoch total loss 0.277499497\n",
      "Trained batch 838 batch loss 0.27760303 epoch total loss 0.277499646\n",
      "Trained batch 839 batch loss 0.261433393 epoch total loss 0.277480483\n",
      "Trained batch 840 batch loss 0.267714322 epoch total loss 0.27746886\n",
      "Trained batch 841 batch loss 0.263658315 epoch total loss 0.277452439\n",
      "Trained batch 842 batch loss 0.284915328 epoch total loss 0.27746129\n",
      "Trained batch 843 batch loss 0.295345753 epoch total loss 0.27748251\n",
      "Trained batch 844 batch loss 0.255338192 epoch total loss 0.277456284\n",
      "Trained batch 845 batch loss 0.260853469 epoch total loss 0.277436614\n",
      "Trained batch 846 batch loss 0.244978219 epoch total loss 0.277398258\n",
      "Trained batch 847 batch loss 0.288718283 epoch total loss 0.27741161\n",
      "Trained batch 848 batch loss 0.268181741 epoch total loss 0.277400732\n",
      "Trained batch 849 batch loss 0.257162094 epoch total loss 0.27737689\n",
      "Trained batch 850 batch loss 0.241592899 epoch total loss 0.27733478\n",
      "Trained batch 851 batch loss 0.26078105 epoch total loss 0.277315348\n",
      "Trained batch 852 batch loss 0.25835228 epoch total loss 0.277293086\n",
      "Trained batch 853 batch loss 0.289197922 epoch total loss 0.277307034\n",
      "Trained batch 854 batch loss 0.284192145 epoch total loss 0.27731511\n",
      "Trained batch 855 batch loss 0.294901103 epoch total loss 0.277335674\n",
      "Trained batch 856 batch loss 0.265686363 epoch total loss 0.277322084\n",
      "Trained batch 857 batch loss 0.274170846 epoch total loss 0.277318388\n",
      "Trained batch 858 batch loss 0.302626967 epoch total loss 0.277347893\n",
      "Trained batch 859 batch loss 0.291306943 epoch total loss 0.277364135\n",
      "Trained batch 860 batch loss 0.310977399 epoch total loss 0.277403235\n",
      "Trained batch 861 batch loss 0.29322052 epoch total loss 0.277421594\n",
      "Trained batch 862 batch loss 0.256609082 epoch total loss 0.277397454\n",
      "Trained batch 863 batch loss 0.257140309 epoch total loss 0.27737397\n",
      "Trained batch 864 batch loss 0.263661265 epoch total loss 0.277358085\n",
      "Trained batch 865 batch loss 0.290941775 epoch total loss 0.277373791\n",
      "Trained batch 866 batch loss 0.278521121 epoch total loss 0.277375102\n",
      "Trained batch 867 batch loss 0.291565567 epoch total loss 0.277391493\n",
      "Trained batch 868 batch loss 0.247317076 epoch total loss 0.277356833\n",
      "Trained batch 869 batch loss 0.26649 epoch total loss 0.277344316\n",
      "Trained batch 870 batch loss 0.270947576 epoch total loss 0.277336985\n",
      "Trained batch 871 batch loss 0.290241241 epoch total loss 0.277351797\n",
      "Trained batch 872 batch loss 0.260923833 epoch total loss 0.277332962\n",
      "Trained batch 873 batch loss 0.255862355 epoch total loss 0.277308345\n",
      "Trained batch 874 batch loss 0.263156861 epoch total loss 0.277292162\n",
      "Trained batch 875 batch loss 0.283357143 epoch total loss 0.277299076\n",
      "Trained batch 876 batch loss 0.26770097 epoch total loss 0.277288139\n",
      "Trained batch 877 batch loss 0.259971231 epoch total loss 0.27726838\n",
      "Trained batch 878 batch loss 0.318711847 epoch total loss 0.277315587\n",
      "Trained batch 879 batch loss 0.265300691 epoch total loss 0.277301908\n",
      "Trained batch 880 batch loss 0.261244148 epoch total loss 0.277283669\n",
      "Trained batch 881 batch loss 0.288395733 epoch total loss 0.277296275\n",
      "Trained batch 882 batch loss 0.25767985 epoch total loss 0.277274042\n",
      "Trained batch 883 batch loss 0.277225643 epoch total loss 0.277273983\n",
      "Trained batch 884 batch loss 0.332383573 epoch total loss 0.277336299\n",
      "Trained batch 885 batch loss 0.256595969 epoch total loss 0.277312875\n",
      "Trained batch 886 batch loss 0.268395036 epoch total loss 0.277302802\n",
      "Trained batch 887 batch loss 0.275236 epoch total loss 0.277300477\n",
      "Trained batch 888 batch loss 0.272098273 epoch total loss 0.277294636\n",
      "Trained batch 889 batch loss 0.267270535 epoch total loss 0.277283341\n",
      "Trained batch 890 batch loss 0.263693959 epoch total loss 0.277268082\n",
      "Trained batch 891 batch loss 0.237000391 epoch total loss 0.277222872\n",
      "Trained batch 892 batch loss 0.269957125 epoch total loss 0.277214736\n",
      "Trained batch 893 batch loss 0.282072783 epoch total loss 0.27722019\n",
      "Trained batch 894 batch loss 0.276697457 epoch total loss 0.277219594\n",
      "Trained batch 895 batch loss 0.283612847 epoch total loss 0.277226746\n",
      "Trained batch 896 batch loss 0.281799287 epoch total loss 0.277231842\n",
      "Trained batch 897 batch loss 0.324884266 epoch total loss 0.27728498\n",
      "Trained batch 898 batch loss 0.316156834 epoch total loss 0.277328283\n",
      "Trained batch 899 batch loss 0.320700914 epoch total loss 0.277376503\n",
      "Trained batch 900 batch loss 0.293100804 epoch total loss 0.277394\n",
      "Trained batch 901 batch loss 0.261145949 epoch total loss 0.277375937\n",
      "Trained batch 902 batch loss 0.275224209 epoch total loss 0.277373552\n",
      "Trained batch 903 batch loss 0.298573762 epoch total loss 0.277397037\n",
      "Trained batch 904 batch loss 0.307417393 epoch total loss 0.277430236\n",
      "Trained batch 905 batch loss 0.274488419 epoch total loss 0.277427\n",
      "Trained batch 906 batch loss 0.259730369 epoch total loss 0.277407467\n",
      "Trained batch 907 batch loss 0.275945812 epoch total loss 0.277405858\n",
      "Trained batch 908 batch loss 0.251207948 epoch total loss 0.27737698\n",
      "Trained batch 909 batch loss 0.260951191 epoch total loss 0.277358919\n",
      "Trained batch 910 batch loss 0.243869841 epoch total loss 0.277322114\n",
      "Trained batch 911 batch loss 0.258209616 epoch total loss 0.277301133\n",
      "Trained batch 912 batch loss 0.250748038 epoch total loss 0.277272016\n",
      "Trained batch 913 batch loss 0.303804576 epoch total loss 0.277301073\n",
      "Trained batch 914 batch loss 0.314205617 epoch total loss 0.277341455\n",
      "Trained batch 915 batch loss 0.310436815 epoch total loss 0.277377635\n",
      "Trained batch 916 batch loss 0.305007458 epoch total loss 0.277407795\n",
      "Trained batch 917 batch loss 0.291851908 epoch total loss 0.277423561\n",
      "Trained batch 918 batch loss 0.31274578 epoch total loss 0.277462035\n",
      "Trained batch 919 batch loss 0.281605601 epoch total loss 0.277466536\n",
      "Trained batch 920 batch loss 0.243291512 epoch total loss 0.277429372\n",
      "Trained batch 921 batch loss 0.287784904 epoch total loss 0.277440608\n",
      "Trained batch 922 batch loss 0.272696465 epoch total loss 0.277435482\n",
      "Trained batch 923 batch loss 0.297638118 epoch total loss 0.277457356\n",
      "Trained batch 924 batch loss 0.305914879 epoch total loss 0.277488142\n",
      "Trained batch 925 batch loss 0.269837171 epoch total loss 0.277479887\n",
      "Trained batch 926 batch loss 0.249511302 epoch total loss 0.277449667\n",
      "Trained batch 927 batch loss 0.251210183 epoch total loss 0.277421385\n",
      "Trained batch 928 batch loss 0.235553592 epoch total loss 0.277376264\n",
      "Trained batch 929 batch loss 0.252085388 epoch total loss 0.277349025\n",
      "Trained batch 930 batch loss 0.265934676 epoch total loss 0.277336746\n",
      "Trained batch 931 batch loss 0.252039 epoch total loss 0.277309597\n",
      "Trained batch 932 batch loss 0.244582668 epoch total loss 0.27727446\n",
      "Trained batch 933 batch loss 0.311568141 epoch total loss 0.277311206\n",
      "Trained batch 934 batch loss 0.290634602 epoch total loss 0.277325481\n",
      "Trained batch 935 batch loss 0.265853465 epoch total loss 0.277313203\n",
      "Trained batch 936 batch loss 0.279799968 epoch total loss 0.277315855\n",
      "Trained batch 937 batch loss 0.298686862 epoch total loss 0.277338624\n",
      "Trained batch 938 batch loss 0.269243091 epoch total loss 0.27733\n",
      "Trained batch 939 batch loss 0.29820779 epoch total loss 0.277352273\n",
      "Trained batch 940 batch loss 0.285085648 epoch total loss 0.277360499\n",
      "Trained batch 941 batch loss 0.293892443 epoch total loss 0.277378052\n",
      "Trained batch 942 batch loss 0.270147175 epoch total loss 0.277370393\n",
      "Trained batch 943 batch loss 0.284792751 epoch total loss 0.277378261\n",
      "Trained batch 944 batch loss 0.295034111 epoch total loss 0.277396947\n",
      "Trained batch 945 batch loss 0.290174961 epoch total loss 0.277410477\n",
      "Trained batch 946 batch loss 0.260511369 epoch total loss 0.277392596\n",
      "Trained batch 947 batch loss 0.267403692 epoch total loss 0.277382046\n",
      "Trained batch 948 batch loss 0.249071971 epoch total loss 0.277352184\n",
      "Trained batch 949 batch loss 0.24179469 epoch total loss 0.277314723\n",
      "Trained batch 950 batch loss 0.250026375 epoch total loss 0.277286\n",
      "Trained batch 951 batch loss 0.247499183 epoch total loss 0.277254671\n",
      "Trained batch 952 batch loss 0.259534627 epoch total loss 0.277236044\n",
      "Trained batch 953 batch loss 0.226271659 epoch total loss 0.277182549\n",
      "Trained batch 954 batch loss 0.259736329 epoch total loss 0.277164251\n",
      "Trained batch 955 batch loss 0.269446701 epoch total loss 0.277156174\n",
      "Trained batch 956 batch loss 0.249436289 epoch total loss 0.277127177\n",
      "Trained batch 957 batch loss 0.296388328 epoch total loss 0.277147323\n",
      "Trained batch 958 batch loss 0.286172688 epoch total loss 0.27715674\n",
      "Trained batch 959 batch loss 0.296959341 epoch total loss 0.277177393\n",
      "Trained batch 960 batch loss 0.307895 epoch total loss 0.277209371\n",
      "Trained batch 961 batch loss 0.272734821 epoch total loss 0.277204722\n",
      "Trained batch 962 batch loss 0.263502479 epoch total loss 0.277190477\n",
      "Trained batch 963 batch loss 0.270456076 epoch total loss 0.277183473\n",
      "Trained batch 964 batch loss 0.308178186 epoch total loss 0.2772156\n",
      "Trained batch 965 batch loss 0.313229501 epoch total loss 0.277252913\n",
      "Trained batch 966 batch loss 0.283656806 epoch total loss 0.277259558\n",
      "Trained batch 967 batch loss 0.284276783 epoch total loss 0.2772668\n",
      "Trained batch 968 batch loss 0.299025804 epoch total loss 0.277289271\n",
      "Trained batch 969 batch loss 0.276643038 epoch total loss 0.277288616\n",
      "Trained batch 970 batch loss 0.286442548 epoch total loss 0.277298033\n",
      "Trained batch 971 batch loss 0.302999705 epoch total loss 0.277324528\n",
      "Trained batch 972 batch loss 0.311775386 epoch total loss 0.277359962\n",
      "Trained batch 973 batch loss 0.294736922 epoch total loss 0.277377814\n",
      "Trained batch 974 batch loss 0.24513343 epoch total loss 0.277344733\n",
      "Trained batch 975 batch loss 0.244425774 epoch total loss 0.277310938\n",
      "Trained batch 976 batch loss 0.26770705 epoch total loss 0.277301103\n",
      "Trained batch 977 batch loss 0.271811813 epoch total loss 0.2772955\n",
      "Trained batch 978 batch loss 0.249297529 epoch total loss 0.27726686\n",
      "Trained batch 979 batch loss 0.233831316 epoch total loss 0.277222484\n",
      "Trained batch 980 batch loss 0.243117154 epoch total loss 0.277187675\n",
      "Trained batch 981 batch loss 0.23588486 epoch total loss 0.277145565\n",
      "Trained batch 982 batch loss 0.251266539 epoch total loss 0.277119219\n",
      "Trained batch 983 batch loss 0.251217127 epoch total loss 0.277092874\n",
      "Trained batch 984 batch loss 0.263339639 epoch total loss 0.277078897\n",
      "Trained batch 985 batch loss 0.248817593 epoch total loss 0.277050197\n",
      "Trained batch 986 batch loss 0.28782922 epoch total loss 0.277061135\n",
      "Trained batch 987 batch loss 0.311244607 epoch total loss 0.277095765\n",
      "Trained batch 988 batch loss 0.295389742 epoch total loss 0.277114272\n",
      "Trained batch 989 batch loss 0.299181402 epoch total loss 0.277136594\n",
      "Trained batch 990 batch loss 0.248755 epoch total loss 0.277107924\n",
      "Trained batch 991 batch loss 0.249617338 epoch total loss 0.277080178\n",
      "Trained batch 992 batch loss 0.288402528 epoch total loss 0.277091593\n",
      "Trained batch 993 batch loss 0.293106079 epoch total loss 0.277107716\n",
      "Trained batch 994 batch loss 0.293522805 epoch total loss 0.277124226\n",
      "Trained batch 995 batch loss 0.306537032 epoch total loss 0.27715382\n",
      "Trained batch 996 batch loss 0.29263851 epoch total loss 0.277169347\n",
      "Trained batch 997 batch loss 0.255764276 epoch total loss 0.277147889\n",
      "Trained batch 998 batch loss 0.22317712 epoch total loss 0.277093798\n",
      "Trained batch 999 batch loss 0.236026555 epoch total loss 0.277052701\n",
      "Trained batch 1000 batch loss 0.241958857 epoch total loss 0.277017623\n",
      "Trained batch 1001 batch loss 0.236405432 epoch total loss 0.276977062\n",
      "Trained batch 1002 batch loss 0.288089752 epoch total loss 0.276988149\n",
      "Trained batch 1003 batch loss 0.264648616 epoch total loss 0.27697584\n",
      "Trained batch 1004 batch loss 0.233925298 epoch total loss 0.276932955\n",
      "Trained batch 1005 batch loss 0.254639745 epoch total loss 0.276910752\n",
      "Trained batch 1006 batch loss 0.28165257 epoch total loss 0.276915461\n",
      "Trained batch 1007 batch loss 0.2462257 epoch total loss 0.276884973\n",
      "Trained batch 1008 batch loss 0.277691603 epoch total loss 0.276885778\n",
      "Trained batch 1009 batch loss 0.255953431 epoch total loss 0.276865035\n",
      "Trained batch 1010 batch loss 0.222621292 epoch total loss 0.276811332\n",
      "Trained batch 1011 batch loss 0.24131313 epoch total loss 0.276776195\n",
      "Trained batch 1012 batch loss 0.260082364 epoch total loss 0.276759684\n",
      "Trained batch 1013 batch loss 0.29414919 epoch total loss 0.27677688\n",
      "Trained batch 1014 batch loss 0.323902369 epoch total loss 0.276823342\n",
      "Trained batch 1015 batch loss 0.341850698 epoch total loss 0.276887417\n",
      "Trained batch 1016 batch loss 0.28415814 epoch total loss 0.276894569\n",
      "Trained batch 1017 batch loss 0.268392414 epoch total loss 0.276886225\n",
      "Trained batch 1018 batch loss 0.264036953 epoch total loss 0.276873618\n",
      "Trained batch 1019 batch loss 0.292252779 epoch total loss 0.276888698\n",
      "Trained batch 1020 batch loss 0.259156793 epoch total loss 0.276871324\n",
      "Trained batch 1021 batch loss 0.278060973 epoch total loss 0.276872516\n",
      "Trained batch 1022 batch loss 0.28466621 epoch total loss 0.276880145\n",
      "Trained batch 1023 batch loss 0.28084296 epoch total loss 0.276884019\n",
      "Trained batch 1024 batch loss 0.306658 epoch total loss 0.276913106\n",
      "Trained batch 1025 batch loss 0.309536844 epoch total loss 0.276944935\n",
      "Trained batch 1026 batch loss 0.257589072 epoch total loss 0.27692607\n",
      "Trained batch 1027 batch loss 0.270657033 epoch total loss 0.27692\n",
      "Trained batch 1028 batch loss 0.255621344 epoch total loss 0.276899248\n",
      "Trained batch 1029 batch loss 0.217281163 epoch total loss 0.276841313\n",
      "Trained batch 1030 batch loss 0.248488128 epoch total loss 0.276813775\n",
      "Trained batch 1031 batch loss 0.265877455 epoch total loss 0.276803166\n",
      "Trained batch 1032 batch loss 0.256958425 epoch total loss 0.276783943\n",
      "Trained batch 1033 batch loss 0.261100084 epoch total loss 0.276768774\n",
      "Trained batch 1034 batch loss 0.261246294 epoch total loss 0.276753753\n",
      "Trained batch 1035 batch loss 0.266181856 epoch total loss 0.276743531\n",
      "Trained batch 1036 batch loss 0.255571872 epoch total loss 0.276723117\n",
      "Trained batch 1037 batch loss 0.264578789 epoch total loss 0.276711404\n",
      "Trained batch 1038 batch loss 0.300782561 epoch total loss 0.276734591\n",
      "Trained batch 1039 batch loss 0.287569165 epoch total loss 0.276745021\n",
      "Trained batch 1040 batch loss 0.294692218 epoch total loss 0.276762277\n",
      "Trained batch 1041 batch loss 0.292457134 epoch total loss 0.276777357\n",
      "Trained batch 1042 batch loss 0.275791705 epoch total loss 0.276776403\n",
      "Trained batch 1043 batch loss 0.292455882 epoch total loss 0.276791424\n",
      "Trained batch 1044 batch loss 0.316248178 epoch total loss 0.276829213\n",
      "Trained batch 1045 batch loss 0.262093633 epoch total loss 0.276815116\n",
      "Trained batch 1046 batch loss 0.287404329 epoch total loss 0.276825249\n",
      "Trained batch 1047 batch loss 0.292282611 epoch total loss 0.276840031\n",
      "Trained batch 1048 batch loss 0.275037169 epoch total loss 0.276838303\n",
      "Trained batch 1049 batch loss 0.314385056 epoch total loss 0.276874095\n",
      "Trained batch 1050 batch loss 0.31517911 epoch total loss 0.276910573\n",
      "Trained batch 1051 batch loss 0.208846092 epoch total loss 0.276845813\n",
      "Trained batch 1052 batch loss 0.222585723 epoch total loss 0.276794225\n",
      "Trained batch 1053 batch loss 0.296053648 epoch total loss 0.276812524\n",
      "Trained batch 1054 batch loss 0.259650648 epoch total loss 0.276796222\n",
      "Trained batch 1055 batch loss 0.282273501 epoch total loss 0.276801437\n",
      "Trained batch 1056 batch loss 0.27450037 epoch total loss 0.276799262\n",
      "Trained batch 1057 batch loss 0.309535086 epoch total loss 0.276830226\n",
      "Trained batch 1058 batch loss 0.307319641 epoch total loss 0.276859045\n",
      "Trained batch 1059 batch loss 0.288797885 epoch total loss 0.27687031\n",
      "Trained batch 1060 batch loss 0.288043261 epoch total loss 0.27688086\n",
      "Trained batch 1061 batch loss 0.308534384 epoch total loss 0.276910692\n",
      "Trained batch 1062 batch loss 0.348563761 epoch total loss 0.276978165\n",
      "Trained batch 1063 batch loss 0.335477 epoch total loss 0.27703321\n",
      "Trained batch 1064 batch loss 0.331100345 epoch total loss 0.277084\n",
      "Trained batch 1065 batch loss 0.283121616 epoch total loss 0.277089655\n",
      "Trained batch 1066 batch loss 0.243932903 epoch total loss 0.277058542\n",
      "Trained batch 1067 batch loss 0.299356371 epoch total loss 0.277079433\n",
      "Trained batch 1068 batch loss 0.293532312 epoch total loss 0.277094841\n",
      "Trained batch 1069 batch loss 0.299001813 epoch total loss 0.277115345\n",
      "Trained batch 1070 batch loss 0.309291512 epoch total loss 0.277145416\n",
      "Trained batch 1071 batch loss 0.291422248 epoch total loss 0.277158737\n",
      "Trained batch 1072 batch loss 0.295112908 epoch total loss 0.277175486\n",
      "Trained batch 1073 batch loss 0.299964935 epoch total loss 0.277196705\n",
      "Trained batch 1074 batch loss 0.28347224 epoch total loss 0.277202547\n",
      "Trained batch 1075 batch loss 0.271113396 epoch total loss 0.277196884\n",
      "Trained batch 1076 batch loss 0.271919906 epoch total loss 0.277192\n",
      "Trained batch 1077 batch loss 0.28604722 epoch total loss 0.277200192\n",
      "Trained batch 1078 batch loss 0.276973248 epoch total loss 0.277199984\n",
      "Trained batch 1079 batch loss 0.298451066 epoch total loss 0.277219713\n",
      "Trained batch 1080 batch loss 0.283610374 epoch total loss 0.277225614\n",
      "Trained batch 1081 batch loss 0.283004552 epoch total loss 0.277230948\n",
      "Trained batch 1082 batch loss 0.312109381 epoch total loss 0.277263165\n",
      "Trained batch 1083 batch loss 0.304688573 epoch total loss 0.277288496\n",
      "Trained batch 1084 batch loss 0.30369693 epoch total loss 0.277312875\n",
      "Trained batch 1085 batch loss 0.270034403 epoch total loss 0.277306139\n",
      "Trained batch 1086 batch loss 0.300958872 epoch total loss 0.277327925\n",
      "Trained batch 1087 batch loss 0.321052402 epoch total loss 0.277368158\n",
      "Trained batch 1088 batch loss 0.311578482 epoch total loss 0.2773996\n",
      "Trained batch 1089 batch loss 0.314901829 epoch total loss 0.277434051\n",
      "Trained batch 1090 batch loss 0.289768785 epoch total loss 0.277445346\n",
      "Trained batch 1091 batch loss 0.261850059 epoch total loss 0.277431041\n",
      "Trained batch 1092 batch loss 0.265748829 epoch total loss 0.277420342\n",
      "Trained batch 1093 batch loss 0.27493763 epoch total loss 0.277418077\n",
      "Trained batch 1094 batch loss 0.300314486 epoch total loss 0.277439\n",
      "Trained batch 1095 batch loss 0.279639065 epoch total loss 0.277441025\n",
      "Trained batch 1096 batch loss 0.279455304 epoch total loss 0.277442843\n",
      "Trained batch 1097 batch loss 0.244155362 epoch total loss 0.277412504\n",
      "Trained batch 1098 batch loss 0.217599794 epoch total loss 0.277358\n",
      "Trained batch 1099 batch loss 0.240070224 epoch total loss 0.27732408\n",
      "Trained batch 1100 batch loss 0.288400352 epoch total loss 0.277334154\n",
      "Trained batch 1101 batch loss 0.335399598 epoch total loss 0.277386874\n",
      "Trained batch 1102 batch loss 0.334731 epoch total loss 0.277438909\n",
      "Trained batch 1103 batch loss 0.310380697 epoch total loss 0.277468771\n",
      "Trained batch 1104 batch loss 0.314162284 epoch total loss 0.277502\n",
      "Trained batch 1105 batch loss 0.319886416 epoch total loss 0.277540356\n",
      "Trained batch 1106 batch loss 0.314036667 epoch total loss 0.277573347\n",
      "Trained batch 1107 batch loss 0.29093945 epoch total loss 0.277585447\n",
      "Trained batch 1108 batch loss 0.302012265 epoch total loss 0.277607471\n",
      "Trained batch 1109 batch loss 0.271023154 epoch total loss 0.27760154\n",
      "Trained batch 1110 batch loss 0.305505782 epoch total loss 0.277626693\n",
      "Trained batch 1111 batch loss 0.309034973 epoch total loss 0.277654946\n",
      "Trained batch 1112 batch loss 0.326137245 epoch total loss 0.277698547\n",
      "Trained batch 1113 batch loss 0.314185679 epoch total loss 0.277731329\n",
      "Trained batch 1114 batch loss 0.28278625 epoch total loss 0.277735859\n",
      "Trained batch 1115 batch loss 0.28393504 epoch total loss 0.277741402\n",
      "Trained batch 1116 batch loss 0.26444155 epoch total loss 0.277729481\n",
      "Trained batch 1117 batch loss 0.306935191 epoch total loss 0.277755648\n",
      "Trained batch 1118 batch loss 0.290699363 epoch total loss 0.277767241\n",
      "Trained batch 1119 batch loss 0.332741529 epoch total loss 0.277816355\n",
      "Trained batch 1120 batch loss 0.332539529 epoch total loss 0.277865231\n",
      "Trained batch 1121 batch loss 0.274065167 epoch total loss 0.277861834\n",
      "Trained batch 1122 batch loss 0.27979511 epoch total loss 0.277863562\n",
      "Trained batch 1123 batch loss 0.289850503 epoch total loss 0.277874231\n",
      "Trained batch 1124 batch loss 0.29699263 epoch total loss 0.277891248\n",
      "Trained batch 1125 batch loss 0.313935 epoch total loss 0.277923286\n",
      "Trained batch 1126 batch loss 0.277269423 epoch total loss 0.27792272\n",
      "Trained batch 1127 batch loss 0.252776 epoch total loss 0.277900398\n",
      "Trained batch 1128 batch loss 0.307915211 epoch total loss 0.277927\n",
      "Trained batch 1129 batch loss 0.311059296 epoch total loss 0.277956367\n",
      "Trained batch 1130 batch loss 0.291018695 epoch total loss 0.27796793\n",
      "Trained batch 1131 batch loss 0.292150825 epoch total loss 0.277980477\n",
      "Trained batch 1132 batch loss 0.305477172 epoch total loss 0.278004766\n",
      "Trained batch 1133 batch loss 0.315340251 epoch total loss 0.278037697\n",
      "Trained batch 1134 batch loss 0.283138692 epoch total loss 0.278042197\n",
      "Trained batch 1135 batch loss 0.274790496 epoch total loss 0.278039336\n",
      "Trained batch 1136 batch loss 0.301699817 epoch total loss 0.278060168\n",
      "Trained batch 1137 batch loss 0.280978352 epoch total loss 0.278062731\n",
      "Trained batch 1138 batch loss 0.295507163 epoch total loss 0.278078049\n",
      "Trained batch 1139 batch loss 0.243880987 epoch total loss 0.278048\n",
      "Trained batch 1140 batch loss 0.318823874 epoch total loss 0.278083771\n",
      "Trained batch 1141 batch loss 0.310861617 epoch total loss 0.278112501\n",
      "Trained batch 1142 batch loss 0.305487335 epoch total loss 0.278136462\n",
      "Trained batch 1143 batch loss 0.307716072 epoch total loss 0.27816233\n",
      "Trained batch 1144 batch loss 0.245358586 epoch total loss 0.278133661\n",
      "Trained batch 1145 batch loss 0.239910811 epoch total loss 0.278100252\n",
      "Trained batch 1146 batch loss 0.274553925 epoch total loss 0.278097183\n",
      "Trained batch 1147 batch loss 0.286682338 epoch total loss 0.278104663\n",
      "Trained batch 1148 batch loss 0.279504091 epoch total loss 0.278105885\n",
      "Trained batch 1149 batch loss 0.250326276 epoch total loss 0.278081715\n",
      "Trained batch 1150 batch loss 0.274704069 epoch total loss 0.278078794\n",
      "Trained batch 1151 batch loss 0.257572532 epoch total loss 0.278060973\n",
      "Trained batch 1152 batch loss 0.242645308 epoch total loss 0.278030246\n",
      "Trained batch 1153 batch loss 0.235013992 epoch total loss 0.277992934\n",
      "Trained batch 1154 batch loss 0.245251179 epoch total loss 0.277964562\n",
      "Trained batch 1155 batch loss 0.28261736 epoch total loss 0.277968585\n",
      "Trained batch 1156 batch loss 0.303089231 epoch total loss 0.277990311\n",
      "Trained batch 1157 batch loss 0.280969769 epoch total loss 0.277992904\n",
      "Trained batch 1158 batch loss 0.30200541 epoch total loss 0.278013647\n",
      "Trained batch 1159 batch loss 0.304571152 epoch total loss 0.278036535\n",
      "Trained batch 1160 batch loss 0.268553734 epoch total loss 0.278028369\n",
      "Trained batch 1161 batch loss 0.250485361 epoch total loss 0.278004646\n",
      "Trained batch 1162 batch loss 0.278869033 epoch total loss 0.278005391\n",
      "Trained batch 1163 batch loss 0.279300749 epoch total loss 0.278006494\n",
      "Trained batch 1164 batch loss 0.271288484 epoch total loss 0.278000742\n",
      "Trained batch 1165 batch loss 0.232889205 epoch total loss 0.277962\n",
      "Trained batch 1166 batch loss 0.206827939 epoch total loss 0.277901\n",
      "Trained batch 1167 batch loss 0.252973825 epoch total loss 0.277879626\n",
      "Trained batch 1168 batch loss 0.29386729 epoch total loss 0.277893305\n",
      "Trained batch 1169 batch loss 0.312756449 epoch total loss 0.277923107\n",
      "Trained batch 1170 batch loss 0.313168526 epoch total loss 0.277953237\n",
      "Trained batch 1171 batch loss 0.307087481 epoch total loss 0.277978122\n",
      "Trained batch 1172 batch loss 0.283171386 epoch total loss 0.277982563\n",
      "Trained batch 1173 batch loss 0.291591465 epoch total loss 0.277994156\n",
      "Trained batch 1174 batch loss 0.302453965 epoch total loss 0.278015018\n",
      "Trained batch 1175 batch loss 0.280798942 epoch total loss 0.278017372\n",
      "Trained batch 1176 batch loss 0.312189639 epoch total loss 0.278046429\n",
      "Trained batch 1177 batch loss 0.291855812 epoch total loss 0.278058171\n",
      "Trained batch 1178 batch loss 0.294051498 epoch total loss 0.278071731\n",
      "Trained batch 1179 batch loss 0.294241369 epoch total loss 0.27808547\n",
      "Trained batch 1180 batch loss 0.319379628 epoch total loss 0.278120458\n",
      "Trained batch 1181 batch loss 0.315839738 epoch total loss 0.278152376\n",
      "Trained batch 1182 batch loss 0.273028225 epoch total loss 0.278148055\n",
      "Trained batch 1183 batch loss 0.275512666 epoch total loss 0.27814582\n",
      "Trained batch 1184 batch loss 0.251674801 epoch total loss 0.278123468\n",
      "Trained batch 1185 batch loss 0.280473 epoch total loss 0.278125465\n",
      "Trained batch 1186 batch loss 0.285695821 epoch total loss 0.278131843\n",
      "Trained batch 1187 batch loss 0.292963058 epoch total loss 0.27814436\n",
      "Trained batch 1188 batch loss 0.28760305 epoch total loss 0.278152317\n",
      "Trained batch 1189 batch loss 0.267496079 epoch total loss 0.278143346\n",
      "Trained batch 1190 batch loss 0.299648762 epoch total loss 0.278161407\n",
      "Trained batch 1191 batch loss 0.278667033 epoch total loss 0.278161824\n",
      "Trained batch 1192 batch loss 0.284073919 epoch total loss 0.278166801\n",
      "Trained batch 1193 batch loss 0.254162639 epoch total loss 0.278146684\n",
      "Trained batch 1194 batch loss 0.285024405 epoch total loss 0.278152436\n",
      "Trained batch 1195 batch loss 0.272910118 epoch total loss 0.278148055\n",
      "Trained batch 1196 batch loss 0.25575152 epoch total loss 0.278129309\n",
      "Trained batch 1197 batch loss 0.254273087 epoch total loss 0.278109401\n",
      "Trained batch 1198 batch loss 0.271990567 epoch total loss 0.278104305\n",
      "Trained batch 1199 batch loss 0.230888203 epoch total loss 0.278064936\n",
      "Trained batch 1200 batch loss 0.261429131 epoch total loss 0.278051078\n",
      "Trained batch 1201 batch loss 0.261752248 epoch total loss 0.278037488\n",
      "Trained batch 1202 batch loss 0.263221741 epoch total loss 0.27802518\n",
      "Trained batch 1203 batch loss 0.241930366 epoch total loss 0.277995169\n",
      "Trained batch 1204 batch loss 0.257375062 epoch total loss 0.277978063\n",
      "Trained batch 1205 batch loss 0.25007993 epoch total loss 0.277954906\n",
      "Trained batch 1206 batch loss 0.279708773 epoch total loss 0.277956367\n",
      "Trained batch 1207 batch loss 0.324835896 epoch total loss 0.277995199\n",
      "Trained batch 1208 batch loss 0.301903576 epoch total loss 0.278015\n",
      "Trained batch 1209 batch loss 0.306148559 epoch total loss 0.278038263\n",
      "Trained batch 1210 batch loss 0.298431605 epoch total loss 0.278055102\n",
      "Trained batch 1211 batch loss 0.278665394 epoch total loss 0.278055608\n",
      "Trained batch 1212 batch loss 0.272264421 epoch total loss 0.27805084\n",
      "Trained batch 1213 batch loss 0.294001937 epoch total loss 0.278063983\n",
      "Trained batch 1214 batch loss 0.289741099 epoch total loss 0.278073609\n",
      "Trained batch 1215 batch loss 0.283410192 epoch total loss 0.27807802\n",
      "Trained batch 1216 batch loss 0.262487352 epoch total loss 0.278065175\n",
      "Trained batch 1217 batch loss 0.309474856 epoch total loss 0.278090984\n",
      "Trained batch 1218 batch loss 0.293990374 epoch total loss 0.278104037\n",
      "Trained batch 1219 batch loss 0.308136046 epoch total loss 0.278128684\n",
      "Trained batch 1220 batch loss 0.313576162 epoch total loss 0.278157711\n",
      "Trained batch 1221 batch loss 0.273516327 epoch total loss 0.278153926\n",
      "Trained batch 1222 batch loss 0.276617885 epoch total loss 0.278152674\n",
      "Trained batch 1223 batch loss 0.234255657 epoch total loss 0.278116763\n",
      "Trained batch 1224 batch loss 0.244296342 epoch total loss 0.278089136\n",
      "Trained batch 1225 batch loss 0.238617092 epoch total loss 0.27805692\n",
      "Trained batch 1226 batch loss 0.272688806 epoch total loss 0.278052539\n",
      "Trained batch 1227 batch loss 0.255908638 epoch total loss 0.278034478\n",
      "Trained batch 1228 batch loss 0.191789642 epoch total loss 0.277964264\n",
      "Trained batch 1229 batch loss 0.220462978 epoch total loss 0.277917475\n",
      "Trained batch 1230 batch loss 0.182616681 epoch total loss 0.27784\n",
      "Trained batch 1231 batch loss 0.232976258 epoch total loss 0.27780354\n",
      "Trained batch 1232 batch loss 0.253425062 epoch total loss 0.277783751\n",
      "Trained batch 1233 batch loss 0.267551661 epoch total loss 0.277775437\n",
      "Trained batch 1234 batch loss 0.260849357 epoch total loss 0.277761757\n",
      "Trained batch 1235 batch loss 0.26126039 epoch total loss 0.277748376\n",
      "Trained batch 1236 batch loss 0.27845785 epoch total loss 0.277748972\n",
      "Trained batch 1237 batch loss 0.292211592 epoch total loss 0.277760655\n",
      "Trained batch 1238 batch loss 0.314488679 epoch total loss 0.277790308\n",
      "Trained batch 1239 batch loss 0.287591636 epoch total loss 0.277798235\n",
      "Trained batch 1240 batch loss 0.298372328 epoch total loss 0.277814835\n",
      "Trained batch 1241 batch loss 0.278839767 epoch total loss 0.27781564\n",
      "Trained batch 1242 batch loss 0.258773088 epoch total loss 0.277800322\n",
      "Trained batch 1243 batch loss 0.252600074 epoch total loss 0.277780026\n",
      "Trained batch 1244 batch loss 0.2742351 epoch total loss 0.277777165\n",
      "Trained batch 1245 batch loss 0.302010775 epoch total loss 0.277796626\n",
      "Trained batch 1246 batch loss 0.294945955 epoch total loss 0.277810395\n",
      "Trained batch 1247 batch loss 0.313672215 epoch total loss 0.277839154\n",
      "Trained batch 1248 batch loss 0.333920509 epoch total loss 0.277884096\n",
      "Trained batch 1249 batch loss 0.308612555 epoch total loss 0.277908713\n",
      "Trained batch 1250 batch loss 0.29467237 epoch total loss 0.277922124\n",
      "Trained batch 1251 batch loss 0.294236153 epoch total loss 0.277935177\n",
      "Trained batch 1252 batch loss 0.28514713 epoch total loss 0.277940929\n",
      "Trained batch 1253 batch loss 0.309029877 epoch total loss 0.277965754\n",
      "Trained batch 1254 batch loss 0.289216518 epoch total loss 0.277974725\n",
      "Trained batch 1255 batch loss 0.310923487 epoch total loss 0.278000951\n",
      "Trained batch 1256 batch loss 0.277609706 epoch total loss 0.278000653\n",
      "Trained batch 1257 batch loss 0.315946609 epoch total loss 0.278030843\n",
      "Trained batch 1258 batch loss 0.294348091 epoch total loss 0.278043807\n",
      "Trained batch 1259 batch loss 0.259871125 epoch total loss 0.278029352\n",
      "Trained batch 1260 batch loss 0.295350105 epoch total loss 0.278043121\n",
      "Trained batch 1261 batch loss 0.286448598 epoch total loss 0.278049767\n",
      "Trained batch 1262 batch loss 0.29148984 epoch total loss 0.278060436\n",
      "Trained batch 1263 batch loss 0.328154832 epoch total loss 0.278100103\n",
      "Trained batch 1264 batch loss 0.337857604 epoch total loss 0.27814737\n",
      "Trained batch 1265 batch loss 0.280467331 epoch total loss 0.278149188\n",
      "Trained batch 1266 batch loss 0.282971323 epoch total loss 0.278153\n",
      "Trained batch 1267 batch loss 0.262531936 epoch total loss 0.278140664\n",
      "Trained batch 1268 batch loss 0.288064927 epoch total loss 0.278148502\n",
      "Trained batch 1269 batch loss 0.290364444 epoch total loss 0.278158128\n",
      "Trained batch 1270 batch loss 0.291782469 epoch total loss 0.278168857\n",
      "Trained batch 1271 batch loss 0.320594847 epoch total loss 0.278202236\n",
      "Trained batch 1272 batch loss 0.301453829 epoch total loss 0.278220505\n",
      "Trained batch 1273 batch loss 0.312111706 epoch total loss 0.278247118\n",
      "Trained batch 1274 batch loss 0.340789139 epoch total loss 0.278296202\n",
      "Trained batch 1275 batch loss 0.31695497 epoch total loss 0.278326541\n",
      "Trained batch 1276 batch loss 0.31698972 epoch total loss 0.27835682\n",
      "Trained batch 1277 batch loss 0.307327867 epoch total loss 0.27837953\n",
      "Trained batch 1278 batch loss 0.300413936 epoch total loss 0.278396785\n",
      "Trained batch 1279 batch loss 0.322309554 epoch total loss 0.278431088\n",
      "Trained batch 1280 batch loss 0.297556669 epoch total loss 0.278446019\n",
      "Trained batch 1281 batch loss 0.287038684 epoch total loss 0.278452754\n",
      "Trained batch 1282 batch loss 0.276717901 epoch total loss 0.278451383\n",
      "Trained batch 1283 batch loss 0.265485734 epoch total loss 0.27844125\n",
      "Trained batch 1284 batch loss 0.239497587 epoch total loss 0.278410941\n",
      "Trained batch 1285 batch loss 0.23097083 epoch total loss 0.278374016\n",
      "Trained batch 1286 batch loss 0.238237768 epoch total loss 0.278342813\n",
      "Trained batch 1287 batch loss 0.285811782 epoch total loss 0.278348595\n",
      "Trained batch 1288 batch loss 0.301515311 epoch total loss 0.278366596\n",
      "Trained batch 1289 batch loss 0.34411779 epoch total loss 0.278417587\n",
      "Trained batch 1290 batch loss 0.319096029 epoch total loss 0.278449118\n",
      "Trained batch 1291 batch loss 0.294531792 epoch total loss 0.278461576\n",
      "Trained batch 1292 batch loss 0.308211297 epoch total loss 0.278484583\n",
      "Trained batch 1293 batch loss 0.26379022 epoch total loss 0.278473228\n",
      "Trained batch 1294 batch loss 0.25940302 epoch total loss 0.278458476\n",
      "Trained batch 1295 batch loss 0.261021495 epoch total loss 0.278445035\n",
      "Trained batch 1296 batch loss 0.289049655 epoch total loss 0.278453201\n",
      "Trained batch 1297 batch loss 0.286368191 epoch total loss 0.278459311\n",
      "Trained batch 1298 batch loss 0.281488955 epoch total loss 0.278461665\n",
      "Trained batch 1299 batch loss 0.292284489 epoch total loss 0.278472304\n",
      "Trained batch 1300 batch loss 0.292925507 epoch total loss 0.27848345\n",
      "Trained batch 1301 batch loss 0.277733445 epoch total loss 0.278482884\n",
      "Trained batch 1302 batch loss 0.276545137 epoch total loss 0.278481394\n",
      "Trained batch 1303 batch loss 0.26992777 epoch total loss 0.278474808\n",
      "Trained batch 1304 batch loss 0.257331 epoch total loss 0.278458595\n",
      "Trained batch 1305 batch loss 0.258342981 epoch total loss 0.278443187\n",
      "Trained batch 1306 batch loss 0.267560244 epoch total loss 0.278434843\n",
      "Trained batch 1307 batch loss 0.275668889 epoch total loss 0.278432727\n",
      "Trained batch 1308 batch loss 0.308871 epoch total loss 0.278455973\n",
      "Trained batch 1309 batch loss 0.29845354 epoch total loss 0.278471261\n",
      "Trained batch 1310 batch loss 0.30231759 epoch total loss 0.27848947\n",
      "Trained batch 1311 batch loss 0.2841914 epoch total loss 0.278493792\n",
      "Trained batch 1312 batch loss 0.254674047 epoch total loss 0.278475642\n",
      "Trained batch 1313 batch loss 0.252942741 epoch total loss 0.278456181\n",
      "Trained batch 1314 batch loss 0.230329022 epoch total loss 0.278419554\n",
      "Trained batch 1315 batch loss 0.24384895 epoch total loss 0.278393239\n",
      "Trained batch 1316 batch loss 0.294432253 epoch total loss 0.278405428\n",
      "Trained batch 1317 batch loss 0.296811461 epoch total loss 0.278419405\n",
      "Trained batch 1318 batch loss 0.293873787 epoch total loss 0.278431147\n",
      "Trained batch 1319 batch loss 0.275473922 epoch total loss 0.278428912\n",
      "Trained batch 1320 batch loss 0.269298553 epoch total loss 0.278422\n",
      "Trained batch 1321 batch loss 0.291777521 epoch total loss 0.278432101\n",
      "Trained batch 1322 batch loss 0.246201739 epoch total loss 0.278407723\n",
      "Trained batch 1323 batch loss 0.266539603 epoch total loss 0.278398752\n",
      "Trained batch 1324 batch loss 0.324572355 epoch total loss 0.278433651\n",
      "Trained batch 1325 batch loss 0.301023424 epoch total loss 0.278450698\n",
      "Trained batch 1326 batch loss 0.275232643 epoch total loss 0.278448284\n",
      "Trained batch 1327 batch loss 0.270985663 epoch total loss 0.278442651\n",
      "Trained batch 1328 batch loss 0.263065815 epoch total loss 0.278431088\n",
      "Trained batch 1329 batch loss 0.268921107 epoch total loss 0.278423935\n",
      "Trained batch 1330 batch loss 0.269975513 epoch total loss 0.278417587\n",
      "Trained batch 1331 batch loss 0.239242 epoch total loss 0.278388143\n",
      "Trained batch 1332 batch loss 0.226135164 epoch total loss 0.278348893\n",
      "Trained batch 1333 batch loss 0.256479204 epoch total loss 0.278332502\n",
      "Trained batch 1334 batch loss 0.255294472 epoch total loss 0.278315216\n",
      "Trained batch 1335 batch loss 0.248129755 epoch total loss 0.278292596\n",
      "Trained batch 1336 batch loss 0.243894577 epoch total loss 0.278266847\n",
      "Trained batch 1337 batch loss 0.261027604 epoch total loss 0.278253973\n",
      "Trained batch 1338 batch loss 0.302995503 epoch total loss 0.27827245\n",
      "Trained batch 1339 batch loss 0.268689603 epoch total loss 0.278265297\n",
      "Trained batch 1340 batch loss 0.278918743 epoch total loss 0.278265804\n",
      "Trained batch 1341 batch loss 0.249303907 epoch total loss 0.278244197\n",
      "Trained batch 1342 batch loss 0.32113868 epoch total loss 0.278276145\n",
      "Trained batch 1343 batch loss 0.295076609 epoch total loss 0.278288662\n",
      "Trained batch 1344 batch loss 0.277876377 epoch total loss 0.278288335\n",
      "Trained batch 1345 batch loss 0.261854768 epoch total loss 0.278276116\n",
      "Trained batch 1346 batch loss 0.258022964 epoch total loss 0.278261065\n",
      "Trained batch 1347 batch loss 0.246622577 epoch total loss 0.278237581\n",
      "Trained batch 1348 batch loss 0.251916766 epoch total loss 0.278218061\n",
      "Trained batch 1349 batch loss 0.288164496 epoch total loss 0.278225422\n",
      "Trained batch 1350 batch loss 0.287385643 epoch total loss 0.278232217\n",
      "Trained batch 1351 batch loss 0.292177945 epoch total loss 0.278242528\n",
      "Trained batch 1352 batch loss 0.272178948 epoch total loss 0.278238058\n",
      "Trained batch 1353 batch loss 0.251880974 epoch total loss 0.278218597\n",
      "Trained batch 1354 batch loss 0.271621555 epoch total loss 0.27821371\n",
      "Trained batch 1355 batch loss 0.239804536 epoch total loss 0.278185368\n",
      "Trained batch 1356 batch loss 0.275265604 epoch total loss 0.278183222\n",
      "Trained batch 1357 batch loss 0.280749768 epoch total loss 0.278185099\n",
      "Trained batch 1358 batch loss 0.307982296 epoch total loss 0.278207064\n",
      "Trained batch 1359 batch loss 0.297761917 epoch total loss 0.278221428\n",
      "Trained batch 1360 batch loss 0.281135172 epoch total loss 0.278223574\n",
      "Trained batch 1361 batch loss 0.266857028 epoch total loss 0.27821523\n",
      "Trained batch 1362 batch loss 0.287182122 epoch total loss 0.278221786\n",
      "Trained batch 1363 batch loss 0.274731308 epoch total loss 0.278219223\n",
      "Trained batch 1364 batch loss 0.283064038 epoch total loss 0.278222769\n",
      "Trained batch 1365 batch loss 0.28380698 epoch total loss 0.278226852\n",
      "Trained batch 1366 batch loss 0.270735711 epoch total loss 0.278221369\n",
      "Trained batch 1367 batch loss 0.312102258 epoch total loss 0.278246164\n",
      "Trained batch 1368 batch loss 0.264368981 epoch total loss 0.278236\n",
      "Trained batch 1369 batch loss 0.259756237 epoch total loss 0.278222531\n",
      "Trained batch 1370 batch loss 0.249459952 epoch total loss 0.27820152\n",
      "Trained batch 1371 batch loss 0.282532781 epoch total loss 0.278204679\n",
      "Trained batch 1372 batch loss 0.288199276 epoch total loss 0.278211981\n",
      "Trained batch 1373 batch loss 0.318666637 epoch total loss 0.278241426\n",
      "Trained batch 1374 batch loss 0.30029422 epoch total loss 0.278257489\n",
      "Trained batch 1375 batch loss 0.276940912 epoch total loss 0.278256536\n",
      "Trained batch 1376 batch loss 0.305316806 epoch total loss 0.278276205\n",
      "Trained batch 1377 batch loss 0.300591201 epoch total loss 0.278292418\n",
      "Trained batch 1378 batch loss 0.27473554 epoch total loss 0.278289825\n",
      "Trained batch 1379 batch loss 0.293433845 epoch total loss 0.278300822\n",
      "Trained batch 1380 batch loss 0.270636141 epoch total loss 0.278295249\n",
      "Trained batch 1381 batch loss 0.278268039 epoch total loss 0.278295219\n",
      "Trained batch 1382 batch loss 0.258176297 epoch total loss 0.278280675\n",
      "Trained batch 1383 batch loss 0.279467642 epoch total loss 0.27828154\n",
      "Trained batch 1384 batch loss 0.278095156 epoch total loss 0.27828142\n",
      "Trained batch 1385 batch loss 0.25472492 epoch total loss 0.278264403\n",
      "Trained batch 1386 batch loss 0.260985494 epoch total loss 0.278251946\n",
      "Trained batch 1387 batch loss 0.28389439 epoch total loss 0.278256029\n",
      "Trained batch 1388 batch loss 0.250578374 epoch total loss 0.278236091\n",
      "Epoch 5 train loss 0.2782360911369324 and time 677.096759557724\n",
      "Validated batch 1 batch loss 0.308993936\n",
      "Validated batch 2 batch loss 0.274953067\n",
      "Validated batch 3 batch loss 0.286156535\n",
      "Validated batch 4 batch loss 0.27873227\n",
      "Validated batch 5 batch loss 0.282096714\n",
      "Validated batch 6 batch loss 0.303570837\n",
      "Validated batch 7 batch loss 0.293557048\n",
      "Validated batch 8 batch loss 0.281694442\n",
      "Validated batch 9 batch loss 0.324144691\n",
      "Validated batch 10 batch loss 0.306720614\n",
      "Validated batch 11 batch loss 0.278380573\n",
      "Validated batch 12 batch loss 0.258323818\n",
      "Validated batch 13 batch loss 0.301809877\n",
      "Validated batch 14 batch loss 0.306377292\n",
      "Validated batch 15 batch loss 0.3349756\n",
      "Validated batch 16 batch loss 0.324595839\n",
      "Validated batch 17 batch loss 0.297693402\n",
      "Validated batch 18 batch loss 0.316393197\n",
      "Validated batch 19 batch loss 0.306163669\n",
      "Validated batch 20 batch loss 0.289470941\n",
      "Validated batch 21 batch loss 0.301803917\n",
      "Validated batch 22 batch loss 0.238047123\n",
      "Validated batch 23 batch loss 0.303842485\n",
      "Validated batch 24 batch loss 0.298167\n",
      "Validated batch 25 batch loss 0.301552236\n",
      "Validated batch 26 batch loss 0.287148058\n",
      "Validated batch 27 batch loss 0.290873\n",
      "Validated batch 28 batch loss 0.316150844\n",
      "Validated batch 29 batch loss 0.345271707\n",
      "Validated batch 30 batch loss 0.28220126\n",
      "Validated batch 31 batch loss 0.298721015\n",
      "Validated batch 32 batch loss 0.283274055\n",
      "Validated batch 33 batch loss 0.294633806\n",
      "Validated batch 34 batch loss 0.298463285\n",
      "Validated batch 35 batch loss 0.271387219\n",
      "Validated batch 36 batch loss 0.339010358\n",
      "Validated batch 37 batch loss 0.271013439\n",
      "Validated batch 38 batch loss 0.315496922\n",
      "Validated batch 39 batch loss 0.295342684\n",
      "Validated batch 40 batch loss 0.321109176\n",
      "Validated batch 41 batch loss 0.252562493\n",
      "Validated batch 42 batch loss 0.311335742\n",
      "Validated batch 43 batch loss 0.273760498\n",
      "Validated batch 44 batch loss 0.304094434\n",
      "Validated batch 45 batch loss 0.289732903\n",
      "Validated batch 46 batch loss 0.28812775\n",
      "Validated batch 47 batch loss 0.292752981\n",
      "Validated batch 48 batch loss 0.290014863\n",
      "Validated batch 49 batch loss 0.276300788\n",
      "Validated batch 50 batch loss 0.285251379\n",
      "Validated batch 51 batch loss 0.291359037\n",
      "Validated batch 52 batch loss 0.309949189\n",
      "Validated batch 53 batch loss 0.30998385\n",
      "Validated batch 54 batch loss 0.313690364\n",
      "Validated batch 55 batch loss 0.301103443\n",
      "Validated batch 56 batch loss 0.279278725\n",
      "Validated batch 57 batch loss 0.289752632\n",
      "Validated batch 58 batch loss 0.286141634\n",
      "Validated batch 59 batch loss 0.287912875\n",
      "Validated batch 60 batch loss 0.314085037\n",
      "Validated batch 61 batch loss 0.31396088\n",
      "Validated batch 62 batch loss 0.293325782\n",
      "Validated batch 63 batch loss 0.336990148\n",
      "Validated batch 64 batch loss 0.266032636\n",
      "Validated batch 65 batch loss 0.319158971\n",
      "Validated batch 66 batch loss 0.242362455\n",
      "Validated batch 67 batch loss 0.280789256\n",
      "Validated batch 68 batch loss 0.307210624\n",
      "Validated batch 69 batch loss 0.278638244\n",
      "Validated batch 70 batch loss 0.275472373\n",
      "Validated batch 71 batch loss 0.262746871\n",
      "Validated batch 72 batch loss 0.279826522\n",
      "Validated batch 73 batch loss 0.269018829\n",
      "Validated batch 74 batch loss 0.280679643\n",
      "Validated batch 75 batch loss 0.303731024\n",
      "Validated batch 76 batch loss 0.294975579\n",
      "Validated batch 77 batch loss 0.288690507\n",
      "Validated batch 78 batch loss 0.28762418\n",
      "Validated batch 79 batch loss 0.270887077\n",
      "Validated batch 80 batch loss 0.286728412\n",
      "Validated batch 81 batch loss 0.303169936\n",
      "Validated batch 82 batch loss 0.272056967\n",
      "Validated batch 83 batch loss 0.278739244\n",
      "Validated batch 84 batch loss 0.295554757\n",
      "Validated batch 85 batch loss 0.275892407\n",
      "Validated batch 86 batch loss 0.334947973\n",
      "Validated batch 87 batch loss 0.300233662\n",
      "Validated batch 88 batch loss 0.267506897\n",
      "Validated batch 89 batch loss 0.29863584\n",
      "Validated batch 90 batch loss 0.287680686\n",
      "Validated batch 91 batch loss 0.274555773\n",
      "Validated batch 92 batch loss 0.286560118\n",
      "Validated batch 93 batch loss 0.274186224\n",
      "Validated batch 94 batch loss 0.2834526\n",
      "Validated batch 95 batch loss 0.283077955\n",
      "Validated batch 96 batch loss 0.261174\n",
      "Validated batch 97 batch loss 0.270830572\n",
      "Validated batch 98 batch loss 0.315060794\n",
      "Validated batch 99 batch loss 0.270528734\n",
      "Validated batch 100 batch loss 0.264139473\n",
      "Validated batch 101 batch loss 0.272051096\n",
      "Validated batch 102 batch loss 0.275656819\n",
      "Validated batch 103 batch loss 0.260881364\n",
      "Validated batch 104 batch loss 0.29510358\n",
      "Validated batch 105 batch loss 0.280888379\n",
      "Validated batch 106 batch loss 0.278370917\n",
      "Validated batch 107 batch loss 0.312354028\n",
      "Validated batch 108 batch loss 0.320676088\n",
      "Validated batch 109 batch loss 0.263125122\n",
      "Validated batch 110 batch loss 0.31372273\n",
      "Validated batch 111 batch loss 0.242122442\n",
      "Validated batch 112 batch loss 0.270149589\n",
      "Validated batch 113 batch loss 0.271594673\n",
      "Validated batch 114 batch loss 0.267883241\n",
      "Validated batch 115 batch loss 0.33555764\n",
      "Validated batch 116 batch loss 0.326222479\n",
      "Validated batch 117 batch loss 0.298226744\n",
      "Validated batch 118 batch loss 0.280980021\n",
      "Validated batch 119 batch loss 0.295187831\n",
      "Validated batch 120 batch loss 0.273103297\n",
      "Validated batch 121 batch loss 0.295199662\n",
      "Validated batch 122 batch loss 0.296468973\n",
      "Validated batch 123 batch loss 0.282901466\n",
      "Validated batch 124 batch loss 0.272080719\n",
      "Validated batch 125 batch loss 0.288806826\n",
      "Validated batch 126 batch loss 0.297080964\n",
      "Validated batch 127 batch loss 0.315074712\n",
      "Validated batch 128 batch loss 0.291671336\n",
      "Validated batch 129 batch loss 0.26342392\n",
      "Validated batch 130 batch loss 0.282990694\n",
      "Validated batch 131 batch loss 0.297032416\n",
      "Validated batch 132 batch loss 0.289242297\n",
      "Validated batch 133 batch loss 0.289538026\n",
      "Validated batch 134 batch loss 0.296078801\n",
      "Validated batch 135 batch loss 0.331262529\n",
      "Validated batch 136 batch loss 0.321892768\n",
      "Validated batch 137 batch loss 0.290344954\n",
      "Validated batch 138 batch loss 0.269598633\n",
      "Validated batch 139 batch loss 0.26623112\n",
      "Validated batch 140 batch loss 0.273339421\n",
      "Validated batch 141 batch loss 0.2678563\n",
      "Validated batch 142 batch loss 0.267493904\n",
      "Validated batch 143 batch loss 0.264352262\n",
      "Validated batch 144 batch loss 0.308744907\n",
      "Validated batch 145 batch loss 0.284127474\n",
      "Validated batch 146 batch loss 0.300613463\n",
      "Validated batch 147 batch loss 0.296716034\n",
      "Validated batch 148 batch loss 0.29046154\n",
      "Validated batch 149 batch loss 0.303734601\n",
      "Validated batch 150 batch loss 0.34213388\n",
      "Validated batch 151 batch loss 0.304788262\n",
      "Validated batch 152 batch loss 0.321037114\n",
      "Validated batch 153 batch loss 0.304536045\n",
      "Validated batch 154 batch loss 0.334543765\n",
      "Validated batch 155 batch loss 0.311518431\n",
      "Validated batch 156 batch loss 0.279038459\n",
      "Validated batch 157 batch loss 0.29375422\n",
      "Validated batch 158 batch loss 0.317761242\n",
      "Validated batch 159 batch loss 0.302252561\n",
      "Validated batch 160 batch loss 0.284226537\n",
      "Validated batch 161 batch loss 0.301465333\n",
      "Validated batch 162 batch loss 0.278909534\n",
      "Validated batch 163 batch loss 0.257865548\n",
      "Validated batch 164 batch loss 0.300753832\n",
      "Validated batch 165 batch loss 0.292300701\n",
      "Validated batch 166 batch loss 0.288610905\n",
      "Validated batch 167 batch loss 0.334516317\n",
      "Validated batch 168 batch loss 0.260721803\n",
      "Validated batch 169 batch loss 0.288312614\n",
      "Validated batch 170 batch loss 0.27992031\n",
      "Validated batch 171 batch loss 0.300138474\n",
      "Validated batch 172 batch loss 0.302406967\n",
      "Validated batch 173 batch loss 0.279214472\n",
      "Validated batch 174 batch loss 0.221301049\n",
      "Validated batch 175 batch loss 0.287475646\n",
      "Validated batch 176 batch loss 0.265340149\n",
      "Validated batch 177 batch loss 0.283124447\n",
      "Validated batch 178 batch loss 0.310165823\n",
      "Validated batch 179 batch loss 0.25118196\n",
      "Validated batch 180 batch loss 0.296098828\n",
      "Validated batch 181 batch loss 0.317229748\n",
      "Validated batch 182 batch loss 0.292468727\n",
      "Validated batch 183 batch loss 0.297147\n",
      "Validated batch 184 batch loss 0.268590808\n",
      "Validated batch 185 batch loss 0.293194234\n",
      "Epoch 5 val loss 0.2911599278450012\n",
      "Model /aiffel/aiffel/CV-PoseEstimation/models/model-epoch-5-loss-0.2912.h5 saved.\n"
     ]
    }
   ],
   "source": [
    "train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007\n",
    "\n",
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/CV-PoseEstimation'\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')\n",
    "best_model_file = train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb083c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "def automatic_gpu_usage() :\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "automatic_gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d710275",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline'\n",
    "\n",
    "if model_name == 'hourglass':\n",
    "    PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "    MODEL_PATH = os.path.join(PROJECT_PATH, 'models/model-v0.0.1-epoch-2-loss-1.3072.h5')\n",
    "    model = StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), num_stack=4, num_residual=1,\n",
    "        num_heatmap=16)\n",
    "    model.load_weights(MODEL_PATH)  # 본인이 학습한 weight path로 바꿔주세요. \n",
    "elif model_name == 'baseline':\n",
    "    PROJECT_PATH = os.getenv('HOME') + '/aiffel/CV-PoseEstimation'\n",
    "    MODEL_PATH = os.path.join(PROJECT_PATH, 'models/model-epoch-5-loss-0.2912.h5')\n",
    "    model = Simplebaseline(input_shape=(256, 256, 3))\n",
    "    model.load_weights(MODEL_PATH)  # 본인이 학습한 weight path로 바꿔주세요.     \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cfc7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ANKLE = 0\n",
    "R_KNEE = 1\n",
    "R_HIP = 2\n",
    "L_HIP = 3\n",
    "L_KNEE = 4\n",
    "L_ANKLE = 5\n",
    "PELVIS = 6\n",
    "THORAX = 7\n",
    "UPPER_NECK = 8\n",
    "HEAD_TOP = 9\n",
    "R_WRIST = 10\n",
    "R_ELBOW = 11\n",
    "R_SHOULDER = 12\n",
    "L_SHOULDER = 13\n",
    "L_ELBOW = 14\n",
    "L_WRIST = 15\n",
    "\n",
    "MPII_BONES = [\n",
    "    [R_ANKLE, R_KNEE],\n",
    "    [R_KNEE, R_HIP],\n",
    "    [R_HIP, PELVIS],\n",
    "    [L_HIP, PELVIS],\n",
    "    [L_HIP, L_KNEE],\n",
    "    [L_KNEE, L_ANKLE],\n",
    "    [PELVIS, THORAX],\n",
    "    [THORAX, UPPER_NECK],\n",
    "    [UPPER_NECK, HEAD_TOP],\n",
    "    [R_WRIST, R_ELBOW],\n",
    "    [R_ELBOW, R_SHOULDER],\n",
    "    [THORAX, R_SHOULDER],\n",
    "    [THORAX, L_SHOULDER],\n",
    "    [L_SHOULDER, L_ELBOW],\n",
    "    [L_ELBOW, L_WRIST]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0055fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_coordinates(heatmaps):\n",
    "    flatten_heatmaps = tf.reshape(heatmaps, (-1, 16))\n",
    "    indices = tf.math.argmax(flatten_heatmaps, axis=0)\n",
    "    y = tf.cast(indices / 64, dtype=tf.int64)\n",
    "    x = indices - 64 * y\n",
    "    return tf.stack([x, y], axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c391ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_from_heatmap(heatmaps):\n",
    "    max_keypoints = find_max_coordinates(heatmaps)\n",
    "\n",
    "    padded_heatmap = np.pad(heatmaps, [[1,1],[1,1],[0,0]], mode='constant')\n",
    "    adjusted_keypoints = []\n",
    "    for i, keypoint in enumerate(max_keypoints):\n",
    "        max_y = keypoint[1]+1\n",
    "        max_x = keypoint[0]+1\n",
    "        \n",
    "        patch = padded_heatmap[max_y-1:max_y+2, max_x-1:max_x+2, i]\n",
    "        patch[1][1] = 0\n",
    "        \n",
    "        index = np.argmax(patch)\n",
    "        \n",
    "        next_y = index // 3\n",
    "        next_x = index - next_y * 3\n",
    "        delta_y = (next_y - 1) / 4\n",
    "        delta_x = (next_x - 1) / 4\n",
    "        \n",
    "        adjusted_keypoint_x = keypoint[0] + delta_x\n",
    "        adjusted_keypoint_y = keypoint[1] + delta_y\n",
    "        adjusted_keypoints.append((adjusted_keypoint_x, adjusted_keypoint_y))\n",
    "        \n",
    "    adjusted_keypoints = np.clip(adjusted_keypoints, 0, 64)\n",
    "    normalized_keypoints = adjusted_keypoints / 64\n",
    "    return normalized_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e5d8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    encoded = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(encoded)\n",
    "    inputs = tf.image.resize(image, (256, 256))\n",
    "    inputs = tf.cast(inputs, tf.float32) / 127.5 - 1\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    outputs = model(inputs, training=False)\n",
    "    heatmap = tf.squeeze(outputs[-1], axis=0).numpy()\n",
    "    kp = extract_keypoints_from_heatmap(heatmap)\n",
    "    return image, kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97e137e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        if index is not None and index != i:\n",
    "            continue\n",
    "        plt.scatter(joint_x, joint_y, s=10, c='red', marker='o')\n",
    "    plt.show()\n",
    "\n",
    "def draw_skeleton_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        joints.append((joint_x, joint_y))\n",
    "    \n",
    "    for bone in MPII_BONES:\n",
    "        joint_1 = joints[bone[0]]\n",
    "        joint_2 = joints[bone[1]]\n",
    "        plt.plot([joint_1[0], joint_2[0]], [joint_1[1], joint_2[1]], linewidth=5, alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "125f34ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAD8CAYAAAD6+lbaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9WbBtW3Keh32ZY8y19j7N7au51TcoFFAE0RAEAYqSSIoiTckSqVDDkOwHqonAgy079OAI8c0RfnDwwQ+2wxEKM2yFqXDIIm2HQrTEkCg2smiREEGBILoqAFWFqrrV3L45zd57zTlGph/+nGsfAFUARaik+3Bn4eCes88+e6015xg5Mv/8/z8tM3nveu9673rveu/69pf/D/0G3rveu9673rvezdd7QfK9673rveu967e43guS713vXe9d712/xfVekHzveu9673rv+i2u94Lke9d713vXe9dvcb0XJN+73rveu967fovruxYkzeyPm9kvm9kXzezPfLde573rveu9673ru3nZd4MnaWYN+BXgjwJfB34a+Fcy85f+O3+x9673rveu967v4vXdyiR/H/DFzPxyZq7AfwD8ye/Sa713vXe9d713fdeu/l36uR8GXnriz18Hfvw7ffO9u4d8/rk7kIkBmJEkmTAxZiSREEAGGAYkZoabYRjuRjNwS5pDApHBNoMRyYxAP90A/T2VRBuGGZhenMwkI0jy13+P69f+cyJT7yONc0KeSWbqZez2fRpG/d/5Z2Lo7+q1zeq9RZCZzBnn79NtqZ9Tn//8tfp3evmoe5dEvZeMxA3MHDPH3evnQNb7238WZpi5PvGvez27/XzU52Z/7dR92z9Y3bbzZzrfw/1DP1m9GHZ787j9KE+8vvn+amQABMkkMuoTPHnpc5P1fvafbfsnpp7f+cu3D+PJn5JP/F3+xte4/R5+3d/kb/gp59sB+/t/4uHb+au1tvP2WSap786sZ8r53mtp7ffGft360Pf/hrfFb/rC7f2w/enpW/L8fPc/63md98gTnyfR9+937/ZVagFk/WR78kV+3fKv+5j1T26f1f6GstaH6ZHqv/v3PPHD9DNu1xFPfM/+5Pf/H+ev53nlArz9xjuvZ+b7+A3XdytI/raXmf0k8JMAzz59wf/iJ3+U3pxj77qnMzhNeIzz4BRcT7iZxrYC4WBObwtHP9CBw9F44U7j/nGj2Urrjett5fXH17z6+MTjLdjS2WYj08gJkYk7NDPcoTfHrZEjmHNjnRtzTCyN5p3lYqEtC5PONpN1DAW0LbV5A9rUDQ830qGx4UvHe8PcaUBPg0ymJe3YObTGxdJwM7YczBnMbXDz+Apz2Nho7cCxX9LoxNByTAbucFgWWu94hxmDjI2xrdycNk7rxpiDbo2lHzhe3OHyeMmBhrkRKKhaayyHI2054q1j7Ui3A90OmHVIh0hiDmAqEFvSzXHXgbHaJEeQAdmM8KS50xIWb3QOChRWGz8mltAsaZY4yeJ2PjzcnWPr0O8x84I5jG0L3FZO4x1u4jHhycjJrE1iMRkxyDDm1KFBQu9dh4MZ4DpEI86HVO08MiBCB0szcNdWCtd7ijrAIrJ+r0CNg5s2VDfwNCwUBqdBWGNmY4sgE7w2/5JO7wtrJmN23BYUMzbSJ5kbczsR22BEEBa4Gb3pZ/fe8b6Hp8acxhyTmNBwwhJMz0xhYpIEjmndNMcyaBiWMCNYI/W5w9lOk2EKzM2gmTMsGeGMqe+n7kG4EQaWiW+h+5iGWQNT0ZrAdCUCjvZBzrqne9BqjhtgSWCwBR7JtMDrXg4aPhPGJCMYYxA5aW1PZqDZAukV+AdukHQ2DG/O4sZMx3LiOfl///m/9NVvF6u+W0HyG8BHn/jzR+pr5ysz/xzw5wA+/OL93MYk5sTMaO7Y1I05mHHpiYUe0slhy41sdVA4tGYczclcmQHpxjaSdULScG80N7ZpxFQAJg3DiUysO26mhc/QBs6E5rWZ9YxnAmHgTkZg6cyYjJxkJo42tpvjwCTA90MxyZjMQEdiJoMkzMiDYd5oEWyZbDHJLfC2ELHh7rSA2DaCIIYRMcCCw6Ex5tCLVBDI3ojstxsZwBrWFporGEdW1mZOxLzNBII6yR2rjDNTG4gAS4PsNIepTwg0Zk5GJIwgMog0osOISauzOmxiKM2PCN3DCix7shro5I9IZuj7M6d+hZNMbraVWVXGmBuRyUYo6EVAPY+k6ac9kd6ZGc303M/Z2RPZSIbWR0YouJ0zJn3POUjW89Q/SB2CzenNODTjYI2eun+RcAJu0mA6Met+Esx9XczAcMUSMyKNmfpvYgSNNAM3zJ00vRcy6FnVR0CkPqyTzNjAAvMACwg/Vw5uCqYWyaE53VAFppfAPLFudFvYqHUUSZo+T0RqL0VWNur6Hnsyo6usOHUwEKmlP5OZWc9aP+NcudXDCrIqDCdD9zsMrO0PY5IziTHIGcwMbK8g0b2ksnGg7pl+3yt3zzQF6n1xf4fruxUkfxr4jJl9EgXHfxn4n/xW/yBnQGuQRvNGXxpk0mgkE4uhDWh6kGTH6Cxm3D06923D48Q2jGkLNzr/GUCzRm/QQjdjX1CJ460R4QycZgPY9OCr3HNMCwejpWNT5WjTUcXMYPpEP63iSwRaAslQTKVjWMA2pxZFPXRfjYmxekdr2ejZGBmk6RTumfgcRNyQ3Yk8EBlYQoRBNmUfFfgsDEuj40Rb8Gy01mmt45WpbalFaO6EQwO2MYnYyDS6VfHoLtgj9vuWdK/yN0N5SQSRYNOImURMZTChJTqbczLY0PPUxoiCAZRxJ5WBOVCB3c1Zt6WCP1gGmaPuHyoDw9mr6kh9D6n7v2+Jxm3WGBHnsjcjFJAq8CkgA9RmNmVokcJ6lEEqQ7LWqkYGT4hpCi5NmfXS4OhaNyOCnMnIZGaQYefXSqtsDL13xwh3nE5Mve5MI72hXHsqaFs9mz04hUraestkBpZB98BNgTEMRtRaqWA0w9gyyGbnA33p4L3dQlyJMlQUHMcMZZF7pr5DSSa4a8+0M/cgqYrFUgHxyadj9eBm1j3A8HgS3piC20iiwTENJ2hhzBHEmGd4K0GHzg6D2aDRwDrmB8xr3YQRczIZeJuYTR0i3+H6rgTJzBxm9m8C/xnaf/9uZv7id/4HYFVCjhHaKA4WiY3BknDjRiM5hleGBNYnjWQx40BgrIwNrrZkJYjmTByn6WFYgE1mqkwWDrLozEkncpA5qbycY+6LOfECQyIDz8S9QajsOWBkDFomHvreJDBL3BodxzOYEXgYWyTWnMWVkRmQY5AYnkFvDY+FmYn5INNZcS76wjYeY3bEbAEL5nZNtiTS8ey0VPZzaAdyGtYbdmi3mVAasUGzzsqqIi06WyS0oC3aadGHHl20woT1UNyCqI06EFacObFMwibZskqoKVjElbVFVqlUpd4OS6ZlBUmHbOf7a2kqtbyyQxt63dww2yAnLQuTziRolTs46QdmTGYGERthRg/XGugQUaXnnt0Mq5xD4INVtqWol8qEQ1lrprBQn67M+ryIlZlEqnpJN6IpeMQUzufZ8HRG7AFd98oJmlfW2wbdFjI7MJnpcC4JE6zh5lXK60AYM/EEj6CZSuqwgOY0W+iubDKa4WGsI9nq3nkGYwYt4nygL4vrUDcnvFL83BSUJmQ0IoI5Q1l3BezoCuMqrHcAMYicJP2Mj2cm0wseOR9Ae5CyAgZ2TLZOUNPRNuveRSRzah8HwWy6h2bK3ps1uoOiRiPQ3lXxqWpV0Moo7Pw2LP/G67uGSWbmXwb+8j/gd+OgkvJUD8MSZtI40PuBTrB5neymPM1TD+q0BlsPDq2xbSvburFhbJZswBzBGJMxBjmibvY8Z0NkYJHEppS/ubLI6zzRXGBTeuIMLMEYuCdGYzHTprDEImhK7/BQ6dBcAVLA8lQWYqZstTZGRjLnrJO3k9kxD/qik289JZ/98PfzI5/+YV5+6w3+q5//j7AejDBiXrJOU6lUmKpZ4A16N3JMzk2n1vGw2qSTGANa4yYSm0G60TMxayxzY6Qyxggn6rO0VoGpMERt/qqWnyiLvLk+T0Juwiqj+W0pTwUYtx0OPIP3SeDmlU2o1CYhvU58S8zyjPk1Mw71epFC3Uhj5nZbGlM46AyUY+9BUp8rAkE19anM9fy8Niep0nr/GWHjXMop+RRuGwHbcDxcQakLrjiXzvtp5YY3g6kEIcPordO9Y+7MhJGOD2jnA8VV/u91KsaY87Zxk5A58Jb0brh3Go3uG60laY11GjOTOanAoexukgwUZNep/XI4HJjpBAe2LZgzif3fj8kovN7a3iTT87ttnAWWe2YZ54wdoFVP4Nwoiv1eVibo+5oImMpKc8er2asHPSNzp3XT4VEh2q2yj2pEZujg3UvrOZMxBnQTtJBPYDK/4fofrHHz5OUGhwwVRubKyMxI72R0xnDSjDEHN3NyShAsrdT8tE3eGiuXDeDAzOA0k1MGa6psnMMY6xMPykwnYAbbugpMT1c5l8q0mk9apzBGNXm8JcZAdVbdc4wwnWLOJEbgafTaYL63GxvEHOdGUOZkhE40m9TJbxx7I9loCc8/9SF+5Af+IN9793O0xyc+96Of49GD1/jFl36aUzzAl4U1Oy0Mpl7z0DtusHSHHMypTRgJc+oenGyyRDLHxtacJSACaE2lUCY5B1mHAGe8SIEzU4HEzSBdmUw6w+LcJY9NwU1w6W0X2+qL5lWjpdVifqKziv5daw0VI40kmXNVKWlG6weV5gbdlXWMqczWrdE9VUpR2Nb+PEybwqo5ADumaxWkID3UrCEVPZm4iXEgjG3F0iqYG5juVYQxA1acec6YgxGNUUF0z2bMo5gEwEycyUK9fib94ByyM2IwYu/EGrOwe3MjrVPtDWDSeie9MEAzuju9OUuHGckMoxX4GPvzsMYI3SdL8KE9MmIWSdBZNzXCImDbJnMm50eVVSZX80WVw6wsWcyPPUgGgnj6ed/k+b1yLpWF/2dl28qNkjmyniHngz+bYd1o/ZZlsjMEAld/w6qkn0HmhqcSk4jJGEHvXffkO1zvjiAJXPrEe2eYsrBmCwOdfDckN81Y0zhFsibMOem1ASMm1905DaeRrDG5mXAzg1MEEZBjsoZ+we1C3SlE+4PtFTg9AqwRUyWju0751rrwKpLMAXvZUh3yTArjE3ifFsKs6qDynrTaKINgRsIQBsahE8vE8oZ7F/f50U/+OD/+2T/IeHjNN7/001wO4+mnfpQ/9iN/gk997FP8J3/7L3EVN2ypki4slAkZbEM4YQyYMwvXAY/KXG0QrREz1CWshZqzcB4bamg1ZXZpWvyzsgMsWWcKP8uOV6DL5roPkbAU4K+OF4YaZOYokzLHbdHXMdyCvU2R6SqT5h5AHayd6VLu7ZyVBgN84DRhxUzcBm6NGZNgaNORyiFTlDGvRsmcUQE/MFejTFjtXh4G0bTY5lQDccc2baftaKcrkFemzlBQ2TG5tO1Mr2pNOU9vydK1XloGC4MwYeQzdbB6dzEuorLYHUN1Z/a6PyjoB65qxgzzhZGBByzmtA4tnZ5Ow4h4IniZ32Z5OWjpMBsZnTmTbcAYwRwwcm+0VFbnOtytvjKtIJtQRknlCNWyFg57poY5XmX4fmUmvjc4gR3XaK777CZGSno7s0jcgtbUrHSvjrbVe4lRWLkC45xFKYoqv1P74jtd74ogaQ6Hosm4JTNckWZUF82hilzCGq3KujmDE8mWGzGN4QdsBq0Z4eJXbhGs6yxQVy3/5o2lN90cBGgnkxZJ3yGYHGqKWHXGmmGt4e76/tDp1LLKZ0MPMAz2xsneiQQyJpkqI3sTzpd7R8067gvRAtrkTnuWP/LD/2M+98L3cfXVb7Lm63zoA8/im3Fzc0O3xsef/jT/wh/6n/Kf/Nd/jTduvkn4YGyTq+3IGgdaQqsyZ04FjN6ammMmSGEYhHeYU3CBqTvuUce4eunsnLrMjZt5o/LXDHpTwMkDlqL3KOs2rAnOgDo5UhlpnDvlibUd7K8u+h7AijmQ1kgWjFYbxui+UKibcCzPc6a68z8ziuRTDZGswNHMlAenqCzN1ERaei9aUtFj6r/zjJXNM4bWXEHuzO0zVAYWq6GlkxO2mMQMNV3OmXfQPLBeWXNOcjqHg7LeJRsdYyZ4NSumiU5W3JfzMzpzKLfAulfX2RWgTRlVzzgf3HOd9FaHjasJOVNNw8DOTSqt1s4IY9LqgKuTf7ZKHvZesGHNiwYpLqWjnoE2SZ7vk3629lOaqmv3+k0F+Ln3CSqwemXZYoHAUomIChDToV/whNnEW8Na/bwIpumgiTlVso9ZB4zun7XfzDX9dte7IkiCMWzh4EdaF33GUuD0lkkPJzfqdO3MMRhT2UEsylw8YBr01sHqtMUw7+C32RTRwDvND1pEGQTCcTCrDjhMT7ba44JC1JOL3AHfOv2qsxaIPmIjISaNwJo2cOxk8xAIX62BKveoDnty0Q48e/dZ/qkf+6f4yJ0Xeeerv8zleMTSr/i5v/nXOPhTfOyzf5yHp2vasfHWy9/gX/qhf4RX1iv+4//mr3MVjznNayyCC4xLh+YTazqFW3NsaWCNGcdzhjhjFIWi0Vqjdf1XpXfRXhjMuGaMK8ZQB7wtC8tSi5RFi/72ltBMwWdmAf5ZgdEL8wPcGt4mFMCegZow3knr+n0WrhHCTffSO03cLGWn2kiTcz1LNq0tS8dNGYioWrW5UtnrzvM7ywRsT4Cs4IlZ4B24qz2U2YUjV+PJ+8RdzYMM130rJsUoyK3nAcfJmefsJy3ZJnSSiJOobU2cjjYnG7NYqbqicNEd5sEq966NPpmFzSYxs7JmVwKQwq5n6gCYUbix6f7arCBljbFnfwYU7zIx0h1Dh+wesHL/lQhKCnEsFUmzmAdPkOCrfHbbCQL7//ZosO82Bd4z9cms1k91djEsG2oz9UJV6xmnKsyZ2vc5BkxBT3tQdEtaHQvT//unAP23ujKNmzgQ7Q7tcBChGzjF4Do2tjSmqxRMN9bcWLN4Vhlcto43aN246AsZk7YOGiI7ZzMihx6U67yjTuQWQSNwm9qQodKrNWe2jreG+6JTLfTwZnXXz0C+FUW3nnLbO9tVTkc4M9QAsWpI2F6eeydsctEXPnj3Rf65P/jP8dSN8fgbX+TNb30BP73B66+9zK/8zM/y8Y9/nP/ym3+e621lW6958KVv8Hu/9/v5nj/+z3BcV96OE2D0ObGl0ZpzODhLF5Hcl8b0yiDyUlxLpiAFlCmbN3xZ6P0Cty7caq5EXDPnibmtbOtjIpLDvKRziR2mAp3APD1TqhRDcEdsQeTAU4eamleGFf8g263yZ3WVSpizxE5E1iaK4tqZuQ4mQcPC0EyUrzAdcCI3q6tdoMH58ARwAstJLxz13HFPUUm2IinnGBC3h11WsJyWysqasXQR4tPVWPLglhJWXdVkENlFWzol0VICgLmRrTPYBN8UCbgXnp0RbDOLErTTlSiIxxk7DdueUOxksmaQs52hpaW5WHZwhh+ovxOTQJFuVsZne+Rr2muzslfLLPFFApPZdCjkTKygG6MOTKxKczuvCiqjF8MkK+M8w5JQ+wNTs8Zp9Xv0Hr0DrRo6TmZls1NPOSgu65iFgtTzj6hgfctHtQqYOz777a53TZDc7JJhF3S/VEMLWAlWBqttDJsC/9vEunAxrxS+mXHRGxcH49iS2GB2Z+RkZLA45NJo3Yu/lQRT7RfTyYkJV1FJBjThOO69grYz0rAJo8p9r9MQOBN0JSl0phkjDG9SL3juJWIVJq5yox0d2sI9v8ePfc8P015/g1e/+SXy5m3a1Wt8/dd+iV995WVefyd45ed+lbe2K1qbHI7Gs/cvefx08J///H/KVT7GJrgdOfTk2JOLC7h7CfeOnbuXF9hyZE242ZJTHLg5QYSTfcHpKnvNsb5gy4EMx2ICN8RcmevKzbpyGhtGsEQjOapR0CYWeymoLmNWWpkEEaJXxRRHdX+tKEA9rKnT3bzyAaNlw2wpaocyOs9Vi9qUsY8YjMoG1wlbrakxi+SPwP+sgJZu2CzIRLkis7ApCq/NTGbCaYQEDiEscyfr7yHWu5oGixkXLoXRvvGiAoC5GloF0+E9OXSthxEiko8NTtFZ+oJzwOyIp7MAPU/chPBIQRXt3AzDnF6foiibNG80BC0Ngi20JokkJ+DKYm+loamDzfRLlXGcaTH6rHsfnzNLAzNolXAUFJEmeGBShPP6d1kJyRlQNhXfEfN86DxptJOIYpfNVc7XHp+V9IKUNGbb+d3lDumkid0QKq1xMSlagQEmXXPBRILyPJP+nRPJd0eQBGOzhZstcRvMXOu0c8YMNoaIuEywybI4ZuoOXyyNZpODN+506CkdyLBkZQpj7E5zWDPYRjBGcbeyVDTeqxSIs6TJXSoeawvYQiACapybIEm3vMXC9u4cwUxnTgHjS3L+u8hSn1hgpkyvtcDbJZ/4wKf56HMvcvP1L/PmK7/My1/7PJfe8c35yAsf4GMfvcM8bVyfgl954xu0p+9wc/cuP3fPuIqNkwvXIgeH5cjFsXE8OvfvHHnu3l3uHg74cmBl4TSdR6fJIwvWAUmnt4vzyW9LLw6kmhYzNyKDGZM1Rt3XZLISuZJsOtFN2hoFkg6xVVaOGDJRmVikuh+VmakjKqWOSLINiRi7OK4urNocfIa4k0ii1/sED0YmMRTcZoRK4co0deqpdANRWIhZpP/9+0QpypFScqAGxRyVHXmeS8uorK01py8KkofWmRZVlRu0TQGi6CuWwrN7Ny4WJURjdkZMchqn1ZijMdvC0hemCb/VfdmAgT5FZeomPC8zlCw00bOWJobDBLzYQROK6zoYM0kvVZsJQ9RJf8thNNuL2T3/k7oLmwpIJoretE73hseoIGkMh+ElSTSr+454ifUnPW/RojJNuG/BIGQWburqATTJD5pScurDiw7VVa8HkxgTD92vmbPI6XHL24zcQRqoQ9EC0rVe222M/k3XuyJIhiWP0riJgZ0mW2wqZ+fe4ZNEbCaYH1g8aMvE2DCb2oiLqayMZJ3BMpPDDnhbE+aWRrRidIzQqQxqnhUlaO6b0XOXiBcmKSxJGlEqQ6Twu45AMHWXN1OzRMYADQupBJa2YJkMM6KLHL60xt1+h8+872MccsHvPMdszrfe/iaPrk4EC3d8od094HcvGYeFi09+mEfHS7Z+4IATrHSH2ZPmC60v9EUqo947h8ORi+NCb3DHjDUXjr1xt3du1iSy0fLAhnEyWFOBwXMyYuU0b7jJE1tccYpHnLYbMo3rGNjitCG+Z/ii5lAqO4kCJ1szODRiOFG4V/cu6OF8sEzGWPHFgS5ydWUYEStpK9g1sGFiYkv5Y53JwHKofA5uA9VeukWQNtQErGpgT72mKyLkTHwkzOLQZZmiZNLSGAktSx2k9irdYTE4LF6YnOg5YUCvQJOpjJiGLcahNy5MWWfHGW6sYcR0VhojFjYWsqsSWbMJMqBgBYUsQOu0uBmCDVqjNaM1ZZR9M1pMVlqt+yHMNh0LBY+5N2wKHkoL8snmFEDLotFIJWVWMtOiHi0OkU5kAyb4JKoEJ8RttQpWWVlmxm1QzsxzJmyAdcd6o3mnlcRXGbrgln3TTjPSh/i5Ffx8RsEbdbDV90fOUo1NsiAem05zHQqxl4Tf5npXBMlpxlURxMc6OJ021jEZQw2HpVM3CPxMF9lLYcNsMptxzWQurbp8ArdF80oynDZFQG9RHUe7TfN3FxH3W45WCEwrYnFnA4bpBGpFoxBsrGwnQxms7XK2mITZ+aE5tXBavXZXs+LpO8/xvrvPc/PGO5wev8PLL3+Lexf34YUP8I1YeXszpi/MdkG2I701zBdiiAHtXfjcxeFAawc6wvvWDa5OyaN1cHFcuOwHFuscU9DChTvjUH3HmGxh3ITzcA2uYnCKE3OsbOvg8bxhW6+Y24ltW5nTuBnJSmPaBZcXR5ZlxVIcPJWDO6lXXLXwogNlqtx2HUxZQc8sYQ5JKM3VsDlr6Vcib+hEHVpFAzljxcZinS2GcLwRjDlFB7EsCpM6m1kk9N1BKWfqZyTKRkdtwF07YtQaEPXIS4mjDrX4g5uLErNZyeRKi9ya8OisRkoAy3JQhiaigbwGzJl2VDYZu8JnMidq9mUTplld3f09ue+Zu4QS06W3PlwcmA7TBrlNsK74tYN/VFAysBySqJpClShVfiZ47yoknsDfVREEK1K86X/StkRBG3vGB6UwquecxfnMehNnuaIbVPPQi0kCOwQCuxY/i3lxGMUAyCRmMOaJNkNNKiBdEM5MSSln6PDPFORguAj9SjW/Y3x6VwTJ0rIwY+PqtLLeTK63wTqDoxvH5lUGO4ujTec76KqAdxqTLWGZE5/q9sVuNOFg3nXiDjVV8DqDK1s4u5BUBkEmzQ56mEW01UnppEmY17EqiQr3gko9hXtkquxbbGrTWyNMJ1fuPL9sfPqj30PerMT6kEfvfBPbrvnwhz/GNw8XsD5mjGSukCt4WnVqN+iT0+Jc2IHFO8viuCtz3QK2NVlZuUl1SHs7cu/YcIPLDA45VaZ1Z3gyRnI9jWgb29U1a9wQc2OOE6f1xOnqmtxOrDElQGkiXPvhCP0ATWYiuxFb6+pCWlXR2bJKxNoYaWdDBa/GieSZZXSi3EaE7eKNDNvJ+BXoqoQGr4aGnTlwTJGqrZqhXlxL9gOy8GcDzsoPbwX4VTOHYiG0PONbhAJu72IqnGZAL0w1rd6zYd4wnLDiHGaWssfpvbErr6Y70xpjmswvKm2MiHofe8zaJYxe0k0RtjEF5EANHlW5DlPsAGVoccbctefqMpA+epBTIgnLLmZGfdPIKZhjTlGS9vWewXB1vLu1s6NWekqvXs8tTRQjvwU2BYPsgGRElbtOtt2QpqmRmJzpc1uw4zYkK33uQtK9+ZPngF4kqSeYKKosbrmhwmFak2KofedE8t0RJEHt+tN24jSkJV1jsk7Jnkq0SHdhDi1LqVsPBZw5FJTWDA7Zb3Gg5sq0fGH4lLY6CtdJlEEU51GpOOWmIrTKWzuXF1SJMiiDiFBpNc0k66t0fozJnIOYA59Ja5PWFgUD9izWiDG4vHyWT370U6xffxNfVh5evcK9py/h6ad46+EKdskyV8hkayuzBX254Hg40FyHw2KNZVHnEsR/XEM6eMtgtWA5rFwcVqY5d48Ll92ZTJoFx0PSeifW4HpKhXPTV278RObKGDfEaSOuB3OTdVYCzUqmMwc5V0Ys9Og0U6DM6LVBrQw2bukfuZ/oFYQkipjKPuYUVlQKJLOpxT2DzQRjtDTZvYVLUhfJOmSGMLaNOYbK9eLFIVxfzYi8bSLsipisphouKSElIdS3Sd3h7meZnZvDFDfRmhFyUlGzoiSIu/58zuL9pnEagwdzoyP605aNm9kZNPFVZ2A+9fNsSHueG8kgQ4V2typrYzc5GUwrS7+JOMMpTDGyQ7SzZDYrQCTI5YpkoNehNPh9JtE7ZVfAdDWv6igCxOP0wpNnqqN/YDmvwfCCSmrvzN1FKJTRzXrOeze84VgXD3rnzZJZLklxe4hRJh+5sc6dayxurJUUcTfBiScgF52TTjTOh2kmjJH05YlD49tc74ogKfxgY8tgHZN1BqchX0XCmDNZjp0YxoiNYzN86WQos3NvnBisYZIcpTawF3m2RcN6Z+nOssisYc4JMaUUwYhZ9IAEL+xwImC4FVE4TSXDNLB06cFj0kM2ZzlXLboZzGkQh5I/pcqOekDNj2y5YXbgox/+XuJh0CasN1fcPLriuf4sX9omD6aaRasKIMwXDg53euewLOUENGh9stR73FLNg1mB2qwzsrOFvBhPp0mEcUOrjGwjj3CvTVoTdXtZJocetD7IuCbXG2yVPdnA8dxoS5n3BsxtsJ1Oyroa+JJY73QuwDvpSzXJdmXSjnFpUzZE/s0cQK/MA2FKJJ1kMggbDEbRRNQcSwumOzc0TpnMXEX3oviPFRA9W5GTDbwksFWmqQIowjzB7K7gr0gjChnF/8vq1pbe2Qjcm4JCuSHNVGZiuDiTw0oWalgYj9NoV1qfYIwRjClIwrzs8AKSjRn6FTHKOs7w0pGLiy1O8IwANynWFucCB9vYgJx1SKRD8T7DgqDJGShXcq7YrOaVBYM4CyF8S2GczTiGzClkhGucEk7oczeCYzOWvlsMCu6IGbi4HUXQtz0TKQqXlDN7TbDDATzhMzmzbPnKa0FCjmCr0NmycFJzpgFp8t4kaanG1YidWdFrP4t3PSIqDnz7610RJJPUaZm3jPtmXc2RKpfmFCH0gLKPDcnImu/UA3VH04QbYrKBmukc/IhHKW0OjTVPTIrUPeu0Lrmi3pDOlSa9EhLRBBPJ2VaKpBuF04xNRPU5KrEK5tAisQ43HQ4xuLM1rMtezaxz0e7zY9//+4hXHnDsyTff+Cb3791hcePNx69xFYNhyBVIZEAZOWybLLdMqprmvbiHej+QdJeqhEW6XW/qao5SteS2VoF24iZvWOPA0bu6xKzstYk8E7OCPRgimx+6FSWrM3JytV2xzsHSNsbxhotj587xGXq7U7SUw23n1PaKtsngYaZ01njhzlZdSRnfLuYSCWRXgN25rik1xjpVilWfXVmEwd7P9upiQjXoQj6O50aAK3jjWQawRXL3veLQgtIGF9CdtmOaLshHxUg1h1IIdMrgeeei79ZnOZNmE2vqGM/cG0QDshMMhvAIcVlz15/rmYy5q7dQCl44pXiCCgDTjGxS9SgLn1DY4654mWNI+JBbOSapYrPWaFMVQiM40DkUfiy2XB0noUxyS9m+dYdLTxaH46Fx7XA9pvDanKwmc5Uxqgnlu0QxiqMriz7b99WeRUYFxoIRLFQpjhA0U1IOSUTjibK+jj2MWjNKqpjFQghoTXr2dXu3B8lITqeVMQorLjkVWSdEBjFEMxkJOYPDsXFIP2cB7kErbtSaT7of66TteVtGm7m6wQnDhJ2ERXU8hQOJKpCin+zKjfpfq3uvQBxsc5VD8rZWjDKYBSaPgV80olsx/Auzms73ffQH+ODhBR7aI15/62W27YqnLi6JQ+PNh69I3WNDUsaijVy0XlionIMMim+mjLo1B6v7Z1LY7PjXKac2IrC0W3L2aT3xRmwc2sI2g0fryjq0sJvJDs4NlqJlCOCPMzQxx0bGNZYH3E9sccH0I97vc7fvrTa50giPrUBi1fEMHXDd2m6MJFoHo9Q2AIk3VQpWnzXNyi1bZZviXBlTpJ832K5PVlArzKqaMM2t+JQKeG529nwU1qWkcsecEz8T2eUkZCq7KYwVUb+smjU77AYq1zN0gAaIZtFEfpYTzQHLvm8KSJXA5CRjYGUmPMeQYS7Iv7L5WRpp1rl1Ardazir9s7I46ZpjB+jOmJ9aF4XlW3XmvbG4gs/xsHD2itxXQOGcmeIEN5scPTk249CN4wanMVnnhk1nSyeivr8aYKKXyOvUUJBM5q2uPLLs1hCEkVqbs+ABry2X51x0P1TqVoKUQrUuKCgAUCc+DzC+cyh8VwTJCFhvYFf7tq6O8LYNZqZoLtHYUljgjMRalKxqKeXGRosGKZfircqTnIObcaJNp/WFZp2ORgZsEbfi/SlvPbuFMWRfBbQQPTpy0qyB12nHLOpKYkOvlVP0As4A8eBwk+TlwiMP5nri2Ixnj3f5x3/kHyMf3GCnG8bpEffv3qXNYNy94Do18qBVh9Ut6IooomkQpE2d7i4VS2tVWs7KKlGfordOhnMzNmyBxmRY0N05mDKc621wdRrcTONqJDaF6fXeOCwLx27EyHM5FGasNok5yLGSnJi54u0CawtLNLZYgAVLL+Soyt2sMnF3dE/YPSeVpQTuKZ/MKLGZqXHS8yj2mzvmDRg0bxyqGmklJ50YZFHJCn+SA3tJLrM21d7I2Q/RqdLaQlnlmQBdXdXYD889e4ssilGvji5VDe0EZz2HTJXQRKj8rAyUCKKy6E1cgTJckG9lxhB1Z67ELOParOCdoDosK8A3bCnpZyoX3xkVGXl2RBeSIWgpcLZszFDTxosVlzgzxSDRGI69PaZ9OgtaCC+eI8koPDxyQpw4uHM8GpsbjzcFuDGcOV2eqiaSN0FhnoIvotZu5K3FWuRuqFGuIQzJkNMLY+6iZ9ke7Ov76z5lGWEwRRk06hwhEA528R3j07siSM4Irk5T/pAZwqSyBEZN2SRzEEPGB95E/dkipL+m06YTs/SgsZ7xrnVs6sZt4P2Gtix0OoQr4FpjEmyxyYWlcb7pHa9ZOCoBCyXSwmCXQkm/O+e4NSWI7cwHbFan4rZhG3Iqadd87nN/lPffe57Hb36VHCfuXN7lanvAxWXn6v5djjRGT9yXArFl57aFAjMufmlbnGNXCWzN6VGcUqfIwuVaQzDmxtiC1adOfFuqZGsMVk4jOYVzE8aS0sC3Nrk4Ok/FBUlys+NECZmN6WXFNhqJ4T5xcy6Wp1iWO7R2pPlBkj5TFmF7dTCrjM8pHhsyecCNdW5SSiEdfRIsLEwvHuLO1St9uLVBS8ErWWJ+w4SZVtanDTPUvTU/mx1QzRlM9+pWUeWQrnEYe55iyhL37I8SHljMwvhM/yZ3+CaKMSF3b8uQeqhwPLVOGjMNY1XDKpIcwhBnYeVnd++95IXqnAsP9Qa0IGn0HdOtA2LHI5NG+FaHrGpu15sAS5YpKGu/29Y602A0WfGNoablKZwdZZwjydnE0R2b4JmLZPGh5l06fljY2LjZrGAM8UvNVRGlq76iGrWtDq5Z61aHxc7RlOTTpjF8VBkuGCvZGQr1uWf5uLvV4SvMuTq2yqzpgqbe7TzJSDhtsj4bVC874YgkXU1sBrqeNkawpRoQTMnYYmyVidRGQOAyGcyxiX4zVaLiR9w6VAfSTZSSJRpH00CwtI4apMKvqIc1TUqB2YweRmYTkRd1POc01vUaYtVgseh48+LIyQThaPf5R37kD3B66zHMFWNj6RBz45n3v8h2ucg+P0bNxJkS548NIosniR5+r4xEe/Pcud11vfu0wr2bt83gatsYLZjNuTDRVCwasa2sEQxrIub2xkW/ULLlxoaT6+DmdEOuq2SbXSMi0o+0tnBYjtw93uPYLzj2I60vmC14GqNsvmDH5k1QQWUKu0OP5SBm8BjdV8tGZMoww/fMDPa0KCzFCaxf8lYoLY3DPkZCr2tyiC8iNtzeq932f8f6pINW1rlThXaX/4l4hNOKiO1RTkJWWGJl8pVZWmETMsvYXYam1pA3wgfNBMVIZWnnIJ6Y+INFW8upYGHWzvSaPTG11N9PpqCQAM0GEs6aNkTNUU2g4SjmZPYCgtDfW9NAODdsk+HF6sa1TXWVZ6VoNZtnWrLOwaMcBMbFsckR3VJ8zqUXlit1kFXoOU+DzL13TUExO/p1m00axamtzHM3e65S5Kys2gUKeLlK7c+hcmFr6nyHJeaqdPK/7/EN/62vhHWKimMJWy+HkZSvX2+Vlrd+xljCsoLjys2q8gQLlQUuWkkmdJOrdoxBwRFM2+ru9vNNXKxxdKPbxKZOMDlBK/hkJscwOsYoAnGG6T1W1xFEZVhsIdloMfDSP08E9ifBD372x/jIcx9m+8bL2qw92W5uaEvnhfe9yKuP32Ydgy0mYwetswalJSzpLEunm3P0Rc7Q8o8qLwgvjXQUDibscUw5tcvgd3B3GveaSq/YjC06EdK+ZkhJsvQD3jv4wpadwQ3ruu5Fityv+0LzA8vhkt4vuTje42AXLK5Ji/NMym64zyfUD8Vjg4I5RI5220icLao7OaWUoRXxO+O8IWi3/3bLZOSeeWmjzRpytfPoKDxux692BYjgtYY3o1dFENg56OxWYlXpFga5Q9OGL/oXkNV4KPwLK/pPlc45CgPUetUhu7cUHGWeeoZWRs6YuJbVW1IgLTK0gtrUeh0BTKbNghs6IVr1rY+nKePfBQ7iDC+1D4fwYlNQ9vJrfGSdFtBn4hNVU4lgh4DdjFimtpNHMzme4KIHy2L4CA3mi64A7ApS51ZKje0QI0H7au4I8BlWUIc6M0WrmyZOcPUHIoOYNQXTFJyztOd7/EtHg/qqL2FFXi9A8ztev6MgaWZfAR4ipHRk5u81s+eAvwB8AvgK8Kcy863f6uckxhZOjEmfAmbpZW/fihWfGhQ19/EkGWS4fPtGwITmg+ay6FJGWSfUWW8d4mXVwtv9BD2F66kuV7ATGZUz6TgwSboCqVzYtxhsU2XfYMNKly0AfWI26jVCNmTe+cM/8cdhA2/q+E2Trvx47z7Hi/vw8AFzG4XTyf7KkbLGArI57dhlK1fW+ZPERRYrfErGxJJHbur4ddFNotQn1y25OmicaAwRmffmWGvIoCMc9yPLYixL0vsUZFCdpOXQuTzc4dAusX5Bb3c5Hu5ycbhDt64ym8SmsgBlcNVQmXr6OveLBM3EYxAu/XjGZMkanjYVRCheXtptuevm9TMnzKBXeT9td82x899nhTbV8sqEWjda09jfDowKxBZ+hgOCynKQYfKtKYPu047NyQGognkaOb3w1yH6TUpFZCkeo4QhWRnmPvoVYN/Iwl+r90xz20kMWpXJ+cDZZ/CkiSPgtgHqdlPGwVkNnd2qbDOYuwzUS51Th0cWdhsGUTzXJgssZXu+Z876rDfVMJurut+HANbCK6NpYmk9m10Mcg6E+y1Dhx2ZHM7c5N3+LdTsD32tF8lesmPqEEw5F2VgUaMzut6rV5DthdhqIICfSfbf7vrvIpP8w5n5+hN//jPAX8vMP2tmf6b+/G//dj8kplyvp00us9GjcJZEOFbhS1SzJcgiMEtZYsOxNmlNkwlbS3IOSsSl036aQJWWNZKkFAyVdZqd17X4d+a1ULRaRuGSmdSpJ9xplzEK3D9pAaarPFrQDA5XJ/ajL36UT37ke+CVt5lx4ma75rSdONC5OFxws25cX99wullZo071NmhdhPHFnUs3loPm6mzV2Y3KdJYJh9SMlQxjmrFuGzYH051ReI2lsfkghjw0x1BpmTjmnZE7TtZrKRWFyha6L0QbHFrjst3h8nCXfryAfge4Q1sWMhsjgFXmxaVI0/Q+xPMLC8IqaETpbbP8F0fCGIzcWBGGacQt5caANtmHrZlp2FnMCWOtUQNRtJDCq3ZydwIhF3onZKic1YyrLBDQ5mcwPWpedmV5BhDVRS4ML0Q7MrQsVCrrvpGdjBBdKzQxckxx/2ZsZSZgtyl14YLeqinXF9Jdbt3s0EHKADdSL1jZFFONDbMGbavGTZGqUqbQ4qzW5MZKi4XdGmRjJ3JTh3Qb0ppv6ONYyVplDhNao5F0awVxSBY8KbUNxroG6wzWUBnvTf5FswJu5J59V9CbaqLOna9Uh4BCWVTyF9zUASiz68Ikm9Xo5CwNvUwyhil+qPwWBJYZhG1VBXz767tRbv9J4A/V7/888F/w2wTJzMBiq/RYxO5pQEgxM2pimhxejBFlPjBLaXGaLFvUXBIjmZwsz0PvrSkblPnq7mANWuhJ8wrQVAAudxJLjXHY5zCfoLIQhd2dxlK7U51wRHxWGSrKi7dFQnwzfvh3/35aLFw/fsDN1Tucrh+x3VzTw7h3uCTH4Ob6IcGNxjGYc2gHjq1zMOPQGgejuu31aFPlNFYQRZW3ykQ1MjSAYRvTi2CfTeXoSScrhMouO7C0zmJJerLOE71pZjl25LCcuHMwjrZw6AcuD5dcHO/SLi4ZfsHMS6zJIGLcrGc2RhSvMDzoFqWKuLVQ0z1VEy8C5rqRp2DMoc1pRu/KRMHPOKAC5iyLLpXwXriVqC/o1NNC0+sU+XoUqLUbr+5GyrvCas/QyytZnE5079VZ7yqFc+hgFAAot6hiNjSrkRJ1sM9tcp7oh8bSZgaxAq2mWpakca94zB2KVbG/r3rsZDU75aEohZUXRo0FWyhQ97ZI0157ZmbU/Pn6VlNmSDmr+7mr7wzbqkSXo/lwKwyvmii1b906ozLBzFVQuu1UM/3KGjnc0sET2zN2hBfH3qA1RKGrjLluiyoCnSOcWzEVXH2HTfbfd8hFP9d3p/RaaJV0FhNknnP3b3f9ToNkAn/FxDf5P2fmnwM+kJnfqr9/GfjAt/uHZvaTwE8CXNw50NmkSKDScJTBxbyFDJRW+7ns0YB0naZpk61KOGfSTaRYSorluzjzTEROybzK0JWUk0psokrMIqh7sYRnajDSrVEoJCLAanBtqUemXFDAiQyO1kU5WBo//vI1f+Iv/xTx+gVXn/kUY31MrNfEJq/G4wt3uHP5FFeP15pyB94bdw8LvXnhNyJNs03ODh7m5PTCtNrZwWaMYAJbqsM7vEqz6tx7OGObNXUQhm/0Bbo3pj3P1anTl/tc9Oe4uHONbV9njRvuxV2sD5ZD53g8cjxe0PolJ+6w5oHBxpiJbSGn9qkgHQ6jB6Mj8L44drFnY3Am+VLwSJTUUGonyL5jaTseKPd0TVHeO8oHdqxEvLpRq1XwSLe9yJdR7z7q1Cxum10AXtZvWR3nXcZYjbHdf1G4trDHmCZJau4qG3VsAaI52Ra9taqO9kSpTSm5ZAZSGT0NK4rL3rvVEDNlURPBAGPHOKlhdQiXj+qE68ZqOqbOjzrgKzvThlQG9iQx3lxBbfqQYokqwwvi2WcTEVtlZK5xIBnVmBnMqSB1pkAlwmTPklAF/Dk0YsFmQQcFVkeCNde+LRwVq3tBY0l/gm4VtNR76rMRPjnniAa7+dPesIvcZ1nZ3tn5ttfvNEj+o5n5DTN7P/Cfm9kXnvzLzEz7DgNtK6D+OYCnn7+b3lSvPDnpzfxwxiNjqhsYRYWQkSvCeGKwbZolHJb0VjKjCoBeJ6IVEZnQiMm9oxWzCL5zkFvxv8y5sVDpmrAVdSAjyTFr3rCm+bkni4uw7iaKR4bUDBcXR2xxfuRbD/m3/uZLHMYvE/+fv8zp3/pf8tbv+RxZEj9MRrfRG28/fsByWFhoHJeFwyJazBZT3eea2OdNTjlZXocLxhr7vSmD2yp3Ws3oWcMZs5HuLLMCmDRwrO2S51/8HJ/71I/wlZfe4ud++u/z2utf4d79B7zv+ef43Od+H+9/8Yrrhz/HMl7jaMZyeWRpRyyOHOaBq3HgJqvr6sJkA93b6rYw9yZNqAFBc2ZMufacOXOAJ72VG3xOaX0bmmPiEAX4E1I57carwyc7hV0+mIULm7DLUK3O3imeMTWvx3XAWBGczW+NVGz6OXvZTS92ez1PRK2Zev2k632lVSNJru2GSaaZUYPhHJqVDlp+mDo8WnX0HVKNj9zxWoTRRdx6Bex0t/M0StvfH/Tw8xA40Z7UNJuZqtI1R0LzKEPhY/Uyww3NiiJ6fS5R4CyMPeLt4Sp9ET48hw48NwI5Y2HONGcY5TROBTo7H4Rj6EBt6RChPkMKj01u36PuXaWSQWWInBs9Uls5wyr1Z8e8KYWqV9eNSn4KkvktUsnfUZDMzG/Uf181s/8Q+H3AK2b2YmZ+y8xeBF79B/lZZon1yhgoNn4LcFmbYcFs9SWsKBhAmed6iLayIczBnZqPXMA8VAdYNUsOUxmUkzlDZXvVriJQ6DTqoRJmMZXk6sDfqlWsgmd3Y2miHcjJRY0AFlgOjR955SGHoUzHTyfu/uzP8NoPf5aZk3VsKnEvjwxbeby9Q1/ED126bPdnncYjCx+bQcfAbfdOEMevmiK7R59mYQ/cjly/fWLmBR//7A/xcL3m5vEbrON1lj7py5HMF/i1X934e3/zpxjbQ8Z8xHz4Bu88eoVHb97j1W99k49+7KN87nN/gA9/CGz9Jdr8Fi2dLTptdvAjjMRzYXB9zhJbZR9nwm8UqdfkfWjVqYyp7D3aPCuULI0xqfoosWroRbiAQAq7na02c2HGO6He4hzYEmU83hpuCzIb8TNkIclolfVmUhmBhkaVwcWOWcqbcec1iOSvYNix3DXmaKKkt+qkiuvYvRV8pMxqd9nf1VpuwhIzkYfBni97rdAxVNLPKeek3fyi6f6YyZ3HrJgO9V7SKLYGZKj9qIaMRjnv0uCKIlV1eTWZQtXVNCUJ5+8qI5BQH8DJUiVVcmJlHmzVWMQ5B6/zoa9kJsZkRElPo1VzpxRblkTTAD9l9pXp1/vc566HZe37SkUbt9l/QWzskAz1mX+LgvsfOkia2V3AM/Nh/f6PAf8b4C8Bfxr4s/Xf/+i3/2G7rZZO8WZdD7o30k0OP1Nd2Gz1cA3cQ/SX4aQHPsU/s9CYUhxxvUyrYi/TPYJoyhAp38ENaXMdlVWROhVHaCLi2dnMKbK767QT4k9rSCWCdKV4kL0yEZLPf+Rp/vCXHtJPK/Nw4O3f/f0y8YhVoxFSOvTT9WOB36bJIxO1Id2blEdzY/cea7XZ7dDPJYeoP8lpTrYYtbicm7c3fuo/+3vcPNz46O++4Uf+4J/kqRd+iOWDK+P6TV575WU+/4tf4+rha8TNDWNe0WyKDJ/G1c0jxtXbrA++xbde+iLf+z2f4B/9iR/h3vGCJR9wfQLrRliTo00e8ZY1/ySxaKKqNGW67qEZ5q5t1pRkMSsA2ghaTnJxlhjYDCJdWmbKySf3AyvOB8UO8u/JhhV+KxinKDkG5h2n49kYRs0o0sb3Aq6Cws+ArFL+XJqnM61GCqeR0zTHyORwE7EHiFZBQmumZAjKYmlaJ+VTvI8lPr9xBBWxv36M0jsHMVesAuScMoNpzZme5RkpieKKsFerpodbkydBJruv5lbej7HzPstebUaNSDE5j1N7QXCBsE0Fpknz1MCxLBpTpLxXK0WLqGZLBBlNDTsT62Q3ZSFyj2eIG6pb0c3o5lg3hhszGzaCmFpTuOMkY0heSdkR4rEDArV/jHCvtZHAoOb/ftes0j4A/Id1Ezrw72fmf2pmPw38RTP7N4CvAn/qt/tBZtAPnb53FtuitLk6VmGym+9DXVzByFRALazL9tM2VH408KYu986R0xAjvcRsUYPRlUGeeVmVbWqqXuAjVbp7sXXrypScjAqgeNRUuq4JhTbobXKvOd7hFz/xIX7lD/1pnvob/xVvf9/HeP1znybXx8z1Idv1W0Q2mgXvPHiHdTsxc0oz2ySnMhM+eTA01c6l3vEurW6o5S6QfxuMYdykrPQPLLz+8gMevnPFMZIv/v2/zZuP3uDDn/4x2t0XuLx7yXh0l2mXXG8vwXZDTz/TZYJk9Mn1+pg8PWKcHvD1ec3P9PfzoU+8j09/+MiyvcE6NFgsTY5E5AHvjSVBg9hWoCzMHLacjLFRvPiy+FegaAsYS027K4rNNPowRMreCpuUA7pJXF4bQ7SgM5E+2rl8bH2hd0n4oCYbGpVB7aRm0ZVySwZZGn9Jr3amg9VD0b2vpUcTncuGynDUJMSsDDfQ5zCxDqbJyAV3RshTcVfVqLuwZ0gIc4whQoVREwxXZgzG2CoI1ZRDgr53grP4hP4EXFCfNervuyM6lqIJe9qZpfe2ouPsWbT2ZpRzVk0zmgN6P3v17j9OOyZVCU1gQuYmbJXKQpNz5eNWIyUEONeIE+nTpb6pgyNSNDv3kmxO0mZl/KqwlEi1Yj94Zf06fKhG1fQySf5uYJKZ+WXgh77N198A/sh/m59lFJje5AKTqXRe9ABjH7+wjwM18lw+qMtZ5FrfKRZZdbluiCOljJnVXBM9REKnO5YsJsrFocwg1hnMbXf7AdzpvVf6Xyn6FL5TKw8RZqzKR6eZSt9trjx19xnWf+Kf5AsfeAFuXifHQ8bpmpurN7l59A6Lddpx4bSJ6J5eaE8THzJR5qhTIc9zwLt5NQiq6WGm8sN7dXkn4UG7UHZiM7hIeOuLv8pxLDz1we/h+niPkVck1xyOjaurgUV1MmcwbTBz4lMa9zmTB/4WL3/zq7x26lxefpL3H25Y10esXDDdCR+U3EUjm6P4iUWl2ebGFqfzhmmlcMnQuNJuHbeujrVLUhk2wXfH92pUIBs8D8emfCvPo34puhDq5Gei7LGK2zRNaST3tnFCbMxqZGUKYqHK9KxsyqiAi2EeNe6g5k1nrbOm/HPf+CrVd9UY5xaTYaJc2Ty7tsuV3Wrz1toqYqTiQ5X4Z4J78RRnQTxBGWaEhA3mZ5bR3rjsKXRiZ76IwF4NmYIsrO7ZLaPjvMnZpwOQ2o+yVVO+vQsbdmmxdONJDkFkw6SuA/EW2yyowUoUUTGrKu3zfpM/pXoR7dwAGsK+m3i0gk+0lkQ29/ohdbdLt00agePlQ2u3n+43Xe8Kxc1+4oxUCs/YRMUpSka3SbRka6bBWlMytr1ocUO4XZe6pLuzHBdaU4Dc21vKPgtyCaWgBnSfLM1YDs6xq+PYNtgKs8xIkXndlWk+EaQjlbG6WflFUpZTtZjHgB5cXtzjndde5ebBa1g8orFwXCary8xhWzceP37MWw/fBofjsihYHI60w1J8tkJf7EAUZhYUNeoJmCWOTeTbaSwGiyfv/8jTfOTTH+T1L74MA3wkr37tC9y7HPQ7zxNcMLxz2e8Sd2548NYrHMsA9YS67Rmmmdt03n4UnL74X3Px8Hnu+H1+/Iee5urx6zxqCycTwd9Y0LzutVDenWs42ebgZjvBPOEml5soHqQq7oXOgXB1dE/rzdnQI894Y+AsHPsiBUYanS4DhilJn9V4Ykn4FDjznJrXYqhfubtvxz6jvYJUbVTJrGAfUUGmRsj2XjirguSS4juk7covPRhPcX33JoLbDg0UhpizSLdojdWoW85k7VBWO5NmoQM/EOZeksU2XUO+iikiM/hk7jO4s+Aj9m50HQjNb3HLvfKq1DPtSaoQ5cFp5/2nTH7fy1mwRuGVgTbFpIj5SbbkVI4/hIKrT/15Vtbt2BOl+hS+aRTlbk80h0j6LnzbOZYXQP76oLcniZZnm76dNtS8nX//na53RZDEnJlNXbcRsA3WkczsZA6CqXnNdtAHKhPRiLlDgur4NZMtWC/Ux3bd6+4ULRMFUrprI/eGK8dj4+7lwuXS5TXYBu2UxFw5lZuQIf5k7qulaUSle2rwVpo6xoZO4zCShZHyBLx5/Zusp7eY2zX2eMNi5ebmEXG10ts9xkwun3qa49NPsbzzmNHAx2QseuAnc+bJtIGriaEZMV6lzyw4yzALDotzaHJ8nhfw4//kD/KF5+/y5S98g/Hgmhefv8M//Xs+ypsPbvi5r7/Oy9tBzuL9LneeeZbHr36LgwXHiwPrJkC9NWldT+uK2TXb6w/4lfn3+OTH/jG8H7i5vmGthbu0CzI3NONXg+K3uTHjpP8O8SA9Toxxw5aj3Gka0TqXflD5lNVM85XFKKJwr0zLwAZuC6135hYSHxQWmCkitDZBBYI9G6zyTV6KcaapjDnUEd55kcW97REQTU3DVBDTdL6UF0D5vPWSEAaFxVVhQxo3tuuzg6XY0XNGScSjmhlPuOGkVFNjbuxvKGZwnnhWmPU5ZHnxGJGoIutQEFFfGV3sdW9BNV4lephhxZbSWNwsrq14n+7ibKYFOYXDWibWbmWeCnxFZn+CyB8uLFJDy6CJ7yRqXaoDL0pUdeab5ItS5O6NpzKsQF9bKmtUku1YzjOtTNixjtHWFQPMNCwQjG0ddO9Ez2p07lyo33y9O4IkhvuhTGtFsdk2ycAanAPZLn1qaXg0qSrqxJsEtC4MqFWWIOtm2BdQaiqfnMazjHZl1384Lty9OHDn0HRqLY13EC1ljJIzzrL26gVs56iRKKKzyB18P8Os5H8LhLCvOW+4uLtw8/ghNw/f5nT9mBYHLg5HaM7jByu/78f/BKcXPsLf+bn/L4eHV/yoP8/fffwtvu43PDqdyJHcqLVDM2XNzbqUJoQ+Vzd8abSDvCTdHJ+Tw9ONH/mD388nfvCjfOtrL/Oh4x0+/ckXuf6FX+XTHzxw8c6Jh2++hq/GYkfsqad54523uNh6zYkOjst97j/zHA/efodtBnO94fHjt/jWK1/ngx9+ipvTO4y50rsRBwnKBFJZWZXVoiwa1batECe2cWKbgxYbFs6JZO0LvR1E5/Ek+mTmymFZcDvQvNObFxl4kdJlajwbFN8vyl8Sjfqw3NU3xcENCRCiZI7CyFL+o/Xvc4QMi1PcvlB+LPON2FUlVbaV6YQn2CzbMyjDizyX8Dt01PwWI7NmpbPfGx52LqXH0AyafSZ4UQfL8eiW/K0K3Ks5gsx7K+/KEWfsFZSJ6rQQFj9THkDNTC7eaWfcMct+rzXwffZ3atSE4ACvVV/ZZkFl7poCoHnuFFFRJXCEKrInTVl2TuNtYpfFky46V93TFupDTNSzEKZd98GtRkTotdw1v3vHgs3k7ETqIBlj++5RgP67ugyj+yWzKVuYnhV4jOZJ8x1bqkUWJgVD7h3J3SjUz3igdTkC7RpvSz0kcy/5WVEdyofP/SC5VP37ng1rK9kaGVNDqUbZdO3T7zKEiZWKRRSP6vjNZORGtmtmHHn+2Q/S7UC2hUNb4HCH5hcc797neLlg7cjrj19j+fzP80Mf/hy/55/7fdz81C/x9P/lr/NjL34/v/Shyb//4Gf46sVDJp01BmZw6Y1jhg6TnCwNGrJXaybqyYJx6QaxMg2eeqrz7Gc/xcf6Pfz6houc/MSP/gRvvPEK8+obvPrVr3LzeOOVmxNf4cTb1yem3WHlkj/yz/zz/Ng/8vv5d/6P/zvm43d4+OgRrRlvvf2A9714h3VbReeiQdwAszjvfubxAQWCRZU+wcgpjfpQyZuLcT2DQ0wRmcvpeNrK2CaHxTSlMsFHKXhWIDgHrN0kYu92yK6f4jCymwixi5QthY3GvkW9FTdPkr0wHaAyz6gqJcGyn0vAKIoOBRXtjZ5z8o82XWBk2ydGbpzBQfMaIFaZcrVAMjXOeEae2RrWasaOIWqU773cBrYUp1iVk4KvcP6GXOvnKEqOwQhlYUtD4yFINZRmnH0o1QlWwMpEjZKyL7HqiO/3ARTod99MFcx5bnDtUwQw0f3yibWxN1hj5tlFiQqoivHlxeBR43UNp5NdtCnKi0FiRP15z0Tj/LPKSyCH7v27PUjq6Og1RwNog94LxM9y3061+AXKaEGZy9MuKLJvZA0y92oU2HnRuNmZP0VKTpUpp+2gM7MxQvNgMkUp6j3Ep5OTqDKh1m475bEThMWBm64mUE7NuRllKSVzgxveeP1L9O1N4uYRc06eft9HuLz3AY6Xz3B55y6W1zx9sWHrQ2w98PgrP8cLP/M3OC4f4Ed/9yfYPvkR/l9vf5lfW07YQYsrimoRhEYqdGexDnQsHA87l0jWOjEHZgdiNR4+uOLOkrx9/YjrL/xdPvi+F3n+k9/H7/6Bf5Q4OW+8/Tq/+vUv8Qu/9qt87Vtv8NbDE7/4M/8VH/zAXf6Ff/6Pcv/uBX/+//oXefhwYzvB5bFx//7CNjcOxwWvjGkMBQxIDbqiKBpVLs5U2RoJzkLz5DoGs8E6Vvk61pi+1geHo5oz2YyjHci5iFM49BoRssartmnNPzGyyewA4OwjFhTLod5XFF9vd39wKyxPkJDmIAk7dQMmeNG16hOqgXHWJBdZ34S99SEK2gTmRRmG7UUPibWGsxRHUDQcqzIXlHXJfm5WQ8jE67Q8k+Vle9bPgT9S8j41VZoSB24PDlmnTRYzDq4Sf7cua26SV1INwzGUlVGuCBV0nB0vzmJeLIDVfUCwST332IfvUfFvhtQ2tkttlSDVrdFBFHt2Wuq3OdW4ccd9UXJDL/d7uctTcSEp9Xqz0mvr4CBgriuN/Wd/++tdESQNOLSGMYVHcSBbkKeVHJMZDtEq41Bp0OaEdVfWKMvwJkliqwUXaYxMGuJS4UXSNWczWUphcj4f6+R6aeRRndBVHlDk0jmsC6eDvDF6JEsZX3Q3eUa26pmmsc1kbMY2jJFO2kJsK7/6yz9NLnd5qhsXdxbuPPU8zzz3Ik89/WHa/ac49IVLktYa15eDC588/vyX4eZVZp44/MJDfuLhJ/nYZ36Q//vhi/wtfwvmxI9HOrIDO3Rn8Ub4ovGuTQt55CZ1C0Zszqc++gO8Lw7Mz/833L17B//B38Plvae5s9zh6fvv4+L+84wO8+LAsw/f4PJwwbNPHzndPOarv/LTfO2zH+Sjn/m9vO/pT3Dvqbs8ePQKOQb3Lu5gpkPGGSSa2ijYUIOYYuyGryUDHcE2hnCqEQTClDsuTXbq3yljHLhLuWGXRt8HPbWOb02BZxZeVkD1mSNbRGbRXkqSGBs2oyR8yi5aBeowcQb3Boi05iUFDZkpz1T1kDhRxsCkcMUORXoOvILOmKPMWmrV5yS94VXhLLnpZ7vj3dSx3WQzlq3R+gXdYdQc+RnUv1VjShSk4vkCLTrTpmSqCVFl8s6h3PFPyOL4Sna7uNRcjEk2wxet6XCpWIKaIpBJnwatyRMgkVNTapaNXJq8VDYpKtiU/4KlKZOlDh5EjB87V5Wau17c0TSI9gQFi1s4gtKnmy8FU5R/gZ9z9tuGamq8RhZmmm0jcmXE9h3j07siSOpDyfTTW7CEsdDFqo/kZtTJVrrpNH1Q5s7iS3qB5oF4lOQO3uYZVzGoLqWRm2RTeBI+GQTXI8jTJq0oTvPO0ifZy0wjpXgY1vUQTE1y77VBxyRWDTqKaTDkxLx549XHV2xxxXP5iA998BnuvHCfTCl1Li8vOF7cF6wQypwfvPINHv3qL3HiEVdj5bC9zb0vP+Tj77zK/+zHfj/P3fsKf7V/hdWNG4KDqX4cFSjdxNkLkyUXM/CAJTqf+MDHef61E2+0zsOraz7wqc/x4ie+n8vDBaera7b1huvXvsnp1a/Rr9/imTZ45Nd88v2Nt94MTq++xPX73s/X7Ybf9YM/zOuv/jVO22v09lGeu4NMNtKYIzkFXBk8HBMbT9BYBsypEnIbGznlhqPhVa1kdpzfe2Yw2aAdOCRcZsO9M5sCEQ7h1fzTbEnlOrtrUCAC8t6gIYkYNWJ4r+i0efcZ71IE7ThfVrkoNY6oKvumk2TW/Lx11WyYScp4tFqqpYhqhjfnYKEDvxnWgsVKNrtnqt6IttCD0r2rubMXtEIa945yYXqpzNjqYDGE00UrJkYFmKyt4OefVvAkKqfNXElHJu3QdTdDru3M0sxUMI7K2D1EWsee4CqmDhqR7FWLZ2oQZQC5DQiTs3tM5pwSfCCsnXYrAJDMVJmn1bQoMJmBuNyrjK4+RaK5R9yW7NN2eaeVy5CfYbN49zduCmBnlqIiqinRWF2OxlabfEIZtlYpXRSGGUNgdTiMGpJezPvMJKpkluGF9LWtnDNaGfNukRqxkE5vjfRB6wt+EMYVifiahXM4mu7WvIvxXwE6oRaZk9lY+gWxwIMMrtfk4Stvc3r8C9y52uifPJFHkx3W5T2yN+bNxsNXvs7xGy9xzYDhPOYE18m9Nyb3furn+Jf/+D/Gp8b7+SvtF/jKUaqFbYNjGLTEDyFTjJJqJY31tLJN+Ft/52/z1MPX+QBXXF0Hnzjc56LdJa0TvnJz9Yhx9SoPX/8SdnqV59pbvPihe3z24x/nzVceceeZ+3zhV/4+v3T4IH/sn/2X+Kv/8V/hzkXj7uWJJRPbDCyYnjKw9eB6DBhBrIORg3XKkGRSh9gYGtOaIS26y4zWZmJVIsUiiKFZZ/GFpR3wtuC2YNmFOyNsehb+FlG0HSpYRNRIBDUvoBxi9iq8NnGGdO+KQtqoCkZyTQq38irUQb3TeJRNRWm2dyNZldhGI133JbvhHXpPWpMT1bEpQMaYkB1weXKqkBJfN24J/mcjYCunc4RXKsjVh07N0/EmOtCui7cQihjsXp5Wnz9Zh5yEJEU3WY8tqZG6oXERPfYy/hZa6KFAbcWfJG5xxshkw9jHdcyo7vMQ+Z/c3ccVmHdO5H6oWjVkdtJ5M8dtEcOkNUkUa9pAxm5hKIcpK3x6Fg/TqEBrNfr2t+L/8K4JkknkyswTc24FqCIcMEWubSGEcStichS/LLPmAJtki61oCdmsBO1SA7RopAXDg/SO+eSQMqgAyDQ5JIdkkFuCppg2/JC07FyMZIuyZiJJd7bW5NFYNI7ZBBK3ppIB0/gJedQm62Xn+uaCV28e86uvfomr48L7D+KGPb18lH7/KRZfuHn4gLuPr3mciCLjycO44upq5ZncuP9fBP/E08/zsTsXvPT9H+Nv3XyLz/crrnvj8VFd7mMmhwhBE1Nl4xrBxz7zA3zqmY/z8uf/Hh96amHeX1jyIVdbJ2xo0959hnvv+yCPHr7C88eF9z/3Ad5+8zU+8tGP89zxeb751V/m73z+b/P3v/wlIh5y59IlX4vJTOdmrgCsc7CNUBD3YPUTNzk45Soa0JRJrKUGn0UqGwk3NsCn65m6E83F3eyNWDrdFnoeMY4qibMoYXnAcjd+CHxuwqMbhWAXvmeFNac61HLkllw1K03LM72mkVViupfElQq2BV9aKKBb3lIwrarBMeWa745K2QYcjLYYdxbn0ORtOXfHpCH6ThhFtg+yS2ShrnQwLcHkcA6J5dShWMFSoxOKL2lOT2O2wgiR+seNck8qsnamLM6YMqRYpGppWV1sc7LmTvUwegRbOmcpaM2TsXODK6t8VqYuon/Qpp8diHYOKOxdenWiYedK7g3blNFMa5Cu9qTvmKrMO8TLnQW1CHudRe2a5mr6FlbraN+p2PjOnZt3RZBMJtt2xWkK0JY9GecWvjHLLknYhePiNxE0K61qDS2C5Bi6CYZmE4sVJv6d5lkY1irDcHlWmjuzmcqhESwRRJ5YWoOmCY6RFVBn1CYQtWDmIDLkS2gil3c3eu/Sl1sUiVV0pcf3GhFwZ544vvYSeecOfnGffu993LtzH788Mq6uuJxBto1HlcWmG4eYxOOvc++lE3ff+QCfurrh+76x8bvef+Tr3/t9/Kxd82vjAV99/JCH7RFbDjkVcUHM5OjOxQkevvIG95/5CHkneLi9zuGt1+DwLKfHD3n01qs8noYdGqe45v3PfJCPfOBz/PxLXyD9yCtf/xpf+tpXefjKW8y+8fyzT/PMs3d4eP02bToj4NG4Yoxgm4N1wNUJ5jRinIg52eLETVyTcVJga86CFBkd+VeGGd7latJbsCwLvWmQW8sOeYAsTLAI9qlFcwutZKo03hUz1U3dhQTWhJft/LuqqFXhuamMryJUndoaIxB5W+5mqYBC32MF9ex/Zymp5vAmoUODw8Fo3bk4NO5eTBZT0NiiMayrFC0/ymkN81m834XwyYy1sqRdk15GEmjDWymKqDnZvYlwv81N79ONfQKoSu6SX2Yd7lEDuGzQDgfce92ToGfSEvriEGXaPIu/q9gmipNBmJqZloCVCUhwljq6GVmE/92ko/muay+2SD0Xz+SQHWsdepdlW0p9Q8jtaWdKYNqzuiemw5sod6DcPaDI8wPfVTm/+Xp3BMmkxmYGgyjumDwdaUrdJ8LWsho3ghOt/PWkRNDsDNECehFLw7JA9SqVqNO8upNehLORgc3dIVYlvaXeU51pWljF4bVSCkRuWFMWCyatae8clsZhQQvZdHpmThqNgxnQeXss2HbN3bff4OH9l7F7L5C2cPHMC8SbJ04bhYVqTOo6Nxb0mR/dvMndHNw14/qbV4xvbPzAr73Fjz71DNtH3scrH/04P9ev+Mrxiq+e3uAbfsXmKuP6+57iMx/63fz0L/00h8ePmTyk8yYRr7C+9TrXD98h+8Y7b7/D1Tvv8PjZezxuyfd87FOMl17m81/+Bn/vjbcJm4y3rvjw934P73vxDo+uH8Eq3OoqVx5er2xjMtJZV+M0k5ubtUwNNtKTQ9sHQg2WMGVbaGKeSlj5AgofTHq74NAuWGyhuUbWZu6/lD25g/uEsHMn1ZMqLL3mOysoqkSuZkCiRVTB0PYBOoiUrsCTRV3Jc0lrISMIdu7iDHk81ivu2VXr0JdkWeCwwPGicejq2DdLeSkuanrE3vwgi35kld5W0KhSO5T8IrpT0aLMcBdnOB3wRuxO7SKzAUUYQBnrDlpGaFbQ7tLulgxbpX92F/81dkWMJk7aFF+XWfQqKxMP3aiyhdvpeirlVekFMfbDxkrVZvvZpoPGlJVien49S3dvzlZom9zWa+wuSeaEZhoTvZPLg3ptziU3mVj/rUtteJcESV1VOmQyouzXvTHX8t6zGrhlNQqBWjPMYuuLQ47p5huaBaJDYpdt1csk9Bpbuc0gcoMm5YB3ce9mJjZ18oUbvR5WWaFqfGw1kzwpVY+603440A6d1kvNGk0C/LkyYtQs4yNvtQvWsXHv61/l5uYxz64PWJ/6GE9/8BNsX/0iPa9pWSYODusMtjLfPTC5Xt/GzHmwPODNbePytZXDa3c5fPUOH777PB978ePEh17g4Sc+zM9fPuRvXH+Rn98e89f++l/ib33xf8949RE/+if+KNyHh/4W2+nEfPgyVw8fMT24eTzhdKJtD7h+5yXW68e89urL/OzLr/MgB8c7hsUNn/zEC9jxhnWqtrzZNh6sJ945DW5Ok20a66YG2xzyBN1y0DpcLgeWdiByyuBkysG9W6PTIBdmkwGysOoLFjvScsHCwRZyLmQsUL6AGh86cEsNf4p900OkDresbGdvLOjHiyo0ax3Zvu5M5fa+Tq0sdZI9aBU9DEr9onUx63VskUnD4knv0FoUzCk1SG+BRVnGdcgBWCN3u7HcLcsme6Ev0rd8Cip542wmXdrrNAXHpS3MlJrN9j1R3EHxA4TR5XBiNjYbZ9qTT1fp3arzVBh8a2VjllYNVpVss/jL55+fath4IjwyFBAnZVaxv/c6EN1lVh1TwSsqI1cFIMzZlOUII0awmioBSV+Neb4HkWXuUZ95/231b85Z75mn+m2ud02QNCu6YUo65uY0vLJE8a2s5mrDnhVEFbB5HpC0Uw6sgPUeVpzIMlqoE3BY8cVGkLadO+nMQT+/iCOPTnk2erbaEirgd22s3Fv0ENthwY8LtjSZH2DE6MxpDAZbuugmbtgwIl/gmxcP2R6/wdWv/gwP7n+Np771RY4//3e5G6tKzycxsgw5jafs3U7NGDF5xOQdewgEI66xd17jYnuFO/Z9HB89y2e//nk+86GFn/qeZ/ivDzc89cGPcJ0n7j//YRhfZ11PjPGQMd/mejzmam3kmnibXF9f8c5bb+F54o2bt3ltbvTlyLP3jB/+Az/EC5+6zzavCzQfrDFYZ3Cz3vD4enKzJusYZMo4Y+kLrTvH3rmkc4EzxA0hlwpG1sX3jAPDq2MLHFhYfEE2Z52soRkKkHuDpTLBlE+jOvyz0hPOEjWqMsmAmv9QyhsqSFr5NlsNi8snMpx95VYpjldTqErg3R3HwN3pzekOvWnWkTwFoppNKsvHyVmTstATId+i7BArixXPVzO/3UqHrVqWZgX/xB78VIbP4eq0p7ik6qfs2akMoucsX8fiIe9jF+QDKg5w1rTOtuwyT2GezcVkiLovHqa54XtIPxvbSjll1Yjx2+iOThO0m03Qmm6tIBIdMuWP6WrCtDQdRvXLf4MIu/kTJfTOa22oOjUp8EDNnXe9LDGBDQ1aN4wWwmdG0QJaFCm7iL9eDideOEImRAua7dZUTS4qZTiwN4CmJdNFbZihk8x3iscMMgd7PW7psKg8m4bKsHromEFzWvlB7Q9cwVk3fpQyYqaxjcE2NEN7IKejNpOL6Wx0vszC8DvcbQuH+53eN+Y7D4kiII+iNDSHJYyHlswmlx5LTUAkk3BYwstbMZind3j0lc9z96Of5plPvcibv/DT/I++dMFP/Nj3819+6KNc/vP/OHc+8hyvv/Q3efjoq+TVQ25uBg+vT4ybKeknC/ee/zj3nn2O9Z1vcnMtZsGdu0d+149+L5/9Pd/PZhsZaiiMObjaBo/WwfUGp22wrZMxq9PoHUs4YsWxEzzRTLb/xFJYoWgdM4/0FOBelZzwKjuQXJLZK3DN25ME2Y5lGqMyv1TScw6U+6S+rC5tJUJnwwgvhxxZRsqGeS/Zgyk1Vystf9TmVregam7xFs2MxZxjCkqgNbJtpX+G7SY4hahgNl0sjG1hyYU1hHdrwOqoDnkQPoXtEaX5vi0fZYFmyON0kunMMSqrizLgDcwm+KLNF5DlZB9TDI8wY3R0QEBpqpsC09DBbG7Y4ozWisMYpdUW2jfYCUuF1dd6xiqzzFn9mixIsHLDNPpOhIdaI43WqqnTCvPdCgveYTLPc5PKPGXaQdEFKeWewgPYroLalULvdkwS2EKSMauu9bBkuuggNmS3pENOHcteXKpd7zUXlTtegLE630UXSs2cDpA1liVWuCRWOEqEBmJ1KouoEQ9VFmle8ajRA7uBhvDG8kBWIB6bvPXM6cuBDGcbm05pjJ5qRq6p+SqWG50LXtuM56+vuDfe5Jg33H3nmkh4jBxTMoxDJseEk8Mh4YiaAo8JDhgLR8wXjhQPLQzbHvPwy1+gnz7Isx/7NI++8hLHk/Fj/8a/znbvOb76Cz/NZV+4PtxhPEi2E2zXg/V0onGXZ+5/hLt3nuH08B1insgLJw/w4qdf5EOf+R4eXaux0Yt4HemMcMZIxnS2Wc9gTql9ujF70PxAtwWsMc3pzRCN+5ZMnc3Z5oExOjackdoIsuI6EDRSQLRwxWocmFuxGRaciZxm1CU109Aka+0cdHd6yfSUQxJZAVt6YZqTNbpTh7N07HsZqEagaeBclZCerbq0qo6EllcsSGV2ayY2khyJ+2Dmys3mbKPhUzQWmZasRG4i+VjI9UYsX7zJ7JZM5pyCH2rui9wqnH3M2qyxuDt30PIW7xT/EOaGsmqDuZhUZD1lQ6hWuPZpJRZa/wCizY1Qf2FEFnMByJon4/uI3KyurM4Ua/7rMrlEVJ0kiodsMiZ2sK6ExIeSHI2jmDv9WXVEc8yKE2u7cxdAlF/sbcUwB+wziL7T9a4JkpmBbWL8Ty/T24r2I8U7mwnr2CAnsw6fakCecSPvjeaiTmhOb5ZBqG6+Z00/aQKPzSBdi9ZRCp75hEN2X4RTYsJsopXpQWEbragaWaL6Ir7jjWVqcMSWKXVEJqeYUA/dm+MtuVwX8M6DR494/e98iccvbzz74BGpnImt4IR7aRytc7TAQvLDRz54K5MP5JG70WldBgstb8d6elvhm1/l0YOnWe/fYVw/4vpLX+W1t/8GL7/0s5yenmw318yrK/K04qeN+3ef5tkXPs39Ox/CWWFL+mHhhaef4sVHnQ98z6e49gNzhcUXlcupJsgcG8ykUVPvACxZuu5737vOaBLmaVN3tHWnLcnh2PCuoVkxLihXYyg+oreS0xUmXIxmBbbyhhx70wSDaOqmnocC71reqvZCShSZqchODJJydQAKckGqkVb+nVq8mhK4j6LIvQyNdn5baribPIFJWgXY4cZImJsxUqN1x3Dm3ICVYy7Kgl3GLNNHjSUQFikWiCguaSKc76MIIq1Mg0KqoKystzLp+oRlEJGqWrK8H2tfFRvnnB2bAz1Jq+bLCGLTvTGr1VoY5CzoYZ++lU2VmGWem13F7GafPaW5SHviAhpdW5xI6nvrebSsR04Wh1nKKztPKZ21FpVlWu31tngZZuyEe60Ifos4+a4IkiQyrB7qrPmctNhNPQs3yVIwDE2Gm1lkcddJZNaBBXKpikqbJ6Ye1o5z7sPJ87zh1MGMOoU6tToy60/CNI2swfdTzuAzzsoApfTSa29DQdY7MJ2lR8mOkxjB6moiLJks6XQL2sVkC3j43PPYB+H4zZd4xZMPk7zQGrZNDtToUzOuzHlskw/awqTjOblvvVzLN/qyCHdNjX84eeBjcvnWQ3Je8Ctf/Qp//d/53/LMp+/x7IuXXD3aeOlrX8PefhkfYHnkqTvPc3nvadrROT3aMOv45V3e//6F7z3CfO5p3sIZOFsES0oC1q1JaueN7lM8tlYjVCNZfB/K54w0csjr0C3PMkr6pDeZFthSBHGcfjYt3INkh1RWRVFo1IzY52FPpHFRYFQ1cNukIcDCzoYneycU9vIZqKZDpBwxZ4kIdvtnzJTd1NCp815zyVQtlbHsvgEzhjwoS8CgIsaZuYjLuhnLUPgCoEPkYJqMhvehbTutbZ8saOV1GjmEyZ6z5yhds0xgzDeMYn4wSmiAsJzeC58dmAfWCr7DaZ70plEKu6fjNNgyiaEqbiuSuLDWnfYjGCqT4jZze3BWtA4KkhSEipnkofuArnOLoBmjlappOricyL2wFKtxIN4U9Dx1nIzYdEg3ZzFlVRNVW+Zq9fyOMEkz+3eBfwZ4NTN/oL72HPAXgE8AXwH+VGa+ZQrz/wfgnwaugH81M3/mt3sNEnKUQgINp29okcm8tJcx66yuctEZdnkY0Hqnt67TxMoJuTiqkRRdo6RakWASxNeHFEYBdLy037XjxpTFO7V4YlKeXFoomyRo08pWairLbel4Tm2drqzHIukTYaNLsnXjgiPTlGG9ySVf+7jz6cORu3/3y7z99Tcg4RmauGPu3GTyYCYPcrK0wd1w7uM85Z2jiVDr2UQoRpI42zQb5PF4hD+44fgYnn6uY3df5FsPTnzx136NV956mWds40Bj0ni4vs6dZ97P4fLIFoMOPP/c++mfeR/LjfN3tkcsLMJs44bT5nQvLiKOLw0PZ2mLsC2fLBEc+oFlOZCtZKS1WiNDnWg3mZuYNqWVhn43WYpEMrTaGOcqpDKkyCR9350iWsfecDGZPjjSd2uom7JdLw9GnjCY1U+Ro3iLPfuqTUWV0TUPG6hslbNDUIrzLWimiZubDJln1KgKEYVKY+8Ui0Lls6z8gmGD2aREEy6aO/2b3WmccoynzDqU1TftkW2SVnNcaryB6HBBL1/IaE4u1fnfJEawqnZ6d3qpggx5F8wU5seclbgAyGJtDFVas8xyo8wkzGocQ5W8IvDHnn6jvkpNjrQyGbHiOCPTixhCYK008mn7PQDvhSU3fX3bosb4llzJ0AFRh0YGjGocxV5afJvrHyST/L8B/yfg33via38G+GuZ+WfN7M/Un/9t4J8CPlO/fhz4d+q/v+WVKAubpc32yCpjq5VvgIkf2Kt0iJzleiKAv5m4cXIBUeYx5qgTPPcXqhxgX4S6cdSiddvLbwHfM1YRg6eaML43SDPP0ikRcGuTFyie1uVQMiXhAp2isaspTBMgtwHXFnSL6kqe8G3ya88cuPzxT/Kh+5dsv/Iy78zB0wQfmI0rm9wkPMrkbUTEPlrnji1csvDYgnUW2NaMll0uKz2ZvjHHyof8yE989TX+yvYmf+fO5OHNFU8fJtxfeOH97+PexVOMmxMEPHrwmG1Mpi1YPsezH/p+ftfbnXde+nl+/v5K34ILkrUfSm6o8bEzg5M3epM/OVzQCHo70r1ce1DTbHeaj4T1RB10RmuDaLLKiDIMtBQ2FpPC6JqypqGmxEh9bgk1ooKrnZtgUdzG3TrMbNbIECrAq2O7b1sllmomLMX7S3So74dsNphtdwOX96SXsUbuXMpzUHCa75zfvdGTmniYXfCIayRHmg7p9Fkd2HHLMcy9USKPm8yat2jIST/VyHxyPpK1nUfJ+TDoRaeZOSV68JRXAeCLDjtr6qbvpfdMsT3CwKbVWA+5OQ12r4QnDLsSWo1N0Z4zOD+HKLaAn7HB3X0+kWTUsDqhJm3qtTfTPgrfsU1hkaAEJ7KedUjk0RKaRcmG81wNhBVf9HeiuMnM/9LMPvEbvvwngT9Uv//zwH+BguSfBP691Gr7KTN7Zh8v+9u8CBHlVkLQoygdPmuRqoFizekpMGKWcqI10St28odoGw500uZZuG65k3uVyQmbL75bmV9Yk+2+5843o0ZIRNEthHd56jScITB9Ik13DSDBTVwtbCOmaDG7Q3XgZ41tZLDBGd8aQFpji+Ttw+Tmez/A1XHh3i9+jcenwUdd+vK1OdcDHs/krnWONedF9mijuJgi3RqdlnKiae2SU1xzs13xybjgn32p8Yo95Jefa8ynDNsOtFNjOTSevfcMF/3AWw8fcdEPfPD553nGBh/5j/9/fOhrnd//Y5/ipfZN3j5sMO7hdsVIWUvMXBjhRJ60kLvsrLrpv6Srp3AmS5dmO9Xh3QYs2ZjhZ3xQxg2TpQ6xSBkZW7neZCkrcmpDYtQGqpItd14dyjhNmt3MWzsvrQXhpWZ2uw5EhFUJX7ieRHHC8TxlJpK+ZyOhzU8WZ7cCxgy8qdN8i7LdXvuo4mlV7FclpHWoJopVghxQjSe7LV1tBxtLn1xk8L50YcRuapBV0lF4QjmA67DGki2LLK4GfU2DlCNTcx386V5CjTjDEKNI9Jq3o/fpKbBEFPYgY+rzFQ1rlwfSuj77TtonC7feOap5qw6qEn3nWSorLfONutlJ4kPySXfxUN1kRBxjaLzJXuNXNvmdrn9YTPIDTwS+l9HkRIAPAy898X1fr6/9piBpZj8J/CTA8fJQn7wWxpRLpPedp6bZ17MeolzPbrtW+5B43DRD2NUYsdSURXUQd6ma3aLSPHmyCZivWe3ivaHsUBQDgxaawOjiaLVojHVUdqNF41Q5L/9pLQ+X0cSEMxXCq0QKK1f1nOrk00QPsoW3jwM++RyfWIPXf+UlfmlufDCQW7rByY0HM3iqLfR+JIfexxrJ9XpD751lkewy5sRs4eDOKR/yBld8cHX+V8v7+Ysvv8kvfmvl4wt8/O7rXNx/kzvPPEXee4fDduK4Jh/evsVn3ob72wXzMz/K73nt/VxePM+/d/plXs8TM1cNux+TsQan02D6rXt6rzEBY9Zs61nA/5iMOsA8S6LmYjpsEfQZZ/cnawa9MUzfB9IyR5GZo57Z3uXOEHmahN18wkonvrMnrOqtrGbSzvXbt+otKFbfV0FL0xJnNReTOZURmoUOpcK+FIluKUi+xyiqiXK7H4R7V3D3yCJBO1g/Z3FSlOzBvPiPcC675TWhNE8fqRRFi96bymSp0GyEHJuaq7Q2hA1X5rz/z/dPURpomvjCcW70mAJllBluzemxNPUW0kviqIpGAp/66VmcaNOBWdlLmWvsd0/5e+7fUZ9/n5rIfpDu3NbC2SIb4cqC9xvvVfrr8wAoG/fvDEn+zhs3mZlmv42Nxrf/d38O+HMA95+9m1ENkfYE0z5SlAH58U02+e3rdCqag1L4ZAcgvYYnpU2NJXVnmgjp6kQq08x9tXLL+o8nP0VoUeSQfZNhRDeWQ6ctTfOHV+fCFmwE6zrlJlOlTmRoDnMeWFphILUQ/IwjJbOMs51k8Qbd8MuOXa9EMx7k4KXve577feWNX/gWz7pzzKzmVXIy49AOLP1ArNd0F1l7WjDmSTryw5EIg+E0M+5yh+QRL8+3+WAO/vTlM3zpxnnt+pp+2njqdbjgMVdIA/t0Op88PMszd59luX+P+eab8Lf/Pj+Yf4B/7ff+k/zFr/wnfKEN2hha0TOw0CRJN+G8h5BxxJbCnDPU/MqQbZlVVdAOjX7opCcjg1OqWbbra6VfVvDyyuT2WSwjtFnddorLnlxV57nwrwpbopek4b2TRM1Msj1p1PN0+Y/ephsVlFD527oz5iSii1WwH7J7N9hu05SsHa+MMUWFofC5ypn2ascMBSPfsx1h9FCQTgaZfs4ijSrxsdupjbKTlbTWpUTLOoiiZuT4FI1Mc2puYamSuZGZrHOFGtOAFdeySln1R1sFSP27TGGt4iTUySBWvQ6ODllKJjdjaR2PKGNmYZnnSq6UO6YIJ4wzVCLLFakyzqxq0/w8syar0ecuOtdQqUAvjrVVQ3b/99/p+ocNkq/sZbSZvQi8Wl//BvDRJ77vI/W13+YSdpJz4DZE8DSrk0qLak4NorIQljNNc0T60oTzRFbneZXJgJlceYCcTc2DEnibyX4tmJSrkkqpfeqhG1sMfAs8gpMF1ozpjUN32mHHjNAmPd0OOZdN1q41BhsKDLOcTcI7kLJxQlnn3sXD9Vk9k4tutOGsrXHVk/a5F/nW2ze8+NW3OBC0Bm0Y3RvP+WV9NP2czoFjc64j2OaEPmQHl8kwoy1HLmJwdwTfmo947vHKDx+e4h078s3xmI2VSXBAjYSDwTpv2B4/oEfiNxubv834wl0+/ewf4l//8L/I//OVv8rfu/k6102D7C2krFgPnWM9r2mwjsa6Tua6QQTdnaM33IPl4PRj2zld2ixDHeExB90viHJct5iid81qklQsypDjkFfJuGeCO6kZUxYZxXVtHXYrmFYjIrRxjOgL5gd2IUGh59U2EaFoBmcRgR6hmiCS2AVhNW3TSt2fNXq2ATH03iLZchJxIQvAWaM3aGQ7lEhgJa0xYmXkeoZuskbVUi5ZS1rZtAkmSBNdZk4p1Ga2YndMiI2RAc3UFDPTQMgoepEl6aqUcqvmiVnh7KrohhenmWrapbJDNZid2aSPtgDzpmaPycSkISMY7wrGUbLFNDEORLXKCnBaBz1NvNXWsOhnSCNMipuogyBqRIQLv1A1WhBGFFac5eYbftt8+3bXP2yQ/EvAnwb+bP33P3ri6/+mmf0HqGHzzm+LRwI6HWcpXQ5n7qNufjJrakMOYQvK5SdWQ66aNbX+d21nFh2EOmFIzDu7gJ86QQy5mYBOpbQs78KyjaI0vy6ssPeDRp02ZQ05BXhjckCfMevsLhzTXWM/bRClxZ0xig8mkL/NmkCH09fBoZtcrx3SO2ozTR4sYJ/7MG+8+pCP3sAWms/9oh15oV+yhB72yIGl01N64ZtYmVtyt99lWbpI7WNwx+/Qe2PMh7yWJ663t/nE8XmO/RleP11xUbO2k+CeOc8cn8bbJWsYh8dXXOTKo7//Mxwe3PCBT3yUf/UHPsf7feOvzC/zKIJ1WxiLTqmWhjVnc+M0Bqd1SGJa2Jb3hUMzDhcHWpd9XbNGTE2BJCgS0KKtVaX2nDX6dUqC2srEYVYTSPWVlxGsErKkiM1Vmt0yeXZQqjK6NJIyV2aHZlBZv+OEWcIFl9zOXcFGqjdBQ801RmIvQSWKuMUbdWBmjfoY0qOngenVm3Wy7PjGnvnEUGJW/9uHYU2j5Ip2rlUnpgZRTS2cyDw6Q3zjJMgtCyoovXjELRbss9RLgrvMDZsalGbmGqRVZI9Iq8PJzyILQz2i1rsOBIvbLL4OMQN5oDbUpR975rmX2SaH96j624T779SgyB1KsR0LwTI147wEAVEHx9lP0+vgcxOW/Dtp3JjZ/wM1aV4ws68D/2sUHP+imf0bwFeBP1Xf/pcR/eeLiAL0r/12Px+EL2j2yiJsxZSFLV7GoE2E1W0WDmJ5liCai5c3i3huNdlQ1YK4a7EjGoVjTEYZCgTsiMucaviFqCgjhFUsyFHF2kLRoxnV5RZXtpVt/CRzEzUjdwDasNSEu/BO0AlaNRryjEGle5VKASk7/2nCVx2V1yeS03P3ePiJF9g+/zrHhOe98+mLp7lrXc0jFynXCl9xazqFx2D4xoV3FvcqiRtPGzyL82o78I2c/Mp4i88uL3B1uODn5gPebwc+ziXHTN4eJ67Wx2wtOTS4awvP+bO0l3+R9vhVLl/9MP/i930fz92/x19YP892TOI0mIfG2qRZlpWW01tXGd5gaY2lNY7LwuXlBdaREicaMZItBzMGhnTOcxYJWIPHq6u7Iycqs4i9pK6vhVgPhPiVQi8VGDWWoQCwvSw+l6xaPbdcXcEcqptrnVbX10yNP5fQBjVvFCB2LFQBNsq42diBNzF9rLBXvedgki3U7GqiLunzJNimJMEU/ESrqWZHjMLFbxschg4R0m8biFFrxdTnzXIE3/0fM3c4qvDaKl0zkuFBWGeE7n26NN6WuzxScs9sTt+HqdXdtWKi7A4/2UopY/XvKPZAYclx/rdNs98rsBtA17PxQCKPUtNlBeK2Z8S/PqBxZrbsEIXq+e94/YN0t/+V7/BXf+TbfG8C//Pf7mf+5heRe0jvIdDe5KazeFMIK531RnIqd5VWHd3oVXL0uP3wWTQfC6iBR+pkFa6RO/G3wPIpRa4DURSDmeLnHUyZI21huswmIuLMvxwVLBuSro0pC1NMILplZZIkma1wKDg7j5gxvPibY9AWBX0F0UED1hj4hKUdePN7n8e/eUO8/Raf9Lu8cLjDHIn1zlhr8fhk19EudsEaJ7bthqU3uncO3eH0mKfmWzjJvQCzC76SKy/Fmzx/5xk+wCUvnx7xul3zbDvygcMdnvan6DMZ2zVbXPPW9crF47dpD9/i7luvMF56iz/4mQ/xuz7+w/zs9hp/izf4lXjEzUVCDnaKqTHpFnQTufxyOXCxNNmm9YWWCzlblUgnbfDCwLKgMMEbGh8rCC0YLRVwCodkB/4jqsvcAWGF+zC3uXdZxf2Cc+kuvNTqcD27/JQUtaH35L47RdWc6GalitEmnBsK6og0P8dgyxpzG6nPVnya3OfIG7iZskeDQ3WIJZjYgDKKkCccbkZ3cWTHPrYVLTUxfFKNstz/SiqhrDa5W2VZe1CyOuDdSxQTQNB3w9pIGg7ZiQbmUbBFqbZDmKMwoY6Xim1PykXB0WdMh9ESn13Qyqx3WCePcRuwA8kUrRutNbJXxlnC+x57kNThFl3O8TGyDoesRFM32VIUoz0B/U7Xu0ZxI8qIcdHUaTIzYuGsdQ53bFmwCpiGQPdwF0fNTKabs7LF2G7pIYj064a0rnViRykb9raTnI3VWQucduzMg0iqrcsmfoYw7CygOUHO6N052pG2aWTtwGokhUjCbsahNktk0Q5qTMFqiafT2xFfDlgvt2VbYZy0+Jpx7YPtuQve/p7384mfecgLvUjjs0yJM89NAffG0Y2e6sBexwnmDffapQ6g06ruLVq7L1jyJgvfzGuubibfe3iezx6OvD6ueczGO1ePeMsfcHfpvNCf5oV8H8dchO3mNXb1gHb1c9x98AXu/uw9Pv7ix/jDH3qRn/3AFX+B1/i1OyveFvpNYLYQeWIJmVyEQbSG+QFvR2UUszO9cWMNGHhsxCbeKjOIMFYHyw1DGb1MkOOcScj5B5WbM0hWWpPFf6DXnZFFQ1FzzVMYmlgOLkVOkajlgqPDzSmuHhoIJ0mcVWdYgSLmPlPHIDSiYpsbW7mx9126WBnUYTNG60w3juYstbH32fKKMOp4m4d8JIlqTol5YWFy77akZzW5ar/syid9lqjsaQpWSRfNKBL8wKgJidYWgpPwW5S19XRp9IHIUaXy/5+6Pw+2Lb/u+7DPWr/f3uecO7x+r/s1utEDhiYGkgAHAJxE0iTFQSQ1x4qlKJZkDSWqEsspV1KVyE6qHJfjsmLZcpyyY0eKbEuOJEqViJJs0mY4SZQIgSRAYiDmsdFzv+433eGcs/fvt1b+WGuf90QBIG0qVZ2DAvrh9n3nnnvO3uu31nd9hxrXbQus3TyOL/GeSp+cGJctskThdBOaEIubPofzui52iMoy+ATpPDETBddCuY++YyWK4QKvueRnQVDHFpmy3PvxiDuTGizRtV/m8ZookpGjkdsu4uRb+GVlKBSt4RfXjd5a5p5onjDL6SXQJcUwceGYhNJASnaNEqae4UwdW9FI14ubqbhhfQbRA4aJxKk11BirzTptTn4dofHWsTKUQuk98qF7tjs9ugQthSIwSPzTTDJLEFwmxlEZV4XVYJF5UgtaR6xHl8kQMi0nLrhPvXHF133yhLFVrM1IFwZKjtJppyV585lQZWRTKtY7+9mCFjQc4/3igPlYOeZhoihcTns+7q/w1OYh3jw+iM4Ana3P3JkmLvwul9xhrSvGesLJeJWRVTqxd3y3Z3ruCzz48jnf/fh1Hnn3N/I3Lj7LB8ordDfGpkjrzEVgrGgPoN2piA9hSeclB6yFPxlFKoqa4gR+FviUUD0XGFroWoLK4ssCIg+s3lO2l93igpkRC6+AN+8FaN0v2fJl9M4OtclhAYxJpCdmHxpFMoiRKTAgD2XDWxQoN2fuLd777JouXRibR6jbmB2PhQ66yZLL48tNE9vpnJAa2S3lItDd77M/iwLHsimH3DjroYtOyXd0fSn3deL1Sk0+ag5nwTHMp0ls1pcF6NJhxxsIuVjJPx1klJFm6YcNtNt97/v9T0VCGSpYqFBjYYskW4HDQaAsUOyibvcklactXI7aC9XIHfrc7uGiX+bxmiiSosKwiiwY8oKVEqOMVIUaJO6wagpD3IUeEGCsgdfg2Xl+4AmCSLmnFw3JW9x41sGbHfJMlpNluVpUJRU9SyLK4k8XHatT0hcygpaKGrUEhWeRGmgztIMOweDL64LwZkmTjaFQh8I6MTldFbRUzGGWBO6MkJCVAhUursPxlQfQW1NgsRgDFjGs6cIeB7YmiB+YYMOYeo8TV9b4+DBj39LKhi5rrkiod17mnBf9kmfPb2CrazxYr7KWFSdUHqDSuWTyMy69cd5uc3t6hYe9ccWd/eYByulTjKzosqU8+yJfvb7Cn/yud/PqjZ/nM3LOzidqKZHy2BveOzrN1NKS+zqA1zgkXaOAehRRIwKc0FjaLXdGRSOCVUvQQMTBeiijWD7/oIsdMtklMLMFe4O84YjpPopkj3XHAR+Lf2/5c4W4HtU6aY0f3Uy/RzxfkBVMcdP4d8GOh/RNdYS5VMRqkNgtFS73cymVxOvjua1HQTb1jI2N69lao7ee7kCJ85VU8niWWYls+cUiLBzXs0p5OziHRVccIywuaWubJhHZgYdG2pab5FDwyHd0eUNDaHMvmTDMeUNuqDneC4uPQhTTfEH5GhNj9fjZPSEQP+jFy70fmdxpT0pg0aBRScIoi5T1kPj4FerTa6NIirBac8Drgs8IRZ1MvcFJXmQPCVq4AsVFEpKnhYIRl3LrLbXAA2IxwpbUoarHh4Av2lninVc7WMNTwpeu5FIlWA/9QNWB6N6sB+4pGiOxWhRiHaDPxuAwVEc14zI7aJPIbC6K1IqMA6uhsFkNkQgoQu8RhAVhLqAi6AA6AFc33HrkmEdv7jl1wzQ6HumBcYqGN6OIUKrneBrvT9XoHZs7PhzRN1fiom7CpJ2VrLhWhNKEc7/gc/tXuWUzb1pd58g6ai220fIQaxdOZIdfPM+mTwgwXL7C3d0WTp5kVVdIFeRp4/o/6fyRb/oG/vKNX+LZ1ZxqJY1wq+RMm8TmVRO876mKidYhSNVaYsGAhDO3q6KekacSx4NmtxejeXzOsb0uUSD7AkItnUgUSHGhuMEygWSRi4YlwM6DdtuT5pJ0GjNypIxDqRu0jI8ILXVMEN0Vo+IpioguNlgZg6ygFjphMOua0Qe2bIBsqd4RGGbpapQjOfnr0jptmpFaEC+YRjdVTRIvz855MfDNQhxqtWiNA64AtVgoenaGQmKoQATrlTiIs7WMUdv/qeLuJkGQJwj6oXEP8QWe+G5ioksDGtzkuPfJhihfRCrm0vsyLoVIriRglqgVZCcaHXPJYhtPkxOCOFAOTJYv93hNFElVokB4p3VDWmjWmvZ0IDbMKvNstL1hc47KEriRuyCSkv8snnCPXS84ZUww2qL7MLU0CiW7VOKklwEomCo6SNiaSfjmRZxnjiGJ7gwlFjRmyozkaA+lg2osHyhOTXB9Tl23AD4ET09rR1eKaW5A3TOTRAi1hYSr9QCMytaNF64X3tHnGPstEXrxkCIaVK20PgdJeyhBofAFT4JZOqZGsxZ63iEDlVw4YcNxrZzJmhvtNrf6GX2aeeT4Kg9MazZ9SIK6Utsxtfd7WA9wbDtu7G7QyxHDuGHjjasfc77l7b+DF9/yLv7WS7/InWaMwzpiOupAqStKGZiplN5jNF2WbUM9dDxF0tJMYmnhabHVStzk2hXpUViFoB6ZadKE0tBC5cCXWzqxwwiGHRZ7aqnXt2RV5PwXzVbccHFTB6WrL5r5VP+Ex4AmITqpKMnVjIEw3rEFPSumUMuBAqXJbRUzoOHao2PqHW875j4nvSfL/LKA6oFl9taiCBZNCMsz9ybTCPNDC0QiCmcRpWVY1/KuiHVcJIxYkk1gyz1wmOhi87x4AcfbmTdWSRNdlYPizA4VcTFEWA4s8h6GmOFyCSahsluevntDezQwzWI5q573p4TWTTyoTPGaEqskdwkuy7B56M2+3OO1USRFWNeB1khzVmPqmTvjyswc+Epz+uRIi3dzCTISX3DH5DX25LotcrZBY1STguuAS0+3/h6HkyZ4L2GHjzsoIYuUyMCZzFAfAgciJF5SalIXUiWARJSsxiitoiE5LIHLtKkxqd4T5ReJbXt6BPYlxzkvkuZJWdHIQpESY9Ee425NwN2Wrig6ElUNEq4sF1xcjGGa4PcOBIkI1k52z94pYoy2pc57Wl1j4wljhaPpgptT41a/jWyuopsVZedYbRnveopOu3uD0XjKUT1iazNtFvALVuL4r36QH/y6389nzl7kvXyWgQEdNpRhxVhHHMVawWcPdyVynM4VUynj4Zq5lzsjQRErQaYuubVeeFAL2RhNfl6+H8EeyH/KATFLjmw/3Ejm98Y9uNchxYAcI5wy5DieXqLZiR2KjJf4nFSzD13UJZLcvjhQJSW1lUIhNO5uS5RCx62BtViOWMP6HJkyafOmWuJ6zi1vvnUBRS6QkkTX7Uo6Ci2obP6GmjEQidk7BB0LS9ghPRDy/S8Wv4NDmve2hXuFdGOJhJVyOIJYsMqlMzS3vHby/5Pkf4upoNak6clS1oj7Og+R3kMaMOeU5NJDcdcSK3WypOehuCzUIOydUqTy5R6viSIpIgw1Fgu4s289ZH6DMlDSwDOMWb2nztJhySoRgteo3im51DEi+mHZ+rrFTnIm3vwILIrNtySe7QTQX70HJmIe+E66Aok51ZxBIkO5S4r7LVt/YoyQZSbXID4bjR0w10pvjVJgyOI3i8WYaAYtsSV1glkbJ3stYUIr1TBpdC1MOQCq6sGefgGqEQ4ORwtYTvYrqplC6GHWiqTES2DVthzvXonfvZ/FiDasONUjVqOyLRd8cf8Su/mSh1ePsKlH0UUdPQbi+HQXK0fIcJ2hzcyMtGmiN8PsnPXzH0L+ydv4Pe9+D589u8klm7C4qytgoDWjz5f45LQ5ZIZSC+OwWgbikNTFpxb5LnCQly20HodYnPgyIofpQoRS9RxP7fCZLy7Zy/cs8jjLMUOy+/mnr1lLjXd0hgaBm2YOUjxlqqniJE6sveDJJF+U0fFZDWECrUGtEa8JccZr7R4+kJ48y94JGnCfaRiihSHE13gyRMLeLQuPBVRkB5zzvqWNJkbq972Hy2FDdIrdBfeIShAVeimh93bJYkiqh+JgUbg3Phv3lokLRS/fH4jimrfzAePtaSzTE0qoRe8rntHBNsIJrBDj/tgkYbR4czpD5GN5O2QkFf+nrxOzEJDoa71IxmEm9/5bQGrgPj1xNtLJA9GkPkRLVEoeMH35kPMMPxBz478l0aRuDTykVvfY98GdC0u1oDdElyHpbE6eznMqc4ReNaVehd4K3jyuWiFGoBIWKtYDi2ziTEVSb0pazAewbt3oanTC3HYh1VeBQQtDEWSQJe8KN1hNcNQD04ubJjJm0CX2NDqpbj2VSEn+yEVCpAgm/gmAUuddooFRdDZtx9nqlN14gv3pP0D56Kd408//AhfzTb7YXuBBOeHK+pSjYYWfPArTw9BbLraM0QRjYoty1s+pZy9x+qFf4Kk3/BDfc/I2fna4SUHwVtgb7CaDfcfm6KpnI8fckrnUcTiZxtZ/yCKJxOEZuUVEl5GkzLTBiK2/dVprOGmOktfLcn+43CMyBzQTlB+R5V1ZHks7Hp957MYE8xrjf7pgLCYXnqM3xOgeuHGqifzeYaZWgwspEXaFRpZ3J/KZoGPFmftyc8cB4SUMfNUdabF5X2CAuB790EVXi25VPNMOF9lKzM05+v7ThXIRY+CaOt8wUjac4hmiJ2QT0eI6tBB3pHFWLltyArcQd5ZcfDWNgrVQdkKCeA9CWP4c4Xfhn1RN8npPnNKNqWT3lDirdM/Xm85ckoXfnQMXqd8rmF/u8dookr5woSSzRDLQa2mR493C1fAaF4dC+AZCOKbkCNUlCKfuHvrXXPvTQ4oV6Fl47S3OI5KsW1EBSav7HAAsx3/p8UO7C3MIXVPalCl5Id0ICkaC1Ijhc8uTNGRllcKszpw30pC3MR5hU1WG4IgSWd5DwFTRqXlcWN6V1Z7sQoIc734QgeHcG3OCBRAGqyo1N7+AO5XAy6ILEuZyzIpz7tGCjsCUeVNYv+H12O/7Qc5+9/dz5f0fYvWB9+PPfZZ5d4MLOw238V5xb7Q+0b3R28S27Lkjzp3e2Gydt734eeyjn+Bbv/kp3ju/yEUd8f3M3oCdMs/LgVMOHd9+mqDEYaFd8Boenm4t9jk9cTL3jALmQJ+BMIm1nvLWFpOElFgPiXp6jsZnID1xbonipoTzdTusa+M9DXo3MTrTcca42RbamEvydKGr3jP45T6tOYu/ZX5mFrOxKXQ1qhOHiMV0EQ734Tbf8nW0+zrfDpSu9CrpuK353KmNzoWGpDnvUvyXGIRKQF+Lm47ZUkBiEvHkPBlyn6QyFmkHWa9ZCA7Ml8s67iWP5UpZ7OdYinfW5qwDmp2zefAXVRQplbkHRq15LQsxZYXMM+Mb+pw69lzkWEuPWovojJLS4Bzvl3vg0KR9mcdro0gSN+mCv9UaQiYnjkp3DQ0s4CWwH/EQpXuCw5HXq/fa7QPaEvih5Ti2WGEFHSBupLiwA6xeuGQqhd6DrOPW8oCS1O9Eex5M/pZhY7Ck48WNmGNdRqU2idO/EWFE7hYx42k3X70GWZegcLj0WAak03hw2kKvqh465VacwRKc18WSKk5KLXHBD8OYp7QnRh6byiJxMIQ0PdrTVo65WD9K7Vu8HuHlOMLG2hnzn/9PkZOHWV97iPLYKcMb38zx+Y6Rl9n5Gto5JuFlOdtM6zPFBTNlx46dwk6Em9sbPPaRj/PYE4/xDdce4B8MZ+zmytkMYy+sveJiB6laSCsjgqNQDy5CPSNVF4KWL+N2OtPE8jq+1ryFvVwLulFXpbfk8qkgXZI+2JMtQVKroiBE4BxJkQnqyYLzuaQNGh4TChoX6WE7vdiJGUViLA6sk5AbppzWSWs4j0CQ8JSUpKjFddTpETLXQ8HVS4RGlMTJc3hltGWU9mRveB4aOViJ5JI8J6aSHd5yDmTRWGCjWKLlkjPAAooFAdyI11bNscVpCLCaSpbkgLrmdZbNjqTfZvPAJg+6azdI/1ZJzNZ7QEvBPohruGsYMHv+HbGeloMEpmDgNueSNGA1T3EJxgELXsx2l4PmSz1eE0XSPSgTiKPVUuJ3jz7hmUmznGkBvC/YUnR/S57FMkEYi1ohugbPIyb89eL5F0IxluNpgWCCVVTGUPks8aE9Mpxx6C1swDx9KX0Z1wjshjk2l+7QpMd4IWFisNhoxXM5tvjreYRMaW8E0T0EaF2cXguyKqkTju5onDtKYJTuYD0dT7JTtr6MOwnoWw+/y1JxE2aFuUSvtGqClwg4a8MJNl4FLDA/F9YN1vMlXHyW/Y1PsPrsmtKHJP+fMgpULbQezj7NgxBqtgRyZTyBwau+5fWvfgH/1Kf4vU+8nrPTC35uFMZeqSZUqUhRJhL7anMWCWP2lr9b3oz1Hndx+axjhPUcuQEXJrcwYO0aSxWPw89KpXvQtJYbvifdZcnwNo9YYIjPyD1MI8yWxVCOk4elguPemRO6EVcWsGNZQDlx0C3j+KHgpmbb0KDRJ0WoeG7Ze6P1mT5P0HrGJkeRjOTDsAdbJeF6GuP6vL9RsiwYQd4vh6xq9+gcl4UfiZ/iQQM6HEKeRAqia1zc0SF/SMlJRfPtSHBSk8aHe3obxPdLz6VJHhQ9ceCs5vmOLq89KTyHp7YDnCACYoVlBdXdcYtF5iJxjPLdDz67ES2RjcNXqE+viSKJR/dkHgoFukHa13kCuMunLKIhivcYnPuiuxZNL12LjqssqpvktFl0jR1yWxgOQGoxUvsSPJau4qHpV/CeW8MEeIkO7UChyHHJFp6YBUieDW4UJ7dcNnAwCvayZBEnbIJRe2yYi4FPyt46E40+VJTku2GsHMZtcu8kt3zL0iFpQCQJfukQRJJ3iBFOOkq1gCQWvpqZH+zCLN/rALsBCdf2amGzryydsFKYMS/x3mss0MSUKZj/XPPKQ6zSiKEzcc7Jpz7J+kbnLd9xnZ/qrzAX5VSOaRSGUhkYaBhFMw54cfeR6OUX0nHLX07RAwE8uJDL4kCY0SiEHh2NZIplFIF2oAstee+eppDiQTHqS/SDZXcHLHJWyelh6bw8x7046IRDyh8pxCKWOUWW64hDDyglm4HskO5JMCPPfDajWfx+ZnNIcBdsXYzFOGVSD0hcQhQhoimtlIV7j0NmScVr7wRvc7kWTQg7IyMcymM+ju1wQhVRaTzhnEMLc9Bkuzos9KqkcAWrmIziIA1vPXDY5bpDWKiMSNyX0cRKRjrH77Jk30jyJhdMM4AFyx1D3m8KS/DfspBSCBEA//RS7tc/XhtFcjmVeihhWjAdEl/NkTUlTJLH7pLj60kk18UFpRvdWy50BKhEdnmMzFbDyFRywxbPH51bB3xwahGKTgBphRa28csmPV5yXtiSeAuwOCX31MWKEBd5YoRFJEKvFKiCDCUVMnFFdI8iKN2xVsIMQSIvpsiQkQOxcKl7WNQUy1nrEvSGbFdjdE+QWktcYEEXCQJwDZc39nD4/RwPmEGWFieeXjz9H00ppcVnUFaI7xBvTESWTkdAw4W8tol9Ec6LcOF79g5Xp04b4PUXN6lPPcQ3vfFb+e5n3suvduG8bNjUINhXFHqjMcfn1gkNLg2VKKThwxnXRJEYjSWpWFgPnqlK6IqTPtUFZgkLszqAqCX/0CnJSV0ykUQKLSGJ5nHopkL8QLyWhIhMlg5IDtv35UaPDi9IKF1ClKWJ0x20xrn8CJlfejOq0NSZ3NgVZ8oD1yVwxJ7GEVEK4rNSnLlAqzDmpHT/dauHkdiyg9KU7YUWG3E0sQ7Xe7nhB9bAcp3l91qOsHEPxnJEfelGl+7ND/8b3Tocej5ZEPB73ai4ZATsQlpPmh9LVEVwZXu5dx8v7IHA5qMhMc1DK7PaNR3Gltv3gGv+BtXpNVIkQWrBU5861yiazWBHY2w56pQS5GsJoq+4MSaU0SWC2yMQbymihSoxCrXkcg0EdSQIuhpgtijRGTToijPnhaU4cXrXHqdeGNIkniXcs5zK8c58uUiio3WVjG5wJqJYaS3IIEgNki8GTE4vM7sSN1pP5/G43w3dtjhZa8UExh5haAs5t9NRr+HuYvdA6INbjUP1sFSLLR9BmEeCTxZGgHQitUcO4Hx0ySW7kpbvdwSh7QFyc9uwdKAZdWQszrnEEmfo8GjCIUdSOGLFq8OKzeUrPPyLH+RHUH7sgYH//kFlEI1OcjJwZU+Q67sZc27Mm4aDkJSKMFASf0Nm0BqfhVp4LJZKKaswaSUIx4VcDGpLzut0yGvBwEwpi8m6LHe8HZYdi1TVSkhHNQuk5Jy6LGWwTkR0FLoKXvPG9ygKHT9slM2NPQG5rEUYEYaFpkMjbTXZW8QSJLyXZ1jQjlScQZzRswiUxSiFZazJhU9cD6WE9V8sj8J9a/BC8RmXwM9NSy440xAkbQtjzlV6DxNfmBHZhZ9q1cOYnQsAlhY73qIwyY41gKRZdAatuSS5XwIrXcqnw+LkJUQCQZhfxImhcTNG4yCaJsIxBS2HSmDIUdAjWTJysL7S0gZeI0VyGTlUlFIKY344E87cwquRbvR5xobOoJF+duB5QfIKA2kI5kN65eWHVGWRhzWKVkTsMGIs27dq2e0JzK0FfpkXcpC8Q9JYLFr7yMVITk8Cz8u14UQH17NbQENqWYdKrUMUyiSbt+SOObHRozvSwyGmd4OqbCuIwdg7K3GqO3sxVlIPF1nM1ByUDQthVg6kaE0sR6mkYzbGYuQRv0mMWtrm4KuRl3ZCDGKa3ZSFdNPJmwTaoKwJoPDSG0dlYANMOFvp7GzmZQtDkYfOnNXnP4A+92muXXuK7/sd38ZH/CVeGh7CdMBtD9JQq2y1MpWZ0oxZlEmhaGEsI9QxjSbs8FrNhZLvr5SK6ADU1Abfw9BcJIqpWWKDHoqnxI5pSeXJLetiBq3uVA0N/pIvHQ5A9zTN84KXL2OGZpaMR5fbWJQf2cf4AuNJYnYxkkPgytTEN0PQfeggXUrGL8fN7IvP5FKYxDMELVgRraQ5dJ8C8slC6cmGaB7EdI+3FMFpaXAQzvrLXj8Py7x3ImplXPjhhA/WfV2y3aP5kAVX1A9BYfiYIEoP6tOy0Fm28yxdaVzbXWBYFlGLkoeI4ejuGRVraIt7LxabsQg9UMUIon5E6H35kfs1USRjKA5idAjmHavC7MKQHnvWPOVWnVadtow6+fd16rhp4lPGUjCjA2iBZebpB4G3Fa1B7jUBCw/PReM55RspxIdhFpEL90YkOBDskKQNLR/i8mdjcbYuBGWolsI4hPQstOgGvQVonxdlyVdREkfxQSmrUNLUBpvWGVqPzoroXo0YvyQaZA5txoIPLcNSVM2gmZDdtIQLdvDjwgBgGzonJutMOZphQpHCiFCJbn6QCDmrLpSdc7cIt3zPLdtTVA4GE3uBta15jM41N1Q22OoxWL8eP3qCN710zB969K386O4V7pwWGIZgCJSKW8Gl0KTH6CchkZtVcSnUopTqSVrPG4JCKRUtQ24agtzvohTLQuLgHu5O91ncRF0rDtaQvhj++uFaWyhULI0S4Gl/tyw13INWpLIwVEmFqiAWRai1MGQO44lY9pV0qTcpsLhW4eDJfXDHWhwHy9+LBZrHhl4jSM2zfTJvIJUl/8Z7xBzgRvMZlFh4JAe3986clDK3eEuKp0Vc2pfZwjTxmEp0cdmiJD/XD5vxw1zL8j2Jay43viyXZUIcyqGgLXQqX/YRSekKz854AslSfDj4yINygTR0gVNzOcU9ClbYKvZ4vxa+6Jd4vDaKpMRoAQcGDlaFtQR43V2ZW/hBkpQalhF3+d06sQUXw5kzbP5+YkTFpSAHPKXk6BSGFpbbWM0tsZBmCx5a4NJBPTXc+cEfSEbZCR8iLsnTHg9T1fglkeSI4Tm69456o/QWcrQSn2jN4t8VfKj4oBzXIRY03Tm+FMY5cCu1heybo8lCZF427wROExtGY3GiXjLESev63GsFN63H3dG9sbeZrccCydwpXlkJjA7VKoNWikiQvaVzw/bc7uFVuRFhhXLFBx60FVIVkw2vIOzEGM4+y0O3Po3fOWK89dW857u/ny+87pSfaedMY8UmsFEYesGsshNnZQFfOIXJols2cbT3MM3wTiXeSymVkhi055JkMVogvRoFAR8y2wVgWap4uOTkZCGLUkcFLYF1eVJsYlx2LI1Qelrake7aS0OpLqGC6wFpLF3k8s/g7uYmVhSVkSqRDU1TeosDbBntJaky8f0gFQ5Z4PHBR95SYpKeG/LlXmvSkB7wU0xikZk+W+Yx9OU55rhMlrX1wdU7mg2V+2SFEtPIYkuzkLdVk85jfm+pmf9p4pTSDhzHuBYX3u+C8MLgfhja2oE3GhMbfeG/BBCsfZmOJBVD6f4TFTuYJ61RxfASS6wv9/jNxDf8F8DvBl5293fm1/6PwJ8GbuS3/Zvu/hP57/4N4E9F2eJ/5e4/+Rv9DDeHHp/TUEJlMvuI+BFqI3u7BJvzpJ8Iv49soylIC7cg0wn3zgJTx+kfmTJdA7uKBDeCS+UEZytHci/R0fU8batEFGbDseJoz041c4Malk7qEaAUIHKnJlnVXMP5B0BLYGcWedFz8sGKKF2VMlbGQRmW4q6VWgNUCcPfgA8mg9HmKJJaYkHgEKyWkGMGI3q5YEqMIdYPJ6tqQXphlLiwmiwysMAXF5eVyCqf6W7M4kFncmfn8bOqd1a9c6IDV1DuiPOizUw4A6E9n6xxoZ2b1pi70sQZBdYOV12gnnAsD9G4Ap9+mR988J3cKPCL5TZVlZNJmPUILY2VKzvv94lEDLzT2tIdObmWpauhEtzKcJnvAbX0hi9pfJpFzw3Vgc4qSPFxWqAEvNG8Lbz0e52POt5T4y1BcEEsNuNJeu7FmA8UA4FcmtA9Mm+WIuARBbzo+AMJ91gyOnEHq9N9SoldjwWVOcJ42GqbOkWDIiUpzxKg+z6bglAa9UOhzVHcQaZYCunCzLDA0WdpySk0Bk+VC9HDuUcHq2r0dBpy6Qhzbr3lcACIxOe1uLqHG1E0G5LLk8VnAM/7WcCJDJ84vJLb3MEtmiQ9GBMrnT3LwJSnGLMELhvvg0XUhIFZcE2jO1fm+3D8X//4zXSS/xXwnwB/7dd9/T9y9//g/i+IyNcC/zPgHcBjwE+LyNvc71lyfqlH3M6J8yWJaSiZmMgAvg4APLz/wyJLiJazC11a6j8XxC1voPx0llyNqhJ29rpgR6SmNcf2pNgZ0FXQDnjIA10k8qtlAexhyFTHHuAMi/Nyv48zt1AlYsyIrmehIGluSEtdUVYVLRoqIi3hIKQgaoyjgniMYd05dmU0Z+eNmYHxQFHpyQeVe7pjAInOI7LCE6vNzoEkZffeDl0uCmUeoM+4Kk063SLru4lRJSIFRlY8MIxcoYLArWnLXTpTXAtUOo+48DovXNeRU6+Rg54Y1FDXFK/oRaP0l+Pzf//IH//Wb+CBXednx7uYKnMpzEP4Lg46YAW8RiphWDBFaJlIRz0OHklvx25TjGem6Sw+U6yDxt+3KjgVZAzbOiec3n2KA8bvRUSQBrod6G1KuZzkbqLH9egl730P8+C4hOKfPag8mgXOPfXfC6yyYMmE+sqsEfay+dl5pVHCK9Li+gxN9OIgla0Y4TiEN8xC2hiHI/Hh9h6fg0uYzpb4Hbq1/F0Cyqp4jtd++J0CEwryjXksRMvSEwpB/8rb3bOFdu94OFwkPh5YqSdWuix3linIjIioXQqrQ6xmkj2SLAXECbpe0OZCCST5hgd+KibU2WjFsAKaz42nAU3PbnypF1/i8ZvJuPl5EXnTb/R9+fh9wI96rD0/LyKfAb4F+Cdf+WfAfo4oWU0lTeRYKON6Q9EB9crMHFbwEjSXSmzRZtH44GxOjmKcEDGJaC5NopvwWtLUM07HKJSWI/A9bmVgGrF9vmfoHFhoXMyKSMniE9rQ5DYk6TgurEHj9PaS/5R+wEUSrEFLITZthSm5oppoS5HoOkwCb2vNGfedFc4ZkfbjZtmFOHObqTJEspzEBQohcYzlQ7r65RjkbqH6OVzo0cVMCluHnRgTzpTt24krD1N5uBxzrBvUYdsmvsglL9G40MgBmjw2tQ3nTI1XZcsOwIWrPnJVCxtpDMVZlZEiE8P2LuPzX2D1y8q/9JYnkAcH/gGvshsKPm6w7gwtO/i64FS2XKcxZsnyZ83Rr0P3MGjoM8UCBzwYSUhgeDEexNIp4LtywDEFzfc4vUhF6D04tAv0G8VgMa1Y1DLxHofPYaQsMjfoPW9+z9E9nsFsObQS7rAwVzlwK7PrITH0ePpQVwV0RI73kr1oVOe41mPUNYnPWoPkiveAa4JWd8+oN2S6iw9jMAHwRqel41VeQ6LhqJVOS0qYxASH8x69J/aK8QJj35ljdFLoIKdJJ+WQuUixXJax8C2z21SY6RTvGfFiB6xuWbg6mjFXy98JWlbsGSXNjj3bqt9CkfwKjz8rIn8MeD/wv3H3W8DjwPvu+55n82tf8eFA64nZeIyW9NA3dysUHVlVp6wrrSmeaozRo5OQJP5ixNibMsNFZmWAqOMVfIiLplgAu+5JSHcHItlNPFHFmBFiu67x/aXEBh7udZFBSgc8aCctC4p6GmvocloC3pOkLCw+giIl1Q6CS6FLp80zqsF7tDnxL4O5OdPFDu2dWf3gkxj5PE6zjvQkzGZolbBgr8EdQxVpsYyxw1ImYQd3ujX2MtGYkN44FuWaDFwtI9fqCuhc9JnP95uoFWaUj+jE8ybs80JuGt3mK0WoDl9F5Z2+5kSVrUzc7jd5tiuzR4Tu4HD1YuDtN6+xuvU89sLj/P5/908yXbzCz33687RhoO2MMkxgU9x0LbokT05fbEOD22q5ce8+RVHJeIdC0KUW5x8tFc8QrWXxt0xrcYgAhJmypWmDuGMelinLyJorNMBjfE/qjeQC0MnC1g1rHemdejh9nd6IDTaWXWmjaUsGhB/01FHg/N5kwuI/GhBUTVuzRB0Om2iI4mN0VLPCdgUKrU33Lk8L7qAVkJqihEgtIyBrZ873APMD0wM1rLR4BzycqWKjHU3GIJ6mxBwoen7oE2r8Posphkcx0y7ZhaZM1O6lXBYPiIHsNOMXsHsbcGKz7RZsCHWh9iiJLIdHFIb4fPnyoOT/2CL5nwH/DlHf/h3gPwT+5P+QJxCRHwF+BGB1NLLfGyYzonPQN7rStdAkaSauqHaGIbabKpUBAowtoDZQWmXSQvP9wcEFDwKtLBk6krz8xWZtAd1TsVI9pEymSU4WD6fXxEdUIvt5Acud6F5KRkzQO4NVbPGNlE5JP8nQscbYB9CTsuOzIzV9LjV8/EhstKvH+DJ3mkVapF60yP2zQiuwSs220zCf4nUzxGZSSxbIEnw9D39MzXEFD/5ZwFQd643mHXzPEXC1nHAsR6ylcM7MS23Hq/2SuRrXi1IZ+Cidzxm8IkoXS8xW2Luxkshfeb5P3KDzL/iatw3HvIVrwIYJB5soMmNqrF3Yn15w+b1XkbeN/KFHvovhoSv8zK9+koujFX0+Q6cBscuwPdPoAsLIJIpdRM+GgXGzQmUIx3FzJhGGlJuqhHhBEqs1WhzSnm5RWfSCOwm9LQxBwTNO1SRNnjVp/bZMHvcORSwXeH2BB+J5W9KLoiHTiEaVILtI74haWPqk0qhLFkQJbA1TRg+JpKaMt4uhswf25pXBC12ClL7EFfQ8AKpY0IwWPACJ0b/GMk4IDwMXD6qFK2olpH5daJJbf1uu2ViQRcORPgLEGByFdenCycJm+UUPEYKHVj0rbXI14/OVnPpwCVMS79mp1/BjUGHo8Z43iVVPLNZaQlXZSEHwmnOWs+xuv9Ljf1SRdPeXlj+LyF8G/tv8v88BT973rU/k177Uc/wl4C8BnFw99v3UmTVOpJV1qle8BPjbiIu6lAjlUjjExrtG/2c1gN1xDkmSZzE0zw5Jg5Gv2eLHd+WFrjlKWfA/FnylJJ6YXthJE1h4W8uf7GBmEV1ntPjSUwlQyE2zRqFKd3MgwHhx+jyDhXtzTXzIRZjN6XNYT5WWY7cZx3tnSMqDFI0YVXLcwnLEztFxGa+iZQ701wSjxs2Y7MK9GmKCloFjGXmIUwrCpTdu9IlX+m0ufMcDVB7TU7R1XhpnPvLowD++dsQzl3vOb1xw7bzzsAulCM8PBZlhZOBYjF8W4RmbeUe75D0r5S2yYjW8nnlcs5I903yDu2/YMP/B38YnrzibD72fx95W+APf/M1s6hX+zgc/yFQ2qFV0vw94LW/IgqQyJPCy0ExycNUOl3MNOpRI5il5Qi7x+bnEUiMycGLdrVnUeg9+nR42xQLpKtOIZEItkRvTyJt+oZ8AC+evawm9PiV3tj35l9ndOCyU12V5uKifTDwOUemLPXvi0CSOmCtLjxWwIMGL1BwmPQ716MzCoDdrVFyO2TiYx7UQTJFgxYYDekAUByOW6HHz5ztIicZsWcRm4Y2fGy8gdkCeksP813lYB8GevLcWXXLYz8Xr7EHj8Wg6Sk7IC6tDdMHu7SATjmufw8K2eS7FCDnjcMg4+ufMkxSR17v7C/l//yfAr+Wf/z7wN0TkLxKLm7cCv/Sbec5uGuah3rHWGZrFRUinSw0L+EAlqAu5dfmPBrVDmidoX7Fa4wNfHIhzMxaXjqJa6WgoGdKQ9LBlWy4elq5hKXKWOFdqTJeuIEcPMaIAWQLOBLYaF27ywxauF3E3NJzJHdOJsVeolTIovUYR7y40kzSRFcQrm33D02TjgDdJPGsob2awgQNPjZ70i1A0WRLHRTq1hD76dCJcZWpl53BjOuNVu+Sm7zF1rhR4Wxm50kdeFOP9tudzj1/nI7/nG3m1rlErbG5ccvOZl7jz3CuMN15lfXHJLe1cyMSjLjw6jnyxd+60C+7sLrmj53xjnzmyR7h4eM3zT1zj5e97kuktK557/4dZX73LrV3noZdf5gff8U103/I33vt+5l5pLqGEkgE5EJLj0GgCvTS0zxSb6bTAhBMXs2QlxKhmuSCJK2NOgwyx9Od0O1xjkXUTB5XkMS3LnsAdp9BVmc2St5h8x0C3ccJ93C221t6yE9O4Pjs5Oi7YoWQ5MgKT9IHR12kIkR1YzVE5MfBIDA28zxPfHHLEtNxWSvplxqW7HO6J8coytCrLVslVoJeYTlxzfI7DpmlL7XhW2jyoF6bw4tJF/rm3xuKkfpjxNXB9kAPkqljCFgWze1V+CVAJBoLcowDGIAGeDYGE21PEmwTkEflFefdJYMj90En+FsZtEfmbwPcA10XkWeDfAr5HRL4xn/kLwJ/JN+GjIvK3gY8RtNx/9TfabMffg7nNRL7ynlaGuNBaQ3UIyVwWGTlskgOntcQrFpv2oEPk6SsaYGFysw4cM40OatGSEpcvVoTew328HroPSb/JyO8Iu/+8fhCEsLvCIpelN2PK66J6+D+qka2+JS50L4fHiU2iouGLWCTdlAX1wtqdqc9hQBslkSEB51gBwSiFGWNyY08/8Dxj8QSSWt3uPYwSFLqE8XBPCOJW3XNn3rGfs/gOwhUvfL0dcWQDZV247Vs+aZd8wDofOx7Rb3k7r5ycMkwrMKM9cpX1o29ieJdT7t5BnnmRh2/d4pSGXz3l8vrrWZ+fc/5rH+V9z73AR4Y93zJ9nrfuXuQLw4obb3iUx1av4+jVV/jUK5/jsVdvcvfmLc7vvsq82/FD3/rtPP38c/zUhz7BZXFqV47rGi+VuQxQBmoJupPZDnaX4fyD0zXkZ4XUKZunt2HLjns5zKKkFWL09ZKdp2ho7i2TNmvMhSl/iCKRxPGi+dySy6AlArcWxIa4JM3BI2faNMj9y8EcXqRxgFYRaqmsfGAuE61KxJdYFGHX1Iq08D7gsHEPiAgjnXBSGpnXrxLX7NK33X8vek5QnoUwyAvRqRfArVHIIE9JifChwFnen3bAcPEllTTNZNxZ4nijKqcwJCteLGo0qVDEtJZ9qxNSw2Ie22qNz00yCfIQ8idBzk87hcO9Liw5STmaZxyF3Pce/PrHb2a7/Ye/xJf/ylf4/n8X+Hd/o+f9dX+LQ8SmCb1PMKxxUUxnvGaCnkt0foNELGu6hwRTxw7SJ0nsMKR5kjSI6JSCWwXuM8s8FAFRMa6qBKk3uokcBRKyiQsofbxN8HQHKh6wQLeSvNbwwRRxpBVaycRFI0nMye2SICBTUv8btpGoCGPSkhxlpcqqGFNuaUubUXEmKaADg3hga6qHPOhoEKJALFvBhjFJKCom78y9IbMySKXRGMU4UcGLsJ5XHNcNtShbm3hlf8HnfOILA+y98uTXvIkPv+mUlTttMPZMwMDgA/NQ2T3yIOWxR1mZIyXGu5d9g8jMlbe9Afvs05w34yduPkt/4dNsji94w75w/NLT9LvXGGf44vYFHjPHZmd7d2L94IP84e//Hj75hc/z8YtL5jJy4YqMG2TcoOMqnH32e7wnDNEF93ZQ/szERV8O3MNYtBz2oQJVWkBwBUw0JKktu62iaM3jyYSeHaKm9j3kcWP+vAUSqbiO8VyJt2n8AZ8HFu3TsNwOmoQXD9ls0YGJgo3O3Du9GCohm8XToidmehDoFXrxg6FwcMDLgbURVJpIWqwS7IiQ5y7Gtpk574JrxXooj7zPaegdIzy+xIHE10Q9Cdv3GgnVIHE3kofLIgBJE49l5l6eI8uVZqkUkaA3ucV9q7kDSIpP5NnIQX0EHCzy1EK5Y2EBlEu97ESdWBAtiZH/vMftf/6PoMzk68d6o4jhpSTGFK40vVR6yCFinGkeRUfC4KLnCBsjd1zUnoqdML4VigYhdhG8a443ztKp5jidkrr7gJN0ekmaR4Y04SktdKKD1cQj49ZBUJrH+F1y3DaP6WFRylQWZ5i41m35p4bTiaKMJgxI3Pj7HaP1sN4qhU4UgcEXQf9iCmALbY7FKzG04o3OzJbOHK+QrtFBzy68zkau1CPuaueV+Yy9z1wQ+M11azz4+mv81He+nssTZQgWDF4K836Ke8sq0kvyOQbUCtSO+g5QztcnyNvfwuVs0B7k5FlBnv0UF3df4ZUXRspV57EHHuGLl8/x8iuvcLXN+L7xqV8+4TueeBP/8g//Dv7Cj/233NYNNh4j4xFlfYRXZRbBaqXvBW8dNWOYL5FGLC6IPKTaJHKC1Ki51PGcGqREh76olpBY/Nnh5o7tdSQhVjrh7BEa90LxJECneYK5YhIcR0sHKrcdWgTxzFWXWMhMSa0QnDXCSCT+6TKV9MAGl5iIJa5ElqvGhRkDCXCq5CVs5gltLkoZsjAozWZKHuSu4ahaPC3MWm7T0/fRszNsiYEWqQFpZS4UvpDb9DDBuPbw5LSgFUli9/eI5gtGnLVg4U1CwkUxJpdchgZrKAqoE/ze3mp2pUuzpTTSWi3vayXv92XBJHlN2AIOfOnHa6JIigh1iEhOa+BS0yFlBjrFQIrQpAcVYjG17REvu3gimhJdmaa+1AOEni0KgGWIWLTn926a+zNM2oF3F50nEBdoYOF5aMcJnxBI0OAFVCJwqGi6t2h84Imx45KGFzniFg1DWK+KjpVhrJE+KBIeisTF0IygYZgg84zM6UrkwQ3zJMlX8WXCigvbw1eRInQaESgVyoouziWNM6JoH3fliqx4HUecq/F8e5UB5wErXJHKWe1MPvOWq8e89wef5MNPjmzcKLQA6duAdqHt51DvpHnB2oMCtPcg9qZggm5xgA3DKfPjb+P2tKe98nm22xuUrfLWp76axx97I88+/TR3z55nRePOMxue/pV/zHf+0O/nA5/5Aj/xqefw0+sMdUTqwNI1u3Rk2mcRCVdya0Ei17xu5q5M3kDmnEqgqlLHJWPdYTHMFaHozGJ5Z14Og7ZRMC8oJW+2+AQOEj3xpDU6tYRGfN7vWAwlLNqmoJeJpl46Tm8X8KqJh0ZJK076CATDY2FwBMUpOtBBa4AtrhGrLLA4/CNBXUMXskws8DrpOuWejlBhEce8j2nJ7jPXXYob94qL528eXeJ9zlr5PlQrWMo541SIn6Vwj3GyPIFET+ken8tgeQToQtxPMrlnV+okYyDpPdxXGCX7hHyfAqaLn9HzfVuC8r7c4zVRJEGSMiHgQygTPARJJUHmbk5rDUypNX7B1pMZauEa0krgJ0Hc7kHSXjZ2qgcssHhSXBdPSvJNVcncGrm37MprsLOcOPE5hrFAPk9KDouCtjR8Ja3SnINdW8fQYTEliCcfqyKjImtBhlD3WOKbJbNIZjH2xDgkahz33HQK4VCTPajR2ScbOtcIFCkhq/TQYveMAZixlIaBaKF34ZY2nuEW16zyiNbsZIQ7pWPMPCVrpjc9ygfeuGY9FXxtFNnHaGgjUh3fGd5jKaAe1JMwuh0OHfwCXUBjvXfacB2e+gamO+dsz1/i9uo2L996ieMrj3D9oevcvjtxcX4HLS/whY/8Ex5/2zv5w9/1HXz8lZ/iueEkCOEQCqE2w/6Scn6XcXuO7c7obcZ6kKG9+2EMnyUWhYNqch07OyaqwVhK2qlJwmYevpOJOx68LCnRIQWPJyeBjsZ+m6qRn91MEEI+2XqLBWUa1gpxEAuEd4AZMsAkxq4aw1DopsikSCnh2J8RtcsUtvgYuAhaaw4QQlMN01ySu+nLZLt4RIbD0eL0FM2y4ZJYO2lyvEzEtkz2iRLmc9yLio1r3aXl9wnuNdVlenDFSv78vdeTBfLARsKzCUnphTgQdMB4j3P6s/i+4L8eblmcKJBqkl3n8vXoyLvFPUEuM399Gub9j9dIkVzwgZJhPYb7fCCdGmlx5BLmD64Hsi8izMlFW0zYZ++Mwz3yrycb3yU2vB0OlvHBJ5XUriha7mEkmi4tCXHE60QOp1Tg5AJawvrMlao9QfQWnDkFrKejTSxRRIUhSemqgi2kXcKc1RIH8B6jvEtj9jArOFHhAavMWaCHJLGTi5mtGmtyOysa21Q3ImO70yRcfaYcYZqAmrGTwokJ79RjBhXOrXFLjSLREV5H6VfWvO8bH2YrIxHP0KkamOYsSpc5DofWUlEi9CGKjyzZzXmnxYVfuaiFLs4DwzHrN7yJ9adu0fY7zi/ustENR6uBtnmI3dkFF9vb9BvP8JmPfIDv+L3/U37fd3wL/8kvfoI2jrh3+jyh+y1yfgcubqHzOX26oO0Nsyneg95iJM0lmbrjFvheUc+YYHBzqqS8oAT3Lg7FeCwNjJATQ0I20ZU0hDlw6BKHrojQ2oTPTrXOvqeVmOazGcx4ymljO+7WwcJJfvHzlJxS4pC5B9AsW17PQh3FNLDDZerRe6dTGlgFxr8Y4HqPa6+KMSP3LPgsts2LVh38sOha3PAti7VK4PguSXWTCNDxvN6Wfm0pZFHkOfxOwboguuKcunoqZVTu0YpEcunS7XAwueZfJihC7ZBJZfcxAELnvcAG1lu+Cvuytek1USSXlbwgwSuUXLi4hCMJoFoYtSIU8vcKf7h0qFnwGHpkv+wLSVeQ9McLsDwwCNJlRTl44xGYkEgQftOg/lAgl240CURoCU1v8QJlQIdVnNStUXTC5z1tcmabQRbnmdzgldANVy2UGv+EwHasBaWiUlGtYVpA4kwIV7rw+klo1hjcWSvgMxWlUtmrsO4ROtUJusssjb1PmIc2d8a58M5WwnHoqleuy4aTOvKC73ihX3CEcFUGTmREtTBL5eLr38zH3nDEJZ1xbnQvFN0wMrB3A4+OpOXYhnVKq0iPrJ9S0vDYg9kY5qodoXHJwHDtzfhDL7C69UVefOVF+u6CB6+9jpWv0NUpZnt02vLCZz/B7eee47e//Sn+0Wee4/23pyB/n51hFxeU3S36xW3mOQjn1owyN1QzuCpDxdSCg9fNoffM5A5fUasW8A4W7jnF08U6QNjFPVxKFIjSC1gsQRaVVdyHTriPpHlw7/TmMfpqi59V8iZtkU3k6uFlST8UtSWZMyIIcr2hBE3IOFytJW+gGE8V9XTzSZcmST6jU8Oo2g3yvgiqFHEtJsopeGjeMWSe8+X4gd3hnnG3RaIry3Cnw3ad6BqD7xzNTPwmLCzLdJ+KInWviArNFwAlHtbnLHpRRD3hJBENsn3m1+aPjb+ZVK4IA8yGyIINoz2rMpKhf1/68dookom1LlyrOI2Alr9orPjiJEpel1kPqyiPi9LyieL+7FHKahB8Y5Kw0MyaZ1KbYKVQLDDMqsvpmMODBwYS2JLkMZbmEB5elOqFVgttGFjLyIqBWTrdNF3DpwOgrgiDFxoCJQpEK+EiHSmHHD4wli4CKBI3X9VCUeGkVK5OneKGFKjWckGUl/TCGkYQqeA1VAfqDAhbMy7p3K3wYB94Sz9Cy8BLtuUL/ZLZjFMZuC5HXK1rrpaR7jN2dc1LX/s4N49mxqnC7Ixe0Brunb1ZQk1Lto5Qe3RZTSygEPTAFTWPxVSMZrF539YBv/4m1rdfoV5cckegyJrN+iR4rbNR9mfs7t7l4x/5KL/tySf5A1/zBj72M+/jjq043u44n25i7S60S3y7ZTFHVoc+9fB7NEESt4uo1zg4g3AP2iTzaIK6okOMa005dEuzRVcVhsPOQE/pYkwyQx7S3mOEjI2ysffA1YsL0pWB4P5JErpmjxt7YBmnY+otEomhqmEerB6y1SpDHN4HzNeWAYsUvcbEJDAdEibJsVYOvMzYuMdQ0lb5cy314sQh4ma5nc/OTOTA0gglTPxMl8TED+2tUz26zs490v4SptbyvtbUils6+7gRcc7xSpPz7Inpp7FMjniLxDh/q6gpNnHw28xGJ36xpD6J435/V/6lH6+JIokoJkNsFsWTiB3UkaIVk7jRujtVhaoFMT0YUhQjOrBwPAUE5rBNcyuplLEcX/ygty0EWI8EWz/0pJKEDEBqLmDiBB9yoycSF6sJMFSGYUQZUAYGqcjsoPso8J4pfBrk41pqJMqVON26xKjfutEJrKrkYkdy3KlSaD5RS7gjdZ8pUqhoJhqShbvcw/skERjvaIdhWHEue271HUWEd9gJV4cjztvMp+Qurp3XsWJD5WQ44lQfYhwK0s7wwbl9UvjstYoTjoWxDS9peiloc6bZwDSVL4BF5+QONUe0AybJ0mU5TkP6jM2Ntnkdu4e+Cnv+Y5SLzt1yQS+dWke6F1bm9IuX+Pwn3s8bvuZJ3vPU1/K1v1R47zMvMs87tDd8mqDHyK+dZC8AHsUJHehlwLQE5y+hAW/RVe0LTA5D7xz1cFyaDQ7MGOs0N6zFza84u+yIwjTXaGkOvES7mhqtQ2kh6Vs4r8Hlawc+YOsTjnJUchGVRVOdHLmhaPJoicLec/FYEteMNzdxfgkbh8W13XvgsPGzE5ZhWSAlz9MD+olGJHBBm+eAjbLoLqNtMCnShs9Bl0iEBC+X+6c0Z9SaOKCzz4kCj4WrKdnpJwnaA/fFwdsivsifSXahLkTUclm4BXn7p2REBClxSHqyFxYB+cIMgCFxz/Jly9NrpkhK3YTwnh4XOpJvVhglSOIT4uC9B/je4pdfVCx6QIlA1REPf0hxOXy45IlSXdKEaiGp5gm7YEykm3jRtC1TVh5fdSmhjBFlM6wZWDP3Ehv51sJKP9B4zAutOKaFnimG0oyadIXJJiQZchVHKkEu9gZqlLKchEYRobfOHXVEB1aW/C7rsWuVsvyCFA3ib5eZKsrelEu74AEGHtIjilaety03fMfrbMUVUTZeOa4bCoW5vcLehXE1Mq8qt7/+CX7xeAd9QLoizcMYpHXwGWmGTR5yvfwUXGMspRl1P0f3oaRMMNybOobajLYJbZ2tCv3hN3Blvo2+8Dzeb2NzZbM+YtATuhnD2SvIjRWf/KX38uCDj/K73vZVfPwTn2IrSr3s9MmxFlZ0EGqqvtwk5HimypxLK0n9dqFEYWkA8SFOZtjsjGlo4i54E1oXfLL0CIBWYzHopSPW8GFIS7xM9SyKW2Xcx2S51fismzlzekQOvYXSBPA+4baJTi3xcxavUMnWMK50XFMoK57qsPvGVom/EgGySUvzdASyDt6xlMda3hdri0mmWUT0WpuxeQour95/l91PnLnXOWoKORZljaiyVwuRQhb7yoJVxgKy4DHV5VvfzPP778N6RdCaS8qFssV915snlfCwpVkOknvzXCySQvttGdXRux9STL/U47VRJFUp6ysU30Pf4m1AMYo0pMdo3NMyXnp0R0b651n88uG3l9ScRUO6oOvpWhyu0iUpB2DhsBqu4DU5Ygs4bEGhUUKxwCC0rnHByTJ6V0pZI2WFdo/T1mdaC/wvzBeGfBELOdyQVnAbmEWZNTKhDSgFagtupA91oa2Dx7bRxLhYd+6shP2856SE4YCX4G0GF1OS+xcddqmwKxN7c67ayAPDFW74ji/4OZN03iwDR6qs6hrDuDPf5VhWrIaHGDYnuDnl8Qf5/JuvcV7P0CZM5njrtKnQvDEDPkOxQkvzDkGpLRdES6qlKy6eqXrh4mRmNJvpDluUoTmXVMrDT1En59arL7BrW45q42iz5WIYub53hnnixsdXvPjVX8s3ffV7+Np/eMqHnn+WaTJqn+ndg0yvHnlFaapqeQipGGNeJEMZckEXfpRgMbnMglilrwrJPqaZMs0wAcwdn2fEArqZVsoWZz0XyqQZM2C5fRWadnaJxNUuaVwetJ29C6UTBiso+BBdlje6FLpYuGebpGRyxhHmnKVVS3CCl469R7a4yJBQVmckSNphZdcJis7igJU+rAg2Z365lshY6vuIsSgxdbHYFdIOzunRTCixtIoIChWPLj2nPO1hDWc+BZRlsewck+tMgUaP4STvlQDSDCsRqDaogEcQnC/Iad6vVctByUbvDJ5yXuIQmGgMWTxnVUpPZXqJZujLPV4TRVJEqes10gSjMZeJTuSYaJ4UMTIrNMIWqvcDf3HhPS0a1OBA3tNhx4Ys+Yi1RoEjvBrRgmi4fwePK1y61YRVjjrSPYBv5yArrG5oKckEixHcbI5xsiyWT/myIHHOwEACX5njQ7bIr+4SDuGesQOm0bm0RKvC9LfSEG6vlcmNEiJXbAglh7iwauBW2IuyKavAeec9V3Skr4WnpzNekh2uwmN95Hi9weaZV+Y7XGHggfGUoWzQ3mjTjnk4ZvX4W9mNM/XyHHGnmLJPo3gsvCMFpc8xShUD5nCtcXHQSKdzIoVPOrjXCBrzkEfm8pFd6swvxlPsibewmiu7m89QB2diQrYTbbPnRAceeBm++P73sVk9xO/69m/hU3/zs0wGfd5jrYUDdua5i1cWzFYA6Uat0Xn3voSipY2/d5p2alK+vEc/6BaKjd6N1meKhbfl7GGmO+xLjt5pHNXjmvQMru4CTduhEyuTUUUZRZAW701fYmNrfJeZHyIPfLkX3FPFEg8lfC6TbYh5DyccVZTFXzUpLxh2SPc08Ck+RB1QHwBhKikd7C0Vaw61pNI3aEhFe+LPsXV3XXYKS9ElqEQWLup5eyZlL8nk6a5hOTGqhdgDXwx94wbyJLqbh5KoDJXWO7Vnx0gsXZOFz9JKH2Cn/B639GqVEn6r6RSlpVDLa3zcFhXKMMbJ0YfY7MqQcrHFjkkSKAYzzYKSdvACKXVhOYMWYf2SbVJLaFyrCbXWpPqEVYmoo2mKS15QgrO32MgqSndjoIIas3ds2qOEkmKlhapDfjCG06Lbdack9QGWz8rvGUwQI2HRoJ9YzddRC9S0bGtxIkrMjGxKoVIoafjLUiynRsW4SmVFx2XP1ubQ2+oK14GXpru8WmYArnW4KgMv9h2nXXioPMSJVNatwlxpYwlYYN15UW7wQd9zVp25N8okacEvYEKfA1ttAnPSe7TIIUcn6GixCQ5+XY57MS9Ex36QkkXs78SK87KhPbVmv1G2zz/PI7qnULgx79nZjv3lF7nyax/kYl94y7f/dt71hsf5mY9/KqIVxOgWJhg9R1jSm1ES27Y2xZiZRhexVohryA6GzOAdmpc8/JZiEzg4PbifXYUx83f2CrMH1qlS6BoHcxinLHQUiWiEXB6595SzZjDYgZKSoV652V6iRmIxl5Qbc5plB+eLMYZDbxwIghpMB+txL6lx6NI0u7LYpkf3u2h4JIs1hwiRdOISyTeH5DgHzreY6Dqx+DKi6+vWwEtquZcFSli+LaFl8b5owmVCXdQ8hGx4I5FzZXM/9JhxX90b+lMKQpFQ4UmJLbbjcZ9JxJlYlouFVyr1y5fC10SRdI8TWrQidUSHVTqkxJiUiRh5AeSWz4W5NBYpjBI2WWAHAqqTRTI5koeRNw6zuKh6aEtLbi1Vw5apt44zxAeoQs3NdmAtPfCcPuGlUrqGCYb3oFPk6Rk3kMU4LHLQjc8lXJVVJboIEYZSoDhDsIGQEjKydripQiWs3nj9vOJUV5zbNriBUsNfr8ZSa9Ui4XF2g2HkXI3n2ivc0JmdNZ7QDSdiXErjDW3DcV2HxlwnzthR3JiaccyKNgqff9z45KaxmjfMDt4iaybw3hq2WmmsUAjD1p4OKyo5amuQ3iUv41jQkfEIxM2cJPjwoCkMbUWvI/2N34wdv8DN5z/MFbvLWirT5cTl5pyXX/w8d8sRl6J873vezS985jOctSkoOGZ4XThl4f6uJcbe7pG53aTjrcf46B2X8JmM6y1ZDi1I2b6olTw6vmq5tZUkkmlIECMYo+dnFqOkEbxFoUccsgm1OqLG1BslN8XkAmXBzmUhr2dhXIQIEawVipROGFST7ykpwaxaQANxL1KzcoXfJkZm1XsaBOdfxNPQdogReoiJyqsyrIeQJrbABBsS16dbnIS5dcbjXp3NmPuELtGukYl6j7MoWVRTBWRKLluDqF9K4JmeCxvpkhLJMHGZD9t/XQiUS68dKFUPv0yR0Oe7atK0UpVWNL42FHR8jRdJeqefn2MDVA/6g2uhlRLdZAd6GE50embIRFeoXcNQVIgQ+qTORFcXUsSgOni6v1QKhrZwyKEQRgAYlAE6CVbHxkuyE5VSoKSZfWKhogRm5HNedI1ZWtrZB9+tIukJmKOxRZdaLMenEv/VQaPDVZirHkxbx2EMk9weJ/ncO2enylzXmHX2o0Dbo0MJ8wVTLtqMEJjozbLnRuu8SJzYX10f4MFuiCuXUnmuwA3ucJQmu9eAh2RgLUfYtcfhre/izQ+/mdOzX+F2CbOQCbCW1ltLo5wO5MWDA9i8BEWr+GGjLbKw3BRzSRaDJOQRnNaS2/FBA0EDuFuO4NG30k6Oac9/iKuvvMiVdcFL4c72Nnb7izzzsUseefIJvu3NT/APPvsZdsPIsFdsVRhaMBwiUbAwtgWjLtATzmgxfq4xBgcvA22E3o2qyqwtRm4NudcgBYY0CamK18LkHtLHzKBxASsG2iN+QzwcnJIbudDNtMbYGW58SqHc+zxLiZs5t9VB8C4pSQwFj6mjNRIBJZVDiDDTUDpaahD/lxWlL1ioZUYODORSRhWqMmhBC9SNonXFsCoMm4Heje20xbaC7gamNtMWhVh6M6obTC38MFE8+cdRP7MzTZWLkB2pECRvaiy7klZUNbBdz2lLeo+8cCIaZVkWLbDEMrWZO0XHcFYSY5DIuFoiV2S28HtogleF1cFe5J95vCaKpFvHLs6wVXDurE24h9msdwugyEKC1N1pFqa67jGaOUEqP2TVZFcIOW1Yuu0IMV7jpKdSbMUspFsxZOSN75IXlIMY1ntsVooiOqIWp6+nSavWQqlCnzzS+RwWJ3TP8bOMAw60uaemtlAKDHWg18B6VCW6CpHoct0QLXgxehF2Q+XyT/0RXvwv/yHyoX/IbMruze9m9eTXMN284JW7H8U++4HYjPfO1jt3ZaIJHLPhc9b5xyvhJYTL+S5fL8pT+5kTjEE2OCtuy5pdNV6nF6xvPcuNlyrT1aBneKqMxOMAQZ06GAxyCFKLOAyik076TakZKZGjkRbyYk9qcR4kRY8iVhWSKgXHdcXsA33zBLsHrnDnMx9m88VPsuqNs80lu1eeY72e+NA/+nm+7wd+mE/dfJFXVahWYYybFNWMea2InMZ2s83Yfkffd6Z9RCiI18C/x5GhFsSdwRX1VEIJQcmREtQiC8pWLwrd6Ls9zfaRuV0EBkeGlNhZiCJKSVpab0n5ASk5TXShWKUOQxwcmlxfCzWalDDJMM2iWhX1KC3S7yOxL1txiQPJpFNKZzCj9DDTFQnfUk8XKiG2/nUsrIaCDsp4PLA5fYD18ciwGWjuTBeX3Ll7zuX5jnGr1MnoC5TSWhThEu+PtHCqt0WrLcEWcfzQUaKJVy73bxLOSd7yQSO+vP95sJb7iqRITCulluBjWo/i2qLDLVWi0clJUbRl016QsVBXr/FO0s2w7Rn0COlqbpk50rA2J39tAdYtdJeiIVeipJg+xg580WbbvTeQ6KIWrztzgpxewuYpFDXBd1sA5lhK9MPYo066nIdhb+hg7VB0e5sCCO8NWke6HdQ+MhTKStFRaUCtglIDAkKow4isKgdpVwnlSuLNoQopoGNhRHnrt30P/93tgbMHHuTdonz7//pHOP/ar+bixjmf+8VfZPi7f5dPfvxDvOOd7+SnP/ohPnT3jFePH6C8/gn6w4/zohs2GuWVMz6qA6vROd1fUlcDXowP/uovUWrl956/wP/8iUd5ZnNBLw2hxuvDKTUIzoM4VWFaRXdt5rQpsdkF0+O+A4c8nNJ9ILqJ+LogFFll5028nlEYVyuabLD1A1R7gnr9Qe6Ohe2nPsGpzkztLm0P8vlPcfHM2/ne93w9/+iFp2njioIw1oJLZP+J1qDZWIdpR5/3zNOei2nmcorPLDwclWE1xjLEJY1JMh/GOuapdDEQC1ccmzu7iwvunidntAiUhhRnGAYqyiDKOAxQBO8asSVu1FICilCl9JoWZAvPMtxztJRcnEi43pKYGkI1MBW6LWTs2DhXGfCRsFcrBZ3zAlcDGSi1ojUOLUnFShWhVqGsCpvTYx688gAPXD1hfbzCgfPLLXV1l7q5ZD7fYttOm4027Zm2W8z6gR/rRmagh1ZtwSMtP/cFGhtqDeK9RcdZJYqahDY00c1cxuSEp0UOE1e4iBhoGuUUpQwV1463hud7plWT9G9o76gIVoF6D9f89Y/XRpHEaNM51uKmsQNTv6d+eaElzFHoHFTGkHNJKnTcMngefG7BHTtcZMJiKeWkjlrT53xZfpnmMgHwIN2aBR5oAKVjGvxDLS2L8bJAiU2g947N+5AVSoDEpRbKqlI2CkMWZFO0gTRixCfHqDx9w9ktMJSiMW5JNVSdq5tjnnn6s/zoj/8sj33zt/DoD3w3H339Y/zo//2v8umPfprTh0/50//7f52//v/4v/FH/9Sf4L/49/8DnnnmJfyy8X/41/4M73zHu3j2M8/w3/yDn+LzR7f5mCmbq1c4KVd4+OSEJ6+ueP4Lz7C5qvj3fwN/74tf4DOnr3IxCKs5ob3SD4D8RgtFK9v1onpw5r0wqLMTY557OmAHzWJpBBK3QLWFeom0A7MousOwZn18zPqksDodKasTylgx6Wi9zvCmJ3jhv/sxbnz4V3jo6jGw5+Lu83zw536C3/kn/gzTceGF4qxlYBwCCwOS6mFUc/p+Ypon9tPMxS4KpaowxEfFMAyxPPOQMqIRZyzdaN3CH9Fhnho7Jubtnv1mQx9ndDsfkgaHYWC12RConLBej2iJONfLrTBPwSHt7mgdKDagVEqpqe+P4hJeQxJj41BCkCManbdFF1cmD5xQlWEYGQahrKKA4slNLXGtIoWa+e5aJTe+pAJNqePI0clVTh56HQ89dI0HjjcMUnh1u+fo6ILtxcTZ5QVn5+ec373L9uwuZkafJvrsgFJKTWVQdH9dggMZPgrgechSYoEVC+pc0qriVRCNvCpZGC4uiVNyXye5fM2RIRqY5h1VR8dCKYqMsRAtJqFD70KpSvv/hyIJHrhekww7ug+AdYs3VRf6RY8WOVMHjR7cyTxRlg4mNlfRrYQyMQB013SYxnNsiq7FllNtwT+RwNZIsD1t6t3BtOcYUOhG4qALO6yxGK9JqehQqKNQRokoB43T0pAcvQYsnZ69JLeut7w5A3saCvhwiZmj/hB/5e/99zz/4qew993gZ++8zHNveSf/n7/3X7LdvcBXveEdnK7+RV595WmEC85f+hz9pRcZG3zbG67zbe98A9PXPM75+af4xX/vbzPPhh5tWA8nPK3K+33m5t0bbGzgF5454/rV19GrcVw00W4O+SqlCHU9UKqzKT064ObUku9vGZAdtCm6igORNwH3WjQs3kosHKzHIkNkpI4DJydrrly7wgNX16xP1pTNQBmEoWwwe5THH/yj/JPzM17+3Gd49LhTa2N7+yU+8jM/x7f8od/LF3Sma4mbpjhFYgGDBK3LW2funWnb2O327Kc9WqJIikEplUOmisUmuAL0xn43MbdGM+dyNyGtstLKqIXujZXsYyQXZzUOHF05xVXYqLJeryJAbN852645u9wytwZ9G53fXLAuaZIb71UE1bWYTrSACcOYm1kEaXH97ktDW0WrUjewHqGs4kOzJmg3ZivhcZrroIgaTompWiw6E1YSVng9YT2ecnR6GrZ0q87JMLE/mbl1fsZqvI2jTPOeMu0j2M5bSmTjM1frsVFOk17vmVsoQxwQqshAmiQbczI3ohmJIjl7cIYtGQVqGoF4RKdZLGMnSozUbjlNWtC2pEHs+Gs4hBEYv5QSRPkv8/jNxDc8Cfw14JG48vlL7v4fi8iDwN8C3kREOPxBd78lUdr/Y+B3ApfAH3f3X/mKP4PAEb21UEbkUoSkQkiy992dUmryrOIvLhbucy4HNGfnYiSBudMlNdfc07PG5jveqJCj5lBoUTwX9UUaitH7HDZmUxTsqhnd2RcNqsTGzoJqIEUpY0FXShkkT3ulK8wq2FhRK4wE5lSSFhRQZbTHXmMEb6sJLZXST3jxeeOZjz7P7tY5L15c8uorZ/zg7/wX+OE/8AM88/RHufn0HX71F97HcOl84KffyxtOH+b5s88yD/CX/19/g3/00Q9z685tfvxv/xiXr95BVxumdsk8OqvVwGYceeiRJ7E2sbs85fpb3sb55ovsVrfDgCG7QjxwMx8EG6NzRAUtdmCdUJxaClNReovTfWqNWjIKQMN1qSyTg4BruK2X1cjqeMPJyZqHrl7h9MEj9HiglPivqDI+8TD8L/6X/MM//xe488rzHD9QOR0rX3z6E1z9ucd4x+/+AV68Vtlh9BGGvbEpI3vdHcQI7kbbd9rU6PMEeFjotuBGTq0ztx5bYWIR570x6Mh2mphawxD6NFDrMbtyEfw+CoYzjJX1OHJ0smG92fDAasN6s6J5o+0b49kZ5W7l8vySaTbEB9ocrAspscG2dLNnMbcVcrEThVzrQBkFK41uW7xBLYVh9LRhL2ituPfohFk28AqZpqkSmnC8J5d0BKu0bWd/cc50dEw7vkItK2qF4WjAysy6GyfNuLi44EwHuld628V9mw7rqNCS9yve0d5xH5L2s9yVenAQWuzU8JBFknCMJj/ae1/IS4f64ZLKnLnjPXmVxAEnPWGM5GDOGtPk7DO4xLa8/dY6yUbkav+KiJwCHxCRnwL+OPAz7v7nReTPAX8O+N8BP0wEgL0V+FYifvZbv9IPUBGGWph7XIw2e1wgFbpGKppagL7LsgAyizdt80fTwCQ6CVgnnafEJrGoUpEDjaeXCGlaII2DLFFIjSeoJKM/bclscUh1ofWOe3y4C1E37LaSTlEdHxwZc9Tpwe3xlHaJKF6U5gELFEmoCPCqdA310GoIHG1/t/LC02ec39izO9szDidM7ZKLO7f4r//r/4yHnnw9Z1Pj5Vde4d/6t/9tpCgf/NCH8Zb8zmb8nf/nj6LDEBdrujz3eY/oOlRJU2z8jjYbxs2KWzdv8YlPPMcT37BhXN3Cyx43Rb0wt1hWedW8sHs4zogH4I9QaqGNyr4q016Ze4OxxibUA44IjDcoPyohIBAtSB2o45r1urI5GTk+XVOOBqSuUU0srVTe/u3fQ/3Xtrz3P/rz+PkFbXOX49XI/oXnef59H+bJ7/lmLq8MvKQzslGm3hioNHFMO7hSpcA44G2kzTM2d2ab6c3YTzP7KfBmFaVlQe8mTLOxmxpTSiBrLRwfHzN5o/WI7R1XK042R1y7dpWjK0dsxhXjOGJuXFyeMYVeierG2dboU2DmrXUoFlS0pTi6U8WpgyLjMWU1sFkdU7TS5s6lXWISGKiWWGy4SmzJtdCYktwdw0BJvBMtHIhGUmLxNklo1eeJPu/Yb3fcuXPJbgrFWu+duc3x+nqntU6bOn1uWJ+ATqkStK7sFMEo1pG5EfG/i1nFEFG+5L5A8p8t+LNWAWLK02YJiy3g2WHnR2Mx90gKkGouk3pwoSUmOStGtwmThqYqx+ffQpHMVMQX8s9nIvJx4HHg9wHfk9/2V4F/kEXy9wF/zQOlf5+IXP116Yr/7CO7Jy2K+FK4/NAZqnm6kWTHJ5FvUQiiqPQWOmw3Gp22yN5ilqNXh1oOXWSvQi9w0MsIB34XEmJ7JLXbySFz8s10QykpY7McLaPIOaHHLVqhFrxWmqfhqlSQCIWKoKeo9UF1jq19AVQrXiK/etBCacpLT9/khc9ccHZry+nJw1xMd6PI+0Atwod/+WPI+78AVfHWsaMT3OYgO4+K1g1a02RVlTZPMO3RMjCOYyyPBKzNzBi6WTNoweUSNePIr9HqGRdMmQdk2X/PLKaloQEO0F0EGCpFBnQY0XEIAvouQsa20xTvJcmr0+ROdmHwhRai9OaYFCaUnTtDj8XbqigDA9YGRhl402//Hdx56Xk+9Tf+Gq+cv8o4KGfbp7ny6iN89r/5eZ769nfzjre+kVfaJS9vb3PZGnNxukTsRXrXwmzMu8a0n7i43LLb7rm83DNPM+aJnS4muvPMdrdnN8+hGKlGF+V4GDg9WtHnDe7COK558PRBHnvdw6yvDIdwTYBBofW0DHGYqzBddGzf6HvDWsdLw0rASi0J+FIGal2zXp9yfHqFlQ60/Qx+l3nX6H0X169XVmVAgP12Yt7OtLkdYi2EzP1mptRKLSN1VJoSTvZMmdW+Z98m2sU5Mu0pHtf/1GYutuec37nN+d1bXGwvmKZLnD0iHSdNYzwEIZBTYhO0Z+SvKqIhwDCyz0mPSMzwZpilxn+OKc/Su1M0xm48TD+AAw68RKOUpcB4Km7iHYTZ0Sap0zf0oF/6Zx//gzBJEXkT8C7gF4FH7it8LxLjOEQBfea+v/Zsfu3LFkkH2qi4h2mEFj1kH4trOvQkp2zpJg+b6LjBmibrrITvY/WlIynISsI01aOxj604iId0rkqqbQhsQsySOxRqVs9toVtJaWFsdkNr6pkdEjy/OhTqakw5ocZWVTTHyBLFukjGT2TnbLG5Q2KD2poidcX5rYlnPvI5Xnn2kisnT4TO2Xf0dknVwjCOXOz2zK2zqs5KKtseOJm4ouOacRxordNb43ddbvn+/Z6fWa348eNThmGFUKOoa5y40xQ3ETJyfr7lBjd45OWrnFw7pfltuk/0aQorr94P7uaLeaxoOA4VMeqwRnRD9RUyClo7+/3MIFnM5zBSFpfw5FSltFiGFRfm2TjfTtSLPbaqjLPBUFmPylRD5bQ349JHnvjef5GXX3ie81/4SW7vt6ye+ywXd50n3/ldPP/Ln+PRm/DU176NJ6++nqfvvMCL5y9xs90NUjtJE5ud3eXENDfOzy+5vDjn8mIbnFmBoQwULQxDxfrEPDdaD36gi6MDeDGKw7BZs58alJH1lausr1zh9OqG3mE/z+FpWUZOreA+xiKyDpyxo+331P2Mz8GoqFJiw46AVgYRSlkxro4ZNqccywrTiTZ1LodztuxoU2NYrVAGvBmXu4ZvW2CfHnlIklS6YSiRMSORJSUxi0cnfTFhxfG9MY8D7g1rGjLaPrHdXjLdPePy/JzLy0ta3zJIlKjWw2AG75lho9FBdqG1kD5q7gzUMqgsG5lCdpN4CDRacJebpYxRPHYN2WBJNioQVDpEaZlJXnXJ7wHVZI2YhJKq9Yyu/fJ17zddJEXkBPh/A/+6u989eLMB7u4iXwH5/NLP9yPAjwAMmwEfY/SqBbwp0mc6GpGQfZFpBc3EPc4dt1Ct9JJ5Hhpcs4FY65dSkVpohSAyOwiFomWJXA9+YhrwxukUYGeItHL1nZu4MGNJ9f0Ce6dbtCZZllLCuFQzuEiCXI0Gz61J4qbu9NbpbU4SrIaDjBt1N/LK8zf49K98Cr/sXH/4SUoZGYcNu8uLGPfbjI6KnhwxthpQgga2UrVQhzWYMW13uDu/8/KCv35xyTHwJ+aZP7Za85PjUV48we0MVRBcXm65/vrHWPdT7p7d5TOf/hRvWl/DrxqX7Qx3Yd8NkRrFRQNSEJxhXCE+UFcF1eh4TDfBmyvgZQcIzbZYiU6qWyhVRIQ1EaWgnUhJ3DXK5YSsRoa9oWXHblTqWBlkh5pw5uf07ciT3/q7+MJHfo3y8heRoys8+MijbOc76Lnw3CfOePULn+P1b3gD3/CtX8dbrzzET3/mwzx/9xZWwvFm3jVaM/bbme3lju1ux36/BwjOo0MZ4rBdrSqlEB4CqkitrDcD41DYbfdwOaeSas1mc8qw2SDjKVUq024HNiODsbKB1a7Q9pUjNbYq1LFi40Tr+zRXjmoQ3FNPxkVg6IcI1eystAs2O6qFVV2H36QIOjrzzvE2MxSlimQonCE9nZI8rNCaEIFkHeoOSp84v7hgXwXtM9KF9Lmn7xveGvv9DvHgYUonUh3T8FatM2ts/VSGoPFJBqp1Z2jOUMaMvI0Gp7gw565h8Y1VjQ15tOOxuFBiIVck+LDmoRgqFjBYl2iMQkIiaDYk5iErtX08V2/Gl3v8poqkiAxZIP+6u/+d/PJLyxgtIq8HXs6vPwc8ed9ffyK/9k893P0vAX8J4OjaxkeRNNaVJCkK2gstmrkoLAn0RjfnLNRkkdzGLRIuB4ZY91OiuylekyaQYLHnmB2XGpa8lBgLNLfQsGzYETJkLLlZRbLwBd9yiZronhiqRq6HtSkw0pKbRAvNrVmnTRPzlEC8dpTCvIfnP/kcz//a09CE9ekpZVDadIbPe0RmRq1MPuOzM4xRENWcPoc5RAGYZ+Z5Anc2qxU/1M84zvf+2J3v3+/5qWOPsfxeGwvAbrfj2aef5ckn38Rjr38MfMa3I2W1Ync5MXua0frMt33mFu/64m0+8NQ1PvC1D7MiUgR7GdEyxOVZVqzqKmJXu+Bjx1qn2Y7f9unP867PPcevvvkNvO8tT8V7bxqmIs1ozZn2zuW2UWpHpaM7Y7US1jU2pVPv7O9cMKyOed1XvYu7dy+47IVXX3mB490Z9ehhdldex92jS57+5c9wZ3uTt7z73Tx+5SE+ces5WhP6FPJWmyJcrkphM46MNahhijMOI+vVQB0qQ/Ja2/KZe3Rkq3HAekE0t7u6QsqaqSnMyjiugMiqDpmtoKWHfNBWDAWOj4XqM5PcxXa72NJ6SGfnbkwW47FOzmpSUGHad+a90aeQDdbNwLgaEa2shw1tWHF3v2ecCyOEvh3CDKMZKsH+aAJTsVguEia91Zy6b8yTU1oU5ohPi4K4XD9iUdw887yLJ/cSQa0H/UecuQp1loMSCA34K3T1FlENrtQSE1gcwtEmFSuxiOmNkjjJYqxxv69mIT7D8IRXxAralWI9sM69I5eO9Ir0nkmoX/rxm9luC5Gz/XF3/4v3/au/D/wrwJ/Pf/69+77+Z0XkR4mFzZ2viEcuPyc980LQ3lNyFRQRK9HGqUeR6xKyIxEOriSLQN2Q6BRrpdSKVGVFdJ+WPColcntzDRO60fhXSUyPU0rS8ALSUXs5tQWsaKo4ykF2hws6h25Zu6MSHMHWO2VosZXHY2ToM73NcYFqFPPeCzdeOOOlZ++CHDGejMhmxcXlFrEGtnjyBVfUe6dMoFX54YtLvvPigp8eV/z9VaXU4OeFYYfy85sT/pX9niN3LkT42U3IGvu0p5SC6AjEcgw3zu/e4mO/dos3vfkprj90ndKO2Ygynz+dHUjnO79wxr/x059j3Ywf+sgN/uKw5mPvfBj6BptXWK20AwwxUEbo80RrBanKt37saf7c3/051nPjBz/8Kf7Pv/8Hef9XvY1OR73hNqN9jTejz7F1LSU4iq05s06Bt7UtdTpjJ+fsr7+en3tmTzt/idfJc3zVtYFHHj3h+OqDnJxc5dlnX+DZD/8Uz/3au3jjO76Db73+Vbw67njZb3JnnvHVGh8MkU73Fa3tsWYMvVJSKuhF8EUddYgHiKyei8nZTcLcC/tekNm5u+uUyVnvYdsM3zklZZ3zXJlbYWrK3gbW6yOOVwNTaVyUkd3ZXXza4TaH5LB3pjbhF8bYCtoqw2rDft5ydvcuu8vb4DND3VDrGEYRWhlTBCBZHFs2GhFtEgINXNMlB4oGu0Nwep8RN2Y6ZgVB4zMiaDjShUEGGqGHB2FMs5Kg6cWd6RIGKPiiqc5mooRAw/AYg/NeKgTro6viQyqnZgk5oXIvvRFPtV3kbIfvplPUcTTVPOQSx7C5M02dy7yfBtEsuF/68ZvpJL8D+KPAR0Tkg/m1f5Mojn9bRP4U8DTwB/Pf/QRB//kMQQH6E7/RDwgtaQrrWcwBokMsKskDDrutZj0s5CXoI8NYqUNBxzG6THMaMFKD1kB0G5YZwJHwdq+o4Y6n4WhaLeS6TNPEONbOcbrFSKoaiyNFYiucLiPhCqRhBtyjy3AXZjeKz9Q+h/68B0bohFWTqNN9oHehn8FGT9CrJ7g6TZU+NQYJlcBiMLxs7QrCD1xe8J/ffpUjd/7l7QV/7NoD/Hhdx2tNutNPbE74o934gd742c2GH6sF2W2pEsTa3qd0Qy/0FpxHt8ZLLz7HtatX+dAHP8HXffPjjD6yn89xg/d88TbrHFPWzXj3527zya8bcEasD/Rg1EQnsIxnNiHq1FXhm59+nvUcgPl6brznC8/yy295CxFlrxgzWENaw+YJcY1oDGnATJOLMKx1Z7TOXioff+4WH3/5Fpta+b4f/t1w4xkup5s8++lnseNbfPjpVznfN77txVt899PP87Zv+2G+5Qd+Dx975Qb/23//L1BOHmBcrXjg+inHpyOboxXHx0ewrrgMDEOMi8wL4FJxM/aEJZt15/KyczYbncL+fMvzN27SR1jNIFTq1NkkXr2fZu6c7bhzsWXSytXNFcY+MNgciz4r7PqtKAJp/mzuzNstdy72nF/eRsqAeWN7dhvfTXQXLGM5Sg3MtbTG4I0mYUwRSp2AiDoBG0jq7JtlI5LfVyw3xh4b5LLw7xJj1IQBnORaWmfNmBBFWJyJBpTVvDFbp5W457WkCkbCILdp3EtNCYJ3uYc7Dl7yXiWJ5OTrCHcwnWMr5kBPdZKl/FLcI8emtdjMi9GKM3g0VfW34gLk7v+Yhdv9zz6+70t8vwP/6m/0vPc/BCImE7JIKlKjrR/rgJcM/BomfL+HFhvmUit1Xalj3NyDBza2d0G0UorgmfyGaBiH9p7+kiVPHVgiHcitORmb4Jr8xxTiH5iWohFoH1T2gwegUkBi8aAa0EHIqRzvM7IPwNn64rkniEQn0kWwLvTdLuSQZrR5ppcV0Gnd8VLoGjdiHQb204S58d27LUe5Mj3G+d7tjh9fb7LTFhKF56dOjvgZC6UH25lSCmMdaK0dRiuzRjejt8bDD1/j4uKCl154hqfe+DV89uPPsXm0UdcdsRUffvIav/NTN1k3Yz8UPvY1T+LrNXMfKH2g74RuDSv7kAHS6X2P20xV+NjXPsX3v/9jrObGfqj82tufYqUltMgSeuJm++DrdYkFkwc2HemPecC5sENYicOmcf3xx3hwU/nqNz/A7X4D9eswzbzu2nVevelw/Rq/9InP8cXb53z9C3d47IMf4SMv3OZj7/0FZhc29RipI11jE3q8WeObgeOrV7j+wDW+7Tu+g9/7L/1uzIzL/Z6zy0vu7O6y3++ZOtwcL1jZLXaXF2x15vb5ObvnjNXmVQYZOCojV8YjVrJiu23cunXJjfO7rIaRk3qMNKGUysnJKba9TF9OmKXQZUC7sZouUDrbC2WSWEhUZmopsQnfX7DbblmfHtF8z+XujNbnoAR52O0JljSo6CbVI7I17sfCLGFOK1JSjz4Ac6hfulDRUOj0WL5JKMjRMsaCRMG9RDF2p0hPmz9h7/EZqnqICjzGZU3lnCzLUgoiCWGJBkHEDLpimai66OJbjzF7IIruJErvJZc6KVjIHYYoVOvUArIq+GvddNfdsbZnCdmKHI9KlYpoxUqEDZVekeLpBh2mCbUOjHUId6kend6Kkrk4nhZQ4bwi2Z0G2yNOHfXAThTBS2yuhZBHFkIj7gqYBL6RJ572+zwUM9oyKDyCEUHsaIxHboa0js/hGB6nXXSvEt4FIZMSxWtoYPvlFiszViqIUOuASqW4UOsY/oclRpm7B0v9OGTuSnTIqvdcVhZgft87RQtHuqYOlWY9KCWlBsm3T1jfU0x49YUXcIzP377JvGt8w7e8m9VDx9yZvohQ+NDbHuX/sj7iG5+9zSe++gl+7RveRtGBbgPumQDZgP1EGcJk2GxGeqPgfOjr38J/+qd+P1//8c/z0be/gY+85Y2sdrEV7WnGWoxwB+8RZCVpVuw5F4R4Kmhhs3fe+e3fyDu/85uR7Tk//bd/lO0HP8PDmw2395e0/V0e3QgPPjjx5uPKjc0V9l//Zj563LhYr/nOJ74L286wg3nacXl2m7u3bnJ5/jIXdxq728KZFVbTLR6/CsfHRxwfH3E0jlwfK0ebY66cXmO9OcVVmeaZZuHO7rnV3fU5rj1Vbk87Xr1xk5MRLkXBTxiHaxyfnERHv99xrndxVmiBwYVxmGjHa3bDlj5NQENK8m9dmWswBvbTlhs3n0XsJOCUeRczhYW4sTvJGS4gYcMXptUwesniFtPTXhpiDS0R7VFbAYMRCXww8ezU0KROOFo9ObBR4qB2N8aqoY7xMLxWje/rBmIt1W9pPhzIEhlQi5swT0JroYbzNMXAw6R3gEgn0JJmwLnfEEEKdC00VUYXyl0LHvZYqOvVl61Pr4kiKYSMSTToMU7ktUSRLPQaX3MhEu0gxm1dIXWI9EFaYIsWNAIjRgPLHBgxv/d38+HIQSfuHPZFgU+Ihkms5DZbNA0c9PB3e3oLWs+AsSxTbpYyNmGQwHCWn3gIIsPSQT1CnWQ/o24Mx0IrjXlxee7x9eadQUYGHcJSSpQyrsA6V1g8q6NQXiV4n8tQJBKmwR2hjitq/seTMjHUwkRPBUq8vt52DGVgszmit5k7N1/mg+/7Zb7pu97OycmDzNIZhxUf/rrrfOKb1gyrFUNdYxI3WOuB7crcQt0wBcfRF7dqCWu4X/uGp/jEu96CdWPcz7TW6DVNi82Ye2OanbafaG1Au8Q9SUYbLIeTd8YSfMMujq2PeOyHfpAvPPJ6zp59mdvPv8z+8WN2X3iVywce58Fv+WaeevytTA9f4UGtzHOljANl3LBZPcTJeo3tL7i8+ypnl7e4Y5eIVx7QkarOCwg377zA9sY587RFTOgNKiXGwt0WWkT9anXWx0esNhs2mzVX1kecrI84PnmAJ1cb3v7U6xjHN6PrE043VzjZXMFcmLpx96sf5/z2LbaXZ2y3F9w6P+Olm69y8/YdLi/PuDPdZetC64bt95id47uAcuZZKZeXlHUBN4ZxFYUjt8uhuBGqDCgdkzncsDQOOU9S9sqOWYlT/IiNKHu/oFlL6lM/UOXugfwplnC77+uxqHFCsFBtIfrEfeFa0GYMPZgrvXhm6ghNnVmchtPpTDrTdEanllQ+p6iy8eBc2krZbzJwDwFZukkJIxFxaidMOeY5jEDqa9yZHLL6l7SXkkLJN15KchAdqoQSx3VkArpUpBT2uYF2TTOQ1sFKuAWljVTNG+vw80STBOSZOrKkzUniHcG3JAsmrgyz0jxkap5uMEHZCjNdkSgC0g1tYTJQenClrQlzl0OsQ+5/4mMXYZxCyLYqjvSJK+tjus0he5OJqU0ghtYOekwZR3yKmIKfXa35IxfnHAMXwM+uVnE4eMgnHcG0olIYy8CglSbB/6wWoHdnH5BAN7yBqNGtMY5HPPT6h7jYnVPGwt2zmasPPUAdO1KHsHEbRqwMYbJAD3qFGdZ3SG+oEpQPife3S0ZpdKN4x4cV5pGz3Nuc4apOb87UGzoLjZniQxjiamh1ew98izaz8o6XERkqbbNm3in1yilPfO934fvGw/tQP02XM2UzMLPmBhfI5RnowOADfesMR8rJ+ogHNw8zHjUu1ifwauXs/AaDjKxFKEysTDkvwm2Z2csOkYG6HhmGDceMlPUp874zeeOV/W3O7rxIv7NjltBgW3dEVtR5RvZGYYWWI15/7TFed/VxTo4fpKgyTzvMZk6OVmyGgarKE298gne8821cWY1shpG5rpk7MSq3c853M9u7W26f3WU7NWYa2z5z+/Y5u8stu+mS7bxl9vARGAH3mf18QZMZ1VCTqUdA11E55Xu//dv4hq/5Bk5K4b/6W3+VL954CdcanFwSusrlyCK0WPYBotmM9OgoQ/6Y8lUPjmo0oWGmq0kFQgUpTtc4uGU2qjQYZqo2lPQTMKOo0leAQB1DEkwdMKlADZqQBmQj3Zhp7McZ9xlVGF/r4/ZSZJY8m0Fq5AsT44B4nAJSJGxEuy8eC3iGrxeXZOo77uEqUxpUQppYsBg7ijCnSHpJjYvy6WlZBSycTBkPBHRRDW/AzOmOOEtLdyE4ZDV68MK6kRkcGhkprcWyxtN0t4TSw3F06jHWe+NoWFNH5/zuTUrZQC0UGxlM8bmzmyfGzTHVK6MMzGXmJ4cVf/LaNb5nu+XnVyt+cr1mVUrudxwphbFEVw4Ssrl5Cn9DEdxnmLf0i0uY0nG8hjP0bntB5xGeetu7maaZ0wceom4aVs4oMiJamA1ab2EMbND6xNQ61uKEbz1pVMnoo0gUN4+clrIPDe08Ndp+Zp4iOtdUYBZ2IrTdLmgzJWy0AJp3LqY9lp6OwzCxspHBG1LWbC3MRprXMH/dO5OATR2xHY7SvGECtW+pcpVHVo/z2ENP8tZHHuFkVTjfnbOWDdN2zzBfsPKQsjXfo/s9fnGJ930YtGwqpVceGK5wenKEboSLacswFLjoXOwXkwplo4rpECYg44zNK6bVKdceehNvuv5mrlx5HB9W3Lx7gxdffokvvPwcF5fPR2e92zO3C6p3TjUOhlpWDEEfgFJYDSuuHp1y+uADPPjAKavhCuMbn+Tk+ITT9YaVDkyt0Uw5OT7BZea9H/kA//CX30eXGanGeq68/ZGv5vu+6z189rOf5md/6if5s3/mT3P9yoN89u6rDA5HBnNJOt4yJblzMBdNCaxilB7fN0XrHw1KQmQihk2dWRvegvojJZqCQTUmrjqj3Rl74RJBm1GaID1iIUoBHYcwXVnFVCpecV/nayA6/gFkXxg10idnZqY6f9n69Jookr78b466KksBIZcipD446B9mxJJEPVLwfEnrSMq5G6OHqsO7w2D4GDedJGgr6YAt2CEIanFYkaQYuUVGSGzeAljuaSfvfc6XHPyfwE3CYkuQCBnqIYLyudHmFoRt1eyEAkUseVrH3DAwTQOuR+zaJe3yBqUo66MTyqDMc6P3Rt/doA5XUZnBJpobf28s/Fg9YlXqwfRXJXicKhLBXm2mzZ3eZ9hf0EVgELwYaivKuMa10/YT1mb6PNOb88zTn+f4gVOuXLsG6mhZgUwxrvVY8ni3IC1bdPKzGbNIdq6SDtXhB6qqSO+xbRTobRvEenP2FnxYdECsUvZKs4mdh72XuDDUyBPat8bldhf0MBXWm1V0za6Y7gIG8XCYiuVswBRIjQVCiTAyb53eOuPxyPUHH+ZNjz3CU9ePOK6N7XSVcftGpldfYXvrWVbZse3UuHQ487jx5joy1g3H5QrXjq/z0Poatu/Uept9aexsh0uj2IRYp0rk4oTD+IAPx5yuH+HBB97I409+LVcfegRDObpzDcqVQHv6FpnO8TVgnZXCtXrMOApaC1Nzbl8ot27fZr+bgmB9XDg92bAZB1p3WmuIxUK01iHgIxPe9sY38L3f89uZtsbzzz/Hzf0Fv+3b3sVT167zl//D/5xPP/tBvu4938xP/aP3crddUDexWA1PBUszmrAYDAjf877QvBbtwF4pYkzaDyC6e6RTtgFaKfgctm06VmxdqDZRm7EdFLGBapVRLQj5zcOoONQbSNWQ5w5J0/KB0jeolVTShfGGqNJkpkul10Yrv0Uy+f+vHyLhkVcSN5ADVJujsBNUAlN6M+alqGlwBEUzH4SSe3hnVs9AqLC2P7B73JYodYBDrk04lCRnUXI1YHHjC2Fq2uVgy8sSGi9LYSA8ITu56fMcsy0UCVinCGlFpaHH1SgIOirdhEEe4ObNc3aXjTqOlGLMu0vO777KsFqzWq0QKUzTJbduXQJCbxnHWcN2rSei4ASNY8FsFol0zW66jZWy7/TLS2gzfRQ2xyeMx2usO/Pugnm/TW/APfN0wX4P5+eNYbqKFWffDGyPz40+G7NmUmIS61sJRUT1IcLeCG5b7RkHLE7HmHd79ts91gmaTanUDrUrrThTm9jNO6zPVFdaqbhqxCnsgy5GURgDk54bgVH30ArP2mMkRFkPax6oJ5ysjil1YNd3nF1eMvU96+GUq6dXeOiBNdc2zhGNk7KmXb3Cy6cP8fLtl1m1mdFAxdlMnWMXrK4Zhg2rcsLJ8ACb8UGOT14Ha8O2Izvt7OYLJr+kdmXonUmDSjNITiDlhOtXr3P1wYc5vX6NBx9ZxQR19BBbq+z3W/a7mzSbw/zXO5sycFyOGJmptbId4OKis5HKMMZSr4wDJ6s1q1UNrF7D2b93CzipVObW+OSLn+PFH3uZx1/3BO9517uYDJ79wuf5v/6f/j12d+7w1q//Gi5M+Zs//lc4uX6Krjx5zXGNNYmOHAuKzqHkeDQEXRqTBlWneaxhVCS8AFjYPsJQ414QFWQUfJXLO23MAphGNrgaA4S+vwe2z2LooRJkewaqrRh8jfSgJjU6NOizYbNQpqBCDfblCDyvkSKpAqNonEqth/46eKUHTXDIESUE8M1osyGFCDSvQtjyF4pK5DqzPEG6lC+kUo+hz91ozaDfy0VeyOMhXFK8K7NC2PRnaHyL5LduPQnujrvgGUfQiTEck/C6834ISoo0zaVyxdbaSgXtrIYVt16auHvjDNntQBz9/zL359G27VtdH/rpv2KMOddauzj7FLcWkEIFQVBABOugRkCwAEUU0SgoYmwGo7ZoDNaJMUhMs3jBZgwS0wyJRUTRh2IReCgocKkFLuW9l3tPvYu11pxj/H6/3t8fvY+5zrmcc+71vX/OpB3uPmfvvdaaY47Rf71/+7eQym6+QMfKclw5LINpmimyp63XrO1ArZNjft18AZSEIhlLkeqnAL4J3PilkotjvcmYph3tcEkh0VZljMbF2S12j10w+oG2HJ28vcCt6TE+6E1v5bJduttL67R2xWid1lypUdQiSwQ3UjXzcSx5Qp2JUodTPpII69pYl8G6Kn3tpGKkya91s8S6rKwMjscDtOg+porsdpRcEXFvwFyya6upDHXicTLP/KkCc91zkc+5t7vNExePc/f2Pczger3mmfkBz96/j8rsJhZZUckw3OtwKp39UMp1Qx8ckFWYauOidR4vMwnhSguzTZxPt8n1NmO6Td4lpknYjUv21zOTOj3sTBIPq2JMTCLO+5wmLs5vc/uxp9jfPuP2HW8C1iKcPdqx318w784ox+Lu3S1T1HX3syakF6dRlmtycgEDObvxC9Bl0HNyQYIMRhUscsZTHqy28O7Dfd75I+8ivSNzz2a++9t+kI/7Rb+GdSzcekJ5tD7LrmQOacU0+WQ1vMHZGAl5yifpsCthIjo5nirzHoRM9e7elCwuCNHAI7MUTAaCY/uaOzY1dloYkpgsUbNhOqHVkBKyQ3EppENfCUbBZ+sSdCTFeoKuyHCJZJHKsIH01zkmaSK0CcpwPuAIHI00yGSg0mw45jiGc6i0kVU8a4VMLY5VpTCSsMi48Oxf8xsoTm2zkJNF3EJWxSRT8uQhXjWTR8SRboRVc8NSl3E1bHQwjZPUO8csckp4wyxoC9vNEh2oNpKc+9iJy7KqTrCe8+D559Gu7EplsUxXT4ssJZHyTA+TWB2DXCq1KNrbyRREtSGFiH/w8PVkhvlRjE2JokKNEUW0cBRlOrtN1lhcJSGJ48K5nlOmvZt41Jm752/lXJ7i4fGSQ7+CtrL2xQn+ODRiCpqSm74CXVcsKYtkdKjf/AWmlMk4Xrmuq+djj44mw4ZxtI7oNdKNtjb62qG7XG4yOJt2pFpIdWaedtSa3YF6qgyLFL/ssbwlV+7MFzw13+Zt997AW9/407h75w5tXbk6Lpw9uM/SO/fbgatH93nh0Zt4al+ouFHr8eoI1wfSdScdB3PKWDf2ubKbhZSgI+zyjNVMnmeYzqBWRBbyXGCqYBVyY+mezTS8A4hJRSgyczbt2c2VlAdzhTKb07NSdkhphOZ/7RxNuW+F1ge5NdqcgyhtHHSg9DCHgDwK1tWjUcRFGbrZxI0VpNN0xRDmvGeu9/iFv/zTabXwzNW7ePb6h8h1QWzHaEE6jwZgHSG6UMfy3csRRtqc/uUlJjXba8TC1GWUzgpJiMZEZ96Q9ORUoWQzZRSyuO2ZaEGHMQ1X2liCRHVqnEFejS0YpJXhz+Qw6D2yvz1scBVXydny6vXpdVEknbid0WDDqzpxW8z97ZxebuSgJEhsv5JBGng2thq1hoMQNzpOB46dbrBleMgY0ATWBD2jzT8MnYK4TKKau/iMjedlYNocjFajr0bvDVEf3kstFJtINbvHpVr45XnMQc5Ctoyan3BmR2dGpMrF9AQPfnIhr+oOKik530uK89hiSVSyUQq0fgQbjp9iPoIBpc6IVPwMNlw57ZQoG67BNRHWHCYCeDxEzY7Nqg6HPorLBkuqEREAVQYP77+Xs11jnV9gafdhSBRIC+2rbQAzNlwg0Idi4xiGvR0K5JpRmSiWUJS1Lw5L6CBZRUaiD3zJ0Ttj7Vh3YndPMJUCEVJf5pl59tAuDWWWB2NJ+FQaVGGqmTu3znjDE4/xQW9+grt37rK0zoOrhWtRzl4o3F8e8OL9H+fH3jVTeDNPnO1IxyPPvfA89/XAscD5+R4pGRvJzS7KwtoO4Wso5JqZdztunV8gGfrqsRxWC+Poh7Oa8w+NJQ7SwejX9HZNHwtjGEsLArkmxDqjH1n6wvVorNppfUWPnXEcrOrvdewyl3rgsHR6c2necZfcDOXYfaIZqy9JUJRMt4oOBfGlIgIr17TpwLve+e2+uZ8rKRfG0SOckrhZhA5vTHx56dDRiEktmatmRjRo4katDv1AeEx6cU0j8o8MdzVvXuCGwQi+pWkOlZuzVkSD5zlSkM4l+JU+0qv6YS/JfD+AYU2xVdyXUpXcldIVaT5yv9rrdVEkifZ4dPWxUdzuPU8+Tog4nmfZE+HIYNUL1yRh2DsLLaJMTPxCa2zTEB+nLQw2tZuPbmuD4UFBnkAXPK7k+JVJcZdwwvwAj8mUMei905orSTy4asumcepCigW5ZXeJyTmzqQe6rUx5IKNzvnsztHOeffd7uX7+WXJaaepdqIgE2Oy4aRIf1XfT5Nnf5vZySRJNzd3LxXFJjRO9SGKkzFR8w7sKXIshw3NM/O2pF1qzOKTUg7Cy31DZhGK+Mb169BCK0Y49zosNg4quOUTwltxQuPXOaA1ZO2bd/TbrRBancIyk9DyQCiJGVY8TteGbz9YOcfKbk+nF1XlShFoL01SoRcjZx6lh6tAHEjZdmYIyFeP8bGK/L8zZuL2v9P2ObsLZlNllwI5cH57hmRcylg88fesO6fqK44NnuCwLdvecmYl9mRl6ZOZI7Y/Ily9QdTCVyn6e2O133D7fkbMylomH00zOO5JWZFQ3+dCGasMlK+oUnOMV6+HA8dhprTCss1xntK0sx/scri5ph8WNTHohqQd/yXQRfqx2IoQnPNCMnihrIQ8XLtjwpiObOafYEkaPPKeCiYsm3vXwGaYS0QlrRscEOlNkC+NLkZPjK1PH8IP+Y8bsl54wMHI7BA3XIoMuzn8kfA4sBbE9PB4HYM3vD1/++Da8Uhw2G7qhcCHCMrDJ9wYWksvk9nyiHsLSeqcZFAyNrbaZL1TX8TpPS3R36gmkuRtJUpciSSJljY2lW3JJFWoWmJxzVxF2CUrJaPFChPnSwvJG3XI9d7IIVR+OvfXhEsAkhHbzhsCYQhZnG8M8CLgwEGtIXmG4fFDM3Cx49ECyPV0xm8MB8+zJbUMyg0RvnZwqhQsu5A18/w/+Bx49fIasC90GR0bwNr1DFlWa2U1iHhK8MudxbuR0Bx07WRLD8enoNDsJhyIsZ0rKiArLesmijSKFkovzJYf7/FG9sNrw5L/7Dx7xoR+0Y9gjjsvqSqjWg4HgD0kOOy/3xxxoWzmOla6N1AfFwIYhbYnwL4+z0CxMGjzLJOQUprzWffySBBglT+ScKVIp4atYJRIKLJGkuN2XRebQcN1xwjNtSJ6h1JrS1u6bzrbCupLVoBttOXJ19ZCUB8vhWezYsGMjp8TZ3XucpXPO5wu0X9Pagfl6pl53Zjq7umeaM3WCMsFUhLMpsa87dvkWe+6Ew1HC2gpjdb23rqR8ThmJcWz0w4IMvz52LbAs9H7J6IM8MtiOqRZu3b7gbH/B4+ePI1m47o8o18+j7UX6cgmASSFpcYMWBqbTaVkiw3X7kgrJvMNQjeXjgL4qidmXm4Hrq5bQkbsZRrdGMlfsKKDm4W+iMLLETsFNXzYJoa8LimOYrtDwJWMurs/34Ci2DB5/FafsiU9PSA+M05eubj+Y4z1raLwj5iX7ASwpMNhwmcoDl/kWhfp6324nYdrvPAJgNHcMj8InmMv+DJJmUnHfvCyb60cCG+woJPGw9TZ8e9xCzO8BVHoKb5eeYAEbwmqOI6ZSKLUgxWMHCtXjCJJTgULT40oQOlV8Sy1FqfiWcvOotOELE8PxxIq7PlspDDJSO0s3dtMbeO87n+HyhedJLJS50EZmysIpyyQlt4cCNmQzWWfVEXspl7wlvCCUZKhCEfeyXGUAfiOt1hyWAMbhSNPVTXPN3AQV50cOGYzjYCqZ/XSGYbR14e3f+S089ebbXHzIuQdQpepdokZsgyVQdxocBtgKfYlO1b0KrSuy3XXmDjLSBW2AJLR6bMHGUnCKVTrJD3OZqGVHzcUT/iwe9li8VXU82SVx3mCwJtbLzgsvXLKfHnJebkOasD64fPSQ64cPWA8ruhiNxnG6plinHC6xDlkrZ+UWZ/sLdvMddue30PXI8fiAyTr7eo2uK7NVdjJRRJiKUYubMO/KxD7PTFyELN8wq5juyH3Qx4pMe6pNZFuxdiSNHcmEyTpJV4efNKFSSbVw++Ieb37izdy78xSP33kjQzsvPHya+vAW1wss10oayrEbLWVqSay2krp7TuYkZBVvyFIFjUAxCwGHGYxBkQm3rmiYDSynKJoS01Hg/uY2Z4ZBdklsFj3BNRM3ND2nqEnQ5SLlNBHLG58Qc4cieLplKHWKhrgjGS4RCUlv8GYFv7ddZRN+EFmQybnJRY2iDsf0VZFlxXIjoa9/xY3kxHz7jDYpdA8u94uc6W1gbfUTGCFJR/LwsC0Tf8g0Ri3tdGmszNTA8Qhc08wVGqaCBi9O8S4mzQWZC6lkypQRyW7Tpr4ZR7wwu9uZa0SLSYzRgyqZWSaXRJkbuA4zkESxTEoTU5lIs28EbRg6Evefvs/T734vvV1C6KpVFWvhwsxwGQ/hc2lBuLfu+FtOvgxRz212apEXlZqTu7EnAu/xDaONxto69JUmwWuzjBUvLBou9qlWjscDU565d/cefQy0L7znPe/hDY+/kfrkmTvAV+cJmpk7QOOhX7kP1pGojgbTxTOnJfuYXMiM1RU1JkJLYMkoKJKyf61w/Nbh9CrN7juYcmKXK3MpTLmSN2NZleDDeQiXJTdGoRkH7bznmYdcL4UHl8qbnljYp8Jy+YD3vPCI+48aY0lUVVJZvIM/m6kI1taACjJMM+z25JIxPZLqjrle0No1qQvSBJp30baFa+EuO2qgFlK+XHyx0Iykk5uimDDGkdFXbDjdLMsCqVFKYiqFmjO7/Y63vPmDePPjb+XJe0/w1BveQOud/bN76n7Ps4f7PLh/CX0w1/BAzVCtomUEhOSfWa5uBu3y3WBHxFQS7EN6SogVRIyRhIwhOjw9VPyzVRznm3XjRwopCqCAK7tkM7J2e7KkGtSdrahB627VJkUgmcfAVhAGNeh4tv2TnI9piZisXAAshlP3LP58Cp9K87bSDO/Y20pvkMmk/fSq9el1USRTTsx3z0lHuFbXugAAvCNJREFUw3oNjpUXP9aGHP3GM1VM1DXVyccWCenh6F6gWoYmA3N/LufmobFJGE5GNzdvnVQ8BiGwJCkQVQWzDrgu2/AxfRrmgK+G/57P1K4Zz2En3xO9+++7k80OyROpZGooDaQp49B45see4fDoEWu7RkdjXY8ePhbefkgObNKvSIJI5fEbyoa7NU8U+tpYAWao2R8+P4UT2r0LcE8rX6Zg3ZGBsIKz6MqzeTZKGw3LO66urtGR2O333D4/50Pe8lauyiNMJYwEElkqoNTsEjf64Pqw8kgL1ou7YUvmrBTmmqjF+Z1NjWyJow1fNplRJLGvmf1UqLkwhnJsxqoGU2Lezdzan/H4+QXnuzNqnU7LrWJukNK6P4z+NQs2CW0kro8Lj66f4d0vPuBdzz/i3sUdpC08f3XFg9UwqZRhpKtBVuciKjDa4LC4Ua5IIZWZ1RqHYVBm6jyjx4XD6Fwerzg/POJwfcFolfVwpI3uMtC6C5GBp/WRjGQT0gY5VZp1ri7ve2bMg9vspsTh8iHL4QG9X2F6JCdlVyu3z27x2J0nePKpx7n3ZOW4Cku/zeV6RaqZnl16J8l1yakIE5leUvifxmITDeGGRAied3HYDb9Waj6xQtxlX4MW1yG7N2Q2YiFiJ2gs+kq3PCSFOXGMzMkjRhwOAZNEG4asinVxFV0W6q54HHMqkXZIlEjx59pLBSLQtogW81E7Ba952Aj2ifOjR0RUz4uQWiYjnO9e75hkycyP3SEdM9p8F2/qRqujZEoS0rp6V6kCESvqI6TRxqBpZ6xg2cdixflUvlQBd/wR8jCyuZY7J98klwxzEdgVhrq8sY/F1Tpd4+bQ2DK7bM+T6HAtlNQAjBvDYNFwBZKNMxbGG8N8G9eF9dC4urzP8fKhv9/krkY5ZT8cguYpKZPrdDohox2BDK0dGa3RwnrNROi9u99fyvQxYr8tQSEZYa6Kk25b9w06Fj9nvFeMXBLr8ZJ8fptujavrleOjF/mQD3kz+c6OF+0RSdydOmd3KSr4CIUkShteeIMYPE+F8zpxMVVqgWVdaTtlWgd5MZeK5sTuvHD31sTteWLOhTYGV4fOdTfyXDnfVZ68dcYbbp1zvj+jVr+Fne3gD1Ezz0IZJnQFo9JGYj4ah+vBoR159OAFdF3JCVZb/WGv2T9f/LNar48wGkkyqxm63MdEmHKm1cSqHSsJneAojWbGo37J7TZzfZjovbAsl3S9ZLUruh6x5PZcZsIYxpAwcyiw2kJb73O4/5M8nIy1TlxdPeL6+WfpDx+h60r1YEfgSE6NXAtdcbs7ayzrFboeSLqCLf551gl2hVDWEqpcwDX1KmHIsmHxCps01zBMjliGRGK2whA98X8lQEYxOxlnx6Ib20LdAiyyDaAUQZNT5opBbp2RhBYUr959D7CbKrt9JVW/+TUmKd8BeGF0kYTjmj0XNww+2Rg6nXBDNyV8Cgwj54TM2Q8/4OLs9b7dlkTenztjvwjV/A213HxDnVfXEpfZc5fF12Z9CJ2OamOsg6YGfTC0+YbZEimsxnpIF+nmqWsomqEUHOcs6nLIcJJp6kYWpSk2PLCd4ieqcwlTLAzclRn1TqiPQRu+KDBxyd4YgzGy8+lMESrX15cMjDK5yS1sCwoJMHrjnHmMRMNHNhluP+9MXCUFUdwwv1FW72hTFqel2CDjWnM1/1qW/USttWADSDnypA21xuBI7kIqM8vxQC6Vu7dvcfnifb75m/8tP/0TfybH/UphJeWMqevEc50dJ8K3lyTcEDkr+11lN81Mc2VXhVkrbQyOh06+zvQBad4xn1cev73nsbOJOQvL0tjVxoXCtNtzfvsuTz1xj8f2Z+wnz5RBDBPn4akawybUEm34Usly9fulC25HWkl5QvGRrpJAhHW18C00uqzIUKptUrYMaYV0QO0RsCflgemRVS/p+pBu3vUeW+XqmNFe6O1Aaw8Yep+cH4B1b3zHYMjwsXIYqwnHdsZyLFy90HmgB/q05/p44PrF51kuXyRpc1qTrRwOL/Dig5+kTIXrwwVLO/DcC89w/8F70PWSs9qZxWi1U3aZPEPJHnrnZ4k/D0OMLgSUFXaC6hVoi20t4pxg79Ky82ZPw7izTiy5zeBmtJWD5xNBzpC8QN24U3mxqwjTlOlJPBdnKqxrd/eh3USd5bStzxoMD8Xz7nfu0SDd+aBTKtFlepH0RAajW4cxQpoKm9D7PCce7vxZONu/zq3SMIIx73xJFrdZ98wWc16cODG4VudsJZlpq1BSR/QKyR1JB3RICOmHG3vihWRYMP7VT0B14ITJhIpShm9qm3ZG96jNovgWLAnOEPCFUiLFyZvIZaIU17/2XiFI7i7P6vQxIqaBwFggjcrx0jffGiOOe+oVVM2dYrLvL0r3vBDL3vHVLA41iDCCiuSVz+9Os0FvKzk71WYbm0xwzI7EIkHVUO9UKQXpHUklbvROHwvFyyt6XCmPJZ5865t44elnuXz2OdJThWsaVnfUIlyQGKzsUsZ6p2v36NCekDKR8sQshalM5LPCVGAvwm5R9gdfZOV54mJXuXsxc+esUmSwLAv1bGY1YT7bc3vvfovnu4lz94dwjpuI67CN0PhbBLf5AQkrXRO7sxlJO0Sq418p0RFKVtrx4F1I5KmnMGyQpG7sPCVsXljKI1RWhh1YlxehP8vd+pBkiXNJroga2UOvxgHSNft55fa0sqbVcdUwWm5mqCYSmQsGJV0zrHO9rEjfc1hWVn1I3h+5KCsI7Ocjtd6na+bFFw88vJqRahz7A+b907zhKeXunR3QkFSRksm7HZTicU22FUkL5kfcY8kY6qoV92J0b8+c73g8sXkSlI3VJxB1KGuouHhBMqbu9G24JDSFbVoqcciLMHp3wULKLhYZntrYUF/cDKg5kaPrTpZJVFSULbQP/5hcLaceBsZw2WUzp5ElwXkiyalMjIGJsz1EFfoZXe/6IkrkFQqTv14XRTKTuFDloCutCdfrSm8N627dpQa1VHalsC8Tu90O8sThaGRbsB6J7ppoAQ4Pdffj1hu77kyu+ITdzizLTeuuQu8WJp9C7kbRjkomVd+wW3ZyKpa880tuEVVyphTnYCaZGE2xtKDVu5pmK11ndlapqVKKslxmlusVHQJWffzVG8U6kshqFHUgWrOwaSq7Dg/92iIg7IbAvb3GGNhhZbJQ4uAdgxt4JA/TsoSNGM3Nc6V7W33JRca0hj2b+0Muy5F7TzzJ3f0FlE43ePr6GibQnZN/u4aJ6VB0VVr8rAmhkTxWIDCpMlfO5h35IrGOwfXaMTL7eWa3m0lTdqXRdKQOoVOou5nbZ3fI+5k8z6QKkt2b0mIhIOKYVNGMqn+mghfSicyQRM5Buh+G0jiOA2orOjth3WIDnUydLgWkSZn2Rs1Hv1YDTFf208JTjwl24QukmhK73cq0W5hnYFm42Au6m7h757aHxSWYxbXEA3xrXmdYjDvn55RkYIOzndsBPsVdmtxBVam5ehpmruScsPwCqSTqXFjWIxOPodzm2A6QFNFOzhNtCLv9BZWJTGbEglFxma0E1q/aoft9N5VCSYWm2RVROgDoeOKlqkM+va9giZwKoztVqw2Prl2Wo3ep7GitoTiTokpmN80IW65OYu3OEUbNzTnMYzumfIZZpSWlpIR3iUaS7pS+pmSprubKmVO2tjrNK+VwdB2DUp2cXxlkMzqZLUf+z79KffpAgsDeBvwtPFfbgK80s78kIn8C+ELg2fijf9TMvi7+zn8F/E6cE/r7zez//dpFEm5rJo/KYV1Zrxu6Lmhw3syMspvYl4lb08zZPNFT9izemuhTZoxCXzK9uXddMmHqPn5vSgLHTgbDfKOay4SZsqwryYq7A0mBPryzEmPL+C7i+d9mvnkTyWSpTLVSqrP8qZk8Bnk0DutgAVQHa29gM/upMs+Vpx8urAc/CAQ8BCloFL4I8cQ5UZcJagD9asrQ5nGr+uq8LjM/tfvayFNm1EzP7jiEdlcsOBKPacOGkOqE6uISSiGIwYPWr2m9sB4WjoeFe7cf4y1vfgvvPT7Hsw+fJ0lzBc0oNJmdjtGdSawkVDyXZ6yNwyTcyXuems54bD7jztkZuWRW6czrwKxSk3fmltykJOVMSRP7+cyNfeuETZUlJXoalIh7SMVhlcEIhVTomnNCt89P3ILLzDHUXGf/fBYh551fi+7qKGRwctY2l1HOux0lF9a2Mk07p0wJbk4rq8eCaLgMpYlaCqmeIcW46vc8fjbwuH1OSG8MVW5f3KJI4sFxIDXT+oKNztn+wiGEDVsbCzCo2bPUa5m80NmCyEBmELnGxmCP0UbnKK5cmqjsqyLjQKmV1hsZYT47o3XfXJfkxVOKzxBjaSQSBc/bMfHceWnCru6RlFn7QkqZLDPJCrXufXKxRq2TH+pJqNl/nmHKcVmoltBh1GlinvbMkjm0Y4SNDc9el8TV5SUXu3sUOUPpFDHWfoXhRPa1Ny6vj2zQZ+sNhjGncooByXjjoAZTmbwsjZU0Brk6EyQ5Ge4VXx9IJ9mBP2hm3y4it4BvE5F/Fr/3FWb2P7z0D4vIRwKfC3wU8Gbgn4vIR5gzfF/xJebJb73tWNcj8zJoV0faWD2KtWQsD6w46KHNTW+dj+hyKztlYiRMoigMA1GOBVTCVCE01UkM6w2zREnFNdzeMwYvspOrhEmde1lm8aAxKYWcHCM92++oTt1CDPcyJNNtMFJGLQf+J9w6myj1gocvPKCtK8KIEcTi2gWTITiWw3wbz3AJghD+lfbqo4F/Ib8OfQx0dHLOVDM38QgDkW7Nt+WjYQZT2rHfn3E8XKHayVlcIzyUw+HIflo4Xh95fjzi9l3l4ok3UI4/Qq5QzyZKnbi135GnjPaVyt4/i3WgxTg/P0PqxJ17j3HnYs+Tj93hzY8/ATJY0kIbUJnZ66BOmTq5dh8xzxzfnZHrxN2yJ+/2tOZywGnyRUrKOcjFjqMlq9Q8UZLnt2SiSIp3j0al5DOMRBu3KAXHY0dQpZxXwNK9WM6lUCIEbGnNu9GQ2OlQsAXEO/ZDW+jrFYsO6lQ4rlcsbUHU1WG1zlyvPb524vrK0wiv++B42cglu8l0u2J0n3zGUDdVSYIO9fCqXEA6uSg6GsfDwnF0Si4RayDcmiuXyxEphff0hq7KXGd30jLj7Mw37mKJ2xe3meoEOtybcvNO7UdUlKWvLMuBy+WK89t3uL5e/DlEyXmmr8rdW49jTZly8TgSydTiBHbDuFqOdFVmhPsvPmCed1zcus1yfe0LpMis3+/PAMEaPH+A87PB0q/p/eDWegEHtdG4Xg9YNmrOzNOeqUyMvpJKRU1da1+csZGrR2p07dSpcL7bM9rRG4hXeX0gQWDvAd4Tv34kIt8PvOU1/spnAX/HzBbgR0XkHcAnAv/m1b+HnwBjrCePR5VBGx3rfnJZ6DXz6ly5QzKWPjgeG8erxnI80vtgDGA4taCLYCWTg3qqONZSe3ajzex0nqkXlMKByLbJQB6giToSI5yVqwm7UslZUAp5V9nNlZ1kkrjaQE059M7UQY6D1pw7mOvwkei6cvn8Q0pf/KYnM6xH8pvf2APfeKLdHc7VTpvnbXv4Wi9PmdyRa2c+S6yrojYxSkazg9zJmtNPZMfQxhgHcrnNvL/L4eo53+zjih9dFi6vHrFfLpl3Fzz97I/xQR/6Bn7hx3wsF7Uw7zPn9Yw3PXkPUqck4bzuONvdpsieUjq7XaHYzH6/R7JQSqHu9qyy0PURYGSpTuNJO2qayQgHGRh+rZpl7totapm5pnG/PUAY7gqP+0vaBDqOnJU9mnYslujjQNdO0+7WebjJa1+v2Yxfc7hmt36ktQXtjbrbsbbuFnVDGdfeFaeUyMm5hGtvHNYF64NSZ7oZ1+s1NlYvZJcTvTeO6zVkodSZ/fWMtrDtooDuMRptrE6Hmys6OtauY0m5UbUKPQoxo8NxCSmqO2MtR+9MF+nU6uYpJRVS2tGboquEosVxcl1XrrUjUyFpIh8vWXuiN3XPThNqrti4YmTj4dUDtK90GaSDcbhaGCjzPLOMA2tviB24fXYblZnLyyuWdaGUwrr6/av4UkhMGcNzzvuDhaurF6lzheSNyv1HYFLR1UnlU00sa6OUCe0DHStVMg+vrzFRsgxI0MdMTuLFbyjdjiztCkM9GqQNzs/u0JbBbt6z2+/oy5G75xev+jz9R2GSIvLBwMcB34JHzf4+EfltwL/Hu80X8QL6b1/y197FKxRVEfki4IsALm6f8+jhkbW75Vazma6Lq0DUN78syuHhkaUqMhW6do5jeE7F2lh6pzejdx9NiFW/hsFm7t4pok7zqlIdrk7CmgopC5O59AoyphMrSurR5Q2hVT+953nCRJhz5jwX5jIxzHxsT5k6zU5rSUsoBwXVRJZz3vuTRy4fXYMKmewSKnM+7RhKFzARrA938dGQ/b1kvHYbKjn9+n1fycDkyGNveYwP++iP4Dv+/X/AHuLRtHOljcboPlql0BCbCr0LZxd3qXab9fIBm70V1jm0Ay9evcjt89ucTTs+9eM/gV/0Kz8Ckl/XOe8QZq716JttMpKOCBW1I4KP06RMQ1nMuNYjrR8Zdo3RWNeGyYSkGTSRIZIA3SKtS+E5WRgrrDpYxwKjUxSqCNfLwTPaZXA+NRJXrAOW9dqTAs23w5jjmMvaKXVHzTuXZGpnaMe0c311zTQdParD4Lh6HG4uRsmQ1zUe3CseHh76oifN5LL35ExpWB9M8x7FOB6PzPMZaitzXrFmNBFgBTOGHrk8PkvJhVrOSTKRUHbzTF+Pvhw0nE2QE613x5QTjutpJskeEZ9O1nVQSuUKDywrRZDqUE0fnd1+h01HZyOkidYG18uAZWX0Qc0uxdRxxbBOyYm+Crt6jo4VbYmadtSU2E8zJQtDG3NN7LL5Yu72nqtLP8HGPnNcFkiJ1ldKSshZIUtjWS4xuaY3X85KSqxrc0d7dUrdw6GMkZmmM9Zjo5bEfrZ4vjJtWWmjIZK4XBfG2jks98lzo+TE9dU1Oe2Y6gUJ2O+m4E93mirPXh5fte59wEVSRC6Avwv8ATN7KCJ/DfjTeG/zp4EvB/6zD/TrmdlXAl8JcOeJu/bO9z4fILIXm7ZAXxNDfQFgo2Nt0MQlhLkrq7n5LsOLWbLQegoeIC++2aWba3rjN1MuoXcWLBUsJ0oRZjpqMEaia6HjyXNJ/YMAo7XGfp6Yp+x+keE16fQfzwZv3YKnR2Cqg9ETV5fCO979Ao84uhJE8JjbUDsk87/nJG8nHffXwB5f+XMC0sRbP+wpft0XfhpPvPUub/jg23z93/53LAOyJjoJpGK6MGiAL4nGcs0gcT7dgrKjtWtAHZtdVw7PPMfV7jaHu7d47sUjBznnqjxk6oWcGsMOXMkl13bFOlbMCtbn0Mh3GM6bW1qnqzl30zr3Hz7jZhC9k+WMMu3d1GIMFjVMV6eH5TOm4hZZ15dXjL4y1UIVp1EdjwfSXOgyKDZR8h6VRB++dEjixGrrfrgO88iHlB85A2EEixpjXY7U7EvCJEJr14xm5DyTUmFZXsR0peuBR4eHbg82EnU643g8UnMkd9YdWyDWfu9cwJpXsmQ0Ka1fYzZxPF6xjAeMIUz1wicBZm5dXDB6IyfHqXU4c2DFVWOFjKQVQ5nnM5aDMteKqRc2kcR+f7k9w1TZuwdkeCBMExwur2ltkHNGtaH40qatixfKkkjD8f1DUSj+3HnmuHC1uHqnrb4AMg5M+ZpaK8vVgZSE/UWm9cE0Z3KpHI7X5NyYag0FUmbKO/bTDimV27cLh8MVfSwI8OjRQyQfkayUqdP7QlND8szDR9esxwPDOrnc4nC45njwJNXDo0uMweF4pNbbpKkBKyVsFHe5sazKvLvzqs/UB1QkRaTiBfJvm9nfiyL39Et+/68D/yj+9d3A217y198a/+1VX613fvK5F1xWR3Kbp2WF1jCGq1FGZ+kd7crkHuZuSQagnphXJWEp0bKcXEKyaUiBlWZKSoUsBYJL6SlqMGX3UFTX1ocxqBdZtdg6q5JzRdfOoJPqxMEW1tYd21o7rQ16c45lH+4+PcagN+OZpx/xwosPUDv4WD08DyeJMZqP1CX7A682tj7uZdP11kHGZxC/m05/ThDe/LbH+O+/4g/zMZ/8MdS84zM++Zfx9A/813zrv/5++pqpdUcPuzXia6gKJGVdLkma2e8uUFX6OLh7Ekpbr3j0/IvUN3wIL/7kA37gvT/Kg7Nn2ffKKJf01TN4jmsnmZtQtCXR29Ef2Opb+uP1Sjt2JAlLPzpQnx1rKzRSPnD16Iq5wKIPgeZb9rynypnLKK2TpLEmQfLEOuD62Ji641G6XDLVM3KZQDUSJiuSM2dTDRMO0DYYhzW24O7WJMnYnd2iHVd6N9q6gvi0ceyN1q+8hnfjsHSuG2QdnO32GDm4mUZfB6o95HdwuH6ebgRWOrH2I2rXjOFcwGl/yx2OyOTsnf9ybJQU4yq+7Fj6Qkurm8yOBmmwNGUesC7XPLwc7KdKKFdp6w6heneaj76EuTbW44uc7QqJwhhGKollPTolqmRGb6QkjCLs80RfVvJUWdcrpuS5Oq27XLNIcZef7LS2Old2ZeJwdYX2QXmYffEp3r1eXj/CaOznmZpnujYqV+zTjmMbWIbWLunjmrPzc5alUdPEbnIKUp4GKRWulyNDF4xGLuKOYcWYqz+PkqDsMn0q9HaNtYeUcnRjGgpSb3FRJvavUQk/kO22AH8D+H4z+4sv+e9vCrwS4NcB3xO//ofA/y4ifxFf3Hw48K2v9T1GHzx47r67gKTiRgmrYzTEibmMztpaRCooJQ16UTLiOcEoqyhWisc90Eg5ux+dCdo9pybLguSGScbUs4yrSlhJudQpJQ+iqt2306JOEk9SI+S8M9bJ8c+0+kKnC60bh+XIsgY2mgulTJRSkemMdz17RV8eIg2sLxGo6Z2o0zCILfd4GffRt6yvBkQaksPkIl1w8aTyB/7sF/Jxv/TnezyoDOxe5jf8F7+W7/u+H+bwk8ZSFyjupemc3xjnh/PnDvqQlCcubt3mwcMVCU4dJtx/8CLPPPccyW7x7nc9x6Pz56h6TUrXrL0xVDArzPMZqexobdCWlbnO9MOgtUZOrizqfWUsg5xmrHtHuw4jyfAAstpZxn26CSXtqZJpRSLjqDDnHcOcW5tKQckMTcgoTFNlnvbO1ZsKJx0/BZHC0IPHIJDJqWKtBYduQO/oas6xVOWwrKh2JC30fnRsTQo5V/bTXYpcuMqoJKYp09bOOg6+7SZ7fhCgurCbJnbzOWKZ1uHW2QXL8oicjLUnSt4zlUouYRqhnZRryFMLx/XI1fWBQ3vIrfOZi92eyzZox4XRL5kSHNvCVDOHdSXNidKFXSmYHmnrAqbMSdBxxQsPlbPdY3TtaAsaUB9kuevenmZMw5VMJVVs9QnpMBpnZWYMw8YgTxUZRmtKN8GGsOgjWj+grWHXQs8JIzOLL8BAuBqD4/EFNpf0ORXWVUKwsWAcWY+wLspUlecfHKnT5Pr8oSytk9Ke3iql7J021I3rnp0DO5SxwHFR5npBmWD0SzKZ3q+5Ul88PdMuX7U+fSCd5KcAnw98t4i8Pf7bHwV+s4h8LD6f/BjwuwHM7HtF5GuA78M341/yWptt8MJwvF4ZrEgpFEmk7trToR3pw0nZrfnDLB3NrhsmSSxkMnX46H3MsLkVr32hiDBKEKNtuDsJSlZjjMwqiVInJsSNBpKxDqVZZGZ4LWLYzKERXEKc5rCvtJyR3d71oExMBrdMUYHd3Qve8NiTPHwavucHfpD1uIbBhRODU0qBN1qYhfZXxBm31yv9XhmVUhPp1uAL/sjn8TM+82P5juVHMKBMTof60J/7kXzyr/5k/tlXfaO7MIehhZgT31/+VY3D8UVu1XvcuniCR5cv4rZJ0MeRH3vXO3jHD/8Qt37OT0PrgZ49y8U7TiPlxPX1FaNdueMNibau9JbwocRzvSUJJc1cHRZMF3IaZANLE2e7PakMdDWqFErakWyi46qLqVTmOiO4DrzkidkSrR9JIi41rds1XVFrzLN3lYmO5MayrmjLZJkYx0adKjVXlvXA0q48yni3h3HgeHiBkuH8bE+SQu9uM5Zz5mK/R8oUD7ZSzm8x2kSpFZGJKc03kE/O1DKDwtl8zjwlrg+VdfGOfT/tSTlxuHrg2fO7ievlinU431NtZZ5m5vkeF2c7ap5ohwesrbEvM2ZQ68TQzLJ00gKPbOFar3j20QvouOasVM5zJcvAZGbpB0gLh+UB81yY8zlJHrIcWnh3ZuY6cWt/hhgcc+f6eE3iWfq6oKvxxJ3H0VWZpgskTaR8zeH4Aq094mzvdmvrYaFOlZFcKHFxfk5KidYatcwIhdacEndYGiVXhhq9ZxITbVU0C48eHR1mK8kVbXqg946lI7VWpEPpmVTO6Dox1mtqqRwvO6XMCI/R8qCNA2kdlFo4/v/jTG5m38Qr71O/7jX+zp8F/uz7+9o3fwGWtXkGinZfrBj0LC6KH8Ode1qYg0bcqZOHw1wz58AH3ZDCzAHqwcCSx7tOMjEnz3u2DE2E3nG8ZwgyTZzPhRKKFMHHjd35DGJIhbu3zrh3+5xpnri4M3Hv8ceY854753e4c36b/TSRa0aq45gXt+8x5zt8xX/3D1gfLFhb0HDiTrUAGrjlVihvytWrd4+8/M/kjNxOfPqX/Co+4Tf+Ap6/fBDhZDCC7lHTjl/xWz6db/+m7+K5H3pIM5BS0MWpQO9beoc1Hl3e5/zicab9BcthkMSNc68O9/n+H/gePvThY+jdxlx3HBWKnblZggiH9ZK2dHJ2Q6w+hIlKtsTaG7XsOD8/w8bg1m4PdGqGSiblSqkTirspTXVmV89JaWJtIz73II+rUXMlpUpri0sIMUotTLudU35M/VDynY3/vXSOaqI1t8qrdePJQpYnGa2x9pVSSyzXPgi/QVMU5hXDyCn715dCrZW2Ht1hXSHliXUM5mnnruDZHaRydrXKYV2RJNy2x1A8HjVF9hG8iapORrpaFiy7i3sON3oHvN3w5Ozek+5KNAwd3Z3+sROFyxRfdC6XdHNFWRkJscFRjxyHk8FFfhq1VGT04EW6e9ApzwlhyoWKUdPOieQkmDIPj0dGhz0dQTm0+xyun2eMa+bLgnahqrvSH2RwGI3WO+vqUMd5mTgrO8dN55llXXC2wUoqhf3+jDyM/dneu+qcmHOmYCzLgVUbUzln6uec17uIZI62chgLfT2gh4ObpxRYGk4hswfYupJlZYzXuVWaCXRRTxU0t2hqA1qK7XRwrDbNdMqFXDwMKG0unjY4Fh8J8zCW8FuUkt2DroS1UqnIJKQZdmLUOnF+vuP2nXOeeOw2b3zsFrt9YTrfM+8qt25d8NjdW0xz5aLe5rFbd3js1i0MmOe71HqLlCudTrMjqx05WufheqCLcl2Md/zwi3zjv/8hjusj2vqQMY6k5KYTo7UbA433vS4v2WK/1qteKJ/2hZ/FJ/+mT+DBowfUcs4Iha0eXN45sbB7445P/R3/Cf/nn/x76BHP78kJ7T/1e4tV1DqX189xdvEEyB2WqxddPmnGe9/5E9SRuH3+Js5v79GLTpWJaZpQjGU90LtSc2FXZuYycVYmkohTWJJTbtDGNE2O3w3lbDch1Z1qWpgYVykUmQI68YMLc1OHrgMhUaSiY+cWa1IIV0uWvoJUv9Z9YEPI4UnYupLOZ+dW6qDk5NipCTpPmO1cf68dZCIxM1ossuTMics5rBTU/RVr8UVNlQkjUfuKdodSUsmM0cnV/T4tZ4+3kIL2Tom8nJyKcwsRWm/cOnNStnshF6cbiVt+9QQ79bG4UE45MjrcEX8dq3uZ9s5UngSEvjhHUtNgtdWNjNOEdZ8sSkrO0bXmXgOqkVHj/vM179Chzo5ILt1lQKoFXQwpE1d6TV+u3JBXzTfbxbHPw+FIKoOlLbR1jakM2jJct12MZb32BZsZ3fy9mK4crxu7ix3H0TiOjh0bh+sjLcHu/Mj1iw8Z+l5Kddegvg6Oy+D6cMl+N3G+L1xeXyN5pvVLalnRdklJ+1d9vl4XRVIwj9lsnXV0z81QY+REKRNruHBnKtggFcjFw6YMCx9Fj1qYc2JKnpC3O9sxzRO1Zm7fmzm7mLi4fcGdO+c8fueMs3nPvXtv4ol797h764w7F3vO9/HQJEipYqVwqYvbXWnlWjIHTfTeWZfnub5+NyoNcK5XGwPKGU2V3b5Q2PHPv+4Hefadz6GXL2C9kyieeTyMzxidX4Hy9cDXvtr1EQl7fTl1CdUy5MzFG3f82i/5NfySX/epXOdHXMw7B9OTOxWpNjcv7sp0NvHpn/VL+JFv/i6+5Z/+AKk7986KBiH6Jd80tutmg+PlC5xf3MP0grFeI6I8/8y7uf8TL/IZn/0roF5j6An6UIvsZfUsnV2pblulI7p7ZzEMa6g174CKE++TFHeLpjHVRF8bx/VAkeyFpblVl8pw7IuKG5gMNDl2msYgF0Bdr5uz23KZFDQDhEAgrSS8CKu43FTD9xDwg2t4h5tFUOtIcSMTzwz3ZYSInaIJcqnuXdqNPppnBtUSRruFkhLaYWVQ1F3lS8qsEtdPFZHB2l1FItm7t9QMtUQulRwha4Z6xpIatfhCsqt/jmYJM2M3JpDEKuGOPzoXt2YYHS0FlT2ihakkNKSu7vCeaepodMFx32FCkkwxz4AP/zHaGNEhJzR7NnzRRJ3OSQo5JW7dFoZ5oNtju9tI8QZghNRxHYMxEiXPqBja1vAfTX5I6WCXC0tbXWJbMnJ0We2IpezgyPVx4dhWhq0onkV+XDvXh4PTCW1hFseh2zIjkujieU6v9np9FEmDeYBY2Meb2xzlnCgp7PlTwoqgcybvM/PZzDxVznYz52c7zi8mLs73vOGpezzx5D3uzDO3bl1w++4d9udn3Lq4oO4m0lxBDCuJowltuJPI2o+8s13THz2i22BtjWqJnjKPliPXyyWZxFQmV+iYcFwO7sKcFdHmmKlUJMFyPAAry9XEt/zLt9Ovr1iWI6bJib6j86v7kf8DZQf8LuA3AV/7Pp3j1k2eOkoByZlSz/ngj3oLX/hHP4Of8Qs/nLyfkPwWMrP/+RD/C0IxYUqFdRhneeb3/Ze/m3e8/ct47l3O79tcXV6+Ro+iqTDawuXD57l770muLwuHw0NybvzTr/l6Pvs3fjqP//Sd59wINOvhk+g0rITQ+/AFUhpQcLcXUZoquVRU3O5OcmH04XEPomRT9+osiabdF3BW6K1FSmNmqCuKcko0dcw6DyVHaqQHwOGbTvNscsseSZxS5J2Mjqn/DIahtm13V8a6kESpKUP2YLYt7MpHIA9iK1lCFOGY8ggrtJz9s1PrJNyH0U1oikf+IgxVanFzkTxNzgnt3QO3Wmd0j0dIkj0vWjsNI2UJLrGyrP4eyL6hx3xMlgY5+8Si3WNfrQ+SKuuxU+eJmpS2uv+imAKdjDHNFRNnAHTXX1JSRsegzimC44zdbmJZF3R0Uu5ITu7Cr37oSHToRZXzWqhpYiSHD8Zwh1TF6C6ZYmlHpFZP7JzCa0iVZXTmXUGyq8lq3vuEiXvF6lq4c/cJbourp/azY9ZqSh89HI4G18crcq2sq+dEJfG9wNfx9a9Yn14XRdJEGNXT7squUBhMu0Iuwu2LPbtbhYvHLpj2O85u73niiTu86YkneOrxx3jysce4c3HBNO2YdpX5bHb7sfCZPCwrw5Tn1Lg6XjHWxLF75zSnilvRNQ6HR6g11rFybItHSpDolmm9oe3aN5ybKa/iS55aPfYhlj7TfueW97IivfLDb3+Gp9/xLOvlC9hQap1JSVnWhS+MAgmww4Xw79tNvu+4nSRx594tPvvzP5Xf9nt/C3ffdofB6vktJlSZ0OFKCzcWyBTcpUiT176f+9Efy+/4ot/M//Cn/woai3S4qZGvtBwauvLw4UPu3HojZonj8QXe8QM/wt/8yr/F7/lvfguHurCq0rfUxK707suhrv5+kcE0VXrzsnx1ffSiNWDpjWm/Q3SwHq+ZUvL87pLR3mhtZar1pBhp3be9Hi2gSB+sfY2wNA8SYwxElDaU9bj4ASeDVaBZSDbVHIcLL063rfNDeV0X0OGHdS6+ZCP03CpA84KEh5nBZqjhHfow3DhCEtBgcRmsSEWTk74hlncWxSu5/6mOwTDvUmsWxlhc6GCJgRu05OKHtZiFLNfjWVUG8+yEfAv/gVw8blaS0EyZckAQQ9G+hIep+LWI2OTcnP9Iym6nlhLHxTmrIsJoq3eyxwJI5EQ56d1x4exer311WhFO80opNOzqFmg6hu8UxJBklJxgGKP3MM9w3uZu9s9g7Y25Vpg9wiGrmyTv5h1uidfdWHv0MDERj2ZOHqHb6ZRy5teGgYBLPF/l9booknWX+aCPeYpSC/OtPY/dvc1Tb3iCi4sznrx3l4uLwr0n7pJkJpuw20/oLjtnskxIqTzbB8t6ZHnhkRPQj57SN3qLkaa4yiW7lvU4VubiyWvHZeG4HEnqS55NwubeyjM2OlNeSNVjIOZauHvnNvv9bYZlpmliyoUpZep+x7ybmOQplsuVv/9t38b64gH6IwQlZ2VZD8AHRhLfCta2Bd+dzfzO3//r+e1f8uthv8fsjCpnNHOS7LCG5ERjsGXfjG0sNAtvKePTfuuv5uv+yb/gu77pe/yh/imrm5e/BOjrFQ8fPcvdu48jSTgeL/n7/+c/5eM/6+dw76PuMYbbBAjJ9cDNA9g0eWckbZBkCZcXdxNX9YJm3Vi0UQVmm8kqrGtjRLCZauVqePyEWDpxCVPxYDPPlfFuTIaSa3ThZKAhc6KU4mYpCiIJFTf9yMm7iSkX0uyFQc31xzkX/3v4IrD3Tsnud++8ViGnia6Os4o4bg4wIlHTTEkl+z94DripB7uN4R0iSbC0LR0NyT46D3VbsVxcK67qy6ox3Owsi/ufmjqLoY/Qesdh0uMENPFJwTxInqM10pYAmgwbjgmKdCw5mV7CQUly8d1AdiVYIuGZ8+HbiFvLbQe6hKlGLoUkQh/+HjoZ1Dimhf1+77hmqMlUld7cxadMrnFPCVp31Y2pf5JZBBZvooY0xvAl2SxOkMeMMjuUNYBYz/vCTzI1Zc7mGamFo3ostA3lfPc6xyTvPX6bz//CX0MN0F6qGxro8Deh2riaJq5WJwBPvWEPFpZl0MeB49rAVpIZOTafl+uB4+GA9U5bVlQSao2S3JLTgFwrZ2dntLXTe+PWrVtMZzMPLi/ZlTPO5so075inidsXlfPZL+T+bOZsN1PKhIg/oMWcVQOOSdkwvuv7foQf+86fQI8PXAtcJ/o4MsaKiPCVBp+Kd5FH4K+/7KpsphcSbsuJUmd+yWd8PL/md386D/YVR/eexiwjqToeqA6u9/BFTOQoWoAZYm6uauedz/niz+YHvvuHaM8ffJkSTaBIetkiadOMp2y09oDLR5l7997I5YM7HJ55xNu/+T/wn370p9HHwBMqslOyqgfeL2Nln3fUKUjLJHIKikwCRoz7QBbzbCEzmnrOj3VDsmNPPhJ6ccV8lEtJPDrDPEa4SPYBzrwANe0MdcWVmiIqcZ2msNxypx/BwhCDk4GvRJKVAjK8y8vJQ9acPqXY8MzzlNJ2AeNrVWpJTmYXICVKQBCmnSl5EfboEaOHocTa3A29iKEje4dm2z3hX38TEgwzJ8CbQysGPtKrFyDbvEMDtkmn8K4Ii9PBOlaown6XXQlVE6O7VBMFG+7ggwhWFOkKKaH+iZCj88UIbuJg7QO79vvcOzUYQ3zioXN5ee3Wb8VZAWO4EMNIcB3+qvGsjjZYajtR/kYfPDoumB6ppVKy68xXgb728J3196ZqpFJ9+lmvyUmoCdqhu+lN9s9+tFevT6+LIplKQXczx5QYHRgNvXzIujrQL0Q0ghqrrc4VSxmxxGHpHHsnF+G8Tkwuk2FKRtnNiJwxP75jmgopD6Zi7nRiwkgwne3Yp8p5nTz7tzr1YTftmKU6d0/M/fuAHpZlNbsRsIo/2DtJaDggA6yW+Lf/4nu5evoBbX0ekYyitLYC/kB/LY5D/grgn+F45GbNZnHDecdilFp5y0e/ld/+ZZ/PYS+Mdu0YVBqQKpXtwTeqZDJh68Zg9IW1tVATuTlqkc7H/uKfxS/7rF/GP/9f/0nwGf3m3LrXl4/6MSplOFzdBxGefPLDQe8xpTPuXTyB2eIhTpaQsOz16M+BRBRoa5GtQ6aH+7vTduJBG4tjfaYkjCmBVhcI6PAxart+ALYCokGI9yKZBBjuClNyoQd7YIum9aLvI6o7k3i3Y9rR7JQyY1uYdR9J4/PIyckSCSEnf3xEHf9T60jyA0UDfvGf1fNV/D0Mtz2zcIBqi4/a5t2hiJs5p5SwHkuYsZkkK6ZeFFNKpCyordgASdkPAfWFm4iQSqKbkiQzpRRCDPxrJHEoIUE2/76ScIx1rORs4ZOaGM2oUyw5emfkRs6JWjOqw3n6cabmnP3PqDsvbT7hBT8IzKdx7/ZTvrnXIjBNYupRFdY2fNyeIWfnRJK82XFoZPI8o36gZO8812XxBii+Xs6JMRYUOB6P9N58qtqC5sz9LOfyOh+317bw4+/+0fCrE+bJFQnZErtaHE+xlf2ucnue0OEb7LlOIE4TOt/dYjdNqHY6g7nMnmOR8FjXoAQE+8O10zkxzzPVYJcmhOTb6ZQZQAs6xCTmp6VFVjPJyerm21yjsyRPYcQKmhsvPN/4//yL7+R4eR/rK0k8fvV9X18r8j44pBfIWnY+ogoIlbtvvcUX/4nP44mf/kFM4fLngHb3qIrI5DbcSs1FjQ6sW64wn4X+3DuxCegc+B2/9zfxXd/4dp75kWfDc8/dVH4KGmAuegRAOsfrF3n2mXfw5Ae9kbd9yJu4EKV5arz/zDJIVn0R4iUwioUraswWqhqTJHqFo3aGDGbx+FizFEsUj6odzU1cdeipqfKioQFjuMkF2UcuE0/0M8KhegzvEKPQbO/GrxuR1eJuTiCx/EqnILichJSB7GOlK7gkCmp0nBIxGht/1y9ExGUIVXwpqbGI0eQ/zxiDUgpTda9LzI2DEQ8j8IJuPuYHxrilL3rQoHffkhKl1tPWfYhT5EqpLi8cA22OwaH+c/SAlRIgY5C6y2TRgYlQy0wp3rmv6wGzbRnlBr0pOWyBuPlGOuXAi+OjuCv+UWPTLwUbTvcCx4E35kZOhVpz2A4KNU+ICqX6dFZ2QsmJqbYoroXeFno7UqtHSNf9/gR3FPHP6LisKMLZ2S2HS2oNyW9CtNDWNX6eV369Loqku5ZcMs0z+93ErduV/XzOvs7spkwt4u7COZI1xCk0GRf9W3KqUE3FcaO4SWv1iz60MdWC4DgmkZ42emc1aAZr6i6HxHm6DeVoCymLuyQPf2iGOX2F4csbNWh9jaE2kfMeLcr3f8+P8qPf/+NYvyYlgjLSeWVe/s3LO8jMUCMXwVLnZ/2cn84f+jNfwkd9ykfRdFCzUxhSuO34Kb5FuWc0DRYn5XhsA56CuOWLhMgQNPGhP+uN/KrP+aX8b1/+NT6y2U1X8LKfCzeY1bF1mYNleY77zy6c5zMmPDHRJzkPpTJcMz2C5zo0Hg4dIRH16pQT7KQykru8a+uO4+H6eR2JOu/QkekjsflpmkWeTxokczcd4vORyk28hZpnokcH4QqdggTfcityueabkdUrNYp3gb6MiG4yZ98Sm5EiotSCURCOpJi6q1Mpxd2yYyFkSUg5kYYXIUse45CzwzYQruiBmY6hMSZ7dyTZD0RfTmgcSAEJqEI3Vy1twV6G59GHm5V2L2x+IHqhqnUiJ/9sHTX10C5Vjza24ETVvGneY/sfI7Ifvl7MfVzxQNnNg9WyY+N+WcOgOns0xMZ9VjzUbyxLEOYTEq7w67LSekcluvgwhtaxMnoPCMMhIrWEDT8ER/Io4nnvvqGmkLOiKDWDJKGvK/vzGlPbK79eF0Xy7OyCn//zPoVa8KJk6rhSyLyGJXKuQcvwLa4UpyPYCNdmMZo2b/2BPlY3lGWPmtw4vAQ3bUSEw9o6V4drdwxCqGWClFh1IK0jOZPzTC1n7OZMTr58kWoUKZ6k1wc1uaAfJixXvvO5H2K9fx/TxpBNWy0nOfb2+ikKGwEzJzyf35n47C/4ND7niz+TJ978OCmfMedHjlXR431viYcSdKFEplOtRdnM8XWdN+ediBftkncI1/zaz/sV/Mt/8E38xA++i9TzCcd63y33jZTcu+hMYXnxyF/6U/8z+3uP8XE//2eg5SEW0sGX/8UIgcopOkoh59mFI627b6WCJiGlShGnhSRTyMXjQK2wdmcYbIqSLZ4B8O7HDNQ81yVtQXCeYZKzXwsLcrScipKbR+QUJSLup+33x1BGi3jV4PBO0VGSnF9ppPj9GIuTj8UbURqR4NoOskh8Tt4p7ubpJE1V9dwdIWiIoSbr3b0LtuvvGn8ndOfs9+G2cMr4AofkmedpmgE/5It4t+cHTFiTYTRrEYw3e0RCUMDGwHPgVendM7s1/j4pu6N3pBNuTvo5uYAjEZ10EqfaEH6tKTEa9NgsI8LY4NaUHUc3C5tEf+32E6sOz9rBnM4U12wM/0wtR8R0Hz4tZkML1OQke3AHIsyXVWqDqe6CLfE67yRrrdy7ddc7mZLD1sqdHYcZNvwkXIZxCjAa3tW15uNdsUQzY2mdnJ2L1fqgHQbgo6jgZqs+DglVMsLgzsV5jFceiuobzQSaKFPFhjJJdp4aHXXNGYkCOjir7vaTBJCOULl6+kVMr6JTAaK7eL8vg5SMPMFv+YOfy+f+vs+k1syKkNKlQ2jqppjesbgMz/Exp78I1V1ZcH/t6IECRHdT45oUrEGaedOH/jQ+87d/Jl/5J/8GNmCVw+lnefWf0x/SZsY7vvcd/Ne/60/zu37/7+bX/Nafz+68OE6YCpIUZfGxd9ui58DgYrwtxU1O0tgMZv3pTKpQEk1XDqvnHXm3nkKJIzTWyDBJkMIodnIOnmiQ78Vc0yvCGJ2eFE2uMWdE0crBoRzqzvd9RD41PvLGrwUfza0QeFwPeMIxRR0BAYQSzClmetouV0txb0s0q66IcvWResEQQ2TEdt5Ha19+eHdlZm4xNnxozCeMLbkIQ5ViMfqDL0MANKah3vHoXF9OWVCiRA2JBBuHNpzDmKSelkCcMHP1+z35gYl4p+Y8UUD83lNVx1DjSqYSmUubC5NFo5ATJSVPRMS5jY5firNKRG5CAVXoOZPrjc+qiCAKqVZ3S1dFg36WcS6qJIUEybyoohZxEfqKtLft9bookqrKqu720w6NJt6WOwDuiXXFnPMnKqiBZIHqH/80eSJcwTd0pUx+k5pjiZ7T67SRlARhoNLdak2dVJwlkzUjVB/DROm4jddQo6cK1vwBMSFZJqfoTkin+Ag1pTCcOO7DRZyWN+/3p9qdveT3Ykb66E/5mXzmb/vV9FmxkV1uRwoczCkr2+Z6loAeZLCFE7jnORDHinuN+OIixc8gZMwKU0581m/6dP7V1/4r/sO3/BC0HN3B+/xs8rI34XkoCAzj6R/9cf6nP/uXeerJt/ALP+tD6cU1zNtCQIfE8iQeXfFCaGMwrJ3ULjk6Gx3O1TML4nDyLaoX1uzxqOBjvngw2tYdOTbo94mJU5C2hc2GY5oY6+rRH4hi2qAt/vB0jwbJkektQCnltNTaOrFhGt2MF84sbk2WonvX2Lab5dOfl+hqzSJnSLa6E96mgTFqHIDbySoSuHPyTjaLf7MUE4KNCDFL3t2m2M53HUiKezy7m5X17iFiRpDRHbc1M9bu7lkpqEwC/nfiPu29e/GMgDlSsCXU5cQpF+842WAAPd03ZurBYDFRnHBh8bHal1vDExvNu/2UXQ7psEkPbqzzDVKKSI7T8sfQ3hynFZBU/MNXIxE54Rr3YdzfyUKK+hoo2OuiSJoq67HF6ZqZhpLUzQPKPPnNkDPztKOmcjM6gj8QpnTTGB8EMzfDqOEopMNNJMZY/GTJfkp1UqSy4dww3LE6WyZlodnk5N+SSKWStGHqzi9JQoKHn/aSikMEplQTsm19x2u1Yz/1pTjo/mt/3a/hI578YHpuHnomWycmHOXgCKgV35oHJma2neq+kfcdsp/gHgzvHaVjk45fglNC3vSme/zeP/if8Yd+1x9nfe41+BDbZ4ZXoFQS2gcmyoPnnuav/oX/kQ/+iD/Mh37MG060KwlsT1/6uRFLhxyZ6Clhtq2jlJ4GI5YPWYS5VKQrhhtmYMrobp3nRccL1qBTkrn8byhrV7aUv5xzTBmJbh5X7Hy/EbxDoaSQjMpwBkN0OlvRsBgNKhkJas5QN4PW7QDCcUWJgrrhdRpWdE7hYbMBxbgpvkKM+aakWk8Yh8SILvF3PdfJI0k2VVZvnUFjmOORORc/wA23rFujwKvftTm7omXDEs2gb0ogNe+UY/Yo1fHImrMffskD1rb4WbK3A6Z4UF7e4B252firvUyQsT0aZiNI5b55905EfTmlLTriIH6LQ3JJPCY6JT+MtpjZeTedDg0fMRMp4ZJXoKRyY3qi7i+bXgK9vNLrdVEkSy7c3Z878dm880gaQDPmZGhxx5zjODCCkyWS4saDVFzDLeL3XlElje1mdA/BvHUCMoDhZrt1h5j4CIfra72bU6bsOuEsxoSiaYYSG9zoBASn1IhEpxoP9a7UU6fwH+Psk1Aubu/5xE/6uSSZmZlJcsWgRU9amKnB9fSfxbd4GcTTfOAlDxeBk8nA/RTl9ODc/FDeBf2yX/op/IpP/6X8/a/+J36zn/h421d6yV+JzeroWzqhc/9+6Hu/nS//Y3+VP/sVf4Q3ffBj5FoQaWhS9/C0GKUCHx02PNIXX8jI8MEs4w9DNaXnHIsMkOaYlI+IEQJnDstsnZoO6OrfL02FMiIWdutM+koyDztDQWRGyuQ+pOYdjWX1hY1u2KzE9XOMsgUv04IIbfHg9+BvWviDplhCnIbeFEqZlE6f0dDhiz11ZsOI6+sTTTrdQxYeo2Ze5CwK4WljnxLZdt4VbgsddYs7US/WSRK5EFt0d9vP4t3eZiQhCiZGLskdi4Z//nmaKDnT8S5f1MfnIZ4dpIErG4ll+Na6RJEyDXOaVL2oB+9S45ARIzbt7oRk2mOLueGyXoRF/T5OiaBSGb27NHXO1d+7GmTxhV4Sevemq+aJFHJRiWnVRg/T49d5kRTc3aTFplqGsfbVZXR5xkho61SNsVPxPGTJaJiwZkmhhPCHuyTvElOoJiwlTGKENHPuY3q51mR4H+cfXgDrUAPLTBTbdp8KOG66bRZDyoJFAS0lnzCs/9iL8ZE/+8P5oA9+azwknYkZoZ6ulVn27Z6YO7JbDoNX716GHGm0kNA5HmRoRO1msoGKg+0EngTC7izzxb//d/Kt//rtvPsnfhIhg3k2NPZTeUEaENUW8JQMtBX+n3/xTfzh33fFn/zv/yt+xs9+K5oWd4zJ/hkYbmwRsxYpCVXzaQNq5sodDVijRrfQU0JqLJUw9qmAeAJm6UozD6PITN57JJhqAVXEBqIDsY6VwpSSP9Ayk60i6riV4dfG39M4XfOoHKfrJeKkZrPILzIfC6UUJ54HwX3TxAv5NFq7cUaMeykHYRtEpng/YZKEngpAKcW39vhn7dU9sEw80iSlHDij49U5ZQZTFNmGiLoRtSp9w03Vyf9O1fGOdyPge0fsZiKm7uvZFP89Vfdpja4MM9pQSp1dq22A+DMIW7fnAhiLTlckuTs//jy3FB04Rt1PsRRrDoXljKXCaA7RCMKUfcyfag7eqi97peRTF+uSx2DHCCQbDG0eryIg4Qr/Wk/q66JIppTY7XYUU8c/UmOaPVskp4mcPZ40SwoCqr5kIQKw8drkpGEFZZom9zM06K6e99Y/RgjHLratcBSQuJPtdOFSjKZpu8MRhi9tyLi/oCHRNgp+kvVm/z9USH+4fuEv+gTOLoQhIx6BEWPcBsYfnAVpjt0Mya5PjU2vp1rE97cUNz9wGgbBAyl6/Nq7HWXwER/5Nn7H7/0c/vyf+Cv049btROzty7rPmzcXpY1tk5s08W++8dv5L//zL+O//Yt/hI/46DdA0Rj5E6IuBDD1Qg9KkUSpfiypOZFY20A2sQmKM4Y0RmyfGjTcdyxysrGB9gNbfrmyRqcb3UMqcW1y/MxC0pvxL4lASPpuXJcEHX6cSvy8OiR04okk3gFutCy/ddKpII7hnLxcphOzwGy4MUqMj1OukF4OR5jlwEKDaJ00xmX/d4/XCM22Ca0N5urLMN+dhJdqKaQ0oeYZTA5LgcQCTMwXKZuZtMb1xYjnKQcVLkcEsv8sBe8+MfPuWJydm9QVaJutnoAvQLEgwDvFfIMu3AnIF69jKG0Jsw5zr9AcxG9MvJPVzWzAF246AjpR984ctkEFrpxyGlbADBlGhqIwN6Mn/56vZFW4vV4XRdKLkhfAUiZGn51esy0qNnA6xqFtfLHTxYqxMvhliGMQY3gmyDYmnZxxRE4AugPsQXTGHyyICYO8NZ7xjSW+3fZ/PuIm1G+GKKxjFf79t77d/+J/ZKGc58LP/wUfS84dVYmTeLz8u8rMQEFW73CCWm7iW9TsvfdJRy1xIBg5/q8wmL1ISmCqFP/3ZHz2534G//yf/Cv+7b/+XpJkkrz29u/mQ/CVgw4QFb7rW7+fL/3iL+O//R//GB/3SR8Wix5IaSLjCpTEQJMHvbW2xiLEO7aahWHrCcgHxy9N40ASwBqdzhiNZk57EQ0hUvIDYgzvAreoBgkliUY3h3hH57Qj/5glXH02dQ7m3++krbaXwBFxf4hFt4kv8Ia5B6REVzis4QbLFlxFL7wnPDLy17ettFgoVgL68M6uxy7H3EIMo05udFFrpqSX3K+AdSUlo2SXhJJGiA6AEECI2QlzHOoRKOKTrnNNxYvTtmmvpkh3m7JqI+5FQZJTnEoupFzDzLrFQi17Z6caqquMqZKLwyzDGj0u1sYuSWGovd0TTjgaJ0L/0lr8XDdntuO2gUnHeyylROffkOrPfO6dnSSaOaF944K+0usDybjZAf8PMMef/7/M7MtE5EOAvwM8Dnwb8PlmtorIDPwt4OcBzwO/ycx+7P1/H3dCySLuyaeC23sHP00dn1RCXiZBymUbTSRS8bovasQQTbHMiBKTvJPcxPglS7i4bI3W9jB495Diht8K76DHSenbQou1zdZtJvPT9j3veY7/8N0/FFvQ10yu+CmvD/rQN/BRH/1hVGaqOBF44O43KTpBMaFLR/AllSBMUhCgB1o5YlkSfyPo425Imyn+VomxDcg23OfRBm946jF+xxf+Rr772/8Mh4cdMXm/RfK0pxLD6SUCw/jB73mOP/fffBVf8ZV/hLd8yG3s1JArGxAv2wEISI5Dx60xQI/kLGx0lWMvULx7cPpL5PQQy748wVwoKjfUj7odjP7gUcC0+NZbBllq/Lyh0Ek3nZrGqJ5jqafqXWUOVYdpLFRMab37AZ0AcVnhifcYyyWPuPD71aMs/O6T6GBfOiLJttEfI7pR/6zGcLldKUHg50aS2gY3CpacqdXfcxYnTCc8AG+c5IQWMlvXMGv3oldSdrOJ7DS5LEpvPXD2mFyGxaES5jEp0c3D05LhvqzDpyO6F8DWN1jBJ4PtnklWqSJI8hTJosQGOj5DSRgDS24WogELqDmVayoVbRYjvD9zPmqnU/FHYDRvIEqttKSwCilXyK9+f38gneQC/HIzu4zUxG8SkX8CfCnwFWb2d0Tk/wX8TuCvxf++aGYfJiKfC/x5XKL8qi9BmMXpD9vJ7C7Ix9gYbjrLDfDfTlVDdWsj45Q1l+NlDCw5vSAlUo0MklMHAiJ2OoH8RG9o2jpRF2t55xb/G+oKcG2uo4DKMKd9ZAqiwvd/1/fx9E8+9wF0XzddbUA4/KJf8nO5e+eWj+wsIfvaZHTxw0ZudDHfCLvLdHMXbQOoQImO8ub9xfyNMagvWQYYofUVH1tNBp/6Kz+RX/Kf/Dy+7h/8G8fB9KduvF9OCfIHTmT7dXADxzVv/5bv4n/7qr/Hf/5HfwtzcbzYzKWDm7TPq7mrRbJkxLLjYJvjDj4maXK9ty/a/B1pNyaZyNOMK46qU1zUKOFev3WFagah2vFhO5/4fMNuwthOyipz3FdSDVMNdw5PWU4EcMkJNbmZGtTcZxQn3LvsSUjZM3ZGUGjG8GmoFi+WwzbIwr9PU8+M9rZ1s1ZzBocEzWlYLHZwSMGioxfZVnTuOdn7Icw0nAq2DlfeeAeRaMPv6FLcXzWJY3uYsY8OEnxEX00Z2btt7U6zs/gZ5jz5Zhw8xqLMTtaO63/STWto7c0PkaGgKm5cnCqJEZp1cf7rafrzS1wR9hVa3PObZFMDNgDz0Roc2khBvVJ3SdIeklf1petrUZg/kIwbA7YosRr/GPDLgc+L//5VwJ/Ai+Rnxa8B/i/gL4uI2GtUDMfRolswttITjsQaK4h4zLPHV6J4VxlyrYxTdUzFxzlxnMWUUzpfrEEdSyrKSP106rje08frhMup6tYdmkuhBhJeeulUtOI5cicgca/A7/qO76EtGxn4fYrJT72+5OxyyloqH/MxH8l+70ssdyxyi6iXju2GG3QkSUF/AYIjKYIXa7vB4V767S0wCyPH7wmQYznjHbJi3Ll9wRf/nt/Bv/3G7+b55x7B6RN49c/wVMPN/8UkYbbS2jX/8Gu+gV/5ab+Ej//4n0my1Y1T4+cFGMlNV0fy6yy4808fxMOSUHHqVU3+0PrY3UmiUZQI6MULZO+dUgqtbR1dPnWGFmO7L2qieKLBo/W3mrKEUetGEE9YgqaD1GPcxq3ehgScE/BNi6kmi38WYxhoc1gk6C1tDKZcGMNNT4bYyy6oBEdQRycLN3Si+Bwt7NJepiJKL4GekrusD3N5pIkXwlxLLDcimgIC7kpufI13Xn040TqXyhDoGL37uA7infMwUj0hjCHhjCVN8vc6LIAf2dglQq7Vw9S2SSb5M2TBDNh04ANC0eQ3liT/OQvJXf7Dh9Ka14ite3atvpukCP53EgbqHqRrb36PFaGWElj1K78+0NztjI/UHwb8FeCHgftmtiH/7wLeEr9+C/DO+CC7iDzAR/LnXv07GEk08AcnsbiBRMZpCo6d+cV1HpsNwh7fnWksPpTRgx+mUDOQw4Yrp5AsxviTnJRcC6fOFLsZnpOllxUYQahs3Ytv4MQExXlXGUE0wyi8/du/J0Z8x7teC5jcgPyNA/cD3//D0CpzqSjdQfPAyizqlMWCYoNJU1wvjf7WRMJs1a/tZhTB6SeJZZQFRxQ5xRA4U9MfsE/4pI/m87/g1/GX/9LfIsyLXnpPvPrHSRTK4LyZNp595wP+5v/0d/mYv/LHmW+l+ClKdDJKNse8svko7osYyBaUJU2sHdLknpHJfCFRcg6MK0jL4oenqjFNoUKieMGIQilqAXtGhAB2ctHefnhTd60R8wMc8QVDR73omD94Gn9WSjlJYv1gdGf9bSEkUcxK8ozzbk6POZGt4+sgnOSTkE5UqxLk75ftF8R18uBiHd9u+9cihQWc+iRmzRdbZtB6w8S7NqKjV1NaD3VbdNypeNOwdqMPpW1cUvE/N+XicFhoyjdJ6CYE2WCVlHz77ObCrps3G8x1IuVEWxs9pkC/gubLf/Hmpha/X3qLqA91vH2MKIA5e/44Qov/LcXvpyS+PLIwRtHu/5tT8V1siDTya9zPH1CRjEjYjxWRu8DfB37mB/L3XuslIl8EfBHAm972FO5m4zzDEiFIoWN3n8itpTc8H9piw2xenDRbyNCcBlPzFPphHykHvrG2lAI2cwK4Y1oSGmBz2lB8X41CuFGvOZlE+PdJkkNTsz1cmQfPP+JdP/5eQjpxemhe9doSeCmJaZq5fHTAuncEOfXgh3lRHkG1UQsIQlxrrFshjK82guYu8Z5kmwRjJPIFQz+NZRtJ2vvx2bsoE9LuyBd98W/k33zzv+db/8333Cwy4MQIePXP15F/04mcGtof8a+//t/wDV//b/nVv/ETfa0k7uodvVEs1cBOiYFAWinJs05yUkZJrKugZDck0UTNhTSlMKltFLrL2ERYljV4sv4lS8mhgrGt5X2JsYfGMlDQOJhOTj8p5KDmByjJ6BbF2QEJzMK/0IFWXxgYgZ352ynibuGYyx51jFDNqHeucvPPaWdkFvgo8bPH5jiwDe++QIrja9t2Opn/3EncAcgvrnqAmXishzhU7d9zOzBlAzj8nhnDOYslO2ZYp4l+WJzyJdt2Oq5lGCoPu5EMugzTt+Vi4sF+st33+dRxDxtsBhkmxmrNlTLbUnejCcYhp6X48mfA0C31copr4iO1b8XVFV1+4zLMnxQTkFyCXP/qu4P/qO22md0XkX8J/ALgroiU6CbfCrw7/ti7gbcB7xJngN/BFzjv+7W+EvhKgJ/9cz/CxASG2yUlTacxIavfEIovLFxuNsipBMYYnDV10FyiQ9iAPgsyn485drqpFGf/EwNtFgWKRzI4MEWOkXRz+Bl2c0LGQBjvJkWnYDzzzPO8+MJDnF7zAWCSEE+pA9Rv+2lvIdWOpEHJDky74USHMATYir+aRd6KgGjss7u/H7Z+cbv5N35hOACJAu6nt23HN/qKyKZ1hbe+7U388S/7Un73F/5hnn7PC/TmHd4Hgrf6uO8E41Q69++/yP/y1/93PumX/SxuPeH55v4h2amLsJCdeYNpQHbuY77B2lLOp8/Qgn+pYj5OinczQsj3Ms6L26zSeiIFjjvCDqyk4i7aOaGhfTb0pIm2+HdJ2ZMDBZfA6WDzfvTlU8gi8Y4xh+nEVsQs4ARfAHlwmSDBDcykUNEM84VWTvlUFDflixQXXFhwg2VjcwSZXNXJ7iZRwLCttWW0zug3ee89NvYM2HhD2/SRkJc4oXsXaBi9rSyx2Q7mdjQy27JrBK0LPyTNjSQwAg6Q0z28QR41V7/eucSSajhsEJ38tnhNgmcNbewA8zwiMyLPyH+tsQiUHPe0Zf9ZMFJY6jnjwfwwzK99P6dX/Z3tIRZ5MjpIRGSPe8R+P/Avgc+OP/YFwP8dv/6H8e/E7/+L18Ij47tQSqWmSqZQ1QnjztHyPml0z97eui7tLp0abWU5HuhtoMNoTenNOC4rvSmoG8AichojSIGX4SPOaIo2dzcX4p/kZrG+CPIClEQdFpAYt/ELnTayMp3nHzzP4XCIIsT7rZPblbEA7T/4Q97GVINjx4QyoVQMt3pLsQ5wzM/dZrp4wJOKMcT9ogeOk6nAECf9dpQmgy4xrqAMcbLwEKUxWFlZWOipsYyVRufnfcrH8Pv/4O9kd1FB/OfIG4L+Gp+pQyYuK2vdQBpv/3ffzTf842+OUe+IaHeVUgoT2+3AM08pLCkKkviDYwwkG1KIf5zms2HDQ5W1Dx8RN0qLObm/5EyKTBhnRfiD17XRrDMEd5Ip+WRsK6d3s/W73oEMFbACltHuuGmWSpKKUBArjCb0Br3ZyWJu7d3xMNmKUnBHJVHTTJZCMl8Dpji4PF8nnzpKkndNgnETUqSYdUQGKRsmPShHDayBriQ601RdbhndmCRXOI026GvzbPsoIKgGlLPd7xHHG1hmG8OFHMnJrCePyBH83ZhxJG0ZarrdmWFSPFjbka4rxks6z+BFllIp0xTBZnb63EpyGKAi7MvErlSmnKmleJTKNDHvZsqcsNQxGU79qb5T0Dg4Ug75Y1tpx8Or3skfSCf5JuCrApdMwNeY2T8Ske8D/o6I/BngO4C/EX/+bwBfLSLvAF4APvf9fQNTpS2rg6fmXn1DjIaz/suAYk5JGL3TRkPETUg3HiUUTGMLJ+JtdvLOwGygojdLmuRwbmi/XL6WN6DZLfHd9bv57xuOlUqOBc9pGMEdtzej0cT9F+6zrm2DVj6gly/shWkqvPWtb6a1ASWxWotL3sO8Igo3m5ltHCJyUmjH/+pLIAL/fxquL07u9YPmRBLHovgmNnNdNXMHH1FGUT778381P/SOH+arvvIf+YGkrz6evMYHzfH6wFf/9f+bT/1Vn8QTb5k83B5OP7eRIHvu81H9OqacfRHSOlJcVZFFThQdgqI0hj98PTrYJHIyvNWhTskJJylJebs0HkdrMVyLOCMisNHt/vTue8P9YOPe5jBqcBmixP0QCx1zr0UvuN799+4YomwuDMNe5pMqkp3GhGvK3dhCbjrt6Kokph3CydxrrqFhbntjj+jFvfXQQOu2yAi9e98WJykklM5+6M4z8nsj+/Tm22hjaCOlQi2V3o3RGy9XYymbBNYXMJmMseoI1Zt/fzWXHG6Hfu83RhrbgbDxQ/36x3uJ60IwKDat+8YaIPn3trBPFHUpqEZH70ssb5A86qFGiNkrvz6Q7fZ3AR/3Cv/9R4BPfIX/fgQ+5/193Z/y99SxEsE5jim7EC+Jd0xjBAUiFx8rbLjhp4Q7iumJCAwBfluMqebAyzb6DFXEhFSi8+o3JrQmNz3DGM3t7dPm+i1xK3i2tG9ncxDfvddbjsspw/pE2Xk/Lwk2Y5ng7uN33FNRNlTUfxY/gwfdeqCOXtrMhKEtHuDN0EBPi5rT94g77SSlNMeRtiLpmExiOwvNOh2lq3f585nxB/7QF/Kud76Xf/5134z2/B9dKH2pMPj+73kH3/BPv4Xf8AW/2LFk2Uq6oaPT4v3U7DK7Y18YfVCIcDC1kyOOP1g3iyT3K/Rt8lCNSA03MjB8MWg5xuMNT0ybPZd/FilA3O3rbs46CKesmM213GklGx7pdSWlEvdlPv1cY/Sb+1IkFkXqMlspHoo1FMRiIeQLSC8PI4wkvJBteUTbltmiSFiM+bpt7m07qWOZEhimLwu9ey+lYtFdbzZvOsL0uDjevR0s272YU/y8LIgE+T+OXjUHeJ3Iv/1Xoevm/ygBEXkh9M9l60I5PaOyTSoWCiB8h/ByH4QbowrbdN/p1B64H2d4NnghNoY4q0Ds5r57f4Pu60Nxg8Ro46dC1w4qTqtJiSEJLT7SDG2Y3VhNmaTAHeOmq9Vv8NFYu6clIsaQhEmKLS6k7VQOW35JYLKezFgF8THXXCa3sSLdbTusvFIsm3Bz2B2VFoTbLd3w/ZVKJ8mCoDz11F3uPfkYLagLVap/L/8OqElgMCOKWahIsrvaEA+6L5jYwBz/c9uSxFworBFtIPHQmLU4gRNYxvBsoYR7NOZceeoNd/lTf+ZLefYnn+U7/v0PsQHkcnM/v5936xDHsqx89f/69/iln/6J3HlqB+jJxSXhhUNt0EeLBYpRanE7uO4dsJpBbJgNPRUdVY1iJwGFOObg/pUwErH48uKY5ebwxJzvqsPxTbObArwtUjxSY1sqmldF2wrYNrn4A2uxoABfbuTk8Rq9jdOQ0bVT89b5eBrjiO7RO0u/R0tJgcn7AecOQ9l5wlELT4CA6ksK/Y2Eb1tWbVZrgrvzmwYWjXdZtTpvsKkbRMRyGcW79SQZR7CCSiWJ1jeXdDZ+e+Crjhs6MiUnvBvFqUXDGxgkDvDARjeZRonFiqrStZ2mQXdsVzaT494XXwr1uI9TOt2PFu793kSFmc3YLPPkVH9e7fU6KZI+AiCKjkZO3k2OzSZ/G3Vz8i0ijjdhxIctgBOBR1+ilAVdJ8cGUKMjCLrFxt1S6T5Whu2UWoS74/nEGR/ttsKjOPcsF3fjSVJiZBxk8qljOL3eDwXIc1WUlBOf9CmfxO3HziEPTDItSN5seJC4m9GIU9E22ktcCwuyvDcNgoUJhx/uwlakRMy7sMB7k0ZXihOvM1DwfJEkxf+xhCTjIz7sg/kLf+FP8Xu+6A/zIz/yLndQAXw8fH+fs55G3+/5znfwr77h2/n0z/lkpLjrdfK4qPCR8AXFNsX10Z3sMiqbM4Nvoj14vg0/DJNkcipO+VDvJJwEsSlkfIMy14mEoc3HUyklxtaIm9Du94gQB1I8YBFLux2CIkKqvvDzznr7TALvxrchfs8uiHq3LuZRCbm467rF6FyKf045B1XJBNPNnAUvyLrRutQx0G3k9NvpJKowM6fJIadD1b0olJxv3Ji6aUxn0S/GSGzJxRM39JztvvJGQlVIkQ4quNn1ZsixwREnGCjcsVIKRRK4DZp6x33y2IyOdet8e2sY0HtztyGc2lQnn+xSdPpT3cXPdaPpd0028RXl5hnoBifmR0ZKuqF/vcLrdVEkRbwQpVwZ4i4dIuGhrepOHRu2dBojdDs0fUudXD+60QOMQWstAGB/cIYOFKHEDTPUsNEdzMfHu81A1EcWwXJB2ShCA5LbPSUKE4VkTiJHEqKJy0eHCDf6AAFJ8U71iSdu8/m//TeQawojAjesdeNT7wBku9HUH3qV7N0xnRRKGbPhfM0A+ntsF0/GpPhDIsNdc/w6x+UcRi6+JTUJGhYFsbSFQJLT4Od8/IfzJ/7cl/KH/uCf473vfva0O/hAaEE+GXb6kvlHf+/r+OWf9gs4u13RpG6jpa62IgmELX9KLlRExJc4eEERs3Di8REwFbetcyhTIEdCpUb2uhTmMrlbEoaNwW4zkPCWjd4Gcy2uALFw+zZz4rRG90akJ/qN5jxWDffwzYwiJywlanTCHmy2TSlbiqJF+63k2KxvfMpNVmhj47JWhvXA6ly+WEs5de5juErIPygvTb4hn2427LZt5F2et65HN4jgBmYw9WiEJIkaJhcadKYttGzTmEvQ6Twi2CMkSvAlt9Hc9z926iw1llWyFX3RU1F03NafNRc3hc9j3FdFSnTHTs3biP8a1ViCBaLBbqjpJQs3M59Ag1kwFCR5LMYpo+dVXq+LIrnhDi+9uKOFNleSYxFYmHC6/joHPgTeFVl0KBvvTySR6qZc9sJQglkf9wlBjsNU3QU7FUrxC2cGKoVSbpyosY5koRYlSeOwZVrjpN4slR//8XfedFQfACRpNITEvcfPeNOb7kQxSzFKRGEhDAR8J3uzBBjNAfU0ArW0GyPZ7tiehKxN0g1xvOTZKTU2ThisGAyCuyeVJW7QKhKu516kO8pIjV/8n/4C/ovnvog/9cf+Ig9fuPK3+/7er0nQswY2Gv/um97O933bO/n4X/yRKNenBYpaxGGwzW+Onzkn8aZwCULOUCYH5VvvYUDsCyfCP3Qq07Yr9ocpGe6aHikzL82jQUjJyBTMIr9GnA7Uez91Nttb9aLnOJx3VC5j3b7edlFOgWh24xegtjkaeSDVhvBuctEUz8Z2pyQ0sGfXK9eS0e7u42xGwxpZNGKsazvhomNEF5b92VA8jzrnHPeGBrQAm47Ts7TdoHpd1xtNuykllZcUMP/ZTPW08PJn82W9ZGgKnWuZ8O3yGI4/b5Stjc3ih2XYzKTksFbosPsYjDbIyeEMDVhJN89KBIbfRxKHn4VX543hr0+HWfwzft0XScVbftf+SlikbeYVyf39kiDZiajEaacGqcZoYs6Vm2qNVD4HhbeiqWIemJ4IZxs3j1B1Em/J1U+6Nk5a2h5hZBof+oaZGP6gDGYntKvGKgV+7Md+gq3I2c0d/hovIcmep9/zgB/4gR/lyTe/KQqkS7aGOWViI2EYQg8pnkkDWpCVB6riRhhmJxeaxBZG7+OwKeSpMMy5pyYbj9IZlttiq4f6ZpJMiWUIgdFRnKDyuZ/3mTz3zAO+4r/7ayzXkZcdLzu9u5e+04xZx4KucvXCkb/65V/Nl9Qv4Od98od6p17ccHXDOnu4Wudcwi+zhLlyoeAP5DB/kGrdMbTTdfE4U/FOM/XISw8Z4hAlJ0IdEq7jZZwCvQwNXmMUTu3kkj2QKzqyLYNpw68HN4sA2TDr7bQUgTCl9QVPLClCueJZ2f4+NqUNAQ9s2CLB9MC8ayXlCMXK3l1HcXKZa8bMY2q9YI3A3bclhVOiVGNJFVvrnNwZaSPQtzRIuaDd8VSNLb+Z0kdz/B9DRztt0yWnCG3bJj1/ZoN0FQ2EQw5+PRyiUm6ysr1h2nB911rb0NMh4l2vIQGHJG+Z0TAHljhcDc+4UR2h+gEdnY3FMIaGg/9r9zOviyIJsarHmYDdtm2cnU4ldfuQIIcqmgbDMmP4SGl9UEqmKYgUlOW04R1D/SKqkMZKNy8ycwlD3SE3OBPuao0IHR/TIDbHktwdBQuMKzGsOZZklePl4Ed+7J3+ISXIKqdT7lVfKgwOrO2CZgdWucKxQyfTe+C93ox1ZnRr6NBT4H1frjF8tBIRsiruc5noPUBwNbaUwaUt/rWz4zSp+++JbZt8H8cNQ1PnWrvzWEPm5jdwZZoqX/Qln8fzzz7PV/3PX0PvSpZMH57vw/tsDY2wkScggDH47m//cb78y/8xXzp9Bp/4iT/ddc62kKXSbQ138okshV4yyTJLdCdZCqoerTr6YASB36JbkaHx9VzVEq00NdyqpbiJRrfk90DAOSI5NrEeYuV2eMGrDNstbf0lyxqFyBgHPDtpU7NImPMm8OJnjNHdPMN9eGN5WMgj+Nnmf1YlufOUDeg+1qYkjGyuAMJI7kuHjhp1dcv8did/8AXoCKNarKHaaWPFEtHxmnNNU3AHh99nucxxIETBzqeblk0CikERdyPaRL2uDOqnJde2zfEYFefB9hQ9pmyfmJtcuCzDFU1b4shLjWjMJEb/jBVPT/TvKuSSt78QmHSwENY16ohfwxPEJGApkxInatYrvV4nRZLIwXCay7DN9SYkhOakboeptq0dPjKpQdh8qSlra7Gb8fFiC2ryBVAI8JOPDEtbmWoNbMetrRAL9+bui8vwQJQkJ9oJ5pQZ92xUp3Co8vR7n+XF5x7gWIzFzf5+ZtC4Ac7OZ9745icZrIwYO7e/nswpI5tFXOvR9WgYF1g406ZCyVNsEAlJnJyghW1zmLI/fMnMYzLMmOMB2cKVuoY2x4wayhOQCJBySd5AkbPE7/8jX8yPveudfMPXfnOY0+It6yu+9+3n8Z/p/v138/xPfBR/96u/jQ//0LvcfeI8lhEVsQUZYNZcTWTKwsqIRcjaDogkWr9xqLHNU1TdyqtKQZLjidMU04IZJdewzwpKWBSgJN7JlFNBGKeYB+CEzW2Ljs0dx04UM1dqJbFIW7R4eDnhZjk5ud/KloQo2Nii2zaFTtiQJccdpRSSFfqILX1g4Y1DRKgW/yzztmGPlXcUNIvPQwQkZ2relng3uT0SajOXwvqyzMyZBTpuyN5mXgR9ceWSwQ1OIJaCHtWQY0SPZcyJnhMsDAmpML5Qk+GjjpnRsSDsjzg4xoaOMYZ3gX1tEEVc/JPyA3zbZxBQWVjD+YgfjUbrQX+6gTde7fW6KJJmSgu5lCsKHEfZEgbU3K4qSTDmxbGFlNIJf6wBwKveRERKiiCs2JSWnJlKpqnSNT7MreIKQdEYpBJ5HSMS1lIsT1COyzUSGFkszhkyMKs8/fQzHC6PnNTc4jfI+33/wO3bF7zp8TdS2McC5oZSITaQ7Lk2wwY5Vco8hezOjTq2GxiH/iFxujZOAnb3ltEHXYdvG80zicnQ0BtiNMooQpKKBZ8S01CrRIEavsVUYLorfPGX/la+7zt/gKd/4iG6Jrbwp9f+3Atmj3jhme/gu/7dQ77uH97lc3/bpyJyRHVBSmZR5yr4IxCYFmDdF3PTtGeeJscjh5sp9PBx9IyXm+WBA/v+vXVtbhuWt222naYJn0A3IrkFRhdXV268G0stqIaRxeaKPxTXxW/UJI9M2Jy2/WcI2SQuiECDpSqbqYoTxIszVXhwv/PoYaMtE6qJ63VhrjPrcoWV+1xcGE89+Ti72RCZbu5/kdOSZeO0WggQTrtncxmhmJA2eWxACiOux6rNi12KjlTi3g62yOa148PVxiLYyPXeaW84sksU1cfwMLzQ7bqoTxfek4a41vxZc5hJ46D3Z3eX6g1/NDtTeWse2PYc4PCZuElI2g6N3QZ/hKXezan4U16viyLpHUp1uRcddPiSQhy7SMlpEpXESDg1xpzjNKLDSdpDax1kWtOT4ecWgTnGyqEP1FJsh32rXnJx3z4dDPOHreZEyrsA+RWJjJfeV89NwbffuWRfeGC86yd/guV6YbuHGBtw/VovP/MOV9c8vH/F7SefwGSQxEFpJ8RKlAlfHllaTttqHSGbjCK5WfQ73zN7Rxjyzm0JUkJhEFMhmsJIlhzSTQ0KVT5x6jZLLl+CQd0UCuYb8Y/7uA/nC37Xr+fL/9TfZHTnWfpvB+bzSludCCc7PHzEi/VZ/vb/8o/5hF/wcXz4zzhzc2SbqWZYcW5nMecwiiRGytSzPaeFHkB0Damm4OUFjED10TsKQ80wbGWaCw2l4IU19mHhuRiTw2n8dZzMt6HeWS+rWyO1vnV8wDAYA5VYQuGTQh8ajfU4XQuLz6a3xpb+J6F39vrl1m3ntyoXd/fOWjDDZGYqCdGJNiq5CsgOo3vXHIcJQO8bFza4nhJO55u+XW5odFk2+KCf9DNdu/NzNYpc4IV5WwCpS3WzZ2vcENnxFlGH+bUN/vF2+BBdp9vdbScXDlPE1+nROurwJU4b3T0bgpLFCL5nfB7uQyo+3/XBlCK7J7byFh+wL7c8ImKzz3vd8ySTJOYy0YcxzfsTBQYkvCAF6y43rKWQrcaHFVgTBtX5Vs4dy8GJujH1rJF1U7Ivhbwj9fZe8P+erDBSpdtCLXGSSYy6AYjX3c5vJtkAgRpDt/CjP/Qe+oh/Gzdeea/58gaD66uF5154hrfxRrDuxPWgLbQw2hiblt1ueHIQBShGnCqFUhywJkVIWHf9bBstSNeddfHTFvGliJlbUWlki09pD1mjU1DQ5oR8nOjtD14ll0xWQXLnN3/+p/Gv/tk3863f+L30ll5zhIGtGBjrcs16eMgPvv2H+dt/9f/gj//5LybvVyRpYJPj1LloisAndQoQcU2GBX9VcBxS3bMxpYy25v6T0cEdwnAhp3CxNo8B2BgSScS7RIwe6p8sOfh8btLaRotF1FZcXdLp9S3SGcW9DjUWkmFDFfNqcIOBgrtRte7wQpLEkOD4qVKTInKJJFccmRlNo7sVoTfF0lXcb3aiE4G5ajFnkM2dOzmWK37f6/+3vXePtjU7yzp/75zz+9Y+51QqVblfIRByISQkXEygCQ2mMSOEGLoRJMJobZohrcLo2DaiUQEVtIc9aBEvrdIDEBwiV2lJWkCEIIoBTUIRg1AkAZJUpahcqOs5Z6/vm3O+/cfzzm+tU1SdqhigTmXsOWrX2Wvtdfkuc77zvTzP89aBFzaqdbGTXIIetVaF3GUmeVdqK0fDPXeWZa/jzwWyil3VO+uybEXXkpV6SFm53GiJQzVX8SUpOjEXftLD+8wWYXB47jllFe1QqGwmgQ73DsuKQvpLLMtKTuWQFhlGtCQsH5rClWKbccxEV8gHGNeEkQSk89bVtyOnpCbiQHLtUh4eYV9c4ThRpd6qeqrgWpDyPWDnhhK9ORu9Vl3gUkhzoXagdeaUsaoevz1Jg7A1BzvFsnauXdpR2+gZHABtGy1wDTzz3vfcthn3q3pQV4wDELg2FR56GFflWkIqzUcuLzPlc/qOAc5WgH2UAZR321jx1vCSKHmiTztaQCNABgQLBIET+NQdKTlliCAzmBDy9KUE71GD6Fr4JlD04570eF77tX+aP/PLr+OO2++lM3omD6/uymshI9HprOANWudf/sC/5HM+74V83qtfDKxg6vM8UjHyAlQVHri+GoIM7p1liYgCpEzTRr3GthwvntR9sDVKnrAcKjddnG6MUHiXfJxsufJoah+ic6lNH55K5CcDPpCzCm+OjFLzut3LNERB04Cu6L6mnJnSjFfNsVTiM1xGdoQVOcfOlix0SLUBphyUyZ4lGdgPOeHeI7/PKKKwoUgsineWkvqWuyr8mFFKgOdtZpeVG+3eN1xiTtMmbqu0pkfay6BGCwkL3OTRD8PBsPDUQ14uBy++9ba9ro10SRusKmfLrQZMTl0SHbPCPE8Mmm9rB4fCuzY8r0ofeThiAw3QHgmFm+Tq4EaEv83rRjrvHjg1rQVVmJPoWTKIg1HgARZ1mkkGrfvImEyUqZBQb97mHkWcEobNKcVIqVBb14VJp8LcdVNI3XPckCOGQODkWoP33XJ7MCfsoaQiNWLHTClx7tw5Fed8yJYlRhCgoo0A4uYKdTyk+xNJ+Zy4NupGF/jK3sikoJYlteXsHWM9Cn+U99mUznFKyOI7YKNKjwD/RqJ73eAzhuTQGs6nf/YL+SNf/kq+8+/+AP0+anH3ZyiVtF/ZL+pweNcd9/IPv/U7+dRPfw6Pe/o5pi7Ppnd5jbWeBv88i7c9lr/qecqjxfVM0eKh5dFiVBe8LiulSDVGqYxBOFVeLtlQ7ZaxGOo2Ov7YkMe8TSq6VEJEoTZ1MJQrteVmLfQfvcvAt67wcczxZV2Yc6HMs8gILlkv60QoGKLI5hHCG2T1gnIXv7q36NzY+3a+A3eIWQQO24yS4U8WfZGiG2UIVpspvSgM8sRkWVA317xqXRJ1pkrXVgBDhyij24Znm0XLDN56753drN7wvQ1uXOSLjQ1HmlLCi5ALBqxRLR+IgtpOAaKVh67DNAnV4R4bx2BBEPtjHqw4NU7rITByNR2Ca8JIGokpTeqEFgJyuYj4XmtVSFwyU5H4wpDUUi1FwgCaz6FX52p3iUH3KjVjh2WVYEWJC6VQXJiwZs66dFKRjqO803PIZao0tw0GNHbl5AMr17n77kvcfuv747gOluHBWCjDiKSUOL87FzqOyhGNb2pHr2vd6WnZEtNj8hNVvYZ6iquvtTyjXp39fq+0QbbNMOOa2MmMNMljWmO3X3yJlESJpL4WzIS6i9MWsVKKUh7WJXVmuz1//E9/CW/62bfw9rf86vGluN9zD1Ellv2p2gq0xH++6V18z3f/CF/zF76cxp6Gs7aVFPFBCg8jh/GAUC1qLgkxD2peNMUa13fkxeZzkwxL1cJVSGHRdAu8n4JJP7IniZ7kDtp0h2taouiisFhFAQlGpEjlqM+4s1SFwJZyUBUhmTOnEF2oyl9WB08KQd00X3sYIJDH7xFhSU1cF3EIdRhQUWFunGuJ9EDz4HOLW3vgL1s4GagkNgRQRGms9LXRU2W1tBnJZKMIdYiCzJXGspzVohejSLicXDITUbUO2uKgDx66rY+2LYf10sJTH7/n0TO8ioIsPCgkK3hoY6qIPxSNIh3lHnNCIPvRoTEl1Ti0QTzwGr0mjKR7Z23L2OhZ26JqU1DyUpI+XzYdrgQCetjJRvO24ZyG7p6FoEDr8kLylMOgKLyYTRWvUUkbPOBWq8Q6S8F8xrqzoiruFJNH4W2SynTLWK+8/32/zR3vv5dEwcPYPyRh2qRJMZ8vPOr6C6SulgYGDHByDoXIFrk3+kgx6NrgQfhPmbVJmsLpuGmDaa0GHGNQxlzqOz40E6UrVHJWGwVHFUsjdDflLWZDoHSv2lxKVmEtfIHJE54mnvzUx/Fn/tyX85f+7Ldw5wfvVTP5FKyLY88yHps7zU/JaQeeWC/D93/P6/m8l382z3rhx6j3thtrdeZ8Es3qTQYdZy4ZdStU8y6vQTv0DlTlNHti7Si8XURTVa5LtEvvq8LEBB7XMQUDpCOWxwgRB/HAYJPmqtnxtigTEdS8ugbLBei+0vqpvKeodOdUto062xRXuZFsgtZFwysRfkbiYgDChfus9LaHJmwnHptEUHXMugDzofSkaz/pHF2f11slWZUx9VFGjPw+WpCpr3hKYFJSsqSIIxt4b+S5HAHlq4re6VDoaW3F0XpMQxQjsJhjPoyl4rEma6/0LkSDu8vByVM4SI3RRbVkdSdQ//VAnCD9UQ9WzUiNp1S2fkbykNFGOML7BxjXhpFEWnMpdrLuLlFdI5gEK2aVVFXA6MPbigsCHp0DXVxsbZY0V2l/kPg3Qn9XNZ1c5Hr3yJHkgBK4vFKPm1SCYaKQLuA/qKNfKRP0zC+/7de4ePclhh4jHNRxrjbGYn76xzyJxzzmUUx5orPph4dnqrBvYN2cekg6pxQ5p0P+00xVXq0LAendR09pZTFtuSwfzKOSmJ3qjZIk/dYjZEqhppIYRREQClpK7ebyCsC5xCnNE6lkPu/zX8p/+Ldv43u/64foo2LZK1deEt+O0b3SWor8Y+e33vMBvvarv5k/9edewyv+8OdQpok0X2BK4cliqHWt0BBdIFiJD5Pw6C1guTB1Y21RhOpOW/dYqiTLtNPLkW4ZyXyHKPyVaHyP9y13N4DVYjh2YQNxamtMUajARIrI0cKjNzFUlBIUXXbQRHts4luO0AxIzGnQY4f4C5F31Za1LivzbiKZPM0Nf9gFEROIO/5m8q5Hddsj2mmB2RysGhz1tYl2DXlAfpAXuq6XISVqDb3NrPulVrqJnG3Lqw9FpE3sz5112Y/MKGYlvD6F5Nu9aWrb3KMI1YPUoI2nxfUecm4wTyMdEQ5FliBvDw53SkaecqQwwCKVokp8p/tec+daN5LdEe4u5WCRRPMB0wIlaeGsbZVXWMSZ9qBQiTXQNwOXclaryIS0KHsjpRKYSF38fRdsZKgdK4HbyW5RFZU6tHJWokDFK7VjEXlCKr3Bz/+Hm9gve4hixJaffgjDDHZzkXpz0Bm3hLMLigNFOzSJRsKyYBFt8NnNRNNKRvclQrCh8LyLzWbw0Jt0DLf+PkpRGBJoSA77RW0tSpLEWnIpItmgKljaJPvl70upqYxlsJv4k1/zx/j3/+7nePfNt8uQD9bL/Q55IWLlNJLPvOedd/F/vO67ePc7fouv+Jo/yoVHd1pdaJ5C0GGlexVl0mCNvCK1U5cFYpOsSyPPk+wMnTxFHxoELyFpA1m9bRtDWwLRUFT1thwbhMMQts2liGbnUufOjjYYCGhLj7/JCxv4QxhZpejwlwZER9dzXZUzG+FsbwcZOGCr2rYmA+s91KpyxkzC1RwFsce4SSEy429dxmitlbaqJYMMRpfn70oLdIy1LrS2MKVM90x3ow5aY1A5u6sAmMzoNUQqIjz0oCIeRHVL5DH3Sg1FcSzyV9usSiF7pgqPbWF199Dh7KoHCEI11sMo2IQOQIjjWEqRgnL60LdUdeyq6/OaMJJmpt1vCyU1G1X1OzAZzDIlGuB1b9G0K6SPikCwQIgGKMFuwOitkULPrptjvZOTU0x5P68jSR6QAcBbDQ1KGQtzTYY0JrAnzBZO76380lt+JQDDH6YQbddNv3jvRZb9nlTOqY1AhFduLaq/XQbT81asUV07cHCEZ22O28CSBWAWFSNIAbDt4qUPh4wEXnN4pYJWabElYU3DM9DSCowp4YAHMygZ7JihG/u2kErmGc96El/0R7+Ab/ub37kVF443jm8GXgW8Hvh6fBMPttio9pcvQU/833/7n3Pb7e/n677+f+FxTzgvGmqORldNuoRGQEXiWsxlotcaosk5+sI4U5mwMgGmlrM5UatonPLONWdyVoMxUtrSCxJCWdiKDNVj4Ysv35ruRg/PenTAHKpVuzwdjIRm/mFD7LqXh7AvZMAsWiaHDNmIIIYBtVTAWwjLugzVhhGVnNnw7IaX2sODzSkFZdGDkigV9RYpAO8icVSAVU3UshnNGnmaICWWtWLJabVS2zD0ygdmCM8V1u6UorYr8tz3ERW2MF5RY7DoeR4iJyNcFsIjxfmkwDdWapVYdLdGstEwojNZZihHkRO1NayHFJ3EQMlJakiHpmr3Px7USJrZCfCzwC5e/0Pu/o1m9k+AzwHuipf+T+5+k+nbvg14JXApnn/r1b8lFE5QJr8kV+KcKIKYJI421WILgHUVq0IVQuVtcuzGbtotRhsv3YAQzyiJ7ArvsyUByedpm5RVAS2k4HF3Ac+n8JLUfVHk+IRz6y238973vO/+rt6DXV6FX9l4z7vfxxt/+s18/qtejkcfECWTeySgR17JI0yRLFqPBT7aggr8XESFM3nK3bv0CJt2z1LURK21RvXRR3nGkdEpaSKlKSZTV2iE+PUkia62rs3mkIMylrZX4SknmonO+EVf8gX84Pe+nve847YrrsY3ufOX4gp9cjz39ZunG/54O+XSJfmHP/g9P8Yd77+Tr/trX8UTn/MEzHQPrUQI6VLBaQ41I7zflDcwNw1tKn2IWAiDmnq0CrZCNXkztVUSxum6D6PnsAZErclzFWSohbp3tAaIwosIOmKXmGuhJiyUh/R4a/Frh1BaOEIxzlqHNcQZ1NQiWimMfF9XDlntUmPDHA3ANvaQx/IZ7SPkibmHArmZEAphuKRoZqFvqTC/R4qnlHlMP5IpelrXVc1EogA1lNNTZNIH/AuDkiOPTnDNe42mX5IDnKZJ5zoYbn4MZB+RUgeS6MUlUYpdQZls3iPfCktbKVNhyiJO9BTOS9Lm2CItYEme50cKAdoDL3P3e81sAv69mf1Y/O3Pu/sP3ef1nw88K35eAvzD+Pcqw1nbqW6sJ+ZUNCm84d1YqsLIQ1FGNCYYu1TbPIC1RbI6S41b2Dfd/NaF8UrVVZU0gyIGQkpJHe4cEeIToT5UmKxAL9TeKUW9SIbRcod3/upvcPEeNRJ6cFzklcOQZ3fXHXv+3t/5p/w3n/MSrrv+Aq1L2KB7k+7dqm5yquBVSJFvmTV5197wNhgmCqvW1phGX54ueTJqpfZG3uWYvDIYvV9WCJRTLE4Ja+j4FDclU0FMHvQUUJNGJ5G6wkzlijuTqdn80z7u8XzZn/gf+Ja/+u3UpTEA5n+YwxZi8fgbKAG36cp3Bl7PMtTThZ98/b9nWTrf9B1fx2NuPGFOM/u6CngdC6k71ApeGykJAuIlijMgz7dFcS5SC8lFrSt5J2PHQkrGujZyLkypqHCTnJPdifB1XQiMFteqt6amZKmTvEWuORTkPbjQUchwCGZK8PHjPHMelV1jyJURCAoPmNqUB8QL6rqE4Yh8Y0QOcIDR9C6gdYtGZKP9xNZxsndyyXIULO5JGOYB3qcviuvifdZFPiglRVFISXEhC0JtKtI7G6g9ikXya4f3lpnKjMhgh1x/C7zznAWyjwQ5nQO9UbRjGJ1Dp1kefZNKhhp/mUVkFdhjB6/COGOiNLc60mMfgSfp8v/vjYdT/FwtiP9C4HvifT9vZjeY2ZPd/bYH/hIZqRw3TjCHOGg3pjIzJEgGJEITMGGU8JR00aWTKF+B4XXmvPXXBe2aA5/WAoSOO6sLstBaxzpMc2Y36SbWeqqkPIneE60aRuWkwM03v+PQ/OvDs5F0JGdWq3PXHXfS93u8i8EgaI0mR5mKwLu1M5XB8lEY3Tz4rkEVI66foDJdIPvkeFb+sXvjdD+4tRFEO/TspFKkwmTgfcWsxX2RKs0IIW3Lp4U0lhmtFzD54cmcwkTLxmte88X8qx/+Gd5+083b4vlRd14Ql8uBNzBhnOCsEL0cnRo5uQjpWuPnfvom3vSvfokv/NLPVsrFi2T2XGkWHxJaSeFvygqXRSzQvMkJlq7WEGZqMNebeNfZhcv17qzrwrIszPOOUYhde6cHW2Sti3QFIicukWcCJeABVVFuWOtSUU5twv3hbEUjM2NdVERMKcs4ed/43JunakQ0o7xnyYm1VkkJpgRNkDaL1Ek6whz2mP/66qCfZt/UoHIUVZIlAdWTUbLgecJ4AiSSZxVoTAr/jUYqQXboHjjkvn1GTom1rkchfyMXF1PIpViUQhsSxkZbtG7jmLzLYTnkNA/Oz9Bx2Pj629oSY6eOs3apQg2RE6FUBH5Xv+77Hw9MWDwaZpbN7Cbg/cBPuvsvxJ/+hpm9zcy+1cx28dxTgfcevf2WeO5qn08pohKpJaSodaVk5l1mmo2UG5ZWcumUAtOUKUUVtXmeKLkwlfjJWTCRVJimHfO0w5LakZQpsTuZ2M2Fecr6mYsUf6yxpgYnCSYLwKr0D9X4XMWglNTZcJ4mqMZvvOvdD5b7fcCRUg4ptMZt77mbH/6BH+d0rZz2lYVORRSutTeWXlm8s2+dfWssrbPvjcvrIoyZqfiAGbWu7JeF3hu1VS7tL3FxvcTlvtAs1F+6UATFMqmc4BRqBTxUhFLBLbOsEiBZ1susa2VdVy4vl9m3haUtojs2eb29i6tbO6zN6alzw5Mv8JWv/XJ2F8qWK/t64G8CvwT8DYyvpyi5n85h6QLYObSHh4HvMgr7S5V//g/ewC2/fpF5vi4A4bCbCru5MGWj5M48Z1KxCNlWWtPxd1+xUmhmrMDSG6enp6z7JTCPI1uoHNw0aV5O88w8TVjtlKZSmvB3nbbsBeaPEHI5PeX09JQaak3rukaBReF8QrhS5dZSeFUwTzPzlKV16Y1a1zDEoXlagqHUxbQRHbOTJ4m71FpZu3CStQsyFu1lVDQKJ5Vg6eQSxiVygBWnJ2NF+q2DIti80Hxi7ZmlKdKoTbC7Zb9n3S+0qm6WvauNrVulzBJFVnFN1F/zTjKP3tpJa7goraQcuoovS6uctsqluue0Ley7Kv2DJaMGYKvEhF1dMHtw4TexFyny0pbASge4XRCmEnn6phTSVdzFh2Qk3b25+4uApwEvNrPnA68Dngv8AeAxwF94aGZBw8y+yszebGZvvuNDd4FH8nddWNtCbQu176ltT+t73Pc4C91Pqe0yTkiZWQUqtAX6Am3FI1xYo9H5fl1Y6ymtL7S60NvKpYt3czl+Lt5zJ8ule6l330u/dJH10j34ulcf72XBeyUlUSZrXVQ9tj1Y5dL+lNtu+yAWPO8Pd/hGceys+8wbXv9z3HNxZQWqw9qrKHJF3oVnUzOrlOjZaAapDJyaivcHDUu5tjkXsYTKzLTbkbMKUSmwnn1t7Otlar9Ma5fwepl1vUTtC7XtqX0BZExzhO85ZyiFPE1YycoIm0tkggn3mUZm6SutLPzBL/gMXvbyl4qxpPvPX8F4ESraOAvOnr/eL3JTv4dvNifPj5Kh7gWVlw1S5Vff9m7+8d/9fi5ebuJ3p1Cw6St0p7cdy5IwzpHsPLQdqZ+QOc/JdCMn+RwX8jkePV3ghukCN0znedS04yRPzLmoYBPV4hJtVVtXHm+2xBxeV3IVNqYseuxJnsmO2sSGd90jr5hMupJtWbEuD9xsyInlkBcTIyVnwY+meSIHLE1Ux4blpup87kw7zYnWm/Kjph4ybgMj6gFrU/TghFxeCj6+fiWF4pUoh75ViNd1ZX96ysX9XVxa7ua03sPpejcXT+9hX/dUPxRdequ0vkppPPLAHumilFTB934whB4kgLru8bbfCoDyuI3sRlqdfnnB91XkEI/oEAIuKAhcijk5osacp4ikEnOemVJhTiXatgAj7dEBL7RqeP8Iwu0rF7TfaWZvBF7h7t8ST+/N7LuAr43HtwJPP3rb0+K5+37WtwPfDvC8Fz7T55wZ0vMtktuGFKU3FJSFyrh3Ka0QtiAqY3VRCN674yVT26qmWV5FEYv2r72pCVCnYyFfn6eJQmYOkGpKExM75iRBh4VKNcetU4nFmBKXq/OBD9yxVeQ/XEPpvTLqnYtd5vYP3M1tt3+Ij3/sE2Onc8FHUN7GklEjJSBAfYeeSXlH79qBKyspOVhjX52UZ2pPTD1tXPfWxeawnEklc94DBVDyoUqcEo4+NzEEWokCUVFyPiiLKVkIFGvCumdWE5Q6e+f6R5/nK7/6y3jTz76Ve3/7IuvIc20ueOebOOUvxz19Qb8EtfKN+Tqm3Q5spS134TQurXfy4z/4Rl7ymZ/Mq1/zYlLJFAppShQDr1UA9w4nNuGtCKNnOxITbVkkQJSkQ6reRozZRItmXUP+34YaUO/kqAwIizpU8OtGlfVu+DSgOk0QIj80Dstz2aZICmzvyLV3F+haXnNoY5ZQtukeKtvRoiQp/E1d+gHdWsBnFA4rHdKDeWUBGRPXPqVErw3LYqLkorxfSpCt05O+R56royZG0YI4BRQqZRgN4iyTijjtraXteQ8ShIPojp4ouTCnrjpDFJcKYpWtdKEJaqPXNXCOCVJohnadi0f72ZKTipvdA4FAFOUCfRFtflVsUsqh+dDADMm0UDcyf2B/8aFUtx8PrGEgzwF/CPhbI88Y1ez/Hnh7vOVHga8xs+9DBZu7rpqPDAPRWiVZIacdKasuNpXobdMFuymWyK5eLM4Bt6bK6sCWhRFY1D7Ve/CZw13v2SL/EezmIChXGp6ddV3VxtKc2k6ZpyLDPPr6xs5usaguX77IxYsXuXqa9qrXd6vY19p4/y23c8uvvo/nPOvptNIZslBjp08kVlcIZyP5bJrItdXI7YYMf6hO176nzNFEKTwa4fyy4CCt0ZMAx22/Ri5LFEwPSJOnqMiOvFLs6Oa6N6kLpyZ+sbY1gfrlrqw4n/jpz+Rlr/4sfvi7f0JCEq1eUeh69XCA0b+v6gt/xe+iu5qSSScwYbZy8a47+N5//CO84hWfTX70ZZEX3fG+V8hXUhRMEmszmi9MFmImPtrAytikcoDX9B5yIekg/aXiiUR8a9yz2tbInSkHh9UAzWsB5zRDPsDJdK/EiFFlfRi7QyFCUK0k7ne36FBpWxvVnGcSQwndUK2lRRgqcQqlH4qcgL6Cr5GzZ8MRr2sNNpqMg9hHmlPTVBS9tcY0TUzTRG7yrLdCz5QDcxHQs2jtKw9YorgeG7Dy3opwWlO/b6+N3AUmTzmxNnmbKQgYu/mEtBOaIsqj0ols0bUycrueV5a2RpO/ThJvIlAZ0VPUO2XKQUkseChDeeB2te4OgjT3Nx6KJ/lk4LttdK2HH3D3N5jZT4cBNeAm4E/F6/8Vgv+8E0GAvuLBvsBdBkKVqpDON1V+UzBKWuDIRLU88FlV7baNXrQsiyAuAUmgN+UiUsBLEAtAEA7Y709VtUuJeVeYo8mwu3QHh5RabuoBriJZFI+ycXr5MhcvXdyO5792yP4Yp5ca+7vPcz49novcLpGJoKXJiwAIkdBgu5TwsgmWRg84w7JfaX1Vb+rwWEdi29fBUXeJLXiNia5iFTZUaAjIlQSNceU+a60Ck0dFY2AsMYtKpHb6Ego5ZoX5XOLLvuLV/MxPvIkP3Hrn77gGPwpXFHNeD0DD22lUpjX5BdNK3HjDE3jcoz6Gu/038FLBM7nAWjO1KU9VGJRDp1tl7ZdxV7GrWKbXlbUK6mPJQukpIpng0DNwuynC2Pibm8uLRPdOON1AYYQBGeIYKs6EkSD62oz7RjBvWGJTMsSyEhq29QEEr9vxJRO+cwqB6pSKvNgGa6u6J9kw28nDd7AkLCxFa6KkvG12OQkqZBhT3pFN7UG8GQP7q6KOClJCMgS+MZyNWtVviRBe0S2TtoK3Tik7MtHQkVNyEUi8TAlviZPpRNJooddQ5pnWO2trzCdTAPCjOuqdlKDGhjyF1NlAExRUnGlNghyWogofG1T3gMB7xw6He7/joVS33wZ8yv08/7IHeL0DX/1gn3s85P5OW7vK0Vh8EziN3E6NCZps5HRsW7jWRjigQLqxRs8MUQdHvqMFbGXgKXMuUel2el1JadaEr53TvOCWmPPElDJ1GNeEcJS9sa4L67pe7QpytVswvMixkc0nN3DX3QXzC9BV/Za826F/h6q0hFjABKFEs0a/D0tamJZSsJi0e8+zmDc5F3IwewaNa4lKcomcoYQMQnkG8LrSWzR+N0GldqHmLHZPF/De2GS+yIZZIwJz3BMveuGz+cIv+Ty+6x/8MG2x7RoAfH1Yxz/MAJhblHMHiziUYawwn3sCnDyKd/zab3HdExbKDaqmki+z75KWyw7JFc7ZVGh0lrZgNkHq7JdTFWtwTvd75t3uULiJ+THazWoTisJBj2sYLBCLHt+C9WQI/U+SjCgxT0eUo5ydvNwRbvcunMOY66XsNi9zRAT0zjTC98g1ErnIXAZ9VPm17Z7QqK2pCh/CGbizm6fAKOYQC9lRDDkXZAbKba11u68ehkciI5Ei9lA6T4ThyptnTOQl3SNvnHrodXYokT7CIxoptLqEN23R+VHFmAJHEojj2oF1OQjyDD1okjKgFum6kWbIxUI1KjjdJspqQt718Nbvb1wTjBsHegnyenfW6PFSUlY3ucA6qYrV6SlpsmO6oabmVfIUQ9SCk+hrYSLn08mTerTU7gH/MHa7ndRNehWIF+UuPXWm+brNralmUjRJ6kQ3EsN3fOgSdUHQAkvKIQJ4Aa8PYiIDFD8mVMqU3Q38h5//OZ7/ohM+6cXPIM1EpzoHovdNX8ipMJ/M8rKDzG8kvC+U3ji3O0fPE2ufBe7Oa3BsoTfHTeIUtbpEd6OQ0Accq/QQUThR+NkrpdQIt/W6QsasEqzwSGEIuC4HKcdzauBVbKLsKn/8T3wxP/Yv3sit7/4QcDQ5Hb7B4BsAUPgvEQyT5w50l5Ctt7v4hTf9W173jZf5ki/7PF78WU/gwnVQ10yeanhPEkP2NMO6CCYTmNE+PMJQhPIkfciR/PeokMqTDlmxKMDIYlSogavNSgPtdjPVpedIkoGSgrfhnljXhWwS8DUSqx/OLaek3KNDzipkYdNW0e1d7Vrl/YE3hbO+mY5oqzBCd+8blS/nJBhYFD6mJE56iQ6C2Tu+VHoy9r3JK4s0Vk6JvCbcOp6cpS8b4D9w5ir+1Wg0Frm+RKJ4IqVCs8O1zDmBzwwl8FGtNjP16AlIj8gjwNDfdKEJsjqiUTGJNxEce4s2ECkBkzDSKLdpmBqpuXQ65Z0LL7u6uif6R5KT/P0a+3WlpMOOZaZdQDfCKNMsmakuyMNa1TGwTLNECCwk3AMXtrTGycmJ3PwsWEVKsNRVOcrN6wwCoIm2uLSgAQ5VlZRD7LOHGKhIvEMooq8OfRIlypeIuk05TJNxvtoYVEoA+srdd/wG//rH3s3q7+P/esFfo6eLKjb1HrTC4V3DUKepXYUUSclN9NW4uK/MJyfq7dMTxactbLOcVBAzUdEsJ6ak52WKnRysjZyVG+tlpjMj6LOuVbOoNBrUtWNJRQnDsU5oemrzaKbcXDfnYz/mqTz72Z/A+9792/dzRezKX8f1iX+GJmOtC5cv3cO7fv29/PiPvZXHP/llfMJzzzHvJujnmKeCpR5IB1VhNZUKNSu87E0QnZQKF86rZ5AiOWcrhBKZlO4SzLADtVUaIiYPrTmtyis1CtlTeJfBDzZjyrM2zqA/TtFHeuvLFHluiWQkKWibqY1BkShtrcIeTlPBlYthFP5kIOP9sQ48vNMUzdIIzy+5qtq1i0Fkk4zELpdIrUSKgc5+N4Q2BhbTg/sf/ei7wlyJOIsd3rsgR635Fn2oAJhIOQeExw85W7fQblWU6FGMlW64LmFFzdJUsoQpMLrdBdVrQRxR5avGjTtw4nPMLUcgdM8ZqxZ5/9+l6vbv1Rj5plor0zTpIvYWTX5sy+/kAQMhkcvMVAR8nUqJnb5vWKmhPWcQqkIVDwyWGlhJPq2FmGsyQT7SrsizAnoUVXKWpFje1FYU7hafSXlH3mXssqqK3nPktPYM5e2HehEcp7dLrMvEze/4IDe/80M871Mfq7xj0YssQev7wJll8q4wdYVx6sVj9Dwpx+vKZzUExagoF1Pcmcy2RP5+2ZOyQ1WRpYWX5cmwWrHalVSPsD4RRZ8oHJRcYiEcqdkko/UUHHMl+quLL1/Zq/CBfVjlrpF70/2fwDLrpYvccP1jedtN7+CZz/00eXB1kQeUomDQc7R0gM6EuUR3yaKr1XVR1DLy2FkpBA92TGvqxb61kHWJ6maIyAa8pPC8ZSBUvypbKsVRv+/e1cqgNcdcxobAKlavkUNLwXJS8a1kPwDBI4StVUZxKH8PCNhAf4yKOsE8s2Ck9bZiKW9ajTmMSJrUx3u0UC4lqxgU2pTbaz3RU7TMaC087RzQLx2T0pTCcErFJ4pGXRSIvq6blNoQzDUfGzjBs4fBgrH4KWY0ErRKNli6UAVDAEQh+ID2tOj+GZ53UBq31F1sShZep6Vr3EgmwmUfe6KjxTDyNa3RV5HWLRWW4HuWbBsmculrdMuLAkJVkaXkQrPBF23Mk+h0RGg1lWhA3xqtGXWC5FLzXrtCvHmODnQ2hCRyLPDMs5//dL7tO/8y73/vnfzSW9/FT/7E27jrg7fT9vuDfbxKvG1xBZyAkHin7G7g0rLjZ//t2/jET3oldn7VtekdXzvepcLSgbU1fH8KLhVJPJGnE3Fa6xK5I2Mqid2804RNKSqgCjsKM9gqDwdwT2HUgvrlXSDqeSJNE6PRWuld1VRUqGDVXt9yJpVJqkBR71Mb1I5T8VQ5OZm3vNVDHcpF7ekNUml87Mc+hS96zR/h53/hTTzxac9kN38aORnzuUROVaKyRJfIdWHQ1nIy0TPXNRZfVpuH7ltV11E04r1TpknekY9sSpI/E/zphstTHvXESA/h0eXIAE8UMj2q5h6b8yaA0XtU0jMpT+LGe2U/cu4pR/tktKgZrRRsY/eDDnIUnMzVX3w4CVpjYy30Q6dNN9ZmdE/Bw05S2kqd1J2SdyjeFR5z9KBS+wjoSWkVyQ4SLWm1aeQ5VLQwPI2e4OrBNIqRjO1yMKfGzzCeDM6Ss0br2ilDSnPQSOOeJD8Y1sCfDv65wmnHqwsoHzTVFCHDNd9SFiAn9ccQvS10+wzR8bJHo3m9ttjoVjhQ9hXzHruSjK73FkIOCkk9FvQ8KzwfzBmS2kZ0T5SpbDnIhHiqKedNJb035YlwJf57W8nXG5/2iuezO30Mj3v8e/jxn3ornXuVu7SiYseRu2TRHGq0jCVJ+Vtf2ilpYpp3XHfjo7n11lt5z6+/l6c97waxYojJkyeJOTQ1sLITAZ7NRN5PJW95tBYA3mTR1bkKS7of4qfh3Uw5oCYO3o0JY5cSTqUtqyZcE2c+bdMykW1SaGZA0eKtNRZiXshesMpBeMFOsdQ4f/4ES4NLHNcmGalnmmXc9qRulHJCTzWasWXBUU7OccMnPIP1wgn/4v/9fp7/gifwxV/6ucKGgsJeS9L69EmwnDzhNErqAULOjP41lgTGLzapGJEKa6tYV2RjIcU2WD+G8petNVLMr4P3F8UwFadD3k44vh7KTKLMNpJLjcgiTN0hKIuaZxndc/R46WAh+hsiEkq3rBIoSSV0Li1iybQVIiygXcUmqWCh43KI7ypiy7QWOghS71kWSaiVaaJW0TNLzpQcEm2Y1KYCQqc+aCmwlknFw67mYQU1GVM6I5q29UpOE71LJ7LjIcorrzoFbtqPtoDuyq1OlsgYLV4rppa4762upGxbJLk1yyOEkPsCjSi6geUw0lfZrK8JI2lmpDJtYGX6yui9Umujxu6dUGtOQxJnVpSIzT7hPUFWvqPuF5L1bXJLf1Khem3CXnXYkvBdGWU8JqcBNGdXpgAIB2zIC5NVaHumfp41dR7tj+J8fwq/estl/s9v+6fcdccl2mqhM3N6P2d7kMNyB1JT/sVgd/2jeMxTnszzP+3FvOM3byanD/KEGydOIk80jKlEAAS6t5SwaVIvbcByZnVRtRJEFd+hSVvILLP2xoqqnXWvFrhL0yzJuUiRvCTWCLv7HCveHPeqJIKrDUFPAc+K1Ij6UGta5ZYxr1KXJpNy17/T9Xzcs56D2b8LJfSO5fOwezzXP/3jyacf5AO3vh23TGMhdShpJp+7AfZO9sr6wVu4/robeeFnPJM/+TV/lEc9pgSEBgkwJGjrGpXorMWIMIGWEmvr1KiMWs7a9CIssx6tPQL1sNQ1PEMgDE0n+ie5ID3JMimrmZabBQA7IhwLeb12AJa7d7qd4kgHIGWJukxTjjkqQyEOtpR7ehcPvIWBdm1hMlQjbA7Y2/BQfRWUJ1uScYp0gGaiKfdpO8rAwVoUvHonTxKArnUv8YnI4wpkqA2gjD5CQKBJQ5IwHTF/ghMxIHhVn9G2vjI96g2KHKWnKeqxiAnh/OROCRGQFgLOycCKek/BaGkR+Nzo6qh7ZiSbKZwfWQuBy49s0AONa8JIukMPnqV28sOkqLVKAScVUimcBEYslNnxSHybQ+sSD7XWmUpMRD94WCokZqxkUkm0KpGCnDOpO6k60zwrvMEivOlbrqW4kxzmdD2lP5Z+8Rxvv2XlF3/tXdzya+/mlpt/k3b5TsznqMrtuaJ6C0DfvDwQY8IwKJmT3Xku33Mn/+Utb+Qz/9sX8ae/+ot44tMusDhbuIE5q4sT3V0YMlsP2LVUsiS+vIcIbApDKbYB2QQVSgoaZ5MslcJJpy5rwEKGsGsN79VpSXCXaLlGmicZIiIn6qOhksKblcrajAt2HefSBU77BS7vZ1hnrjt5Hicnj+Py5Q9i19/IuSd9CnV+CvOjVy6+6zeUW7KQpWhGShPnH30jp3d9kCc/8QJf9hWfz8u/+LO57sbrMKtSfyKTsro+9ipWzFobLXKJlhIsCzlEDpQ77XhsygkLNhYbvlGLR5TUONEtQ7BVkVEzsS2XnZDGaa8SWfAoOCYZjLZGMSOoehYdOnt0jJS2ZEfQJ6WNeoSnI2IopQg8niR8UuuoIA+2TIm1JLexdhER3PKWOso5C1Y3WjP76E1+OL/uwb4yC5Up6SpI0DYKdx4c9DjGjIX8SqAd8AjDc0CTQH1ptPHKOxaAPufCVE5kBJPqD+puOaGCuKKW1pswy64croWH3UrfquIt6TunPAUdNlrrRa7UUoq6A5vjcn/jmjCSHRmrZBHOJVWbcvTqzXQG+yF7VFNNEAdDk3107QMoqUQimEh0O9MsAdXamyZwip06xFZH4ratAZjuwkGOS+fAzqCuH8e/+dkP8Z9u+jnedcsHeOfNt/G+d/0ifvkW6sW7sbYw+od4TwwGxhiHTWCkozt5Stz4uPN8zLNv5KWf8xKe//xn8tLPfTHlgnGxLlqwLphH751992hC1aLopIZUvTd6JeTMInNgTkVAcfdOprCLjYaAXGAd8xAyRZOu9ro1oA/IAdZCp7AoREuhpiLmjkW+ScWq1hq5Z5I/nXe9d+Kdv3477/yt9/Bzv/Bm7vnQB7jrtg9wcuOTWKxRLjyBNk+s7Q4++F9+kX7PexCyspEtU84Vcmk89fErL/+Tr+LFL30hz/uUZ9NzhWYR0mbU+aFFJfqgQei94p4xpAQlRkijWSiXN4+KswoU2nhh3p1IkBYj2yyjNTwjK2HkAuQ/mEgDoJ8SZjPFnJve8hZyTnzi85+vxVwATMeBkzohiRcpCdj6o2stHErtG1UyKkKtNtZotTpNQ6BLPymFNHMLBEdSuFpSik7xvqn15J5C5BYZS5fc4JRLeGQoX2pak6MokgIF0czIqraIpy5i4CF/bTlIHhZ5aFXQxdCS5+gueJoFgWQwa2wUVcmxeTi1N53XEWwIM3UQcCncm3swfaocHmClYXHMvqqFxYbrfIBxTRhJA7IVMUuSgSs3KIZJx7MmjWSZjMmVfylEi4e4ORChtUrASpOlRDcCrmKk3tnNu62BU6uNZV0UIlpmDc+zuUuvzzIlKtu9PJofff2tfPPf/H4u3XsZ8m+Dn1JP34ff/VvKm+ZE9z0WXe8EdJV60OOe8Che8arP4klPfDJvfvNbed/7buf5n/IcPvkPfCLPfcEzedZzP4Z5N8voGSyrUVunRbiDydubzJmSKydYCh7ah0R1P5vCmlZDVLeoQVJ236iAowWtJuLQIuzhdayCb+BQMlN4m3kDVstuDhA+Jkpi7WuIXxj7fedCfwo/8ENv5+/9o/+PO+64C7+8Z718B77eSfZT8AapsNz9Acql38baii330FshlYlnfsLj+JyXfwqf9KLnsjtvvOiFz+GGJz+eU1/pVHbRrL6jZlO4wsFk8+Z1FUPc4FCpAeiWKSn6KdUVd1HVUngVG+3NR/e+HCBpgZFbU6O34Xn22MBG7kzpGWEMl2Xhfbfexgte8Em6T72FIrjyomZiqijhrgKYijoZt6p8ZzSLU5471ONbx0qhoJ5CfbwPIwVQW+rjAQnypGp74Ilb0FZrRVAYsyBWZMwbqa+SkAtN1iFuMui8Q4KtV6UmirkICBBwq5FHjEo7qiB7ACyVn5aX6X7ora5iDSpujQ6ILtk6XKw7jIORHNABTNfQHKgR2UiU2h1qUn2hxfEMR6g/BKbcNWIkhSHz5HgauUK20E3wH8QnJvKJRIEHeRGt17hxGZKyYF4l2kvJMjLE5yd5FGICJHbTzLpWfX/szikZemsGE3Tltls/wPd+x/dz9/veDOspuKT8ez2FfhnoQb53rf/IpU/nZp7x7EfzTd/ylXzqH3gJuezYX/5C7rn3Itdfdw6bYPFVIUYAlasPfqySy9kmLJVAiklhfPWQuG8mgDwI3xd5yO4BMs+j8x3BeLCoQIYKNUSeVh5HixBScApNwkxiaDcPMY8WXPF1Uc5u76uofn3B8gX+2Xf+IP/P3/8R7vrQXdAv09aK11VnZRIiIBndT6MPugDpZWe89L97Pn/lr/+vPOHjH4ulztJOsaTWstkSrVf2TULHtUulfeiRTpMKJbggMaqPRcfpyPFljJIML4Z1Aeu92xH1s9HqqhuYoFZVwtV0q5NSiTxdwhKsI2XpuobWOoR812f/wc9lN+/Ai0QjnKBwKmTcOM6ENmewQEbxP4Unl03KT94UUflUKFaEBLFC65CzClWjuVrxQzU8RRXana2DZm0CZ48wOwVVMXVRQdcQ4SidMG4Vz0N1ysPjHTJ5kUqKnzFXNF+CcURndPoc+XmhHBreekCKtEl1HzMzPqcN2qtRu1ITx7lEUQ/1eSMSxI++o9WY23H943MfTCj7mjCSGHhSS9nukjhTGlC7yYh5LQ05eRmvNAJsd5JJHkkZ+0SlMrJH3nv00NE1ri1udpiOAXRV43movsq178Z+XbDUWVPj3e++jV9/+89QLn2AtYa4AZLxd2tbV0JDO7kh0dJnPPMcr/3zX8RTn34j77nt1wJClChl5gN3fFDK6tPE6F0syTEJBavIL5iO2YxHhVShmRRoplLIecaBuuzDGzoSW0UCCIqAXOK5HtzWmNhrhJtDXxD3DTNXPQxnQGS2amBUxmutwh1Grsu9c9elO/mJn/oZ7rnjFsp6KYRPjZRV8WxjA29hns3oNmEJnvXCx/I//2+vZHrsZT70oVuiFYWzrHuynQiA753dJGGG5m2jlzpQWwjIZrVzsOE1ePB4c2KpjWraCGvQ89Lo++OiZ5JyBChGKnlDJFixEFuI3kwp0F4jX46TXYU2P2exIURZI9JAlpRX761HAy/l31IwmlQJjnYjluitbUayt0ZqTkti4CQrYJMMfRir7g1jUjvfiBxqXWk9opO+qhsiFTc/kARIAeVZce+sXd5dySmUhyQ0MYpcPiolR8ZpEwjhYCQHd/qwwR5y9c7hb9oYFMk1RpqJw4Znh6gnHWWyxndY3Afdt2jTEfTH49cej6uF2nCNGElHjdC9dyrKX2jnU97OPJD5SWBSRRVjwqXNWwBiYUcxB9garVfhCFNSni5lUyP6uEApCTwrxZSkZlOts3So3jg9vcj77n4/T3n+Ezm991FM843kfLqpjticyLuJ5J15Spw7mTiZC49/bOFZz70eP//b3PyuzG53HfM8CzQfqYC8m8kNdqWwrI0yDX1BeXeJRMNJ1vEUoNy10nqVEnvdsywCZ0vt3vAqqpsDtR9N1mgH0Fpwbi3Cb5SApw0YkXKWW9MzC3xftm2iW8qxiWT1+u6ifN55793cdW/j2S95Gr7b0y7usXyBzsSUIFmD0sklMSfjZDLmKXPuwgVuuPEcz3n+U8jnE7fefjvXnzthmmYsZcq0C/wglElq9b3CNJ8wl1k4xiydzJ0pKX/aRMU0Q+05QnwjJWcuM14G/S1U1pN6YCcKa23qvx6MDDkxHorZs5ATkcteNYm0aaIC33F4uAbwORPkBoBo5wvyGG0LL0P6zIbOo/KsnjprF/3PQESIWnHbYwMOEznATWwkXj9CUg9khNQHwtNq2rR6eFRDnHb8mGU1fUPPt74efddgnx0VafDNmdm8xjaKXAqJ+4DA+aEoZVsRJbQhJUGxGc9RQCWiod9h3Ny2HOhBpVxfMlrU6pgO1zxfYT7vf1wTRhIOeaASHNahuGWMZPlxAyfHrUiItK/sa5XXZll5xua4tQCXZzzJo1AjIlHVgsOjz4tcXm3avboZa11ptXG6Nk4DR/bEp1zPa7/xK1lrw9dOz3tymei+0Kypb4onzBrZnHkqtArZZs7vTki+kIPX7EXcuJP5HB0LTKcI+3nQA5uqu5angG9IDEBhhDyyIV4wNgpNcKl8kyN8jubrhsQPSmZL/mtSCvCrCdv0+iZDa96wopyqvAVVZJt7qM14UMIal9tKq521dy4X+PxXfyYve/lnqKeMweICZmcrUV0t7LKxS2oUdXLuhJzVs7oE15siLzHnmTSJgx3uAnOesC4WTh5CuaVEz2sZo/MhCGHIg8tmuj4dcpnDq1b6xcLoqRiYgsYpL3AA6boPFleEjeE5Q4ZO4BrZ4DZTzrSQ/Lq8LEyuJbtG4cTQvJRjLkOjJnhdiA+Xh2dRHFlNQi7ZjUbGu/Cf2CqFIEYnxej4GV5Z7xF2WxSnMHqVAEdvrtYfsQFrfdm2ueQ4x9odonncMGpoWjDauMYswTcjSXh+vl2z4+h2C423sDcBjehcrrkZu9jWpyainsHaGZ/LkdF0l+HXM9oU8MGYG6bzKEVyFUt5zRjJtTbU9dQYWnvdW1wQtlPbbn2EFa1VQVos0a1KpBxXoaU3+qL3YeIajxBH7U0DvBqc8NErx3GJQbiwb+fzBBTcT9BltQ2nVqbCEEtNlsQ1LZm1VnLJTCVhOStRX8PYR9Ho4AErHwURXqWRnI9GVHmm9lOFNrVFpzcoJZhALs8Ir0o79Cy4U0rUMBbJVXTp3qm9qe0AqrJLt3B0lQykQPDuutdwc6RX6NHTWUWdqCpWYeMukILffF2IDcgjtmhPMFptJBc7paSZUk6EXbQUFUzRHouV2DBz9NDJNFN9UzM7k0ySbj28EwZkCCOFCEkPo2A2sq7qayKvKoW3YtpQojDTcVaDlrWBFjMswPd9AJSD6eWNKO7YRmUM5xEI/KnpPtTesd5welAUh6H0OJqdQlVT/tFD6KUOjw0J2crTlFCwcmxBSSVaFBibd1fND96qVaGKgjUjhR4OuM4eaS4G/Ep+YWbdDKK78LaSKBznqfA+VtrB8MWIDMbmVSrveJRLjGPFj8PuLqYctvW+2a55rO3EpGsRSkPHx6ij0o95OFpbkYcD+iOKSdd8dbv3zuXlsuAxJnyiiieZqRRBpdxx1g1qYeFNtCYpKCvQe+AhkzymFLkdS4nmel65Iw/pMYFJe0Qjuq+aGnkqZORtJMlSK8x33xRMTM1IMDsRjCJH7+dScES7y1GpzpbIM3RrypMlCahaKDSLlywDtOXBzChppruRKPIwTOGIqsiFnJz9qhQBTAqZ0oCRxAKwORRuMinPmkwW7ZG8Q5eSt05LfG9lOoyBNMglU7rjyaTWhEEP/ves8zxJM6MlgVmCrD5DOU/y9nxWu9oI/3QPndHh0QivDuUvtZgEXgf1+hm5sxFRjCqqh0oQyBdRqkLNxLDw0LbS1D7eK2+6RV6Z1sgBLWseXThdH5bG9/WRtpC3r9DZkehueFM9uO7msg7yBdW6VrV4CUd7284NYOmX1HPdZbxTvOawgA85PbNOtzWCxeHBCaMpjz/ecexdVaVb5EmOKi8EFys+o4NXnZePPtYhdju86Vgl1sMTRkZrzONjAwlhNOP3Ye+u8ESP/rZlOEeHw0NJAqjBFw8nqnYGFloIhUN4LeM/OodGbtNdaYuRb/dY+48EIwnieyrp69GgqIAbS+RMhD4xvKtfLoCRYxKG0CeD4hUMhqSCjHuPqxFsCRVXycEQUWifNgZOivznaONpKGeZArqgsCwdKpI54XlSniiUb4Z3IV6wDGcqWTuu69hTN6Y8IVyhej1bTtTaQtKtsda98KIUVFVFFVEzxswrWR3ngngBCLeXXKmHZFLfTjb4rIQuZuhNYpjnEP8wypTJnIuqaVSc3cgB9lVOLpPtXHj8o6ufxCcgQrstvImfzSII/gGjMOdR+ax0u5M2pOySKuDJZVpqeAPaHyOkS+MTA/Y5Ol9ZlSnyeEmsQKVXlOdr3oOiZ2KB9Eo2l9hFbIhYcOSJc9F/CO4dDancGXz+tPlfQfsMPOzIOQ4zbT08tUh3qCXCcM38KIw8XryjiJFj4YcSfGwxRFis14yN8oCr3HJ7Iyzefj+o+uv8hlen0XwoCBH3W7nBYWiwo3D7KFd5xbAIdOM4ut3Hm9yso2/fbcZRmB73rY9Nw7A0CrzH53L0vb1tj7c0XRznKEoeqAEPPK4JIznc83GS1RFUowUx3bTXpeFjhBepu6Y8YDKZkZKTwLWupDe4ONYYbRE/tVgi90GiQuKbllQ8MnmIwhsKB5hi4nRTr+XRrpMWWMEuDFtvjTlPpJI3GM2EoCIWFCjxdit056RMpGysdWHeFdw7a10HygGQVBnUYCjIC8ulkPLYNWFGecjWjVTk9SYymMDyUzkh5524zCEIawijlK2QUY6w+9BLdHKXR+gRkttm4WQlxkSHEFogjFF43KNxlXxCDp5cJO99iPkGODgg6HpPgO0ljirh3+F/jXuvdTKSFHrcXb4iLIowDDqJ1I4A2IA16Yf2HhhEd4imVZ0msQciTUAKIHIaZ7+N0WWweSdTyZEMIrxLD0/SN8M+wsFDWDpqymFp2ILESBdcMYwww9Hygb5tlGbDeg9/bLhgozgUxiOM8riHR6twO66D2lb4YUN/sx+MDe7BYx/34+j58UFHV8zGBu5jAxgFn3Ettz9rK3C2uSMFcbRhDnk2PKKEbQs6nOM4l+2URzmJLQoc5J2h9HWFcb3PuCaMpLCBKvELAlFiJx+5SRkVuVF5C2kiYCJlw6JxUu+V3ittQDFSouRJkmo4PpLClrcEcu+afGaSzuq4aFDBZNgwZDbwaxknU2ZNJjUfAywL4L41EBZez5K6E54EpKf7qN6r09tUdmwSYzgRHdBn5UYtO7vdeZJN5LQDjhY8xpV6eIImHcObRiirfGIJ47LC1uNaO6qEN+K1KVgTfuVianKDN+1D9ZGpYHWT3ULB5uZ1AZtnhI3dPULsYCQpz9VjjSs6MMvyLhmBsngi+JFxDNUbnYP46s0FC1LWQkZY3lVUj81DfELXLSVJzNEF7Nb5ZryHao5ihCvmbAroi1BVsSK7qtqOUVNUtsddcfGXCSTBMHIe59OjSDQMhzP0KkdaYYSFh/DbXLRW2cLhMguWM7yv5sNEcIVRctgYNrUfzi1ZlJOGyLV3WoLctI15UzpCWEgdVxqi2Ibu/ZH3Ojzc1KOYhV6XQwzEwhVswFAEEbzHSXFduw2qIeGBEoUrma9DJX1c7+FARRRoKnyRlGuXJ8mRgf1dMpLR4+bNwK3u/ioz+zjg+4DHAm8B/kd3X0z9t78H+DTgQ8CXuvtvXvWzMUrabb9r4kZO0V0iCHYc7qQQFT1UysycKSeMidoT3aewqxJn8JCI0s6e6WbR/pIIy2swXQ4ek8OBfmUHfmgxgdo9sG4lTwrvHSYs2DsyFslRUSKpAFEs5O0hlFty7PTD8B12ZxVZVjx1is1KVGO0bRlBxJBXGE0XIGULr7CKs4bas0JiLeHGFhYyMahdMZ/Y7FWIOwwGijaEuB8+cj4KQFOwoBIovxbHuME3XMwKAZyDbsdRNbSJymmphoc4QtaOWwttBduukvo0y3CPXFlrq5SeCBjVkdd0MBO6dL2PirVvepzeLYyLsLa2eS+H0QaQeYTxpuvicQd75+AtO6LIhZGEMPo+Fv8oZihqGlHECJUdQpvxdy7kIYRPM6yzQXMGLrS5Wrxqnid5iZhylz420HEPRoRgh8JNeIw9qJ49Hh+H1G5Hc43wVGP+paTza6ZNtwXcR5oFLkcIP/LodCwbDpNh8AWp7ePOu0FOHKcSBtyPuNNXDjukUOLYNNFTnPvvjif5WuBXgOvj8d8CvtXdv8/M/hHwlcA/jH/vcPdPMLPXxOu+9GofbGbM03zFwRsGCVoNfZGxM8WkMQRt2Yyk5xAnMJJNmLWDK9+dHn26ZfBUrc7pRMY3hZRYNoW14RFNuZBsOjKSOfiwutiZGbMShYcQELPg9WIoZTZEeHXU6eheGBJGGDJYcbQ0IhSM3GqPEHbImvW0xit7eOBg2+dFKLKFP7LXFrqBMiM9JnIUYNT9JTzgFKFr2wzbgGeN/Fsc/PEd1Hyjk0w+YkeZri3EZKQtZMpUW4/eQkfwDScxOOkhb44HntCtRWfTzZJgHpx1nGYBzelS3h79eip9CyUZtwIO6a8t1JNBPooMY7Mb+MXDG4e4ymZ8N46+VLXl8Y6X+/Y7wyvcqrhHwaBHZXxU6lsIHRNGUpY30jFhbCOnS4SvnmJLGkYuuoTalq904WjHbfTDjbQIsbuHkbQrQ2vvnfF1x5CfcY66llo7x97ouMBtoEhwtf4gNo/tChyMlY3r7H27YQPWNA5+eKwQOXZnu6ZDwR58Q6yM+GXzJMd3X8VAwkM0kmb2NOALgL8B/DnTkb0M+LJ4yXcDfxUZyS+M3wF+CPj7ZmZ+lSMZyfRtOcWaKaWEpZdRHJUzd8hlR+uZkma1eKVtPTU2CkRKpDyHrqOqz6q0zqRgSpgd+glnCsl2qHrcKTRymnAf6tqavJU6/BhcJjX247SxOqLDBniJWkIou1zh1tuWazsMEfRVyR6GI6qLnrbPgsOiTUf5VYHoR14LGYVmGx1t0MUE1Tl4bd5G9Z6Y5IcFsjWg3zYwwBJ9Y1Ek8BL9n32AasSL3XKBElpV0WtweFcJTbSotIf3rL/FtW0ggVSF9cmj1W1slkQLhma+oRc2VaMtbzEWmY6lI6hM7y6PNh28i9G2IN6g50JHczNqw6DLDQ1XUdAlXRdFEWMncffYPAKE5IPBFLCzrT9N4jhM9MgDDgMztCy3/Or4Gda+H6TC4osZbVPHGJjCrbMjglm5j3A5cinJYzsdHn4Y9WxXTmHfgvmYq7alMQi4EogdY64QOqJ8GastJhie6PBOZajHpDxORVyx+VxxHLHBR3F1XBePN3kUGVsTqsCCycTR8d/feKie5N8Bvg54VDx+LHCnuw867y3AU+P3pwLvjZOoZnZXvP6Dxx9oZl8FfBXAk576eCmY+JjIgsykVDArylOO8DfyeL0beGKaTiQU4OLWbiFjhH1jgQ9K4hbOg/IdJLn83unWwZbNg+iR2wLdNDVj0g5rFkGtQ3JhubZEe6iQKGc6MQoLbLtcqOU4uNVNV88scImunjXmIaFlQ3A4WgWw6nFglzw2hOYSgGWAkzkKK0zTvccfcotrHbJ0a5e+38iVTpQDDayrL/foO6JzHMYxvLy+YF6J3lM6qM2wxFvirfWoiDJcueFRDVB7Mk32FKH2yDu1LiaK2wDAy0txbINoKWR1AbujkLEZChcgfxi7FoiF4WWMIUktHXVkQrf3NTvAZ4YflOjRXE55Q3M16To4kIHAjPeMuaDFPcLFthmBcSqHY47N68gIjE30EMIThvfgWRICMO767DQ2uz6KISNPDAePmSO6IXQLLQSTFoIdnENdq5FnNccTdF9JHvRZ19WEaAedTG1Bxgwdc9j7lhM/zIc4Jx8pgU61cO6bUg0eWqaWkgz7hggwGJHP8G575NytHObO4Q7xQONBjaSZvQp4v7u/xcw+98Fe/1CHu3878O0An/Spz/brrnvUZsTMzzGlmZxmLKnyepgPw40PDzBc6YPrrNckoogTF+w4ab19Di72QGvgTS1QSbFoBGDeMpQjYhq7UngBCYmZapcd9DWp0qhFbkVktAGST1tyfMAZhmfQAoaiPFqHdAC3p64qrDffSgmGIBC9Nloetf8jQPNx/iVCsE3mdHhSgdRft55CQwbfA8Qd+3wIfhzLdHk7Ag1H+Dni1O5tW3BbrBu4NUAKSR7kABvbluOEmo8Z3py1C3EwaHYpPDRxvcOYWeAVuzyT7MSCi3ahFvm2ONY0aHeODEyKADhCSh2QhB66meZIb5sX1DYu8GZ5ozp72ERsCyEP10bwtSNPkGHQ9Z50xQw9hNRb9dU8OPejoKYPtyNj3MNojPdbtoh2jlIIQfsbYfvBO/a4toeNDZDGpY3oJJAHx8eJjO52rj5yh/qS4RUP2BSBXb4CksMhn3pfj32cJd1VJIrc6HCcYpth9LfajOR9DKAhZ2F4sb4Z8auPh+JJfhbwajN7JXCCcpLfBtxgZiW8yacBt8brbwWeDtxiAs49GhVwHnAkK5ybbgDYwq2UxCJxr9oB4rU9OKAWjac0IRxKTER9iEKbeGwhi3XsUnskkVuENIbLawx8tdqsTlEcjZsY7xxGOoWuYxviCU1h4BAN9siXDTbOuHm9m/B53uSJhZ3xYGR0tCv3FB4cTm6u/s6A2xw+lyau+aAwqpppHqHM5oGMlXhYTqrD1YMaChDuMO6qeNaABJkjD3YYPeKauB9VMqM7ID1gMeoTNC75cU5sPJb8VoSYY/PPvrEheg/P2Niak+WjzXBUU4eQQfcAOI+cXlc+swUZ4WDg21E+0elZV2DLUzmIGhge3SgQ+giPtVAP13Ucx8GwMbCFw/i66LB60YhojqekkjRXbuXxCZsrrkU+UhE6fIW1I7y/Aup0XAzZjiugTdu1gG0CjvMdBan47j7yw5HL7n5gwXQj+psfPsC9h/edYp4FjIe4DiCBmeHxesC3IhS+77AIvc1dDIneoxqu89qOMY732OgPp0nUz86mRT6KZkdpkQcaD2ok3f11wOviYD8X+Fp3/3Iz+0Hgi1GF+08A/zLe8qPx+E3x95++Wj4yvoR1WbbdpXGJ3uQWK8/HFp6MXJlSlUO4M0lt+ii0q/34IhrWO3aYC3REz9P0il68qQXVKjJ80Q1uo2GNyxkUtxTSWi08GXNRK1sbHoDe0RsRokdeMOhvZqEWfXxcGyi3yptJ4TmHFFo3KL5sRqG7M8fiaGG4Dsl136bA5tEdjWNJKinRHFG7LHb/KgHfblypvSc7tHnokQyRh4yW7aZvmEbPovH+OF4EkfKjz1TxO7yEFhsXo5lU/NYPi8lDGo8t/A5jZB08M5SktvxtSoKU2JGhidAyHUdfm/EbGedDyG646JYcjMlxa2D3ARsLYx7GbBiMg2cTC1w71BEQ/cqxGV6zCD2PNFStKwQ23xSExjFsx7IZ5XFcoQ0QxvvYSA7DeSgMuVrabj7bwaQ0G/uq5mjiOOIa567v7GKHHnmNfQv7xykfg+ePmTsDRZC20IQI2e/rCR+M5JC886NzsQ2jy3Zfjvz9BxwfCU7yLwDfZ2bfDPwi8B3x/HcA/9TM3gn8NvCaB/sgd6ev+y1sal1CZym14CKrsNPHTdFVhq58IA7retg1dFEGPzdCz1HIAE0sCwxZeD9mGXOiQVQEPn14PiOMHEZBE01ANRheiDIBtoW7cdsYc2wsje4hEmAekJkwTIRPFBMnmYdgRhQUIofYo8rdJO9DTwclpOTQ0ggdw7ANZwI2L81cOLnRcK0RUvaIlqgR4qmm/OqImg9z6pBbqhEwdzfExlG/oeFlYkbtK7hYLVvI5uH1H93XWJ4Mytm2MAy62j9uwhLuNSrhA7Yizy9F6O1b+D9ogn6o3DJc1kifEO1X49xDYYVEVWhmoodKWHwUJ8YCVfrHOdo4ogBicZ5jDmze9HYvRnFhLObwsOBQoLKxx0Qf7aQNhgDfJ5MYhBkhqntI5RCG2OLmubcopAekZ9uAxjWN943Hm4E7FIw2KLAN7GnMB2dTAReYXoZORsvZ0ipJm6BH6iDFeSc/uj5mV/w4BNf6YDg3Ezeippif2YzDkvdQ6495AkHjHUb1yEu5n/FhGUl3/xngZ+L3XwdefD+vOQW+5MP8XPbrInPkymeBU7KHhl14CMkCChMXPaS8cN+AuypGJNzr5gNszb0sxSQ+LJANPjMmqWsS9aOwYvt0H3txuiLvMkzcMJA9GsFXeuTNBKYdQr+Oh1GIMMI4mpixGzsbBKP3fsWk9+j0JhVutX5Ndnh/azVgHodj2/4fBqcwWCujkho7P8PbHUWGjQe5vU7D2JS0ZY6idq/FlUEbTywq8aTl12bTgmtYbARsPpTFhfYo1lyZl4JWQ118LGY9OqQB0P1PkW91NdFGOWb1XzkGeXtcOw9jntLonyTaprvKbyNVsoHYt+sxNreDMYOYoz7ydIa5yXiMvx/d5xHd+sbq6dv5jmjBtysdVNwNgxlzwX3DLx7T/UYENryywTi5YmxoA982+DYgaCmNugubPxoLZnyLb9chzO2RV3d8ncfJuyM5vthIt8q5BYRppLmPcrLqr2OH67l971gsw0vmiv+P+8PwImN+Hv7efgec6b7jmmDcOILtDl6rbzu0wt9R8WLkQroMhHbgtN0UCGPjvm3TiRTd22K7i4Q8w4uwwzGM4sAII68wknIKJCARIUkLybIhCV9GFb41au86pymFOtDYVeuRMVIoejypD57qMGzqdVJrZXS5o+Rtc8BCQy+2zd4FKRqFJzsybpsYA8CoWPrBt+nb5BZYeptuh8PR32MHT57Bc+zoLZL747IOr4ODMTZtMDagQRE6jvD1EPqM7z3yGo7ny1FIlhhejW+LxsMjkfcdi997QJaM+3wccFBq73JADtfTBdJymVtECpQXxNH3lfjM4RFveeUwcAkoYz2PTfKw8+owt5BDxzswfUN5SB7V8KzjXDxtOc/eO32t92sIj6/hFQZhM0RaU1uDtKNwe1skDzCGNzbKWcMwj7/dX0isbWtzb5U35mDUtAVfeaz3nQcPdCzDHpiPTfswZx/kVO532IOlC38/hpndA9z8cB/H7/J4HPeBPX0UjI+2c/poOx84O6ePZHysuz/+vk9eE54kcLO7f/rDfRC/m8PM3nx2Ttf2+Gg7Hzg7p9+LcT8JirNxNs7G2TgbY5wZybNxNs7G2bjKuFaM5Lc/3AfwezDOzunaHx9t5wNn5/S7Pq6Jws3ZOBtn42xcq+Na8STPxtk4G2fjmhwPu5E0s1eY2c1m9k4z+4sP9/E81GFm32lm7zeztx899xgz+0kze0f8e2M8b2b2d+Mc32Zmn/rwHfn9DzN7upm90cz+i5n9spm9Np5/JJ/TiZn9RzP7pTinvxbPf5yZ/UIc+/eb2RzP7+LxO+Pvz3hYT+ABhpllM/tFM3tDPH6kn89vmtl/NrObzOzN8dw1M+8eViNpIrP+A+DzgecBf8zMnvdwHtOHMf4J8Ir7PPcXgZ9y92cBPxWPQef3rPj5KqS7ea2NCvzv7v484DOAr4578Ug+pz3wMnd/IfAi4BVm9hkcBKM/AbgDCUXDkWA08K3xumtxvBYJYI/xSD8fgD/o7i86gvpcO/PuvtJEv58/wGcCP3H0+HXA6x7OY/owj/8ZwNuPHt8MPDl+fzLCfwL8Y+CP3d/rrtUfJFjyhz5azgk4D7wVeAkCJpd4fpuDwE8Anxm/l3idPdzHfp/zeBoyGi8D3oA4JI/Y84lj+03gcfd57pqZdw93uL0J9MY4Fu99JI4nuvtt8ftvAU+M3x9R5xlh2acAv8Aj/JwiNL0JeD/wk8C7eIiC0cBdSDD6Whp/BwlgD1WGhyyAzbV5PiDG4L82s7eYxLjhGpp31wrj5qNuuLvbJh39yBlmdh3ww8Cfdfe778P5fcSdk0ud+UVmdgPwI8BzH94j+q8f9nskgH0NjJe6+61m9gTgJ83sV4//+HDPu4fbkxwCvWMci/c+EsftZvZkgPj3/fH8I+I8zWxCBvKfufu/iKcf0ec0hrvfCbwRhaM3mMRK4f4Fo7GHKBj9+zyGAPZvIh3Xl3EkgB2veSSdDwDufmv8+360kb2Ya2jePdxG8j8Bz4rq3Iy0J3/0YT6mj2QMwWH4nULEfzwqc58B3HUUSlwTw+QyfgfwK+7+t4/+9Eg+p8eHB4mZnUM51l9BxvKL42X3Padxrg9NMPr3cbj769z9ae7+DLRWftrdv5xH6PkAmNkFM3vU+B14OfB2rqV5dw0kbV8J/BrKFf3lh/t4Pozj/ufAbcCK8iJfifI9PwW8A/g3wGPitYaq+O8C/jPw6Q/38d/P+bwU5YbeBtwUP698hJ/TJyNB6LehhfcN8fzHA/8ReCfwg8Aunj+Jx++Mv3/8w30OVzm3zwXe8Eg/nzj2X4qfXx424Fqad2eMm7NxNs7G2bjKeLjD7bNxNs7G2bimx5mRPBtn42ycjauMMyN5Ns7G2TgbVxlnRvJsnI2zcTauMs6M5Nk4G2fjbFxlnBnJs3E2zsbZuMo4M5Jn42ycjbNxlXFmJM/G2TgbZ+Mq4/8HG05B9x7FfCkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "IMG_PATH = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(IMG_PATH)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfb7ea00",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[0], expected a dimension of 1, got 64 [Op:Squeeze]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3478/552700347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mIMG_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdraw_keypoints_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdraw_skeleton_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3478/428616262.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mkp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_keypoints_from_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msqueeze_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   4535\u001b[0m   \"\"\"\n\u001b[1;32m   4536\u001b[0m   \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name, squeeze_dims)\u001b[0m\n\u001b[1;32m   4483\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4484\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4485\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m  10180\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10182\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10183\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10184\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[0], expected a dimension of 1, got 64 [Op:Squeeze]"
     ]
    }
   ],
   "source": [
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "IMG_PATH = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(IMG_PATH)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d860b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
